trial	group	subject	repetition	x	y	random
training	oneLayer	oneLayer - rat 1	0	0.009471097	-0.34607694	false
training	oneLayer	oneLayer - rat 1	0	0.016664844	-0.3388832	false
training	oneLayer	oneLayer - rat 1	0	0.02083464	-0.3288164	false
training	oneLayer	oneLayer - rat 1	0	0.02083464	-0.3187998	false
training	oneLayer	oneLayer - rat 1	0	0.01698766	-0.30951238	false
training	oneLayer	oneLayer - rat 1	0	0.009614987	-0.3021397	false
training	oneLayer	oneLayer - rat 1	0	0.0019414177	-0.29446614	false
training	oneLayer	oneLayer - rat 1	0	-0.0051576965	-0.28736702	false
training	oneLayer	oneLayer - rat 1	0	-0.012289358	-0.28023538	false
training	oneLayer	oneLayer - rat 1	0	-0.019362815	-0.27316192	false
training	oneLayer	oneLayer - rat 1	0	-0.026992518	-0.2655322	false
training	oneLayer	oneLayer - rat 1	0	-0.034137715	-0.258387	false
training	oneLayer	oneLayer - rat 1	0	-0.041783392	-0.25074133	false
training	oneLayer	oneLayer - rat 1	0	-0.049343016	-0.24318172	false
training	oneLayer	oneLayer - rat 1	0	-0.056488287	-0.23603645	false
training	oneLayer	oneLayer - rat 1	0	-0.064175114	-0.22834961	false
training	oneLayer	oneLayer - rat 1	0	-0.071659684	-0.22086506	false
training	oneLayer	oneLayer - rat 1	0	-0.07931323	-0.2132115	false
training	oneLayer	oneLayer - rat 1	0	-0.08641913	-0.2061056	false
training	oneLayer	oneLayer - rat 1	0	-0.093935415	-0.19858932	false
training	oneLayer	oneLayer - rat 1	0	-0.1017084	-0.19081634	false
training	oneLayer	oneLayer - rat 1	0	-0.109404236	-0.1831205	false
training	oneLayer	oneLayer - rat 1	0	-0.11679884	-0.1757259	false
training	oneLayer	oneLayer - rat 1	0	-0.12404388	-0.16848086	false
training	oneLayer	oneLayer - rat 1	0	-0.13135749	-0.16116725	false
training	oneLayer	oneLayer - rat 1	0	-0.13903882	-0.15348592	false
training	oneLayer	oneLayer - rat 1	0	-0.14664954	-0.1458752	false
training	oneLayer	oneLayer - rat 1	0	-0.15392636	-0.13859838	false
training	oneLayer	oneLayer - rat 1	0	-0.16162948	-0.13089526	false
training	oneLayer	oneLayer - rat 1	0	-0.16905582	-0.12346892	false
training	oneLayer	oneLayer - rat 1	0	-0.17677481	-0.11574993	false
training	oneLayer	oneLayer - rat 1	0	-0.18394645	-0.1085783	false
training	oneLayer	oneLayer - rat 1	0	-0.19356768	-0.10459306	false
training	oneLayer	oneLayer - rat 1	0	-0.20354404	-0.100460716	false
training	oneLayer	oneLayer - rat 1	0	-0.21329834	-0.096420355	false
training	oneLayer	oneLayer - rat 1	0	-0.22274747	-0.092506394	false
training	oneLayer	oneLayer - rat 1	0	-0.23282708	-0.08833128	false
training	oneLayer	oneLayer - rat 1	0	-0.24260637	-0.084280565	false
training	oneLayer	oneLayer - rat 1	0	-0.25259194	-0.08014442	false
training	oneLayer	oneLayer - rat 1	0	-0.26224428	-0.076146275	false
training	oneLayer	oneLayer - rat 1	0	-0.2722746	-0.071991585	false
training	oneLayer	oneLayer - rat 1	0	-0.28157085	-0.06814096	false
training	oneLayer	oneLayer - rat 1	0	-0.2908674	-0.06429021	false
training	oneLayer	oneLayer - rat 1	0	-0.3005334	-0.06028641	false
training	oneLayer	oneLayer - rat 1	0	-0.31025672	-0.056258887	false
training	oneLayer	oneLayer - rat 1	0	-0.31957254	-0.052400146	false
training	oneLayer	oneLayer - rat 1	0	-0.32895067	-0.048515603	false
training	oneLayer	oneLayer - rat 1	0	-0.33910173	-0.044310898	false
training	oneLayer	oneLayer - rat 1	0	-0.34902668	-0.04019985	false
training	oneLayer	oneLayer - rat 1	0	-0.35830456	-0.036356825	false
training	oneLayer	oneLayer - rat 1	0	-0.36796057	-0.03235718	false
training	oneLayer	oneLayer - rat 1	0	-0.37733164	-0.028475542	false
training	oneLayer	oneLayer - rat 1	0	-0.38690504	-0.024510114	false
training	oneLayer	oneLayer - rat 1	0	-0.39675933	-0.020428337	false
training	oneLayer	oneLayer - rat 1	0	-0.40647906	-0.016402295	false
training	oneLayer	oneLayer - rat 1	0	-0.41381446	-0.009066887	false
training	oneLayer	oneLayer - rat 1	0	-0.41794342	9.012859E-4	false
training	oneLayer	oneLayer - rat 1	0	-0.41794342	0.011329207	false
training	oneLayer	oneLayer - rat 1	0	-0.41794342	0.021884685	false
training	oneLayer	oneLayer - rat 1	0	-0.41794342	0.032686014	false
training	oneLayer	oneLayer - rat 1	0	-0.41794342	0.042774253	false
training	oneLayer	oneLayer - rat 1	0	-0.41794342	0.05295705	false
training	oneLayer	oneLayer - rat 1	0	-0.41794342	0.063547745	false
training	oneLayer	oneLayer - rat 1	0	-0.41794342	0.07408241	false
training	oneLayer	oneLayer - rat 1	0	-0.41794342	0.084328495	false
training	oneLayer	oneLayer - rat 1	0	-0.41380855	0.09431097	false
training	oneLayer	oneLayer - rat 1	0	-0.40968817	0.10425844	false
training	oneLayer	oneLayer - rat 1	0	-0.40555102	0.11424638	false
training	oneLayer	oneLayer - rat 1	0	-0.40162262	0.1237304	false
training	oneLayer	oneLayer - rat 1	0	-0.3974722	0.1337504	false
training	oneLayer	oneLayer - rat 1	0	-0.3932881	0.1438517	false
training	oneLayer	oneLayer - rat 1	0	-0.3894596	0.15309449	false
training	oneLayer	oneLayer - rat 1	0	-0.38530627	0.16312155	false
training	oneLayer	oneLayer - rat 1	0	-0.38113105	0.17320143	false
training	oneLayer	oneLayer - rat 1	0	-0.37716225	0.18278296	false
training	oneLayer	oneLayer - rat 1	0	-0.37318578	0.19238304	false
training	oneLayer	oneLayer - rat 1	0	-0.36919925	0.20200738	false
training	oneLayer	oneLayer - rat 1	0	-0.36503986	0.21204904	false
training	oneLayer	oneLayer - rat 1	0	-0.3610587	0.22166036	false
training	oneLayer	oneLayer - rat 1	0	-0.3572125	0.23094593	false
training	oneLayer	oneLayer - rat 1	0	-0.35323882	0.24053922	false
training	oneLayer	oneLayer - rat 1	0	-0.3491124	0.2505013	false
training	oneLayer	oneLayer - rat 1	0	-0.34520978	0.25992304	false
training	oneLayer	oneLayer - rat 1	0	-0.34118477	0.26964033	false
training	oneLayer	oneLayer - rat 1	0	-0.33714405	0.2793955	false
training	oneLayer	oneLayer - rat 1	0	-0.3294638	0.2870757	false
training	oneLayer	oneLayer - rat 1	0	-0.31971425	0.29111412	false
training	oneLayer	oneLayer - rat 1	0	-0.3096443	0.29111412	false
training	oneLayer	oneLayer - rat 1	0	-0.299633	0.28696728	false
training	oneLayer	oneLayer - rat 1	0	-0.2920136	0.2793479	false
training	oneLayer	oneLayer - rat 1	0	-0.28808206	0.26985633	false
training	oneLayer	oneLayer - rat 1	0	-0.28808206	0.2596898	false
training	oneLayer	oneLayer - rat 1	0	-0.29218638	0.24978112	false
training	oneLayer	oneLayer - rat 1	0	-0.29612482	0.2402729	false
training	oneLayer	oneLayer - rat 1	0	-0.30021766	0.23039186	false
training	oneLayer	oneLayer - rat 1	0	-0.3042941	0.22055045	false
training	oneLayer	oneLayer - rat 1	0	-0.30824918	0.21100207	false
training	oneLayer	oneLayer - rat 1	0	-0.3121396	0.20160979	false
training	oneLayer	oneLayer - rat 1	0	-0.31597766	0.19234389	false
training	oneLayer	oneLayer - rat 1	0	-0.32002366	0.182576	false
training	oneLayer	oneLayer - rat 1	0	-0.3241148	0.17269906	false
training	oneLayer	oneLayer - rat 1	0	-0.32805732	0.16318099	false
training	oneLayer	oneLayer - rat 1	0	-0.33201462	0.1536272	false
training	oneLayer	oneLayer - rat 1	0	-0.33588812	0.14427583	false
training	oneLayer	oneLayer - rat 1	0	-0.33984065	0.13473353	false
training	oneLayer	oneLayer - rat 1	0	-0.34368023	0.12546395	false
training	oneLayer	oneLayer - rat 1	0	-0.3475218	0.116189554	false
training	oneLayer	oneLayer - rat 1	0	-0.35172355	0.1060457	false
training	oneLayer	oneLayer - rat 1	0	-0.3558236	0.09614727	false
training	oneLayer	oneLayer - rat 1	0	-0.35987073	0.08637663	false
training	oneLayer	oneLayer - rat 1	0	-0.36753762	0.078709744	false
training	oneLayer	oneLayer - rat 1	0	-0.37483647	0.071410894	false
training	oneLayer	oneLayer - rat 1	0	-0.38213247	0.06411488	false
training	oneLayer	oneLayer - rat 1	0	-0.38942227	0.056825105	false
training	oneLayer	oneLayer - rat 1	0	-0.39661643	0.049630955	false
training	oneLayer	oneLayer - rat 1	0	-0.40432647	0.041920904	false
training	oneLayer	oneLayer - rat 1	0	-0.41170627	0.034541104	false
training	oneLayer	oneLayer - rat 1	0	-0.4189703	0.027277103	false
training	oneLayer	oneLayer - rat 1	0	-0.42308512	0.017342947	false
training	oneLayer	oneLayer - rat 1	0	-0.42308512	0.0068516936	false
training	oneLayer	oneLayer - rat 1	0	-0.41908577	-0.0028036295	false
training	oneLayer	oneLayer - rat 1	0	-0.41201192	-0.009877474	false
training	oneLayer	oneLayer - rat 1	0	-0.4026915	-0.01373811	false
training	oneLayer	oneLayer - rat 1	0	-0.3917249	-0.01373811	false
training	oneLayer	oneLayer - rat 1	0	-0.3809747	-0.01373811	false
training	oneLayer	oneLayer - rat 1	0	-0.37071466	-0.01373811	false
training	oneLayer	oneLayer - rat 1	0	-0.3598252	-0.01373811	false
training	oneLayer	oneLayer - rat 1	0	-0.3495877	-0.01373811	false
training	oneLayer	oneLayer - rat 1	0	-0.3390432	-0.01373811	false
training	oneLayer	oneLayer - rat 1	0	-0.32899162	-0.01373811	false
training	oneLayer	oneLayer - rat 1	0	-0.3189204	-0.01373811	false
training	oneLayer	oneLayer - rat 1	0	-0.30794296	-0.01373811	false
training	oneLayer	oneLayer - rat 1	0	-0.29751697	-0.01373811	false
training	oneLayer	oneLayer - rat 1	0	-0.28665975	-0.01373811	false
training	oneLayer	oneLayer - rat 1	0	-0.27594766	-0.01373811	false
training	oneLayer	oneLayer - rat 1	0	-0.26591042	-0.01373811	false
training	oneLayer	oneLayer - rat 1	0	-0.25544468	-0.01373811	false
training	oneLayer	oneLayer - rat 1	0	-0.24513726	-0.01373811	false
training	oneLayer	oneLayer - rat 1	0	-0.23501174	-0.01373811	false
training	oneLayer	oneLayer - rat 1	0	-0.2244038	-0.01373811	false
training	oneLayer	oneLayer - rat 1	0	-0.21377786	-0.01373811	false
training	oneLayer	oneLayer - rat 1	0	-0.20323902	-0.01373811	false
training	oneLayer	oneLayer - rat 1	0	-0.19322485	-0.01373811	false
training	oneLayer	oneLayer - rat 1	0	-0.1828256	-0.01373811	false
training	oneLayer	oneLayer - rat 1	0	-0.17201474	-0.01373811	false
training	oneLayer	oneLayer - rat 1	0	-0.16107789	-0.01373811	false
training	oneLayer	oneLayer - rat 1	0	-0.15098782	-0.01373811	false
training	oneLayer	oneLayer - rat 1	0	-0.14000656	-0.01373811	false
training	oneLayer	oneLayer - rat 1	0	-0.12980449	-0.01373811	false
training	oneLayer	oneLayer - rat 1	0	-0.118926816	-0.01373811	false
training	oneLayer	oneLayer - rat 1	0	-0.10865367	-0.01373811	false
training	oneLayer	oneLayer - rat 1	0	-0.09834386	-0.01373811	false
training	oneLayer	oneLayer - rat 1	0	-0.08771555	-0.01373811	false
training	oneLayer	oneLayer - rat 1	0	-0.07689688	-0.01373811	false
training	oneLayer	oneLayer - rat 1	0	-0.06665007	-0.01373811	false
training	oneLayer	oneLayer - rat 1	0	-0.05629024	-0.01373811	false
training	oneLayer	oneLayer - rat 1	0	-0.04581829	-0.01373811	false
training	oneLayer	oneLayer - rat 1	0	-0.034837727	-0.01373811	false
training	oneLayer	oneLayer - rat 1	0	-0.024224367	-0.01373811	false
training	oneLayer	oneLayer - rat 1	0	-0.014041457	-0.01373811	false
training	oneLayer	oneLayer - rat 1	0	-0.0035511795	-0.01373811	false
training	oneLayer	oneLayer - rat 1	0	0.007357721	-0.01373811	false
training	oneLayer	oneLayer - rat 1	0	0.017419605	-0.01373811	false
training	oneLayer	oneLayer - rat 1	0	0.028026212	-0.01373811	false
training	oneLayer	oneLayer - rat 1	0	0.03821523	-0.01373811	false
training	oneLayer	oneLayer - rat 1	0	0.04917369	-0.01373811	false
training	oneLayer	oneLayer - rat 1	0	0.059185363	-0.01373811	false
training	oneLayer	oneLayer - rat 1	0	0.07002242	-0.01373811	false
training	oneLayer	oneLayer - rat 1	0	0.08040215	-0.01373811	false
training	oneLayer	oneLayer - rat 1	0	0.091216445	-0.01373811	false
training	oneLayer	oneLayer - rat 1	0	0.10208113	-0.01373811	false
training	oneLayer	oneLayer - rat 1	0	0.112875104	-0.01373811	false
training	oneLayer	oneLayer - rat 1	0	0.12301373	-0.01373811	false
training	oneLayer	oneLayer - rat 1	0	0.13338254	-0.01373811	false
training	oneLayer	oneLayer - rat 1	0	0.14338428	-0.01373811	false
training	oneLayer	oneLayer - rat 1	0	0.15400662	-0.01373811	false
training	oneLayer	oneLayer - rat 1	0	0.16460474	-0.01373811	false
training	oneLayer	oneLayer - rat 1	0	0.17492828	-0.01373811	false
training	oneLayer	oneLayer - rat 1	0	0.1853012	-0.01373811	false
training	oneLayer	oneLayer - rat 1	0	0.19618368	-0.01373811	false
training	oneLayer	oneLayer - rat 1	0	0.20629913	-0.01373811	false
training	oneLayer	oneLayer - rat 1	0	0.2172669	-0.01373811	false
training	oneLayer	oneLayer - rat 1	0	0.22805978	-0.01373811	false
training	oneLayer	oneLayer - rat 1	0	0.23825938	-0.01373811	false
training	oneLayer	oneLayer - rat 1	0	0.24875854	-0.01373811	false
training	oneLayer	oneLayer - rat 1	0	0.25948527	-0.01373811	false
training	oneLayer	oneLayer - rat 1	0	0.26994514	-0.01373811	false
training	oneLayer	oneLayer - rat 1	0	0.28075537	-0.01373811	false
training	oneLayer	oneLayer - rat 1	0	0.29140428	-0.01373811	false
training	oneLayer	oneLayer - rat 1	0	0.3015917	-0.01373811	false
training	oneLayer	oneLayer - rat 1	0	0.31183454	-0.01373811	false
training	oneLayer	oneLayer - rat 1	0	0.32200453	-0.01373811	false
training	oneLayer	oneLayer - rat 1	0	0.3320671	-0.01373811	false
training	oneLayer	oneLayer - rat 1	0	0.34279925	-0.01373811	false
training	oneLayer	oneLayer - rat 1	0	0.35302097	-0.01373811	false
training	oneLayer	oneLayer - rat 1	0	0.36319774	-0.01373811	false
training	oneLayer	oneLayer - rat 1	0	0.37336704	-0.01373811	false
training	oneLayer	oneLayer - rat 1	0	0.38370672	-0.01373811	false
training	oneLayer	oneLayer - rat 1	0	0.39426273	-0.01373811	false
training	oneLayer	oneLayer - rat 1	0	0.4047863	-0.01373811	false
training	oneLayer	oneLayer - rat 1	0	0.41453153	-0.009701505	false
training	oneLayer	oneLayer - rat 1	0	0.4220208	-0.0022122336	false
training	oneLayer	oneLayer - rat 1	0	0.42588568	0.0071184128	false
training	oneLayer	oneLayer - rat 1	0	0.42588568	0.017237425	false
training	oneLayer	oneLayer - rat 1	0	0.42179462	0.027114121	false
training	oneLayer	oneLayer - rat 1	0	0.41414958	0.03475915	false
training	oneLayer	oneLayer - rat 1	0	0.40469274	0.0386763	false
training	oneLayer	oneLayer - rat 1	0	0.39531228	0.04256181	false
training	oneLayer	oneLayer - rat 1	0	0.38492134	0.04256181	false
training	oneLayer	oneLayer - rat 1	0	0.374117	0.04256181	false
training	oneLayer	oneLayer - rat 1	0	0.3633218	0.042561807	false
training	oneLayer	oneLayer - rat 1	0	0.35243216	0.042561807	false
training	oneLayer	oneLayer - rat 1	0	0.3423192	0.042561807	false
training	oneLayer	oneLayer - rat 1	0	0.3313638	0.042561807	false
training	oneLayer	oneLayer - rat 1	0	0.32129514	0.042561803	false
training	oneLayer	oneLayer - rat 1	0	0.31044593	0.042561803	false
training	oneLayer	oneLayer - rat 1	0	0.29989377	0.042561803	false
training	oneLayer	oneLayer - rat 1	0	0.28949186	0.042561803	false
training	oneLayer	oneLayer - rat 1	0	0.2792357	0.0425618	false
training	oneLayer	oneLayer - rat 1	0	0.26893106	0.0425618	false
training	oneLayer	oneLayer - rat 1	0	0.25837108	0.0425618	false
training	oneLayer	oneLayer - rat 1	0	0.24753688	0.0425618	false
training	oneLayer	oneLayer - rat 1	0	0.237218	0.042561796	false
training	oneLayer	oneLayer - rat 1	0	0.22711064	0.042561796	false
training	oneLayer	oneLayer - rat 1	0	0.21669057	0.042561796	false
training	oneLayer	oneLayer - rat 1	0	0.20588653	0.042561796	false
training	oneLayer	oneLayer - rat 1	0	0.19564559	0.04256179	false
training	oneLayer	oneLayer - rat 1	0	0.18497147	0.04256179	false
training	oneLayer	oneLayer - rat 1	0	0.17405482	0.04256179	false
training	oneLayer	oneLayer - rat 1	0	0.16340487	0.04256179	false
training	oneLayer	oneLayer - rat 1	0	0.15304996	0.042561788	false
training	oneLayer	oneLayer - rat 1	0	0.14223784	0.042561788	false
training	oneLayer	oneLayer - rat 1	0	0.13162392	0.042561788	false
training	oneLayer	oneLayer - rat 1	0	0.12111652	0.042561788	false
training	oneLayer	oneLayer - rat 1	0	0.11040638	0.042561784	false
training	oneLayer	oneLayer - rat 1	0	0.09974635	0.042561784	false
training	oneLayer	oneLayer - rat 1	0	0.08898427	0.042561784	false
training	oneLayer	oneLayer - rat 1	0	0.07844906	0.042561784	false
training	oneLayer	oneLayer - rat 1	0	0.06824494	0.04256178	false
training	oneLayer	oneLayer - rat 1	0	0.057970036	0.04256178	false
training	oneLayer	oneLayer - rat 1	0	0.047472317	0.04256178	false
training	oneLayer	oneLayer - rat 1	0	0.036755502	0.04256178	false
training	oneLayer	oneLayer - rat 1	0	0.026272707	0.042561777	false
training	oneLayer	oneLayer - rat 1	0	0.015532012	0.042561777	false
training	oneLayer	oneLayer - rat 1	0	0.0049587986	0.042561777	false
training	oneLayer	oneLayer - rat 1	0	-0.0056612925	0.042561777	false
training	oneLayer	oneLayer - rat 1	0	-0.015957415	0.042561773	false
training	oneLayer	oneLayer - rat 1	0	-0.026768269	0.042561773	false
training	oneLayer	oneLayer - rat 1	0	-0.037461583	0.042561773	false
training	oneLayer	oneLayer - rat 1	0	-0.048447832	0.042561773	false
training	oneLayer	oneLayer - rat 1	0	-0.058484074	0.04256177	false
training	oneLayer	oneLayer - rat 1	0	-0.06906952	0.04256177	false
training	oneLayer	oneLayer - rat 1	0	-0.07928557	0.04256177	false
training	oneLayer	oneLayer - rat 1	0	-0.08951337	0.04256177	false
training	oneLayer	oneLayer - rat 1	0	-0.10031805	0.042561766	false
training	oneLayer	oneLayer - rat 1	0	-0.11115362	0.042561766	false
training	oneLayer	oneLayer - rat 1	0	-0.12181514	0.042561766	false
training	oneLayer	oneLayer - rat 1	0	-0.13188967	0.042561766	false
training	oneLayer	oneLayer - rat 1	0	-0.1419023	0.042561766	false
training	oneLayer	oneLayer - rat 1	0	-0.15260461	0.042561762	false
training	oneLayer	oneLayer - rat 1	0	-0.162742	0.042561762	false
training	oneLayer	oneLayer - rat 1	0	-0.1734483	0.042561762	false
training	oneLayer	oneLayer - rat 1	0	-0.18346947	0.042561762	false
training	oneLayer	oneLayer - rat 1	0	-0.19356635	0.04256176	false
training	oneLayer	oneLayer - rat 1	0	-0.20416819	0.04256176	false
training	oneLayer	oneLayer - rat 1	0	-0.21495634	0.04256176	false
training	oneLayer	oneLayer - rat 1	0	-0.22526231	0.04256176	false
training	oneLayer	oneLayer - rat 1	0	-0.23589514	0.042561755	false
training	oneLayer	oneLayer - rat 1	0	-0.24632743	0.042561755	false
training	oneLayer	oneLayer - rat 1	0	-0.2572047	0.042561755	false
training	oneLayer	oneLayer - rat 1	0	-0.26769337	0.042561755	false
training	oneLayer	oneLayer - rat 1	0	-0.2781784	0.04256175	false
training	oneLayer	oneLayer - rat 1	0	-0.28827763	0.04256175	false
training	oneLayer	oneLayer - rat 1	0	-0.29859984	0.04256175	false
training	oneLayer	oneLayer - rat 1	0	-0.30935428	0.04256175	false
training	oneLayer	oneLayer - rat 1	0	-0.32032216	0.042561747	false
training	oneLayer	oneLayer - rat 1	0	-0.331097	0.042561747	false
training	oneLayer	oneLayer - rat 1	0	-0.34145024	0.042561747	false
training	oneLayer	oneLayer - rat 1	0	-0.35210222	0.042561747	false
training	oneLayer	oneLayer - rat 1	0	-0.36191183	0.03849848	false
training	oneLayer	oneLayer - rat 1	0	-0.37191236	0.034356125	false
training	oneLayer	oneLayer - rat 1	0	-0.3815865	0.030348968	false
training	oneLayer	oneLayer - rat 1	0	-0.39165863	0.026176937	false
training	oneLayer	oneLayer - rat 1	0	-0.40178272	0.021983406	false
training	oneLayer	oneLayer - rat 1	0	-0.41108787	0.018129088	false
training	oneLayer	oneLayer - rat 1	0	-0.41857103	0.01064593	false
training	oneLayer	oneLayer - rat 1	0	-0.42257807	9.7209064E-4	false
training	oneLayer	oneLayer - rat 1	0	-0.42257807	-0.00903898	false
training	oneLayer	oneLayer - rat 1	0	-0.41845948	-0.018982098	false
training	oneLayer	oneLayer - rat 1	0	-0.41087866	-0.026562916	false
training	oneLayer	oneLayer - rat 1	0	-0.40101662	-0.030647907	false
training	oneLayer	oneLayer - rat 1	0	-0.39057562	-0.030647906	false
training	oneLayer	oneLayer - rat 1	0	-0.38029757	-0.030647904	false
training	oneLayer	oneLayer - rat 1	0	-0.37077966	-0.026705451	false
training	oneLayer	oneLayer - rat 1	0	-0.36141652	-0.022827113	false
training	oneLayer	oneLayer - rat 1	0	-0.3516718	-0.018790709	false
training	oneLayer	oneLayer - rat 1	0	-0.34156004	-0.01460228	false
training	oneLayer	oneLayer - rat 1	0	-0.33156154	-0.010460769	false
training	oneLayer	oneLayer - rat 1	0	-0.32231948	-0.006632572	false
training	oneLayer	oneLayer - rat 1	0	-0.31295523	-0.0027537767	false
training	oneLayer	oneLayer - rat 1	0	-0.30331278	0.0012402602	false
training	oneLayer	oneLayer - rat 1	0	-0.29323354	0.001240262	false
training	oneLayer	oneLayer - rat 1	0	-0.28314352	0.005419677	false
training	oneLayer	oneLayer - rat 1	0	-0.27245408	0.005419679	false
training	oneLayer	oneLayer - rat 1	0	-0.26279306	0.00942141	false
training	oneLayer	oneLayer - rat 1	0	-0.252659	0.009421412	false
training	oneLayer	oneLayer - rat 1	0	-0.24334414	0.013279755	false
training	oneLayer	oneLayer - rat 1	0	-0.23240884	0.0132797565	false
training	oneLayer	oneLayer - rat 1	0	-0.22293405	0.017204339	false
training	oneLayer	oneLayer - rat 1	0	-0.21223354	0.01720434	false
training	oneLayer	oneLayer - rat 1	0	-0.2023494	0.021298496	false
training	oneLayer	oneLayer - rat 1	0	-0.19174655	0.021298498	false
training	oneLayer	oneLayer - rat 1	0	-0.18238638	0.025175609	false
training	oneLayer	oneLayer - rat 1	0	-0.17207816	0.02517561	false
training	oneLayer	oneLayer - rat 1	0	-0.16184713	0.025175612	false
training	oneLayer	oneLayer - rat 1	0	-0.1508863	0.025175614	false
training	oneLayer	oneLayer - rat 1	0	-0.14074597	0.025175616	false
training	oneLayer	oneLayer - rat 1	0	-0.13023631	0.025175618	false
training	oneLayer	oneLayer - rat 1	0	-0.11981299	0.02517562	false
training	oneLayer	oneLayer - rat 1	0	-0.10903664	0.025175622	false
training	oneLayer	oneLayer - rat 1	0	-0.0982523	0.025175624	false
training	oneLayer	oneLayer - rat 1	0	-0.08745843	0.025175625	false
training	oneLayer	oneLayer - rat 1	0	-0.07674596	0.025175627	false
training	oneLayer	oneLayer - rat 1	0	-0.065894835	0.02517563	false
training	oneLayer	oneLayer - rat 1	0	-0.055839863	0.025175631	false
training	oneLayer	oneLayer - rat 1	0	-0.04502697	0.025175633	false
training	oneLayer	oneLayer - rat 1	0	-0.034119613	0.025175635	false
training	oneLayer	oneLayer - rat 1	0	-0.023368375	0.025175637	false
training	oneLayer	oneLayer - rat 1	0	-0.012856248	0.025175638	false
training	oneLayer	oneLayer - rat 1	0	-0.0025514248	0.02517564	false
training	oneLayer	oneLayer - rat 1	0	0.008101963	0.025175642	false
training	oneLayer	oneLayer - rat 1	0	0.018201346	0.025175644	false
training	oneLayer	oneLayer - rat 1	0	0.028908232	0.025175646	false
training	oneLayer	oneLayer - rat 1	0	0.03985845	0.025175648	false
training	oneLayer	oneLayer - rat 1	0	0.05003396	0.02517565	false
training	oneLayer	oneLayer - rat 1	0	0.060240664	0.025175652	false
training	oneLayer	oneLayer - rat 1	0	0.07092608	0.025175653	false
training	oneLayer	oneLayer - rat 1	0	0.08123394	0.025175655	false
training	oneLayer	oneLayer - rat 1	0	0.09161202	0.025175657	false
training	oneLayer	oneLayer - rat 1	0	0.10185474	0.025175659	false
training	oneLayer	oneLayer - rat 1	0	0.11248322	0.02517566	false
training	oneLayer	oneLayer - rat 1	0	0.122982696	0.025175663	false
training	oneLayer	oneLayer - rat 1	0	0.13330348	0.025175663	false
training	oneLayer	oneLayer - rat 1	0	0.14334472	0.025175665	false
training	oneLayer	oneLayer - rat 1	0	0.15367451	0.025175666	false
training	oneLayer	oneLayer - rat 1	0	0.16406742	0.025175668	false
training	oneLayer	oneLayer - rat 1	0	0.17461066	0.02517567	false
training	oneLayer	oneLayer - rat 1	0	0.1849134	0.025175672	false
training	oneLayer	oneLayer - rat 1	0	0.19492067	0.025175674	false
training	oneLayer	oneLayer - rat 1	0	0.20542277	0.025175676	false
training	oneLayer	oneLayer - rat 1	0	0.21597575	0.025175678	false
training	oneLayer	oneLayer - rat 1	0	0.22691847	0.02517568	false
training	oneLayer	oneLayer - rat 1	0	0.23721002	0.025175681	false
training	oneLayer	oneLayer - rat 1	0	0.24734458	0.025175683	false
training	oneLayer	oneLayer - rat 1	0	0.25744691	0.025175685	false
training	oneLayer	oneLayer - rat 1	0	0.2675796	0.025175687	false
training	oneLayer	oneLayer - rat 1	0	0.2776773	0.025175689	false
training	oneLayer	oneLayer - rat 1	0	0.2880808	0.02517569	false
training	oneLayer	oneLayer - rat 1	0	0.29876193	0.025175693	false
training	oneLayer	oneLayer - rat 1	0	0.30915734	0.025175694	false
training	oneLayer	oneLayer - rat 1	0	0.31935152	0.025175696	false
training	oneLayer	oneLayer - rat 1	0	0.32991818	0.025175698	false
training	oneLayer	oneLayer - rat 1	0	0.34031978	0.0251757	false
training	oneLayer	oneLayer - rat 1	0	0.35074392	0.025175702	false
training	oneLayer	oneLayer - rat 1	0	0.3613635	0.025175704	false
training	oneLayer	oneLayer - rat 1	0	0.37161797	0.025175706	false
training	oneLayer	oneLayer - rat 1	0	0.38229382	0.025175707	false
training	oneLayer	oneLayer - rat 1	0	0.39310983	0.02517571	false
training	oneLayer	oneLayer - rat 1	0	0.40273085	0.029160867	false
training	oneLayer	oneLayer - rat 1	0	0.41009885	0.036528856	false
training	oneLayer	oneLayer - rat 1	0	0.41416866	0.046354223	false
training	oneLayer	oneLayer - rat 1	0	0.42174405	0.053929638	false
training	oneLayer	oneLayer - rat 1	0	0.4258948	0.06395044	false
training	oneLayer	oneLayer - rat 1	0	0.42997628	0.07380403	false
training	oneLayer	oneLayer - rat 1	0	0.4338359	0.08312197	false
training	oneLayer	oneLayer - rat 1	0	0.4338359	0.09385811	false
training	oneLayer	oneLayer - rat 1	0	0.42976755	0.103679985	false
training	oneLayer	oneLayer - rat 1	0	0.42205116	0.11139636	false
training	oneLayer	oneLayer - rat 1	0	0.41248587	0.11535844	false
training	oneLayer	oneLayer - rat 1	0	0.40210554	0.115358435	false
training	oneLayer	oneLayer - rat 1	0	0.3921377	0.11122963	false
training	oneLayer	oneLayer - rat 1	0	0.38498136	0.10407328	false
training	oneLayer	oneLayer - rat 1	0	0.38091016	0.09424451	false
training	oneLayer	oneLayer - rat 1	0	0.38091016	0.08374958	false
training	oneLayer	oneLayer - rat 1	0	0.38507223	0.07370148	false
training	oneLayer	oneLayer - rat 1	0	0.38925534	0.06360255	false
training	oneLayer	oneLayer - rat 1	0	0.3934637	0.053442687	false
training	oneLayer	oneLayer - rat 1	0	0.40112922	0.045777176	false
training	oneLayer	oneLayer - rat 1	0	0.4087471	0.038159274	false
training	oneLayer	oneLayer - rat 1	0	0.41645607	0.03045032	false
training	oneLayer	oneLayer - rat 1	0	0.42065156	0.020321527	false
training	oneLayer	oneLayer - rat 1	0	0.42065158	0.009465258	false
training	oneLayer	oneLayer - rat 1	0	0.41664478	-2.0797784E-4	false
training	oneLayer	oneLayer - rat 1	0	0.40940008	-0.007452688	false
training	oneLayer	oneLayer - rat 1	0	0.39957708	-0.011521508	false
training	oneLayer	oneLayer - rat 1	0	0.38918543	-0.011521511	false
training	oneLayer	oneLayer - rat 1	0	0.37965888	-0.007575479	false
training	oneLayer	oneLayer - rat 1	0	0.37040552	-0.003742625	false
training	oneLayer	oneLayer - rat 1	0	0.3609693	1.6597935E-4	false
training	oneLayer	oneLayer - rat 1	0	0.3511811	0.0042203874	false
training	oneLayer	oneLayer - rat 1	0	0.34140775	0.008268646	false
training	oneLayer	oneLayer - rat 1	0	0.33141968	0.0124058295	false
training	oneLayer	oneLayer - rat 1	0	0.32208967	0.01627045	false
training	oneLayer	oneLayer - rat 1	0	0.31202325	0.020440089	false
training	oneLayer	oneLayer - rat 1	0	0.30244446	0.024407748	false
training	oneLayer	oneLayer - rat 1	0	0.29316002	0.028253492	false
training	oneLayer	oneLayer - rat 1	0	0.28300315	0.0324606	false
training	oneLayer	oneLayer - rat 1	0	0.27337745	0.036447696	false
training	oneLayer	oneLayer - rat 1	0	0.26397	0.040344384	false
training	oneLayer	oneLayer - rat 1	0	0.25456825	0.04423871	false
training	oneLayer	oneLayer - rat 1	0	0.24446915	0.048421897	false
training	oneLayer	oneLayer - rat 1	0	0.23522654	0.052250307	false
training	oneLayer	oneLayer - rat 1	0	0.22596522	0.05608647	false
training	oneLayer	oneLayer - rat 1	0	0.21584144	0.060279872	false
training	oneLayer	oneLayer - rat 1	0	0.20605037	0.064335465	false
training	oneLayer	oneLayer - rat 1	0	0.1968108	0.06816262	false
training	oneLayer	oneLayer - rat 1	0	0.18693233	0.07225441	false
training	oneLayer	oneLayer - rat 1	0	0.17762467	0.07610977	false
training	oneLayer	oneLayer - rat 1	0	0.16752969	0.08029124	false
training	oneLayer	oneLayer - rat 1	0	0.15800647	0.08423588	false
training	oneLayer	oneLayer - rat 1	0	0.14832374	0.0882466	false
training	oneLayer	oneLayer - rat 1	0	0.13829228	0.092401765	false
training	oneLayer	oneLayer - rat 1	0	0.12825479	0.09655943	false
training	oneLayer	oneLayer - rat 1	0	0.118134454	0.1007514	false
training	oneLayer	oneLayer - rat 1	0	0.10846343	0.10475727	false
training	oneLayer	oneLayer - rat 1	0	0.09893054	0.108705916	false
training	oneLayer	oneLayer - rat 1	0	0.08883398	0.112888046	false
training	oneLayer	oneLayer - rat 1	0	0.07939862	0.1167963	false
training	oneLayer	oneLayer - rat 1	0	0.07003327	0.12067555	false
training	oneLayer	oneLayer - rat 1	0	0.06052261	0.12461499	false
training	oneLayer	oneLayer - rat 1	0	0.051144473	0.12849954	false
training	oneLayer	oneLayer - rat 1	0	0.041039206	0.13268527	false
training	oneLayer	oneLayer - rat 1	0	0.03121965	0.13675267	false
training	oneLayer	oneLayer - rat 1	0	0.02161862	0.14072955	false
training	oneLayer	oneLayer - rat 1	0	0.012178432	0.14463979	false
training	oneLayer	oneLayer - rat 1	0	0.00261909	0.1485994	false
training	oneLayer	oneLayer - rat 1	0	-0.0074229655	0.15275896	false
training	oneLayer	oneLayer - rat 1	0	-0.016677903	0.15659247	false
training	oneLayer	oneLayer - rat 1	0	-0.02628141	0.16057037	false
training	oneLayer	oneLayer - rat 1	0	-0.03597204	0.16458435	false
training	oneLayer	oneLayer - rat 1	0	-0.04556798	0.16855912	false
training	oneLayer	oneLayer - rat 1	0	-0.055550776	0.17269413	false
training	oneLayer	oneLayer - rat 1	0	-0.06505217	0.17662974	false
training	oneLayer	oneLayer - rat 1	0	-0.07462755	0.18059598	false
training	oneLayer	oneLayer - rat 1	0	-0.08393726	0.18445219	false
training	oneLayer	oneLayer - rat 1	0	-0.09369599	0.18849438	false
training	oneLayer	oneLayer - rat 1	0	-0.10315996	0.19241448	false
training	oneLayer	oneLayer - rat 1	0	-0.112656906	0.19634825	false
training	oneLayer	oneLayer - rat 1	0	-0.1220209	0.20022693	false
training	oneLayer	oneLayer - rat 1	0	-0.13182744	0.20428893	false
training	oneLayer	oneLayer - rat 1	0	-0.14159963	0.20833671	false
training	oneLayer	oneLayer - rat 1	0	-0.15144914	0.2124165	false
training	oneLayer	oneLayer - rat 1	0	-0.16134837	0.2165169	false
training	oneLayer	oneLayer - rat 1	0	-0.17136894	0.22066756	false
training	oneLayer	oneLayer - rat 1	0	-0.18141432	0.22482848	false
training	oneLayer	oneLayer - rat 1	0	-0.19147208	0.22899453	false
training	oneLayer	oneLayer - rat 1	0	-0.20147298	0.23313704	false
training	oneLayer	oneLayer - rat 1	0	-0.2108909	0.23703808	false
training	oneLayer	oneLayer - rat 1	0	-0.22045143	0.24099816	false
training	oneLayer	oneLayer - rat 1	0	-0.23003067	0.24496602	false
training	oneLayer	oneLayer - rat 1	0	-0.23950541	0.24889058	false
training	oneLayer	oneLayer - rat 1	0	-0.24919116	0.25290254	false
training	oneLayer	oneLayer - rat 1	0	-0.2593474	0.2571094	false
training	oneLayer	oneLayer - rat 1	0	-0.26678956	0.26455155	false
training	oneLayer	oneLayer - rat 1	0	-0.27433023	0.27209222	false
training	oneLayer	oneLayer - rat 1	0	-0.28162247	0.27938446	false
training	oneLayer	oneLayer - rat 1	0	-0.28878957	0.28655154	false
training	oneLayer	oneLayer - rat 1	0	-0.29841274	0.2905376	false
training	oneLayer	oneLayer - rat 1	0	-0.30900264	0.2905376	false
training	oneLayer	oneLayer - rat 1	0	-0.31892234	0.28642872	false
training	oneLayer	oneLayer - rat 1	0	-0.3281692	0.28259853	false
training	oneLayer	oneLayer - rat 1	0	-0.33557364	0.27519408	false
training	oneLayer	oneLayer - rat 1	0	-0.34329414	0.26747358	false
training	oneLayer	oneLayer - rat 1	0	-0.34720173	0.2580398	false
training	oneLayer	oneLayer - rat 1	0	-0.35125425	0.24825616	false
training	oneLayer	oneLayer - rat 1	0	-0.3554189	0.23820184	false
training	oneLayer	oneLayer - rat 1	0	-0.3595172	0.22830763	false
training	oneLayer	oneLayer - rat 1	0	-0.36342618	0.21887052	false
training	oneLayer	oneLayer - rat 1	0	-0.36726284	0.20960799	false
training	oneLayer	oneLayer - rat 1	0	-0.3711319	0.20026724	false
training	oneLayer	oneLayer - rat 1	0	-0.37523568	0.19035982	false
training	oneLayer	oneLayer - rat 1	0	-0.37940112	0.18030357	false
training	oneLayer	oneLayer - rat 1	0	-0.38334244	0.17078832	false
training	oneLayer	oneLayer - rat 1	0	-0.387455	0.1608598	false
training	oneLayer	oneLayer - rat 1	0	-0.3913327	0.15149817	false
training	oneLayer	oneLayer - rat 1	0	-0.39528006	0.14196834	false
training	oneLayer	oneLayer - rat 1	0	-0.39920884	0.13248341	false
training	oneLayer	oneLayer - rat 1	0	-0.40333164	0.12253011	false
training	oneLayer	oneLayer - rat 1	0	-0.407415	0.11267199	false
training	oneLayer	oneLayer - rat 1	0	-0.4114101	0.10302701	false
training	oneLayer	oneLayer - rat 1	0	-0.41539258	0.09341239	false
training	oneLayer	oneLayer - rat 1	0	-0.41950914	0.08347412	false
training	oneLayer	oneLayer - rat 1	0	-0.42344207	0.07397919	false
training	oneLayer	oneLayer - rat 1	0	-0.42739815	0.06442838	false
training	oneLayer	oneLayer - rat 1	0	-0.43148264	0.054567568	false
training	oneLayer	oneLayer - rat 1	0	-0.4356274	0.044561166	false
training	oneLayer	oneLayer - rat 1	0	-0.4356274	0.034286864	false
training	oneLayer	oneLayer - rat 1	0	-0.43170053	0.024806537	false
training	oneLayer	oneLayer - rat 1	0	-0.42400584	0.017111842	false
training	oneLayer	oneLayer - rat 1	0	-0.414374	0.013122207	false
training	oneLayer	oneLayer - rat 1	0	-0.4036572	0.01312221	false
training	oneLayer	oneLayer - rat 1	0	-0.39415768	0.017057037	false
training	oneLayer	oneLayer - rat 1	0	-0.3866891	0.024525633	false
training	oneLayer	oneLayer - rat 1	0	-0.38250402	0.034629337	false
training	oneLayer	oneLayer - rat 1	0	-0.37863535	0.04396911	false
training	oneLayer	oneLayer - rat 1	0	-0.37447307	0.054017745	false
training	oneLayer	oneLayer - rat 1	0	-0.3703572	0.06395438	false
training	oneLayer	oneLayer - rat 1	0	-0.36615595	0.074097075	false
training	oneLayer	oneLayer - rat 1	0	-0.36215973	0.08374479	false
training	oneLayer	oneLayer - rat 1	0	-0.35800013	0.09378696	false
training	oneLayer	oneLayer - rat 1	0	-0.3540971	0.103209734	false
training	oneLayer	oneLayer - rat 1	0	-0.34995773	0.1132031	false
training	oneLayer	oneLayer - rat 1	0	-0.34585926	0.123097695	false
training	oneLayer	oneLayer - rat 1	0	-0.34172934	0.13306819	false
training	oneLayer	oneLayer - rat 1	0	-0.33771998	0.14274764	false
training	oneLayer	oneLayer - rat 1	0	-0.33354267	0.1528326	false
training	oneLayer	oneLayer - rat 1	0	-0.3296747	0.1621707	false
training	oneLayer	oneLayer - rat 1	0	-0.32565376	0.17187811	false
training	oneLayer	oneLayer - rat 1	0	-0.32179832	0.18118598	false
training	oneLayer	oneLayer - rat 1	0	-0.31794783	0.19048189	false
training	oneLayer	oneLayer - rat 1	0	-0.31794783	0.20071965	false
training	oneLayer	oneLayer - rat 1	0	-0.31794783	0.2115166	false
training	oneLayer	oneLayer - rat 1	0	-0.31794783	0.2216405	false
training	oneLayer	oneLayer - rat 1	0	-0.31794786	0.23217607	false
training	oneLayer	oneLayer - rat 1	0	-0.31794786	0.24250796	false
training	oneLayer	oneLayer - rat 1	0	-0.31794786	0.25266594	false
training	oneLayer	oneLayer - rat 1	0	-0.31794786	0.2627105	false
training	oneLayer	oneLayer - rat 1	0	-0.31794786	0.27328902	false
training	oneLayer	oneLayer - rat 1	0	-0.31794786	0.28428	false
training	oneLayer	oneLayer - rat 1	0	-0.31386012	0.29414868	false
training	oneLayer	oneLayer - rat 1	0	-0.30990094	0.30370706	false
training	oneLayer	oneLayer - rat 1	0	-0.30236855	0.31123942	false
training	oneLayer	oneLayer - rat 1	0	-0.29239467	0.31537077	false
training	oneLayer	oneLayer - rat 1	0	-0.2820284	0.31537077	false
training	oneLayer	oneLayer - rat 1	0	-0.272114	0.3112641	false
training	oneLayer	oneLayer - rat 1	0	-0.26452646	0.30367655	false
training	oneLayer	oneLayer - rat 1	0	-0.26059827	0.2941931	false
training	oneLayer	oneLayer - rat 1	0	-0.26059827	0.28377292	false
training	oneLayer	oneLayer - rat 1	0	-0.26473	0.273798	false
training	oneLayer	oneLayer - rat 1	0	-0.26864332	0.26435038	false
training	oneLayer	oneLayer - rat 1	0	-0.27248922	0.25506553	false
training	oneLayer	oneLayer - rat 1	0	-0.27664316	0.24503708	false
training	oneLayer	oneLayer - rat 1	0	-0.28072727	0.23517714	false
training	oneLayer	oneLayer - rat 1	0	-0.28470942	0.22556338	false
training	oneLayer	oneLayer - rat 1	0	-0.2885378	0.21632086	false
training	oneLayer	oneLayer - rat 1	0	-0.29252198	0.20670217	false
training	oneLayer	oneLayer - rat 1	0	-0.29647115	0.19716805	false
training	oneLayer	oneLayer - rat 1	0	-0.30051196	0.18741262	false
training	oneLayer	oneLayer - rat 1	0	-0.30449203	0.17780387	false
training	oneLayer	oneLayer - rat 1	0	-0.30859736	0.16789278	false
training	oneLayer	oneLayer - rat 1	0	-0.31260887	0.1582081	false
training	oneLayer	oneLayer - rat 1	0	-0.31678754	0.14811984	false
training	oneLayer	oneLayer - rat 1	0	-0.32094207	0.13808991	false
training	oneLayer	oneLayer - rat 1	0	-0.32490677	0.12851834	false
training	oneLayer	oneLayer - rat 1	0	-0.32882935	0.11904839	false
training	oneLayer	oneLayer - rat 1	0	-0.3360434	0.11183435	false
training	oneLayer	oneLayer - rat 1	0	-0.34342816	0.10444956	false
training	oneLayer	oneLayer - rat 1	0	-0.3510753	0.09680241	false
training	oneLayer	oneLayer - rat 1	0	-0.35848796	0.08938974	false
training	oneLayer	oneLayer - rat 1	0	-0.36584374	0.082033955	false
training	oneLayer	oneLayer - rat 1	0	-0.3734164	0.0744613	false
training	oneLayer	oneLayer - rat 1	0	-0.38115528	0.06672242	false
training	oneLayer	oneLayer - rat 1	0	-0.38830543	0.059572272	false
training	oneLayer	oneLayer - rat 1	0	-0.39595264	0.05192504	false
training	oneLayer	oneLayer - rat 1	0	-0.40336502	0.044512678	false
training	oneLayer	oneLayer - rat 1	0	-0.41073862	0.037139077	false
training	oneLayer	oneLayer - rat 1	0	-0.4178928	0.029984863	false
training	oneLayer	oneLayer - rat 1	0	-0.42529774	0.02257992	false
training	oneLayer	oneLayer - rat 1	0	-0.42950723	0.012417332	false
training	oneLayer	oneLayer - rat 1	0	-0.43371236	0.0022652524	false
training	oneLayer	oneLayer - rat 1	0	-0.43371236	-0.008454496	false
training	oneLayer	oneLayer - rat 1	0	-0.42981443	-0.01786489	false
training	oneLayer	oneLayer - rat 1	0	-0.42261684	-0.025062475	false
training	oneLayer	oneLayer - rat 1	0	-0.41302544	-0.029035363	false
training	oneLayer	oneLayer - rat 1	0	-0.40226316	-0.02903536	false
training	oneLayer	oneLayer - rat 1	0	-0.39230478	-0.024910465	false
training	oneLayer	oneLayer - rat 1	0	-0.38484383	-0.017449506	false
training	oneLayer	oneLayer - rat 1	0	-0.38074467	-0.0075532347	false
training	oneLayer	oneLayer - rat 1	0	-0.3765752	0.0025127353	false
training	oneLayer	oneLayer - rat 1	0	-0.37249276	0.012368633	false
training	oneLayer	oneLayer - rat 1	0	-0.3684107	0.022223597	false
training	oneLayer	oneLayer - rat 1	0	-0.36440903	0.031884555	false
training	oneLayer	oneLayer - rat 1	0	-0.3604991	0.04132389	false
training	oneLayer	oneLayer - rat 1	0	-0.35663554	0.050651398	false
training	oneLayer	oneLayer - rat 1	0	-0.3526136	0.06036126	false
training	oneLayer	oneLayer - rat 1	0	-0.348495	0.070304394	false
training	oneLayer	oneLayer - rat 1	0	-0.344448	0.08007475	false
training	oneLayer	oneLayer - rat 1	0	-0.34028673	0.09012096	false
training	oneLayer	oneLayer - rat 1	0	-0.33645892	0.09936213	false
training	oneLayer	oneLayer - rat 1	0	-0.332595	0.108690515	false
training	oneLayer	oneLayer - rat 1	0	-0.32854912	0.11845808	false
training	oneLayer	oneLayer - rat 1	0	-0.32462293	0.12793678	false
training	oneLayer	oneLayer - rat 1	0	-0.32056528	0.13773277	false
training	oneLayer	oneLayer - rat 1	0	-0.31652242	0.14749314	false
training	oneLayer	oneLayer - rat 1	0	-0.31652242	0.15756887	false
training	oneLayer	oneLayer - rat 1	0	-0.31652242	0.1684582	false
training	oneLayer	oneLayer - rat 1	0	-0.3204269	0.17788447	false
training	oneLayer	oneLayer - rat 1	0	-0.32042694	0.18888234	false
training	oneLayer	oneLayer - rat 1	0	-0.32450292	0.1987226	false
training	oneLayer	oneLayer - rat 1	0	-0.32450292	0.20964284	false
training	oneLayer	oneLayer - rat 1	0	-0.3286414	0.2196341	false
training	oneLayer	oneLayer - rat 1	0	-0.32864144	0.22997655	false
training	oneLayer	oneLayer - rat 1	0	-0.3327231	0.23983057	false
training	oneLayer	oneLayer - rat 1	0	-0.3327231	0.2501201	false
training	oneLayer	oneLayer - rat 1	0	-0.3327231	0.2602853	false
training	oneLayer	oneLayer - rat 1	0	-0.3327231	0.27116933	false
training	oneLayer	oneLayer - rat 1	0	-0.33272314	0.28165236	false
training	oneLayer	oneLayer - rat 1	0	-0.32883054	0.2910499	false
training	oneLayer	oneLayer - rat 1	0	-0.3214552	0.29842523	false
training	oneLayer	oneLayer - rat 1	0	-0.3116164	0.3025006	false
training	oneLayer	oneLayer - rat 1	0	-0.30121014	0.3025006	false
training	oneLayer	oneLayer - rat 1	0	-0.29186866	0.29863125	false
training	oneLayer	oneLayer - rat 1	0	-0.28443635	0.29119894	false
training	oneLayer	oneLayer - rat 1	0	-0.28044483	0.2815626	false
training	oneLayer	oneLayer - rat 1	0	-0.28044483	0.27082077	false
training	oneLayer	oneLayer - rat 1	0	-0.28447732	0.26108545	false
training	oneLayer	oneLayer - rat 1	0	-0.28864643	0.25102034	false
training	oneLayer	oneLayer - rat 1	0	-0.29283568	0.24090664	false
training	oneLayer	oneLayer - rat 1	0	-0.29682934	0.23126505	false
training	oneLayer	oneLayer - rat 1	0	-0.3008123	0.2216493	false
training	oneLayer	oneLayer - rat 1	0	-0.30468425	0.21230161	false
training	oneLayer	oneLayer - rat 1	0	-0.30876234	0.20245625	false
training	oneLayer	oneLayer - rat 1	0	-0.31265002	0.1930705	false
training	oneLayer	oneLayer - rat 1	0	-0.316767	0.18313123	false
training	oneLayer	oneLayer - rat 1	0	-0.32074028	0.1735389	false
training	oneLayer	oneLayer - rat 1	0	-0.32474807	0.16386323	false
training	oneLayer	oneLayer - rat 1	0	-0.3286323	0.15448588	false
training	oneLayer	oneLayer - rat 1	0	-0.3325833	0.14494726	false
training	oneLayer	oneLayer - rat 1	0	-0.33661962	0.13520274	false
training	oneLayer	oneLayer - rat 1	0	-0.34054112	0.12573542	false
training	oneLayer	oneLayer - rat 1	0	-0.344634	0.115854315	false
training	oneLayer	oneLayer - rat 1	0	-0.34877306	0.10586171	false
training	oneLayer	oneLayer - rat 1	0	-0.35269517	0.09639293	false
training	oneLayer	oneLayer - rat 1	0	-0.35987085	0.08921722	false
training	oneLayer	oneLayer - rat 1	0	-0.36757597	0.08151211	false
training	oneLayer	oneLayer - rat 1	0	-0.37506562	0.074022435	false
training	oneLayer	oneLayer - rat 1	0	-0.38253403	0.066554055	false
training	oneLayer	oneLayer - rat 1	0	-0.39018816	0.058899913	false
training	oneLayer	oneLayer - rat 1	0	-0.39778247	0.051305596	false
training	oneLayer	oneLayer - rat 1	0	-0.4054767	0.04361137	false
training	oneLayer	oneLayer - rat 1	0	-0.41291267	0.0361754	false
training	oneLayer	oneLayer - rat 1	0	-0.42033628	0.028751785	false
training	oneLayer	oneLayer - rat 1	0	-0.4275064	0.021581663	false
training	oneLayer	oneLayer - rat 1	0	-0.43148792	0.01196935	false
training	oneLayer	oneLayer - rat 1	0	-0.43148792	0.0016530196	false
training	oneLayer	oneLayer - rat 1	0	-0.42756563	-0.007816256	false
training	oneLayer	oneLayer - rat 1	0	-0.42034522	-0.015036647	false
training	oneLayer	oneLayer - rat 1	0	-0.41089386	-0.018951528	false
training	oneLayer	oneLayer - rat 1	0	-0.40030384	-0.018951524	false
training	oneLayer	oneLayer - rat 1	0	-0.39061287	-0.014937388	false
training	oneLayer	oneLayer - rat 1	0	-0.38283947	-0.0071639745	false
training	oneLayer	oneLayer - rat 1	0	-0.37866297	0.0029189454	false
training	oneLayer	oneLayer - rat 1	0	-0.37866297	0.013700794	false
training	oneLayer	oneLayer - rat 1	0	-0.378663	0.023983741	false
training	oneLayer	oneLayer - rat 1	0	-0.38286915	0.034138296	false
training	oneLayer	oneLayer - rat 1	0	-0.38286915	0.045055967	false
training	oneLayer	oneLayer - rat 1	0	-0.38680714	0.054563113	false
training	oneLayer	oneLayer - rat 1	0	-0.38680714	0.06505642	false
training	oneLayer	oneLayer - rat 1	0	-0.3908033	0.07470398	false
training	oneLayer	oneLayer - rat 1	0	-0.3908033	0.085027	false
training	oneLayer	oneLayer - rat 1	0	-0.39475134	0.09455839	false
training	oneLayer	oneLayer - rat 1	0	-0.39475134	0.10555203	false
training	oneLayer	oneLayer - rat 1	0	-0.39864367	0.11494895	false
training	oneLayer	oneLayer - rat 1	0	-0.39864367	0.125534	false
training	oneLayer	oneLayer - rat 1	0	-0.40261725	0.13512701	false
training	oneLayer	oneLayer - rat 1	0	-0.40261725	0.14612025	false
training	oneLayer	oneLayer - rat 1	0	-0.39866197	0.15566917	false
training	oneLayer	oneLayer - rat 1	0	-0.39866197	0.16635917	false
training	oneLayer	oneLayer - rat 1	0	-0.3944584	0.17650747	false
training	oneLayer	oneLayer - rat 1	0	-0.3944584	0.18710972	false
training	oneLayer	oneLayer - rat 1	0	-0.39053646	0.19657819	false
training	oneLayer	oneLayer - rat 1	0	-0.39053646	0.2075689	false
training	oneLayer	oneLayer - rat 1	0	-0.38661662	0.21703224	false
training	oneLayer	oneLayer - rat 1	0	-0.38661662	0.22741398	false
training	oneLayer	oneLayer - rat 1	0	-0.3824334	0.23751311	false
training	oneLayer	oneLayer - rat 1	0	-0.37850782	0.24699035	false
training	oneLayer	oneLayer - rat 1	0	-0.37450275	0.2566595	false
training	oneLayer	oneLayer - rat 1	0	-0.37049195	0.2663424	false
training	oneLayer	oneLayer - rat 1	0	-0.36651096	0.2759534	false
training	oneLayer	oneLayer - rat 1	0	-0.36264417	0.28528866	false
training	oneLayer	oneLayer - rat 1	0	-0.35862717	0.29498658	false
training	oneLayer	oneLayer - rat 1	0	-0.35133168	0.30228207	false
training	oneLayer	oneLayer - rat 1	0	-0.34185767	0.30620632	false
training	oneLayer	oneLayer - rat 1	0	-0.33099666	0.30620632	false
training	oneLayer	oneLayer - rat 1	0	-0.3205129	0.30620635	false
training	oneLayer	oneLayer - rat 1	0	-0.30959958	0.30620635	false
training	oneLayer	oneLayer - rat 1	0	-0.29901028	0.30620635	false
training	oneLayer	oneLayer - rat 1	0	-0.28895086	0.30620635	false
training	oneLayer	oneLayer - rat 1	0	-0.27942842	0.31015068	false
training	oneLayer	oneLayer - rat 1	0	-0.26938456	0.31015068	false
training	oneLayer	oneLayer - rat 1	0	-0.2593585	0.30599776	false
training	oneLayer	oneLayer - rat 1	0	-0.24934156	0.30599776	false
training	oneLayer	oneLayer - rat 1	0	-0.23924243	0.30181456	false
training	oneLayer	oneLayer - rat 1	0	-0.22873718	0.30181456	false
training	oneLayer	oneLayer - rat 1	0	-0.21884951	0.29771897	false
training	oneLayer	oneLayer - rat 1	0	-0.20786455	0.29771897	false
training	oneLayer	oneLayer - rat 1	0	-0.19812348	0.2936841	false
training	oneLayer	oneLayer - rat 1	0	-0.18775867	0.2936841	false
training	oneLayer	oneLayer - rat 1	0	-0.17772205	0.2895268	false
training	oneLayer	oneLayer - rat 1	0	-0.16675669	0.2895268	false
training	oneLayer	oneLayer - rat 1	0	-0.15660982	0.28532383	false
training	oneLayer	oneLayer - rat 1	0	-0.14580141	0.28532383	false
training	oneLayer	oneLayer - rat 1	0	-0.136551	0.28149217	false
training	oneLayer	oneLayer - rat 1	0	-0.12599474	0.2814922	false
training	oneLayer	oneLayer - rat 1	0	-0.11603758	0.2773678	false
training	oneLayer	oneLayer - rat 1	0	-0.105401516	0.2773678	false
training	oneLayer	oneLayer - rat 1	0	-0.096072145	0.27350345	false
training	oneLayer	oneLayer - rat 1	0	-0.08533348	0.27350345	false
training	oneLayer	oneLayer - rat 1	0	-0.075264856	0.26933292	false
training	oneLayer	oneLayer - rat 1	0	-0.06455469	0.26933292	false
training	oneLayer	oneLayer - rat 1	0	-0.055292442	0.26549637	false
training	oneLayer	oneLayer - rat 1	0	-0.04471551	0.26549637	false
training	oneLayer	oneLayer - rat 1	0	-0.03464152	0.2613236	false
training	oneLayer	oneLayer - rat 1	0	-0.023974482	0.2613236	false
training	oneLayer	oneLayer - rat 1	0	-0.014536536	0.25741428	false
training	oneLayer	oneLayer - rat 1	0	-0.0037438397	0.25741428	false
training	oneLayer	oneLayer - rat 1	0	0.0057531837	0.2534805	false
training	oneLayer	oneLayer - rat 1	0	0.015971191	0.2534805	false
training	oneLayer	oneLayer - rat 1	0	0.025417179	0.24956784	false
training	oneLayer	oneLayer - rat 1	0	0.03552577	0.24956784	false
training	oneLayer	oneLayer - rat 1	0	0.045322448	0.24550992	false
training	oneLayer	oneLayer - rat 1	0	0.05543824	0.24550994	false
training	oneLayer	oneLayer - rat 1	0	0.065282404	0.24143235	false
training	oneLayer	oneLayer - rat 1	0	0.07548189	0.24143235	false
training	oneLayer	oneLayer - rat 1	0	0.08477285	0.23758392	false
training	oneLayer	oneLayer - rat 1	0	0.09480737	0.23758392	false
training	oneLayer	oneLayer - rat 1	0	0.104426876	0.2335994	false
training	oneLayer	oneLayer - rat 1	0	0.11443371	0.23359941	false
training	oneLayer	oneLayer - rat 1	0	0.1243872	0.22947654	false
training	oneLayer	oneLayer - rat 1	0	0.13462633	0.22947654	false
training	oneLayer	oneLayer - rat 1	0	0.14461748	0.22533807	false
training	oneLayer	oneLayer - rat 1	0	0.15553166	0.22533809	false
training	oneLayer	oneLayer - rat 1	0	0.16557367	0.22117855	false
training	oneLayer	oneLayer - rat 1	0	0.17615148	0.22117855	false
training	oneLayer	oneLayer - rat 1	0	0.18595184	0.21711911	false
training	oneLayer	oneLayer - rat 1	0	0.19666572	0.21711911	false
training	oneLayer	oneLayer - rat 1	0	0.20675051	0.21294187	false
training	oneLayer	oneLayer - rat 1	0	0.21763524	0.21294187	false
training	oneLayer	oneLayer - rat 1	0	0.22714707	0.20900194	false
training	oneLayer	oneLayer - rat 1	0	0.23776509	0.20900194	false
training	oneLayer	oneLayer - rat 1	0	0.24763185	0.204915	false
training	oneLayer	oneLayer - rat 1	0	0.2578894	0.204915	false
training	oneLayer	oneLayer - rat 1	0	0.26715896	0.20107543	false
training	oneLayer	oneLayer - rat 1	0	0.27734295	0.20107543	false
training	oneLayer	oneLayer - rat 1	0	0.2872328	0.19697894	false
training	oneLayer	oneLayer - rat 1	0	0.29726276	0.19697894	false
training	oneLayer	oneLayer - rat 1	0	0.30659682	0.19311264	false
training	oneLayer	oneLayer - rat 1	0	0.31686	0.19311266	false
training	oneLayer	oneLayer - rat 1	0	0.32617602	0.18925382	false
training	oneLayer	oneLayer - rat 1	0	0.3370944	0.18925382	false
training	oneLayer	oneLayer - rat 1	0	0.3466253	0.18530601	false
training	oneLayer	oneLayer - rat 1	0	0.35752964	0.18530601	false
training	oneLayer	oneLayer - rat 1	0	0.3670942	0.18134424	false
training	oneLayer	oneLayer - rat 1	0	0.37441778	0.17402066	false
training	oneLayer	oneLayer - rat 1	0	0.38207632	0.16636214	false
training	oneLayer	oneLayer - rat 1	0	0.3862086	0.15638597	false
training	oneLayer	oneLayer - rat 1	0	0.39003718	0.14714293	false
training	oneLayer	oneLayer - rat 1	0	0.39407814	0.13738719	false
training	oneLayer	oneLayer - rat 1	0	0.398089	0.12770414	false
training	oneLayer	oneLayer - rat 1	0	0.40228066	0.117584564	false
training	oneLayer	oneLayer - rat 1	0	0.40638667	0.10767177	false
training	oneLayer	oneLayer - rat 1	0	0.41038355	0.09802247	false
training	oneLayer	oneLayer - rat 1	0	0.4142527	0.08868152	false
training	oneLayer	oneLayer - rat 1	0	0.418449	0.07855074	false
training	oneLayer	oneLayer - rat 1	0	0.4222977	0.069259234	false
training	oneLayer	oneLayer - rat 1	0	0.4264737	0.059177414	false
training	oneLayer	oneLayer - rat 1	0	0.43053368	0.049375795	false
training	oneLayer	oneLayer - rat 1	0	0.43438023	0.040089432	false
training	oneLayer	oneLayer - rat 1	0	0.43438023	0.029742997	false
training	oneLayer	oneLayer - rat 1	0	0.430406	0.02014834	false
training	oneLayer	oneLayer - rat 1	0	0.42324325	0.012985609	false
training	oneLayer	oneLayer - rat 1	0	0.41605067	0.0057930155	false
training	oneLayer	oneLayer - rat 1	0	0.40611827	0.001678879	false
training	oneLayer	oneLayer - rat 1	0	0.39865652	-0.005782882	false
training	oneLayer	oneLayer - rat 1	0	0.3889038	-0.009822598	false
training	oneLayer	oneLayer - rat 1	0	0.38151717	-0.017209228	false
training	oneLayer	oneLayer - rat 1	0	0.37155065	-0.021337505	false
training	oneLayer	oneLayer - rat 1	0	0.36379063	-0.029097525	false
training	oneLayer	oneLayer - rat 1	0	0.35405946	-0.033128303	false
training	oneLayer	oneLayer - rat 1	0	0.34693092	-0.040256847	false
training	oneLayer	oneLayer - rat 1	0	0.33712605	-0.044318166	false
training	oneLayer	oneLayer - rat 1	0	0.32979393	-0.05165028	false
training	oneLayer	oneLayer - rat 1	0	0.31995124	-0.05572726	false
training	oneLayer	oneLayer - rat 1	0	0.31270018	-0.06297832	false
training	oneLayer	oneLayer - rat 1	0	0.30290547	-0.06703543	false
training	oneLayer	oneLayer - rat 1	0	0.2955579	-0.07438303	false
training	oneLayer	oneLayer - rat 1	0	0.28581777	-0.07841751	false
training	oneLayer	oneLayer - rat 1	0	0.2785572	-0.08567808	false
training	oneLayer	oneLayer - rat 1	0	0.26869616	-0.089762665	false
training	oneLayer	oneLayer - rat 1	0	0.26149455	-0.09696427	false
training	oneLayer	oneLayer - rat 1	0	0.2518166	-0.10097301	false
training	oneLayer	oneLayer - rat 1	0	0.24407515	-0.108714476	false
training	oneLayer	oneLayer - rat 1	0	0.23434542	-0.11274467	false
training	oneLayer	oneLayer - rat 1	0	0.22677353	-0.120316565	false
training	oneLayer	oneLayer - rat 1	0	0.21661156	-0.124525785	false
training	oneLayer	oneLayer - rat 1	0	0.20901208	-0.13212527	false
training	oneLayer	oneLayer - rat 1	0	0.1996076	-0.13602075	false
training	oneLayer	oneLayer - rat 1	0	0.19212933	-0.14349902	false
training	oneLayer	oneLayer - rat 1	0	0.18273687	-0.14738952	false
training	oneLayer	oneLayer - rat 1	0	0.17526472	-0.15486166	false
training	oneLayer	oneLayer - rat 1	0	0.1655306	-0.15889366	false
training	oneLayer	oneLayer - rat 1	0	0.15832193	-0.16610235	false
training	oneLayer	oneLayer - rat 1	0	0.14867917	-0.17009652	false
training	oneLayer	oneLayer - rat 1	0	0.14102967	-0.17774601	false
training	oneLayer	oneLayer - rat 1	0	0.1311187	-0.18185128	false
training	oneLayer	oneLayer - rat 1	0	0.12338422	-0.18958576	false
training	oneLayer	oneLayer - rat 1	0	0.11323125	-0.19379126	false
training	oneLayer	oneLayer - rat 1	0	0.10597659	-0.20104593	false
training	oneLayer	oneLayer - rat 1	0	0.09606296	-0.20515229	false
training	oneLayer	oneLayer - rat 1	0	0.08876381	-0.21245144	false
training	oneLayer	oneLayer - rat 1	0	0.07937763	-0.21633933	false
training	oneLayer	oneLayer - rat 1	0	0.07228605	-0.22343092	false
training	oneLayer	oneLayer - rat 1	0	0.062350344	-0.22754642	false
training	oneLayer	oneLayer - rat 1	0	0.05495742	-0.23493935	false
training	oneLayer	oneLayer - rat 1	0	0.044884283	-0.23911178	false
training	oneLayer	oneLayer - rat 1	0	0.037408732	-0.24658734	false
training	oneLayer	oneLayer - rat 1	0	0.027603531	-0.2506488	false
training	oneLayer	oneLayer - rat 1	0	0.02008663	-0.2581657	false
training	oneLayer	oneLayer - rat 1	0	0.01055823	-0.2621125	false
training	oneLayer	oneLayer - rat 1	0	0.003289368	-0.26938137	false
training	oneLayer	oneLayer - rat 1	0	-0.006269881	-0.27334094	false
training	oneLayer	oneLayer - rat 1	0	-0.013759561	-0.28083062	false
training	oneLayer	oneLayer - rat 1	0	-0.023322308	-0.28479165	false
training	oneLayer	oneLayer - rat 1	0	-0.030612417	-0.29208174	false
training	oneLayer	oneLayer - rat 1	0	-0.040215526	-0.2960595	false
training	oneLayer	oneLayer - rat 1	0	-0.047647193	-0.30349118	false
training	oneLayer	oneLayer - rat 1	0	-0.05751123	-0.30757698	false
training	oneLayer	oneLayer - rat 1	0	-0.06503605	-0.3151018	false
training	oneLayer	oneLayer - rat 1	0	-0.07489917	-0.31918725	false
training	oneLayer	oneLayer - rat 1	0	-0.08235049	-0.32663858	false
training	oneLayer	oneLayer - rat 1	0	-0.092179224	-0.3307098	false
training	oneLayer	oneLayer - rat 1	0	-0.09963378	-0.33816433	false
training	oneLayer	oneLayer - rat 1	0	-0.10908465	-0.342079	false
training	oneLayer	oneLayer - rat 1	0	-0.11640881	-0.3494032	false
training	oneLayer	oneLayer - rat 1	0	-0.12597823	-0.35336697	false
training	oneLayer	oneLayer - rat 1	0	-0.13335983	-0.3607486	false
training	oneLayer	oneLayer - rat 1	0	-0.14285016	-0.3646796	false
training	oneLayer	oneLayer - rat 1	0	-0.15021914	-0.3720486	false
training	oneLayer	oneLayer - rat 1	0	-0.15998355	-0.37609315	false
training	oneLayer	oneLayer - rat 1	0	-0.16945909	-0.38001806	false
training	oneLayer	oneLayer - rat 1	0	-0.17986205	-0.38001806	false
training	oneLayer	oneLayer - rat 1	0	-0.18923694	-0.38390127	false
training	oneLayer	oneLayer - rat 1	0	-0.20019083	-0.38390127	false
training	oneLayer	oneLayer - rat 1	0	-0.2099245	-0.38793308	false
training	oneLayer	oneLayer - rat 1	0	-0.22009273	-0.38793308	false
training	oneLayer	oneLayer - rat 1	0	-0.2294723	-0.39181823	false
training	oneLayer	oneLayer - rat 1	0	-0.23974307	-0.39181823	false
training	oneLayer	oneLayer - rat 1	0	-0.24942239	-0.38780895	false
training	oneLayer	oneLayer - rat 1	0	-0.25710875	-0.3801226	false
training	oneLayer	oneLayer - rat 1	0	-0.26485497	-0.37237635	false
training	oneLayer	oneLayer - rat 1	0	-0.2720191	-0.36521223	false
training	oneLayer	oneLayer - rat 1	0	-0.2792559	-0.35797542	false
training	oneLayer	oneLayer - rat 1	0	-0.28670904	-0.3505223	false
training	oneLayer	oneLayer - rat 1	0	-0.29424518	-0.34298617	false
training	oneLayer	oneLayer - rat 1	0	-0.30199116	-0.3352402	false
training	oneLayer	oneLayer - rat 1	0	-0.30957064	-0.3276607	false
training	oneLayer	oneLayer - rat 1	0	-0.31667334	-0.320558	false
training	oneLayer	oneLayer - rat 1	0	-0.32417917	-0.3130522	false
training	oneLayer	oneLayer - rat 1	0	-0.32802895	-0.30375803	false
training	oneLayer	oneLayer - rat 1	0	-0.33217272	-0.293754	false
training	oneLayer	oneLayer - rat 1	0	-0.3363472	-0.283676	false
training	oneLayer	oneLayer - rat 1	0	-0.3402125	-0.27434435	false
training	oneLayer	oneLayer - rat 1	0	-0.34423506	-0.26463303	false
training	oneLayer	oneLayer - rat 1	0	-0.34842363	-0.25452092	false
training	oneLayer	oneLayer - rat 1	0	-0.35259157	-0.24445859	false
training	oneLayer	oneLayer - rat 1	0	-0.3567615	-0.23439158	false
training	oneLayer	oneLayer - rat 1	0	-0.36094838	-0.2242835	false
training	oneLayer	oneLayer - rat 1	0	-0.36480692	-0.2149682	false
training	oneLayer	oneLayer - rat 1	0	-0.36884546	-0.20521829	false
training	oneLayer	oneLayer - rat 1	0	-0.37290064	-0.19542822	false
training	oneLayer	oneLayer - rat 1	0	-0.3767301	-0.18618308	false
training	oneLayer	oneLayer - rat 1	0	-0.38060725	-0.17682284	false
training	oneLayer	oneLayer - rat 1	0	-0.384479	-0.16747564	false
training	oneLayer	oneLayer - rat 1	0	-0.38863626	-0.1574391	false
training	oneLayer	oneLayer - rat 1	0	-0.39283118	-0.14731166	false
training	oneLayer	oneLayer - rat 1	0	-0.3968761	-0.13754642	false
training	oneLayer	oneLayer - rat 1	0	-0.4010665	-0.12742986	false
training	oneLayer	oneLayer - rat 1	0	-0.4050353	-0.11784835	false
training	oneLayer	oneLayer - rat 1	0	-0.40923536	-0.10770854	false
training	oneLayer	oneLayer - rat 1	0	-0.41344374	-0.09754855	false
training	oneLayer	oneLayer - rat 1	0	-0.41751567	-0.08771808	false
training	oneLayer	oneLayer - rat 1	0	-0.42163083	-0.07778319	false
training	oneLayer	oneLayer - rat 1	0	-0.42553565	-0.06835614	false
training	oneLayer	oneLayer - rat 1	0	-0.42966136	-0.058395777	false
training	oneLayer	oneLayer - rat 1	0	-0.43369034	-0.048668984	false
training	oneLayer	oneLayer - rat 1	0	-0.43773806	-0.03889696	false
training	oneLayer	oneLayer - rat 1	0	-0.43773806	-0.028177612	false
training	oneLayer	oneLayer - rat 1	0	-0.43363705	-0.018276906	false
training	oneLayer	oneLayer - rat 1	0	-0.4297443	-0.008878934	false
training	oneLayer	oneLayer - rat 1	0	-0.4255861	0.0011597995	false
training	oneLayer	oneLayer - rat 1	0	-0.4216282	0.010715044	false
training	oneLayer	oneLayer - rat 1	0	-0.4177715	0.020025978	false
training	oneLayer	oneLayer - rat 1	0	-0.41393542	0.029287094	false
training	oneLayer	oneLayer - rat 1	0	-0.40988955	0.039054643	false
training	oneLayer	oneLayer - rat 1	0	-0.4057688	0.04900304	false
training	oneLayer	oneLayer - rat 1	0	-0.40180635	0.058569267	false
training	oneLayer	oneLayer - rat 1	0	-0.39780277	0.06823473	false
training	oneLayer	oneLayer - rat 1	0	-0.3938691	0.077731505	false
training	oneLayer	oneLayer - rat 1	0	-0.38999656	0.08708064	false
training	oneLayer	oneLayer - rat 1	0	-0.38597816	0.096781924	false
training	oneLayer	oneLayer - rat 1	0	-0.38212648	0.1060807	false
training	oneLayer	oneLayer - rat 1	0	-0.3780581	0.1159026	false
training	oneLayer	oneLayer - rat 1	0	-0.3741146	0.1254231	false
training	oneLayer	oneLayer - rat 1	0	-0.37016964	0.13494706	false
training	oneLayer	oneLayer - rat 1	0	-0.36598417	0.14505169	false
training	oneLayer	oneLayer - rat 1	0	-0.3618691	0.15498635	false
training	oneLayer	oneLayer - rat 1	0	-0.35791582	0.16453041	false
training	oneLayer	oneLayer - rat 1	0	-0.35408872	0.17376988	false
training	oneLayer	oneLayer - rat 1	0	-0.34997386	0.18370403	false
training	oneLayer	oneLayer - rat 1	0	-0.34607333	0.19312078	false
training	oneLayer	oneLayer - rat 1	0	-0.34214047	0.2026155	false
training	oneLayer	oneLayer - rat 1	0	-0.33808646	0.21240278	false
training	oneLayer	oneLayer - rat 1	0	-0.3342475	0.22167085	false
training	oneLayer	oneLayer - rat 1	0	-0.33028746	0.23123126	false
training	oneLayer	oneLayer - rat 1	0	-0.32624134	0.24099945	false
training	oneLayer	oneLayer - rat 1	0	-0.3221896	0.2507812	false
training	oneLayer	oneLayer - rat 1	0	-0.3181237	0.26059717	false
training	oneLayer	oneLayer - rat 1	0	-0.3181237	0.27106047	false
training	oneLayer	oneLayer - rat 1	0	-0.3140677	0.28085256	false
training	oneLayer	oneLayer - rat 1	0	-0.30641812	0.28850213	false
training	oneLayer	oneLayer - rat 1	0	-0.29633415	0.29267904	false
training	oneLayer	oneLayer - rat 1	0	-0.28619567	0.29267904	false
training	oneLayer	oneLayer - rat 1	0	-0.27566683	0.29267904	false
training	oneLayer	oneLayer - rat 1	0	-0.26540646	0.29267904	false
training	oneLayer	oneLayer - rat 1	0	-0.25522596	0.29267904	false
training	oneLayer	oneLayer - rat 1	0	-0.24522227	0.2885354	false
training	oneLayer	oneLayer - rat 1	0	-0.23760529	0.28091842	false
training	oneLayer	oneLayer - rat 1	0	-0.22808458	0.2769748	false
training	oneLayer	oneLayer - rat 1	0	-0.21719523	0.2769748	false
training	oneLayer	oneLayer - rat 1	0	-0.20704584	0.2727708	false
training	oneLayer	oneLayer - rat 1	0	-0.19679214	0.2727708	false
training	oneLayer	oneLayer - rat 1	0	-0.18690035	0.26867348	false
training	oneLayer	oneLayer - rat 1	0	-0.17681767	0.26867348	false
training	oneLayer	oneLayer - rat 1	0	-0.16740374	0.2647741	false
training	oneLayer	oneLayer - rat 1	0	-0.15661204	0.2647741	false
training	oneLayer	oneLayer - rat 1	0	-0.14722915	0.2608876	false
training	oneLayer	oneLayer - rat 1	0	-0.13699082	0.2608876	false
training	oneLayer	oneLayer - rat 1	0	-0.12716278	0.2568167	false
training	oneLayer	oneLayer - rat 1	0	-0.116225906	0.2568167	false
training	oneLayer	oneLayer - rat 1	0	-0.106081344	0.25261468	false
training	oneLayer	oneLayer - rat 1	0	-0.0960103	0.25261468	false
training	oneLayer	oneLayer - rat 1	0	-0.086672485	0.24874683	false
training	oneLayer	oneLayer - rat 1	0	-0.076185256	0.24874683	false
training	oneLayer	oneLayer - rat 1	0	-0.06608202	0.24456193	false
training	oneLayer	oneLayer - rat 1	0	-0.05561411	0.24456194	false
training	oneLayer	oneLayer - rat 1	0	-0.04589602	0.24053657	false
training	oneLayer	oneLayer - rat 1	0	-0.03547834	0.24053657	false
training	oneLayer	oneLayer - rat 1	0	-0.026076267	0.2366421	false
training	oneLayer	oneLayer - rat 1	0	-0.015091275	0.2366421	false
training	oneLayer	oneLayer - rat 1	0	-0.0053627007	0.2326124	false
training	oneLayer	oneLayer - rat 1	0	0.005383565	0.23261242	false
training	oneLayer	oneLayer - rat 1	0	0.015496885	0.22842334	false
training	oneLayer	oneLayer - rat 1	0	0.02614109	0.22842334	false
training	oneLayer	oneLayer - rat 1	0	0.036025893	0.22432892	false
training	oneLayer	oneLayer - rat 1	0	0.046073638	0.22432892	false
training	oneLayer	oneLayer - rat 1	0	0.056213815	0.22012873	false
training	oneLayer	oneLayer - rat 1	0	0.067087404	0.22012873	false
training	oneLayer	oneLayer - rat 1	0	0.07700563	0.21602046	false
training	oneLayer	oneLayer - rat 1	0	0.08766825	0.21602046	false
training	oneLayer	oneLayer - rat 1	0	0.0973196	0.21202275	false
training	oneLayer	oneLayer - rat 1	0	0.10778603	0.21202275	false
training	oneLayer	oneLayer - rat 1	0	0.117919505	0.20782533	false
training	oneLayer	oneLayer - rat 1	0	0.12807128	0.20782533	false
training	oneLayer	oneLayer - rat 1	0	0.13746046	0.2039362	false
training	oneLayer	oneLayer - rat 1	0	0.14756948	0.2039362	false
training	oneLayer	oneLayer - rat 1	0	0.15724084	0.19993019	false
training	oneLayer	oneLayer - rat 1	0	0.16763799	0.1999302	false
training	oneLayer	oneLayer - rat 1	0	0.17694986	0.1960731	false
training	oneLayer	oneLayer - rat 1	0	0.1877604	0.1960731	false
training	oneLayer	oneLayer - rat 1	0	0.19762908	0.19198537	false
training	oneLayer	oneLayer - rat 1	0	0.20846337	0.19198537	false
training	oneLayer	oneLayer - rat 1	0	0.21820334	0.18795094	false
training	oneLayer	oneLayer - rat 1	0	0.2288506	0.18795094	false
training	oneLayer	oneLayer - rat 1	0	0.23838212	0.18400286	false
training	oneLayer	oneLayer - rat 1	0	0.2492159	0.18400286	false
training	oneLayer	oneLayer - rat 1	0	0.2586939	0.18007694	false
training	oneLayer	oneLayer - rat 1	0	0.26902238	0.18007696	false
training	oneLayer	oneLayer - rat 1	0	0.27878174	0.1760345	false
training	oneLayer	oneLayer - rat 1	0	0.28954855	0.1760345	false
training	oneLayer	oneLayer - rat 1	0	0.2991995	0.17203695	false
training	oneLayer	oneLayer - rat 1	0	0.30939943	0.17203695	false
training	oneLayer	oneLayer - rat 1	0	0.31873554	0.1681698	false
training	oneLayer	oneLayer - rat 1	0	0.32887802	0.1681698	false
training	oneLayer	oneLayer - rat 1	0	0.33840984	0.1642216	false
training	oneLayer	oneLayer - rat 1	0	0.3461044	0.15652701	false
training	oneLayer	oneLayer - rat 1	0	0.3538423	0.14878915	false
training	oneLayer	oneLayer - rat 1	0	0.36117265	0.14145878	false
training	oneLayer	oneLayer - rat 1	0	0.36865148	0.13397995	false
training	oneLayer	oneLayer - rat 1	0	0.3758418	0.12678966	false
training	oneLayer	oneLayer - rat 1	0	0.38306746	0.11956399	false
training	oneLayer	oneLayer - rat 1	0	0.3904414	0.11219006	false
training	oneLayer	oneLayer - rat 1	0	0.39819145	0.10444	false
training	oneLayer	oneLayer - rat 1	0	0.40592477	0.09670669	false
training	oneLayer	oneLayer - rat 1	0	0.4130867	0.08954473	false
training	oneLayer	oneLayer - rat 1	0	0.42054704	0.08208442	false
training	oneLayer	oneLayer - rat 1	0	0.4279448	0.07468664	false
training	oneLayer	oneLayer - rat 1	0	0.4351784	0.06745307	false
training	oneLayer	oneLayer - rat 1	0	0.43931246	0.05747252	false
training	oneLayer	oneLayer - rat 1	0	0.44321316	0.048055407	false
training	oneLayer	oneLayer - rat 1	0	0.44321316	0.03780174	false
training	oneLayer	oneLayer - rat 1	0	0.4391338	0.027953269	false
training	oneLayer	oneLayer - rat 1	0	0.43205854	0.020878015	false
training	oneLayer	oneLayer - rat 1	0	0.42251265	0.016923977	false
training	oneLayer	oneLayer - rat 1	0	0.41193682	0.016923977	false
training	oneLayer	oneLayer - rat 1	0	0.40214416	0.012867727	false
training	oneLayer	oneLayer - rat 1	0	0.39185497	0.012867726	false
training	oneLayer	oneLayer - rat 1	0	0.38259867	0.00903364	false
training	oneLayer	oneLayer - rat 1	0	0.37176937	0.009033639	false
training	oneLayer	oneLayer - rat 1	0	0.36205232	0.0050087017	false
training	oneLayer	oneLayer - rat 1	0	0.35109904	0.005008701	false
training	oneLayer	oneLayer - rat 1	0	0.34098765	8.204304E-4	false
training	oneLayer	oneLayer - rat 1	0	0.33019775	8.204295E-4	false
training	oneLayer	oneLayer - rat 1	0	0.32094863	-0.003010684	false
training	oneLayer	oneLayer - rat 1	0	0.31081024	-0.0030106849	false
training	oneLayer	oneLayer - rat 1	0	0.30150744	-0.0068640304	false
training	oneLayer	oneLayer - rat 1	0	0.29133198	-0.0068640313	false
training	oneLayer	oneLayer - rat 1	0	0.28175065	-0.010832756	false
training	oneLayer	oneLayer - rat 1	0	0.27120343	-0.010832757	false
training	oneLayer	oneLayer - rat 1	0	0.26113242	-0.015004302	false
training	oneLayer	oneLayer - rat 1	0	0.25067613	-0.015004303	false
training	oneLayer	oneLayer - rat 1	0	0.24075189	-0.019115057	false
training	oneLayer	oneLayer - rat 1	0	0.2297576	-0.019115059	false
training	oneLayer	oneLayer - rat 1	0	0.22025229	-0.023052294	false
training	oneLayer	oneLayer - rat 1	0	0.2096274	-0.023052294	false
training	oneLayer	oneLayer - rat 1	0	0.20026481	-0.02693041	false
training	oneLayer	oneLayer - rat 1	0	0.1896435	-0.026930412	false
training	oneLayer	oneLayer - rat 1	0	0.17965242	-0.031068858	false
training	oneLayer	oneLayer - rat 1	0	0.1695529	-0.031068858	false
training	oneLayer	oneLayer - rat 1	0	0.15959424	-0.035193875	false
training	oneLayer	oneLayer - rat 1	0	0.14894766	-0.035193875	false
training	oneLayer	oneLayer - rat 1	0	0.13908422	-0.039279446	false
training	oneLayer	oneLayer - rat 1	0	0.12862366	-0.039279446	false
training	oneLayer	oneLayer - rat 1	0	0.11870395	-0.043388333	false
training	oneLayer	oneLayer - rat 1	0	0.10867094	-0.043388333	false
training	oneLayer	oneLayer - rat 1	0	0.09862764	-0.047548406	false
training	oneLayer	oneLayer - rat 1	0	0.0884132	-0.047548406	false
training	oneLayer	oneLayer - rat 1	0	0.07899544	-0.051449377	false
training	oneLayer	oneLayer - rat 1	0	0.068170376	-0.051449377	false
training	oneLayer	oneLayer - rat 1	0	0.05812285	-0.055611197	false
training	oneLayer	oneLayer - rat 1	0	0.04810502	-0.0556112	false
training	oneLayer	oneLayer - rat 1	0	0.03822369	-0.05970418	false
training	oneLayer	oneLayer - rat 1	0	0.028003395	-0.05970418	false
training	oneLayer	oneLayer - rat 1	0	0.018141605	-0.06378907	false
training	oneLayer	oneLayer - rat 1	0	0.0074443812	-0.06378907	false
training	oneLayer	oneLayer - rat 1	0	-0.0024685918	-0.06789516	false
training	oneLayer	oneLayer - rat 1	0	-0.01310109	-0.06789516	false
training	oneLayer	oneLayer - rat 1	0	-0.022453997	-0.07176927	false
training	oneLayer	oneLayer - rat 1	0	-0.03333679	-0.07176927	false
training	oneLayer	oneLayer - rat 1	0	-0.042977165	-0.07576244	false
training	oneLayer	oneLayer - rat 1	0	-0.05371826	-0.07576244	false
training	oneLayer	oneLayer - rat 1	0	-0.06384162	-0.079955675	false
training	oneLayer	oneLayer - rat 1	0	-0.07446831	-0.079955675	false
training	oneLayer	oneLayer - rat 1	0	-0.083788194	-0.083816096	false
training	oneLayer	oneLayer - rat 1	0	-0.09477946	-0.083816096	false
training	oneLayer	oneLayer - rat 1	0	-0.10491589	-0.088014744	false
training	oneLayer	oneLayer - rat 1	0	-0.11566534	-0.08801475	false
training	oneLayer	oneLayer - rat 1	0	-0.12574422	-0.09218956	false
training	oneLayer	oneLayer - rat 1	0	-0.13622232	-0.092189565	false
training	oneLayer	oneLayer - rat 1	0	-0.14607555	-0.096270904	false
training	oneLayer	oneLayer - rat 1	0	-0.1564855	-0.096270904	false
training	oneLayer	oneLayer - rat 1	0	-0.16591305	-0.100175925	false
training	oneLayer	oneLayer - rat 1	0	-0.1761658	-0.10017593	false
training	oneLayer	oneLayer - rat 1	0	-0.18607469	-0.10428033	false
training	oneLayer	oneLayer - rat 1	0	-0.19617684	-0.10428033	false
training	oneLayer	oneLayer - rat 1	0	-0.20601387	-0.10835496	false
training	oneLayer	oneLayer - rat 1	0	-0.21644789	-0.10835496	false
training	oneLayer	oneLayer - rat 1	0	-0.22590084	-0.10443942	false
training	oneLayer	oneLayer - rat 1	0	-0.23517899	-0.10059629	false
training	oneLayer	oneLayer - rat 1	0	-0.24526827	-0.096417174	false
training	oneLayer	oneLayer - rat 1	0	-0.25481656	-0.092462145	false
training	oneLayer	oneLayer - rat 1	0	-0.26439947	-0.088492766	false
training	oneLayer	oneLayer - rat 1	0	-0.2741579	-0.0844507	false
training	oneLayer	oneLayer - rat 1	0	-0.28407598	-0.0803425	false
training	oneLayer	oneLayer - rat 1	0	-0.2942237	-0.076139174	false
training	oneLayer	oneLayer - rat 1	0	-0.30376914	-0.072185315	false
training	oneLayer	oneLayer - rat 1	0	-0.31322506	-0.06826855	false
training	oneLayer	oneLayer - rat 1	0	-0.32325992	-0.06411197	false
training	oneLayer	oneLayer - rat 1	0	-0.33325878	-0.05997031	false
training	oneLayer	oneLayer - rat 1	0	-0.34335247	-0.055789378	false
training	oneLayer	oneLayer - rat 1	0	-0.35297126	-0.05180514	false
training	oneLayer	oneLayer - rat 1	0	-0.36223918	-0.04796625	false
training	oneLayer	oneLayer - rat 1	0	-0.37220535	-0.043838117	false
training	oneLayer	oneLayer - rat 1	0	-0.38173407	-0.0398912	false
training	oneLayer	oneLayer - rat 1	0	-0.39155272	-0.035824183	false
training	oneLayer	oneLayer - rat 1	0	-0.401104	-0.031867906	false
training	oneLayer	oneLayer - rat 1	0	-0.41043225	-0.028004028	false
training	oneLayer	oneLayer - rat 1	0	-0.41798264	-0.020453643	false
training	oneLayer	oneLayer - rat 1	0	-0.42185977	-0.011093427	false
training	oneLayer	oneLayer - rat 1	0	-0.42185977	-1.249317E-4	false
training	oneLayer	oneLayer - rat 1	0	-0.4179021	0.009429666	false
training	oneLayer	oneLayer - rat 1	0	-0.4105031	0.01682868	false
training	oneLayer	oneLayer - rat 1	0	-0.40053454	0.020957794	false
training	oneLayer	oneLayer - rat 1	0	-0.38963932	0.020957794	false
training	oneLayer	oneLayer - rat 1	0	-0.37957752	0.020957794	false
training	oneLayer	oneLayer - rat 1	0	-0.3688329	0.020957794	false
training	oneLayer	oneLayer - rat 1	0	-0.35857093	0.020957794	false
training	oneLayer	oneLayer - rat 1	0	-0.3480413	0.020957794	false
training	oneLayer	oneLayer - rat 1	0	-0.33742723	0.020957794	false
training	oneLayer	oneLayer - rat 1	0	-0.3269249	0.020957794	false
training	oneLayer	oneLayer - rat 1	0	-0.31650347	0.020957794	false
training	oneLayer	oneLayer - rat 1	0	-0.30584458	0.020957794	false
training	oneLayer	oneLayer - rat 1	0	-0.29549915	0.020957794	false
training	oneLayer	oneLayer - rat 1	0	-0.2848974	0.020957794	false
training	oneLayer	oneLayer - rat 1	0	-0.27448344	0.020957794	false
training	oneLayer	oneLayer - rat 1	0	-0.26411003	0.020957794	false
training	oneLayer	oneLayer - rat 1	0	-0.25322688	0.020957794	false
training	oneLayer	oneLayer - rat 1	0	-0.2426105	0.020957794	false
training	oneLayer	oneLayer - rat 1	0	-0.23197082	0.020957794	false
training	oneLayer	oneLayer - rat 1	0	-0.2218881	0.020957794	false
training	oneLayer	oneLayer - rat 1	0	-0.21090475	0.020957794	false
training	oneLayer	oneLayer - rat 1	0	-0.2006713	0.020957794	false
training	oneLayer	oneLayer - rat 1	0	-0.1905653	0.020957794	false
training	oneLayer	oneLayer - rat 1	0	-0.18044658	0.020957794	false
training	oneLayer	oneLayer - rat 1	0	-0.17038573	0.020957794	false
training	oneLayer	oneLayer - rat 1	0	-0.15961693	0.020957794	false
training	oneLayer	oneLayer - rat 1	0	-0.14902198	0.020957794	false
training	oneLayer	oneLayer - rat 1	0	-0.13828357	0.020957794	false
training	oneLayer	oneLayer - rat 1	0	-0.12827152	0.020957794	false
training	oneLayer	oneLayer - rat 1	0	-0.118240066	0.020957794	false
training	oneLayer	oneLayer - rat 1	0	-0.10820511	0.020957794	false
training	oneLayer	oneLayer - rat 1	0	-0.097305536	0.020957794	false
training	oneLayer	oneLayer - rat 1	0	-0.086464755	0.020957794	false
training	oneLayer	oneLayer - rat 1	0	-0.07601573	0.020957794	false
training	oneLayer	oneLayer - rat 1	0	-0.06552366	0.020957794	false
training	oneLayer	oneLayer - rat 1	0	-0.055395775	0.020957794	false
training	oneLayer	oneLayer - rat 1	0	-0.045008514	0.020957794	false
training	oneLayer	oneLayer - rat 1	0	-0.034276616	0.020957794	false
training	oneLayer	oneLayer - rat 1	0	-0.023434013	0.020957794	false
training	oneLayer	oneLayer - rat 1	0	-0.012726448	0.020957794	false
training	oneLayer	oneLayer - rat 1	0	-0.0017777322	0.020957794	false
training	oneLayer	oneLayer - rat 1	0	0.008835743	0.020957794	false
training	oneLayer	oneLayer - rat 1	0	0.019229325	0.020957794	false
training	oneLayer	oneLayer - rat 1	0	0.02999692	0.020957794	false
training	oneLayer	oneLayer - rat 1	0	0.04004491	0.020957794	false
training	oneLayer	oneLayer - rat 1	0	0.050296273	0.020957794	false
training	oneLayer	oneLayer - rat 1	0	0.061123893	0.020957794	false
training	oneLayer	oneLayer - rat 1	0	0.07171945	0.020957794	false
training	oneLayer	oneLayer - rat 1	0	0.08179479	0.020957794	false
training	oneLayer	oneLayer - rat 1	0	0.09188049	0.020957794	false
training	oneLayer	oneLayer - rat 1	0	0.10226094	0.020957794	false
training	oneLayer	oneLayer - rat 1	0	0.112375714	0.020957794	false
training	oneLayer	oneLayer - rat 1	0	0.122840956	0.020957794	false
training	oneLayer	oneLayer - rat 1	0	0.13371243	0.020957794	false
training	oneLayer	oneLayer - rat 1	0	0.14395209	0.020957794	false
training	oneLayer	oneLayer - rat 1	0	0.1546939	0.020957794	false
training	oneLayer	oneLayer - rat 1	0	0.16492784	0.020957794	false
training	oneLayer	oneLayer - rat 1	0	0.17570528	0.020957794	false
training	oneLayer	oneLayer - rat 1	0	0.18609416	0.020957794	false
training	oneLayer	oneLayer - rat 1	0	0.19697885	0.020957794	false
training	oneLayer	oneLayer - rat 1	0	0.2074221	0.020957794	false
training	oneLayer	oneLayer - rat 1	0	0.2177341	0.020957794	false
training	oneLayer	oneLayer - rat 1	0	0.22810675	0.020957794	false
training	oneLayer	oneLayer - rat 1	0	0.238954	0.020957794	false
training	oneLayer	oneLayer - rat 1	0	0.24956362	0.020957794	false
training	oneLayer	oneLayer - rat 1	0	0.2605098	0.020957794	false
training	oneLayer	oneLayer - rat 1	0	0.27085307	0.020957794	false
training	oneLayer	oneLayer - rat 1	0	0.28104928	0.020957794	false
training	oneLayer	oneLayer - rat 1	0	0.2916933	0.020957794	false
training	oneLayer	oneLayer - rat 1	0	0.30201468	0.020957794	false
training	oneLayer	oneLayer - rat 1	0	0.312707	0.020957794	false
training	oneLayer	oneLayer - rat 1	0	0.3228546	0.020957794	false
training	oneLayer	oneLayer - rat 1	0	0.3333888	0.020957794	false
training	oneLayer	oneLayer - rat 1	0	0.3434305	0.020957794	false
training	oneLayer	oneLayer - rat 1	0	0.35348395	0.020957794	false
training	oneLayer	oneLayer - rat 1	0	0.36436966	0.020957794	false
training	oneLayer	oneLayer - rat 1	0	0.37494966	0.020957794	false
training	oneLayer	oneLayer - rat 1	0	0.38514355	0.020957794	false
training	oneLayer	oneLayer - rat 1	0	0.39547592	0.020957794	false
training	oneLayer	oneLayer - rat 1	0	0.40641236	0.020957794	false
training	oneLayer	oneLayer - rat 1	0	0.41614643	0.02498978	false
training	oneLayer	oneLayer - rat 1	0	0.4233091	0.032152455	false
training	oneLayer	oneLayer - rat 1	0	0.42728493	0.041750934	false
training	oneLayer	oneLayer - rat 1	0	0.42728493	0.052127138	false
training	oneLayer	oneLayer - rat 1	0	0.4311294	0.061408512	false
training	oneLayer	oneLayer - rat 1	0	0.4311294	0.07225516	false
training	oneLayer	oneLayer - rat 1	0	0.43497744	0.08154519	false
training	oneLayer	oneLayer - rat 1	0	0.43497744	0.0924362	false
training	oneLayer	oneLayer - rat 1	0	0.43106008	0.1018936	false
training	oneLayer	oneLayer - rat 1	0	0.43106008	0.11203971	false
training	oneLayer	oneLayer - rat 1	0	0.42690763	0.122064605	false
training	oneLayer	oneLayer - rat 1	0	0.4269076	0.13283591	false
training	oneLayer	oneLayer - rat 1	0	0.42301714	0.14222834	false
training	oneLayer	oneLayer - rat 1	0	0.42301714	0.15240191	false
training	oneLayer	oneLayer - rat 1	0	0.41917598	0.16167532	false
training	oneLayer	oneLayer - rat 1	0	0.41917598	0.17185673	false
training	oneLayer	oneLayer - rat 1	0	0.41522092	0.18140508	false
training	oneLayer	oneLayer - rat 1	0	0.4075248	0.18910122	false
training	oneLayer	oneLayer - rat 1	0	0.40010828	0.19651772	false
training	oneLayer	oneLayer - rat 1	0	0.39065433	0.20043367	false
training	oneLayer	oneLayer - rat 1	0	0.3810587	0.20440832	false
training	oneLayer	oneLayer - rat 1	0	0.3717467	0.20826547	false
training	oneLayer	oneLayer - rat 1	0	0.36213765	0.21224567	false
training	oneLayer	oneLayer - rat 1	0	0.35197967	0.21645324	false
training	oneLayer	oneLayer - rat 1	0	0.3418384	0.22065389	false
training	oneLayer	oneLayer - rat 1	0	0.33256596	0.22449467	false
training	oneLayer	oneLayer - rat 1	0	0.32263523	0.2286081	false
training	oneLayer	oneLayer - rat 1	0	0.3128306	0.23266931	false
training	oneLayer	oneLayer - rat 1	0	0.30278215	0.23683152	false
training	oneLayer	oneLayer - rat 1	0	0.29338437	0.24072419	false
training	oneLayer	oneLayer - rat 1	0	0.28365877	0.24475268	false
training	oneLayer	oneLayer - rat 1	0	0.27412522	0.2487016	false
training	oneLayer	oneLayer - rat 1	0	0.26419204	0.25281605	false
training	oneLayer	oneLayer - rat 1	0	0.25456157	0.25680512	false
training	oneLayer	oneLayer - rat 1	0	0.24468297	0.26089698	false
training	oneLayer	oneLayer - rat 1	0	0.23534113	0.26476648	false
training	oneLayer	oneLayer - rat 1	0	0.22573194	0.26874673	false
training	oneLayer	oneLayer - rat 1	0	0.21606065	0.27275273	false
training	oneLayer	oneLayer - rat 1	0	0.20609567	0.27688035	false
training	oneLayer	oneLayer - rat 1	0	0.19628914	0.28094235	false
training	oneLayer	oneLayer - rat 1	0	0.1864105	0.2850342	false
training	oneLayer	oneLayer - rat 1	0	0.17695616	0.28895032	false
training	oneLayer	oneLayer - rat 1	0	0.16748273	0.29287437	false
training	oneLayer	oneLayer - rat 1	0	0.15808845	0.2967656	false
training	oneLayer	oneLayer - rat 1	0	0.14821589	0.30085495	false
training	oneLayer	oneLayer - rat 1	0	0.13811105	0.3050405	false
training	oneLayer	oneLayer - rat 1	0	0.12827723	0.3091138	false
training	oneLayer	oneLayer - rat 1	0	0.11881691	0.3130324	false
training	oneLayer	oneLayer - rat 1	0	0.10889961	0.31714028	false
training	oneLayer	oneLayer - rat 1	0	0.09913968	0.32118297	false
training	oneLayer	oneLayer - rat 1	0	0.088884935	0.32118297	false
training	oneLayer	oneLayer - rat 1	0	0.07810299	0.32118297	false
training	oneLayer	oneLayer - rat 1	0	0.06710322	0.32118297	false
training	oneLayer	oneLayer - rat 1	0	0.056215074	0.32118297	false
training	oneLayer	oneLayer - rat 1	0	0.046033375	0.32118297	false
training	oneLayer	oneLayer - rat 1	0	0.035613414	0.32118297	false
training	oneLayer	oneLayer - rat 1	0	0.024636514	0.32118297	false
training	oneLayer	oneLayer - rat 1	0	0.014408152	0.32118297	false
training	oneLayer	oneLayer - rat 1	0	0.004035051	0.32118297	false
training	oneLayer	oneLayer - rat 1	0	-0.0061460184	0.32118297	false
training	oneLayer	oneLayer - rat 1	0	-0.01670892	0.32118297	false
training	oneLayer	oneLayer - rat 1	0	-0.026925351	0.32118297	false
training	oneLayer	oneLayer - rat 1	0	-0.0377099	0.32118297	false
training	oneLayer	oneLayer - rat 1	0	-0.048035014	0.32118297	false
training	oneLayer	oneLayer - rat 1	0	-0.058402326	0.32118297	false
training	oneLayer	oneLayer - rat 1	0	-0.06933915	0.32118297	false
training	oneLayer	oneLayer - rat 1	0	-0.08027264	0.32118297	false
training	oneLayer	oneLayer - rat 1	0	-0.09124874	0.32118294	false
training	oneLayer	oneLayer - rat 1	0	-0.101382315	0.32118294	false
training	oneLayer	oneLayer - rat 1	0	-0.111871384	0.32118294	false
training	oneLayer	oneLayer - rat 1	0	-0.121888176	0.32118294	false
training	oneLayer	oneLayer - rat 1	0	-0.13279027	0.32118294	false
training	oneLayer	oneLayer - rat 1	0	-0.14354363	0.32118294	false
training	oneLayer	oneLayer - rat 1	0	-0.15361738	0.32118294	false
training	oneLayer	oneLayer - rat 1	0	-0.16450927	0.32118294	false
training	oneLayer	oneLayer - rat 1	0	-0.17466813	0.32118294	false
training	oneLayer	oneLayer - rat 1	0	-0.18534288	0.32118294	false
training	oneLayer	oneLayer - rat 1	0	-0.1956713	0.32118294	false
training	oneLayer	oneLayer - rat 1	0	-0.205867	0.32118294	false
training	oneLayer	oneLayer - rat 1	0	-0.21624604	0.32118294	false
training	oneLayer	oneLayer - rat 1	0	-0.22720267	0.32118294	false
training	oneLayer	oneLayer - rat 1	0	-0.23734725	0.32118294	false
training	oneLayer	oneLayer - rat 1	0	-0.24738127	0.32118294	false
training	oneLayer	oneLayer - rat 1	0	-0.25813112	0.32118294	false
training	oneLayer	oneLayer - rat 1	0	-0.26842332	0.32118294	false
training	oneLayer	oneLayer - rat 1	0	-0.2784934	0.32118294	false
training	oneLayer	oneLayer - rat 1	0	-0.28813943	0.31718743	false
training	oneLayer	oneLayer - rat 1	0	-0.29552203	0.3098048	false
training	oneLayer	oneLayer - rat 1	0	-0.3052125	0.30579087	false
training	oneLayer	oneLayer - rat 1	0	-0.31296834	0.29803503	false
training	oneLayer	oneLayer - rat 1	0	-0.3223045	0.29416788	false
training	oneLayer	oneLayer - rat 1	0	-0.3296471	0.28682524	false
training	oneLayer	oneLayer - rat 1	0	-0.33901224	0.28294608	false
training	oneLayer	oneLayer - rat 1	0	-0.34659263	0.27536568	false
training	oneLayer	oneLayer - rat 1	0	-0.35655192	0.2712404	false
training	oneLayer	oneLayer - rat 1	0	-0.36381266	0.26397967	false
training	oneLayer	oneLayer - rat 1	0	-0.36772734	0.25452876	false
training	oneLayer	oneLayer - rat 1	0	-0.37172017	0.24488924	false
training	oneLayer	oneLayer - rat 1	0	-0.37590975	0.23477466	false
training	oneLayer	oneLayer - rat 1	0	-0.3797941	0.22539705	false
training	oneLayer	oneLayer - rat 1	0	-0.38392222	0.21543086	false
training	oneLayer	oneLayer - rat 1	0	-0.38781464	0.20603372	false
training	oneLayer	oneLayer - rat 1	0	-0.39193723	0.19608095	false
training	oneLayer	oneLayer - rat 1	0	-0.39590758	0.18649565	false
training	oneLayer	oneLayer - rat 1	0	-0.39984882	0.17698064	false
training	oneLayer	oneLayer - rat 1	0	-0.4039794	0.16700855	false
training	oneLayer	oneLayer - rat 1	0	-0.4079633	0.15739055	false
training	oneLayer	oneLayer - rat 1	0	-0.4118451	0.14801909	false
training	oneLayer	oneLayer - rat 1	0	-0.41591015	0.1382051	false
training	oneLayer	oneLayer - rat 1	0	-0.41991496	0.12853663	false
training	oneLayer	oneLayer - rat 1	0	-0.42374507	0.11928996	false
training	oneLayer	oneLayer - rat 1	0	-0.4275847	0.11002028	false
training	oneLayer	oneLayer - rat 1	0	-0.43159783	0.10033169	false
training	oneLayer	oneLayer - rat 1	0	-0.435751	0.09030505	false
training	oneLayer	oneLayer - rat 1	0	-0.43982008	0.08048141	false
training	oneLayer	oneLayer - rat 1	0	-0.44392896	0.07056175	false
training	oneLayer	oneLayer - rat 1	0	-0.44791114	0.06094786	false
training	oneLayer	oneLayer - rat 1	0	-0.45201498	0.051040296	false
training	oneLayer	oneLayer - rat 1	0	-0.45201498	0.04012518	false
training	oneLayer	oneLayer - rat 1	0	-0.447866	0.030108599	false
training	oneLayer	oneLayer - rat 1	0	-0.44372365	0.020108128	false
training	oneLayer	oneLayer - rat 1	0	-0.43958983	0.010128223	false
training	oneLayer	oneLayer - rat 1	0	-0.4324291	0.0029674799	false
training	oneLayer	oneLayer - rat 1	0	-0.42839652	-0.006768045	false
training	oneLayer	oneLayer - rat 1	0	-0.42095077	-0.014213774	false
training	oneLayer	oneLayer - rat 1	0	-0.41689178	-0.024013015	false
training	oneLayer	oneLayer - rat 1	0	-0.40973726	-0.031167565	false
training	oneLayer	oneLayer - rat 1	0	-0.40554285	-0.04129376	false
training	oneLayer	oneLayer - rat 1	0	-0.39791828	-0.048918307	false
training	oneLayer	oneLayer - rat 1	0	-0.39371982	-0.05905426	false
training	oneLayer	oneLayer - rat 1	0	-0.3859842	-0.066789865	false
training	oneLayer	oneLayer - rat 1	0	-0.381827	-0.07682629	false
training	oneLayer	oneLayer - rat 1	0	-0.37406093	-0.08459235	false
training	oneLayer	oneLayer - rat 1	0	-0.3699286	-0.09456871	false
training	oneLayer	oneLayer - rat 1	0	-0.36230925	-0.10218805	false
training	oneLayer	oneLayer - rat 1	0	-0.35814822	-0.11223367	false
training	oneLayer	oneLayer - rat 1	0	-0.35101616	-0.119365714	false
training	oneLayer	oneLayer - rat 1	0	-0.34718502	-0.12861496	false
training	oneLayer	oneLayer - rat 1	0	-0.33954087	-0.13625908	false
training	oneLayer	oneLayer - rat 1	0	-0.33533618	-0.14641011	false
training	oneLayer	oneLayer - rat 1	0	-0.32757342	-0.15417285	false
training	oneLayer	oneLayer - rat 1	0	-0.32357988	-0.16381411	false
training	oneLayer	oneLayer - rat 1	0	-0.31636637	-0.1710276	false
training	oneLayer	oneLayer - rat 1	0	-0.31235462	-0.18071285	false
training	oneLayer	oneLayer - rat 1	0	-0.3049382	-0.18812928	false
training	oneLayer	oneLayer - rat 1	0	-0.3007701	-0.19819193	false
training	oneLayer	oneLayer - rat 1	0	-0.293063	-0.20589902	false
training	oneLayer	oneLayer - rat 1	0	-0.2891996	-0.21522614	false
training	oneLayer	oneLayer - rat 1	0	-0.28198424	-0.22244151	false
training	oneLayer	oneLayer - rat 1	0	-0.27781653	-0.23250325	false
training	oneLayer	oneLayer - rat 1	0	-0.27032688	-0.23999289	false
training	oneLayer	oneLayer - rat 1	0	-0.26629463	-0.2497276	false
training	oneLayer	oneLayer - rat 1	0	-0.25900537	-0.25701684	false
training	oneLayer	oneLayer - rat 1	0	-0.25483567	-0.2670834	false
training	oneLayer	oneLayer - rat 1	0	-0.2477576	-0.2741615	false
training	oneLayer	oneLayer - rat 1	0	-0.24371868	-0.28391227	false
training	oneLayer	oneLayer - rat 1	0	-0.23649174	-0.29113922	false
training	oneLayer	oneLayer - rat 1	0	-0.23249766	-0.30078176	false
training	oneLayer	oneLayer - rat 1	0	-0.22474	-0.30853942	false
training	oneLayer	oneLayer - rat 1	0	-0.22065951	-0.3183906	false
training	oneLayer	oneLayer - rat 1	0	-0.21346286	-0.32558724	false
training	oneLayer	oneLayer - rat 1	0	-0.2092775	-0.3356916	false
training	oneLayer	oneLayer - rat 1	0	-0.20213617	-0.34283292	false
training	oneLayer	oneLayer - rat 1	0	-0.19805531	-0.35268497	false
training	oneLayer	oneLayer - rat 1	0	-0.19073275	-0.36000755	false
training	oneLayer	oneLayer - rat 1	0	-0.18678477	-0.3695388	false
training	oneLayer	oneLayer - rat 1	0	-0.17905028	-0.3772733	false
training	oneLayer	oneLayer - rat 1	0	-0.17510647	-0.38679448	false
training	oneLayer	oneLayer - rat 1	0	-0.16738364	-0.3945173	false
training	oneLayer	oneLayer - rat 1	0	-0.15808131	-0.39837047	false
training	oneLayer	oneLayer - rat 1	0	-0.14741482	-0.39837047	false
training	oneLayer	oneLayer - rat 1	0	-0.13644049	-0.39837047	false
training	oneLayer	oneLayer - rat 1	0	-0.12636912	-0.39419878	false
training	oneLayer	oneLayer - rat 1	0	-0.116302535	-0.39419878	false
training	oneLayer	oneLayer - rat 1	0	-0.10650914	-0.3901422	false
training	oneLayer	oneLayer - rat 1	0	-0.095813684	-0.3901422	false
training	oneLayer	oneLayer - rat 1	0	-0.08639697	-0.38624167	false
training	oneLayer	oneLayer - rat 1	0	-0.07620131	-0.38624167	false
training	oneLayer	oneLayer - rat 1	0	-0.06681506	-0.38235375	false
training	oneLayer	oneLayer - rat 1	0	-0.05629014	-0.38235375	false
training	oneLayer	oneLayer - rat 1	0	-0.046788704	-0.37841815	false
training	oneLayer	oneLayer - rat 1	0	-0.036648132	-0.37841812	false
training	oneLayer	oneLayer - rat 1	0	-0.026489105	-0.37421012	false
training	oneLayer	oneLayer - rat 1	0	-0.01551535	-0.37421012	false
training	oneLayer	oneLayer - rat 1	0	-0.0047469833	-0.37421012	false
training	oneLayer	oneLayer - rat 1	0	0.005116931	-0.37012434	false
training	oneLayer	oneLayer - rat 1	0	0.015986567	-0.37012434	false
training	oneLayer	oneLayer - rat 1	0	0.025393149	-0.366228	false
training	oneLayer	oneLayer - rat 1	0	0.03539991	-0.366228	false
training	oneLayer	oneLayer - rat 1	0	0.045212023	-0.3621637	false
training	oneLayer	oneLayer - rat 1	0	0.05535779	-0.3621637	false
training	oneLayer	oneLayer - rat 1	0	0.06491766	-0.35820386	false
training	oneLayer	oneLayer - rat 1	0	0.07493251	-0.35820386	false
training	oneLayer	oneLayer - rat 1	0	0.08509199	-0.35399565	false
training	oneLayer	oneLayer - rat 1	0	0.09578243	-0.35399565	false
training	oneLayer	oneLayer - rat 1	0	0.10531263	-0.35004812	false
training	oneLayer	oneLayer - rat 1	0	0.11587128	-0.35004812	false
training	oneLayer	oneLayer - rat 1	0	0.12660766	-0.35004812	false
training	oneLayer	oneLayer - rat 1	0	0.13650249	-0.34594953	false
training	oneLayer	oneLayer - rat 1	0	0.14686216	-0.34594953	false
training	oneLayer	oneLayer - rat 1	0	0.15624097	-0.3420647	false
training	oneLayer	oneLayer - rat 1	0	0.1663774	-0.3420647	false
training	oneLayer	oneLayer - rat 1	0	0.17629337	-0.33795738	false
training	oneLayer	oneLayer - rat 1	0	0.1865522	-0.33795738	false
training	oneLayer	oneLayer - rat 1	0	0.19640918	-0.3338745	false
training	oneLayer	oneLayer - rat 1	0	0.20660068	-0.33387446	false
training	oneLayer	oneLayer - rat 1	0	0.21585208	-0.33004242	false
training	oneLayer	oneLayer - rat 1	0	0.22639771	-0.33004242	false
training	oneLayer	oneLayer - rat 1	0	0.23634098	-0.32592377	false
training	oneLayer	oneLayer - rat 1	0	0.24716924	-0.32592377	false
training	oneLayer	oneLayer - rat 1	0	0.25730753	-0.32172436	false
training	oneLayer	oneLayer - rat 1	0	0.26749238	-0.32172436	false
training	oneLayer	oneLayer - rat 1	0	0.27693132	-0.3178146	false
training	oneLayer	oneLayer - rat 1	0	0.28759408	-0.3178146	false
training	oneLayer	oneLayer - rat 1	0	0.2969428	-0.31394222	false
training	oneLayer	oneLayer - rat 1	0	0.30423328	-0.30665174	false
training	oneLayer	oneLayer - rat 1	0	0.3140577	-0.30258232	false
training	oneLayer	oneLayer - rat 1	0	0.321516	-0.29512405	false
training	oneLayer	oneLayer - rat 1	0	0.3308671	-0.29125068	false
training	oneLayer	oneLayer - rat 1	0	0.33851454	-0.28360325	false
training	oneLayer	oneLayer - rat 1	0	0.34811646	-0.279626	false
training	oneLayer	oneLayer - rat 1	0	0.35541615	-0.27232632	false
training	oneLayer	oneLayer - rat 1	0	0.35956162	-0.2623182	false
training	oneLayer	oneLayer - rat 1	0	0.36354378	-0.25270447	false
training	oneLayer	oneLayer - rat 1	0	0.36755875	-0.24301143	false
training	oneLayer	oneLayer - rat 1	0	0.37153253	-0.2334179	false
training	oneLayer	oneLayer - rat 1	0	0.3754866	-0.2238719	false
training	oneLayer	oneLayer - rat 1	0	0.37963906	-0.21384698	false
training	oneLayer	oneLayer - rat 1	0	0.38366392	-0.2041301	false
training	oneLayer	oneLayer - rat 1	0	0.3876647	-0.19447133	false
training	oneLayer	oneLayer - rat 1	0	0.39160153	-0.18496701	false
training	oneLayer	oneLayer - rat 1	0	0.39553124	-0.17547981	false
training	oneLayer	oneLayer - rat 1	0	0.3996449	-0.16554858	false
training	oneLayer	oneLayer - rat 1	0	0.40371382	-0.15572533	false
training	oneLayer	oneLayer - rat 1	0	0.4076797	-0.1461508	false
training	oneLayer	oneLayer - rat 1	0	0.41188043	-0.13600938	false
training	oneLayer	oneLayer - rat 1	0	0.4159972	-0.12607063	false
training	oneLayer	oneLayer - rat 1	0	0.4200547	-0.11627493	false
training	oneLayer	oneLayer - rat 1	0	0.4240117	-0.10672183	false
training	oneLayer	oneLayer - rat 1	0	0.42812577	-0.096789666	false
training	oneLayer	oneLayer - rat 1	0	0.43202573	-0.087374285	false
training	oneLayer	oneLayer - rat 1	0	0.43612462	-0.077478714	false
training	oneLayer	oneLayer - rat 1	0	0.44025153	-0.06751546	false
training	oneLayer	oneLayer - rat 1	0	0.44410995	-0.058200397	false
training	oneLayer	oneLayer - rat 1	0	0.44809875	-0.048570562	false
training	oneLayer	oneLayer - rat 1	0	0.44809875	-0.037968174	false
training	oneLayer	oneLayer - rat 1	0	0.45214683	-0.028195234	false
training	oneLayer	oneLayer - rat 1	0	0.45214683	-0.017307293	false
training	oneLayer	oneLayer - rat 1	0	0.44815516	-0.0076705604	false
training	oneLayer	oneLayer - rat 1	0	0.44096875	-4.841575E-4	false
training	oneLayer	oneLayer - rat 1	0	0.43327162	0.0072129774	false
training	oneLayer	oneLayer - rat 1	0	0.42562824	0.0148563385	false
training	oneLayer	oneLayer - rat 1	0	0.41623303	0.018747969	false
training	oneLayer	oneLayer - rat 1	0	0.40609777	0.02294612	false
training	oneLayer	oneLayer - rat 1	0	0.39647555	0.026931768	false
training	oneLayer	oneLayer - rat 1	0	0.38664705	0.031002868	false
training	oneLayer	oneLayer - rat 1	0	0.3771377	0.03494177	false
training	oneLayer	oneLayer - rat 1	0	0.36718023	0.03906629	false
training	oneLayer	oneLayer - rat 1	0	0.35788348	0.042917125	false
training	oneLayer	oneLayer - rat 1	0	0.34773463	0.047120906	false
training	oneLayer	oneLayer - rat 1	0	0.338096	0.051113356	false
training	oneLayer	oneLayer - rat 1	0	0.3286977	0.055006262	false
training	oneLayer	oneLayer - rat 1	0	0.3191032	0.058980428	false
training	oneLayer	oneLayer - rat 1	0	0.3098403	0.062817246	false
training	oneLayer	oneLayer - rat 1	0	0.30022344	0.06680067	false
training	oneLayer	oneLayer - rat 1	0	0.2909413	0.07064547	false
training	oneLayer	oneLayer - rat 1	0	0.28118977	0.07468468	false
training	oneLayer	oneLayer - rat 1	0	0.27146733	0.078711845	false
training	oneLayer	oneLayer - rat 1	0	0.26192617	0.082663916	false
training	oneLayer	oneLayer - rat 1	0	0.25251698	0.08656132	false
training	oneLayer	oneLayer - rat 1	0	0.24256368	0.090684116	false
training	oneLayer	oneLayer - rat 1	0	0.2327469	0.09475035	false
training	oneLayer	oneLayer - rat 1	0	0.22317699	0.09871434	false
training	oneLayer	oneLayer - rat 1	0	0.21332406	0.102795556	false
training	oneLayer	oneLayer - rat 1	0	0.20333984	0.10693115	false
training	oneLayer	oneLayer - rat 1	0	0.19339876	0.11104888	false
training	oneLayer	oneLayer - rat 1	0	0.18396285	0.114957355	false
training	oneLayer	oneLayer - rat 1	0	0.1745229	0.11886751	false
training	oneLayer	oneLayer - rat 1	0	0.16481876	0.12288709	false
training	oneLayer	oneLayer - rat 1	0	0.15537901	0.12679715	false
training	oneLayer	oneLayer - rat 1	0	0.14566581	0.1308205	false
training	oneLayer	oneLayer - rat 1	0	0.13559133	0.13499348	false
training	oneLayer	oneLayer - rat 1	0	0.12571518	0.13908431	false
training	oneLayer	oneLayer - rat 1	0	0.1156594	0.14324956	false
training	oneLayer	oneLayer - rat 1	0	0.10610951	0.14720525	false
training	oneLayer	oneLayer - rat 1	0	0.0965362	0.15117063	false
training	oneLayer	oneLayer - rat 1	0	0.086445555	0.15535031	false
training	oneLayer	oneLayer - rat 1	0	0.0764661	0.15948394	false
training	oneLayer	oneLayer - rat 1	0	0.06687978	0.16345471	false
training	oneLayer	oneLayer - rat 1	0	0.057496384	0.16734144	false
training	oneLayer	oneLayer - rat 1	0	0.04805039	0.1712541	false
training	oneLayer	oneLayer - rat 1	0	0.03834419	0.17527454	false
training	oneLayer	oneLayer - rat 1	0	0.028281674	0.17944257	false
training	oneLayer	oneLayer - rat 1	0	0.018526675	0.18348321	false
training	oneLayer	oneLayer - rat 1	0	0.009022907	0.1874198	false
training	oneLayer	oneLayer - rat 1	0	-7.7466323E-4	0.19147809	false
training	oneLayer	oneLayer - rat 1	0	-0.010370303	0.19545272	false
training	oneLayer	oneLayer - rat 1	0	-0.020233305	0.19953811	false
training	oneLayer	oneLayer - rat 1	0	-0.03001051	0.20358796	false
training	oneLayer	oneLayer - rat 1	0	-0.039391253	0.20747359	false
training	oneLayer	oneLayer - rat 1	0	-0.049313035	0.21158332	false
training	oneLayer	oneLayer - rat 1	0	-0.05892979	0.21556671	false
training	oneLayer	oneLayer - rat 1	0	-0.06835027	0.2194688	false
training	oneLayer	oneLayer - rat 1	0	-0.077894434	0.22342211	false
training	oneLayer	oneLayer - rat 1	0	-0.08801219	0.22761302	false
training	oneLayer	oneLayer - rat 1	0	-0.09767919	0.23161723	false
training	oneLayer	oneLayer - rat 1	0	-0.10736684	0.23562998	false
training	oneLayer	oneLayer - rat 1	0	-0.11738226	0.2397785	false
training	oneLayer	oneLayer - rat 1	0	-0.1269627	0.24374685	false
training	oneLayer	oneLayer - rat 1	0	-0.13670532	0.24778236	false
training	oneLayer	oneLayer - rat 1	0	-0.14673178	0.25193545	false
training	oneLayer	oneLayer - rat 1	0	-0.15678939	0.25610146	false
training	oneLayer	oneLayer - rat 1	0	-0.16633287	0.2600545	false
training	oneLayer	oneLayer - rat 1	0	-0.17634706	0.2642025	false
training	oneLayer	oneLayer - rat 1	0	-0.18608208	0.26823488	false
training	oneLayer	oneLayer - rat 1	0	-0.1962367	0.27244106	false
training	oneLayer	oneLayer - rat 1	0	-0.20568207	0.27635345	false
training	oneLayer	oneLayer - rat 1	0	-0.21526857	0.2803243	false
training	oneLayer	oneLayer - rat 1	0	-0.22533923	0.2844957	false
training	oneLayer	oneLayer - rat 1	0	-0.23490362	0.2884574	false
training	oneLayer	oneLayer - rat 1	0	-0.24442108	0.29239967	false
training	oneLayer	oneLayer - rat 1	0	-0.25442228	0.2965423	false
training	oneLayer	oneLayer - rat 1	0	-0.2642647	0.30061916	false
training	oneLayer	oneLayer - rat 1	0	-0.2739299	0.30462262	false
training	oneLayer	oneLayer - rat 1	0	-0.2844424	0.3046226	false
training	oneLayer	oneLayer - rat 1	0	-0.29436597	0.30051214	false
training	oneLayer	oneLayer - rat 1	0	-0.30175418	0.2931239	false
training	oneLayer	oneLayer - rat 1	0	-0.30572882	0.28352824	false
training	oneLayer	oneLayer - rat 1	0	-0.30572882	0.2729885	false
training	oneLayer	oneLayer - rat 1	0	-0.30159134	0.26299968	false
training	oneLayer	oneLayer - rat 1	0	-0.2939628	0.25537118	false
training	oneLayer	oneLayer - rat 1	0	-0.28979552	0.24531044	false
training	oneLayer	oneLayer - rat 1	0	-0.28263444	0.23814936	false
training	oneLayer	oneLayer - rat 1	0	-0.2724909	0.23394778	false
training	oneLayer	oneLayer - rat 1	0	-0.26230904	0.23394778	false
training	oneLayer	oneLayer - rat 1	0	-0.25196013	0.23394778	false
training	oneLayer	oneLayer - rat 1	0	-0.24096842	0.2339478	false
training	oneLayer	oneLayer - rat 1	0	-0.23047249	0.2339478	false
training	oneLayer	oneLayer - rat 1	0	-0.22006375	0.2339478	false
training	oneLayer	oneLayer - rat 1	0	-0.20935288	0.2339478	false
training	oneLayer	oneLayer - rat 1	0	-0.19875388	0.23394781	false
training	oneLayer	oneLayer - rat 1	0	-0.18775515	0.23394781	false
training	oneLayer	oneLayer - rat 1	0	-0.1773751	0.23394781	false
training	oneLayer	oneLayer - rat 1	0	-0.16712967	0.23394781	false
training	oneLayer	oneLayer - rat 1	0	-0.15617204	0.23394783	false
training	oneLayer	oneLayer - rat 1	0	-0.1461462	0.23394783	false
training	oneLayer	oneLayer - rat 1	0	-0.13586788	0.23394783	false
training	oneLayer	oneLayer - rat 1	0	-0.12504263	0.23394783	false
training	oneLayer	oneLayer - rat 1	0	-0.114232056	0.23394784	false
training	oneLayer	oneLayer - rat 1	0	-0.104117304	0.22975817	false
training	oneLayer	oneLayer - rat 1	0	-0.0939717	0.22975817	false
training	oneLayer	oneLayer - rat 1	0	-0.08430087	0.2257524	false
training	oneLayer	oneLayer - rat 1	0	-0.073739395	0.2257524	false
training	oneLayer	oneLayer - rat 1	0	-0.06375705	0.22161758	false
training	oneLayer	oneLayer - rat 1	0	-0.053353064	0.22161758	false
training	oneLayer	oneLayer - rat 1	0	-0.043679763	0.21761078	false
training	oneLayer	oneLayer - rat 1	0	-0.03365313	0.21761078	false
training	oneLayer	oneLayer - rat 1	0	-0.023709398	0.21349195	false
training	oneLayer	oneLayer - rat 1	0	-0.012839579	0.21349196	false
training	oneLayer	oneLayer - rat 1	0	-0.0035456226	0.20964228	false
training	oneLayer	oneLayer - rat 1	0	0.0073753437	0.20964228	false
training	oneLayer	oneLayer - rat 1	0	0.016621057	0.20581259	false
training	oneLayer	oneLayer - rat 1	0	0.027048573	0.20581259	false
training	oneLayer	oneLayer - rat 1	0	0.037203953	0.2016061	false
training	oneLayer	oneLayer - rat 1	0	0.047303203	0.2016061	false
training	oneLayer	oneLayer - rat 1	0	0.056613836	0.19774951	false
training	oneLayer	oneLayer - rat 1	0	0.06728795	0.19774951	false
training	oneLayer	oneLayer - rat 1	0	0.076760605	0.19382581	false
training	oneLayer	oneLayer - rat 1	0	0.08703635	0.19382583	false
training	oneLayer	oneLayer - rat 1	0	0.096470214	0.18991819	false
training	oneLayer	oneLayer - rat 1	0	0.10736194	0.18991819	false
training	oneLayer	oneLayer - rat 1	0	0.116811566	0.18600404	false
training	oneLayer	oneLayer - rat 1	0	0.12740523	0.18600404	false
training	oneLayer	oneLayer - rat 1	0	0.13714176	0.18197104	false
training	oneLayer	oneLayer - rat 1	0	0.14726226	0.18197104	false
training	oneLayer	oneLayer - rat 1	0	0.15684633	0.1780012	false
training	oneLayer	oneLayer - rat 1	0	0.16766275	0.1780012	false
training	oneLayer	oneLayer - rat 1	0	0.17757066	0.17389722	false
training	oneLayer	oneLayer - rat 1	0	0.18831302	0.17389722	false
training	oneLayer	oneLayer - rat 1	0	0.1983183	0.1697529	false
training	oneLayer	oneLayer - rat 1	0	0.20908448	0.16975291	false
training	oneLayer	oneLayer - rat 1	0	0.21833	0.1659233	false
training	oneLayer	oneLayer - rat 1	0	0.2285994	0.1659233	false
training	oneLayer	oneLayer - rat 1	0	0.23789246	0.16207398	false
training	oneLayer	oneLayer - rat 1	0	0.2480139	0.162074	false
training	oneLayer	oneLayer - rat 1	0	0.25754365	0.15812664	false
training	oneLayer	oneLayer - rat 1	0	0.26805103	0.15812665	false
training	oneLayer	oneLayer - rat 1	0	0.2775672	0.15418492	false
training	oneLayer	oneLayer - rat 1	0	0.28778034	0.15418492	false
training	oneLayer	oneLayer - rat 1	0	0.29791775	0.1499859	false
training	oneLayer	oneLayer - rat 1	0	0.30853233	0.1499859	false
training	oneLayer	oneLayer - rat 1	0	0.31802785	0.14605273	false
training	oneLayer	oneLayer - rat 1	0	0.32574004	0.13834055	false
training	oneLayer	oneLayer - rat 1	0	0.33576757	0.13418701	false
training	oneLayer	oneLayer - rat 1	0	0.3430681	0.1268865	false
training	oneLayer	oneLayer - rat 1	0	0.352787	0.122860804	false
training	oneLayer	oneLayer - rat 1	0	0.36012068	0.1155271	false
training	oneLayer	oneLayer - rat 1	0	0.36941725	0.11167634	false
training	oneLayer	oneLayer - rat 1	0	0.37691212	0.10418147	false
training	oneLayer	oneLayer - rat 1	0	0.38622946	0.10032211	false
training	oneLayer	oneLayer - rat 1	0	0.39351657	0.093035	false
training	oneLayer	oneLayer - rat 1	0	0.4032599	0.088999175	false
training	oneLayer	oneLayer - rat 1	0	0.41064796	0.08161113	false
training	oneLayer	oneLayer - rat 1	0	0.41480297	0.0715801	false
training	oneLayer	oneLayer - rat 1	0	0.42222828	0.064154774	false
training	oneLayer	oneLayer - rat 1	0	0.42619392	0.05458089	false
training	oneLayer	oneLayer - rat 1	0	0.43357137	0.04720344	false
training	oneLayer	oneLayer - rat 1	0	0.4376225	0.037423182	false
training	oneLayer	oneLayer - rat 1	0	0.4376225	0.027141623	false
training	oneLayer	oneLayer - rat 1	0	0.43354374	0.017294649	false
training	oneLayer	oneLayer - rat 1	0	0.4262406	0.009991495	false
training	oneLayer	oneLayer - rat 1	0	0.41626823	0.0058608046	false
training	oneLayer	oneLayer - rat 1	0	0.40584266	0.005860802	false
training	oneLayer	oneLayer - rat 1	0	0.39580604	0.0058607995	false
training	oneLayer	oneLayer - rat 1	0	0.38540038	0.0058607967	false
training	oneLayer	oneLayer - rat 1	0	0.37533122	0.010031579	false
training	oneLayer	oneLayer - rat 1	0	0.36556074	0.014078644	false
training	oneLayer	oneLayer - rat 1	0	0.35612887	0.017985448	false
training	oneLayer	oneLayer - rat 1	0	0.34660608	0.021929912	false
training	oneLayer	oneLayer - rat 1	0	0.33736706	0.025756842	false
training	oneLayer	oneLayer - rat 1	0	0.32783592	0.029704757	false
training	oneLayer	oneLayer - rat 1	0	0.31836763	0.033626653	false
training	oneLayer	oneLayer - rat 1	0	0.30848405	0.037720557	false
training	oneLayer	oneLayer - rat 1	0	0.2990472	0.041629437	false
training	oneLayer	oneLayer - rat 1	0	0.2890704	0.045761958	false
training	oneLayer	oneLayer - rat 1	0	0.27945164	0.049746167	false
training	oneLayer	oneLayer - rat 1	0	0.2693922	0.053912926	false
training	oneLayer	oneLayer - rat 1	0	0.25982583	0.057875447	false
training	oneLayer	oneLayer - rat 1	0	0.25026926	0.061833896	false
training	oneLayer	oneLayer - rat 1	0	0.24094768	0.065695025	false
training	oneLayer	oneLayer - rat 1	0	0.23107672	0.06978371	false
training	oneLayer	oneLayer - rat 1	0	0.2209335	0.07398516	false
training	oneLayer	oneLayer - rat 1	0	0.2110506	0.07807879	false
training	oneLayer	oneLayer - rat 1	0	0.20134808	0.0820977	false
training	oneLayer	oneLayer - rat 1	0	0.19121617	0.08629448	false
training	oneLayer	oneLayer - rat 1	0	0.18105476	0.09050346	false
training	oneLayer	oneLayer - rat 1	0	0.17120297	0.094584204	false
training	oneLayer	oneLayer - rat 1	0	0.16162778	0.09855038	false
training	oneLayer	oneLayer - rat 1	0	0.152041	0.10252135	false
training	oneLayer	oneLayer - rat 1	0	0.1420047	0.106678516	false
training	oneLayer	oneLayer - rat 1	0	0.13186643	0.11087793	false
training	oneLayer	oneLayer - rat 1	0	0.12206296	0.114938654	false
training	oneLayer	oneLayer - rat 1	0	0.1126593	0.11883377	false
training	oneLayer	oneLayer - rat 1	0	0.10277727	0.12292704	false
training	oneLayer	oneLayer - rat 1	0	0.09264569	0.12712367	false
training	oneLayer	oneLayer - rat 1	0	0.082931094	0.1311476	false
training	oneLayer	oneLayer - rat 1	0	0.073304065	0.13513523	false
training	oneLayer	oneLayer - rat 1	0	0.06345145	0.13921632	false
training	oneLayer	oneLayer - rat 1	0	0.0539155	0.14316623	false
training	oneLayer	oneLayer - rat 1	0	0.044417903	0.14710027	false
training	oneLayer	oneLayer - rat 1	0	0.03503651	0.15098616	false
training	oneLayer	oneLayer - rat 1	0	0.025582135	0.1549023	false
training	oneLayer	oneLayer - rat 1	0	0.015454119	0.15909745	false
training	oneLayer	oneLayer - rat 1	0	0.006032741	0.16299991	false
training	oneLayer	oneLayer - rat 1	0	-0.0037231026	0.16704091	false
training	oneLayer	oneLayer - rat 1	0	-0.013755362	0.1711964	false
training	oneLayer	oneLayer - rat 1	0	-0.02308748	0.1750619	false
training	oneLayer	oneLayer - rat 1	0	-0.032770876	0.17907289	false
training	oneLayer	oneLayer - rat 1	0	-0.04207347	0.18292613	false
training	oneLayer	oneLayer - rat 1	0	-0.052233852	0.1871347	false
training	oneLayer	oneLayer - rat 1	0	-0.062012378	0.1911851	false
training	oneLayer	oneLayer - rat 1	0	-0.07160108	0.19515686	false
training	oneLayer	oneLayer - rat 1	0	-0.08162074	0.19930714	false
training	oneLayer	oneLayer - rat 1	0	-0.09178283	0.20351642	false
training	oneLayer	oneLayer - rat 1	0	-0.1019248	0.20771736	false
training	oneLayer	oneLayer - rat 1	0	-0.111206025	0.21156175	false
training	oneLayer	oneLayer - rat 1	0	-0.12053175	0.2154246	false
training	oneLayer	oneLayer - rat 1	0	-0.12997892	0.21933775	false
training	oneLayer	oneLayer - rat 1	0	-0.13968527	0.22335824	false
training	oneLayer	oneLayer - rat 1	0	-0.1490325	0.22722998	false
training	oneLayer	oneLayer - rat 1	0	-0.15830529	0.2310709	false
training	oneLayer	oneLayer - rat 1	0	-0.16835307	0.23523282	false
training	oneLayer	oneLayer - rat 1	0	-0.17849573	0.23943405	false
training	oneLayer	oneLayer - rat 1	0	-0.18773913	0.24326278	false
training	oneLayer	oneLayer - rat 1	0	-0.19730882	0.24722669	false
training	oneLayer	oneLayer - rat 1	0	-0.20693073	0.2512122	false
training	oneLayer	oneLayer - rat 1	0	-0.2163926	0.25513145	false
training	oneLayer	oneLayer - rat 1	0	-0.22587001	0.2590571	false
training	oneLayer	oneLayer - rat 1	0	-0.2354152	0.26301086	false
training	oneLayer	oneLayer - rat 1	0	-0.24544209	0.2671641	false
training	oneLayer	oneLayer - rat 1	0	-0.25556028	0.2713552	false
training	oneLayer	oneLayer - rat 1	0	-0.26550624	0.27547497	false
training	oneLayer	oneLayer - rat 1	0	-0.2748346	0.2793389	false
training	oneLayer	oneLayer - rat 1	0	-0.28486606	0.28349406	false
training	oneLayer	oneLayer - rat 1	0	-0.29493272	0.2876638	false
training	oneLayer	oneLayer - rat 1	0	-0.3047196	0.29171765	false
training	oneLayer	oneLayer - rat 1	0	-0.31559494	0.29171765	false
training	oneLayer	oneLayer - rat 1	0	-0.325591	0.28757715	false
training	oneLayer	oneLayer - rat 1	0	-0.33307332	0.2800948	false
training	oneLayer	oneLayer - rat 1	0	-0.3423964	0.27623305	false
training	oneLayer	oneLayer - rat 1	0	-0.35015115	0.2684783	false
training	oneLayer	oneLayer - rat 1	0	-0.35976678	0.26449537	false
training	oneLayer	oneLayer - rat 1	0	-0.36714345	0.2571187	false
training	oneLayer	oneLayer - rat 1	0	-0.37132686	0.24701907	false
training	oneLayer	oneLayer - rat 1	0	-0.37132686	0.23672698	false
training	oneLayer	oneLayer - rat 1	0	-0.37525326	0.22724776	false
training	oneLayer	oneLayer - rat 1	0	-0.37525326	0.21663386	false
training	oneLayer	oneLayer - rat 1	0	-0.37909088	0.20736904	false
training	oneLayer	oneLayer - rat 1	0	-0.37909088	0.1973424	false
training	oneLayer	oneLayer - rat 1	0	-0.38291863	0.18810135	false
training	oneLayer	oneLayer - rat 1	0	-0.38291863	0.17802903	false
training	oneLayer	oneLayer - rat 1	0	-0.38687155	0.16848585	false
training	oneLayer	oneLayer - rat 1	0	-0.38687155	0.1579678	false
training	oneLayer	oneLayer - rat 1	0	-0.3907413	0.14862542	false
training	oneLayer	oneLayer - rat 1	0	-0.3907413	0.13801758	false
training	oneLayer	oneLayer - rat 1	0	-0.39491764	0.12793493	false
training	oneLayer	oneLayer - rat 1	0	-0.39491764	0.11762788	false
training	oneLayer	oneLayer - rat 1	0	-0.39908728	0.107561454	false
training	oneLayer	oneLayer - rat 1	0	-0.39908728	0.09673091	false
training	oneLayer	oneLayer - rat 1	0	-0.40309075	0.08706572	false
training	oneLayer	oneLayer - rat 1	0	-0.40309075	0.0762651	false
training	oneLayer	oneLayer - rat 1	0	-0.4071678	0.06642222	false
training	oneLayer	oneLayer - rat 1	0	-0.4071678	0.056293324	false
training	oneLayer	oneLayer - rat 1	0	-0.4111551	0.04666707	false
training	oneLayer	oneLayer - rat 1	0	-0.4111551	0.03617687	false
training	oneLayer	oneLayer - rat 1	0	-0.41519985	0.026412025	false
training	oneLayer	oneLayer - rat 1	0	-0.41519982	0.015890434	false
training	oneLayer	oneLayer - rat 1	0	-0.41136175	0.0066244993	false
training	oneLayer	oneLayer - rat 1	0	-0.40413558	-6.01653E-4	false
training	oneLayer	oneLayer - rat 1	0	-0.39482304	-0.0044590333	false
training	oneLayer	oneLayer - rat 1	0	-0.3874826	-0.0117994705	false
training	oneLayer	oneLayer - rat 1	0	-0.3777324	-0.015838135	false
training	oneLayer	oneLayer - rat 1	0	-0.3699678	-0.02360273	false
training	oneLayer	oneLayer - rat 1	0	-0.36611202	-0.032911398	false
training	oneLayer	oneLayer - rat 1	0	-0.35842615	-0.04059725	false
training	oneLayer	oneLayer - rat 1	0	-0.35435143	-0.05043448	false
training	oneLayer	oneLayer - rat 1	0	-0.34684435	-0.05794158	false
training	oneLayer	oneLayer - rat 1	0	-0.33736464	-0.06186819	false
training	oneLayer	oneLayer - rat 1	0	-0.32998404	-0.06924881	false
training	oneLayer	oneLayer - rat 1	0	-0.32032686	-0.07324893	false
training	oneLayer	oneLayer - rat 1	0	-0.31258315	-0.080992654	false
training	oneLayer	oneLayer - rat 1	0	-0.30868763	-0.09039723	false
training	oneLayer	oneLayer - rat 1	0	-0.3011491	-0.09793576	false
training	oneLayer	oneLayer - rat 1	0	-0.29171857	-0.101842	false
training	oneLayer	oneLayer - rat 1	0	-0.28397948	-0.10958111	false
training	oneLayer	oneLayer - rat 1	0	-0.27421072	-0.11362746	false
training	oneLayer	oneLayer - rat 1	0	-0.26696637	-0.12087178	false
training	oneLayer	oneLayer - rat 1	0	-0.2627745	-0.13099189	false
training	oneLayer	oneLayer - rat 1	0	-0.25539884	-0.13836755	false
training	oneLayer	oneLayer - rat 1	0	-0.2459247	-0.14229186	false
training	oneLayer	oneLayer - rat 1	0	-0.23873755	-0.149479	false
training	oneLayer	oneLayer - rat 1	0	-0.22867781	-0.15364587	false
training	oneLayer	oneLayer - rat 1	0	-0.22090153	-0.16142215	false
training	oneLayer	oneLayer - rat 1	0	-0.21683593	-0.17123736	false
training	oneLayer	oneLayer - rat 1	0	-0.20925675	-0.17881654	false
training	oneLayer	oneLayer - rat 1	0	-0.20001397	-0.18264502	false
training	oneLayer	oneLayer - rat 1	0	-0.19283022	-0.18982877	false
training	oneLayer	oneLayer - rat 1	0	-0.18322463	-0.19380753	false
training	oneLayer	oneLayer - rat 1	0	-0.17585008	-0.20118207	false
training	oneLayer	oneLayer - rat 1	0	-0.165818	-0.2053375	false
training	oneLayer	oneLayer - rat 1	0	-0.15809497	-0.21306051	false
training	oneLayer	oneLayer - rat 1	0	-0.14811648	-0.21719374	false
training	oneLayer	oneLayer - rat 1	0	-0.1407517	-0.22455852	false
training	oneLayer	oneLayer - rat 1	0	-0.13076368	-0.22869569	false
training	oneLayer	oneLayer - rat 1	0	-0.123335585	-0.23612377	false
training	oneLayer	oneLayer - rat 1	0	-0.11338613	-0.24024497	false
training	oneLayer	oneLayer - rat 1	0	-0.10587684	-0.24775425	false
training	oneLayer	oneLayer - rat 1	0	-0.09625411	-0.25174013	false
training	oneLayer	oneLayer - rat 1	0	-0.08860516	-0.25938907	false
training	oneLayer	oneLayer - rat 1	0	-0.07887635	-0.26341885	false
training	oneLayer	oneLayer - rat 1	0	-0.071415156	-0.27088004	false
training	oneLayer	oneLayer - rat 1	0	-0.06162414	-0.2749356	false
training	oneLayer	oneLayer - rat 1	0	-0.054050636	-0.28250912	false
training	oneLayer	oneLayer - rat 1	0	-0.044145565	-0.2866119	false
training	oneLayer	oneLayer - rat 1	0	-0.03666864	-0.29408884	false
training	oneLayer	oneLayer - rat 1	0	-0.027233811	-0.29799688	false
training	oneLayer	oneLayer - rat 1	0	-0.01973825	-0.30549243	false
training	oneLayer	oneLayer - rat 1	0	-0.009999236	-0.30952644	false
training	oneLayer	oneLayer - rat 1	0	-0.0022332165	-0.31729248	false
training	oneLayer	oneLayer - rat 1	0	0.0071099	-0.32116252	false
training	oneLayer	oneLayer - rat 1	0	0.014765955	-0.32881856	false
training	oneLayer	oneLayer - rat 1	0	0.024621291	-0.33290076	false
training	oneLayer	oneLayer - rat 1	0	0.03194528	-0.34022477	false
training	oneLayer	oneLayer - rat 1	0	0.041596305	-0.34422234	false
training	oneLayer	oneLayer - rat 1	0	0.049100745	-0.35172677	false
training	oneLayer	oneLayer - rat 1	0	0.058377136	-0.35556918	false
training	oneLayer	oneLayer - rat 1	0	0.06573417	-0.36292621	false
training	oneLayer	oneLayer - rat 1	0	0.075831614	-0.3671087	false
training	oneLayer	oneLayer - rat 1	0	0.083112165	-0.37438926	false
training	oneLayer	oneLayer - rat 1	0	0.09274114	-0.3783777	false
training	oneLayer	oneLayer - rat 1	0	0.1004288	-0.38606533	false
training	oneLayer	oneLayer - rat 1	0	0.10967675	-0.38989598	false
training	oneLayer	oneLayer - rat 1	0	0.117069006	-0.39728823	false
training	oneLayer	oneLayer - rat 1	0	0.1264082	-0.40115663	false
training	oneLayer	oneLayer - rat 1	0	0.13645007	-0.40115663	false
training	oneLayer	oneLayer - rat 1	0	0.14635389	-0.39705434	false
training	oneLayer	oneLayer - rat 1	0	0.153693	-0.3897152	false
training	oneLayer	oneLayer - rat 1	0	0.16347657	-0.38566273	false
training	oneLayer	oneLayer - rat 1	0	0.17113687	-0.3780024	false
training	oneLayer	oneLayer - rat 1	0	0.18069132	-0.37404484	false
training	oneLayer	oneLayer - rat 1	0	0.18807603	-0.3666601	false
training	oneLayer	oneLayer - rat 1	0	0.19815294	-0.3624861	false
training	oneLayer	oneLayer - rat 1	0	0.20526926	-0.35536978	false
training	oneLayer	oneLayer - rat 1	0	0.21470916	-0.35145965	false
training	oneLayer	oneLayer - rat 1	0	0.22247227	-0.34369653	false
training	oneLayer	oneLayer - rat 1	0	0.23186877	-0.33980435	false
training	oneLayer	oneLayer - rat 1	0	0.23895848	-0.33271465	false
training	oneLayer	oneLayer - rat 1	0	0.24844913	-0.32878348	false
training	oneLayer	oneLayer - rat 1	0	0.25617585	-0.32105675	false
training	oneLayer	oneLayer - rat 1	0	0.2659731	-0.3169986	false
training	oneLayer	oneLayer - rat 1	0	0.27340963	-0.30956206	false
training	oneLayer	oneLayer - rat 1	0	0.28271005	-0.3057097	false
training	oneLayer	oneLayer - rat 1	0	0.28979003	-0.2986297	false
training	oneLayer	oneLayer - rat 1	0	0.29908237	-0.2947807	false
training	oneLayer	oneLayer - rat 1	0	0.3066852	-0.28717783	false
training	oneLayer	oneLayer - rat 1	0	0.31625232	-0.28321502	false
training	oneLayer	oneLayer - rat 1	0	0.32391393	-0.27555338	false
training	oneLayer	oneLayer - rat 1	0	0.33372384	-0.27148998	false
training	oneLayer	oneLayer - rat 1	0	0.34087065	-0.26434317	false
training	oneLayer	oneLayer - rat 1	0	0.3449851	-0.25441003	false
training	oneLayer	oneLayer - rat 1	0	0.34914374	-0.2443701	false
training	oneLayer	oneLayer - rat 1	0	0.3531026	-0.23481257	false
training	oneLayer	oneLayer - rat 1	0	0.35726956	-0.22475263	false
training	oneLayer	oneLayer - rat 1	0	0.36143973	-0.21468492	false
training	oneLayer	oneLayer - rat 1	0	0.36549643	-0.20489125	false
training	oneLayer	oneLayer - rat 1	0	0.369468	-0.19530295	false
training	oneLayer	oneLayer - rat 1	0	0.37358868	-0.18535477	false
training	oneLayer	oneLayer - rat 1	0	0.37765244	-0.17554398	false
training	oneLayer	oneLayer - rat 1	0	0.38152194	-0.16620216	false
training	oneLayer	oneLayer - rat 1	0	0.38564542	-0.15624721	false
training	oneLayer	oneLayer - rat 1	0	0.38970426	-0.14644825	false
training	oneLayer	oneLayer - rat 1	0	0.3935597	-0.1371404	false
training	oneLayer	oneLayer - rat 1	0	0.39755258	-0.12750076	false
training	oneLayer	oneLayer - rat 1	0	0.40141848	-0.11816762	false
training	oneLayer	oneLayer - rat 1	0	0.4054695	-0.10838755	false
training	oneLayer	oneLayer - rat 1	0	0.40946057	-0.098752245	false
training	oneLayer	oneLayer - rat 1	0	0.41360635	-0.08874344	false
training	oneLayer	oneLayer - rat 1	0	0.41775283	-0.07873296	false
training	oneLayer	oneLayer - rat 1	0	0.42176938	-0.06903612	false
training	oneLayer	oneLayer - rat 1	0	0.42565453	-0.05965654	false
training	oneLayer	oneLayer - rat 1	0	0.4295245	-0.050313562	false
training	oneLayer	oneLayer - rat 1	0	0.4336585	-0.040333208	false
training	oneLayer	oneLayer - rat 1	0	0.4336585	-0.029539661	false
training	oneLayer	oneLayer - rat 1	0	0.4295971	-0.019734625	false
training	oneLayer	oneLayer - rat 1	0	0.4295971	-0.009271622	false
training	oneLayer	oneLayer - rat 1	0	0.42539316	8.7759923E-4	false
training	oneLayer	oneLayer - rat 1	0	0.42539316	0.011183867	false
training	oneLayer	oneLayer - rat 1	0	0.42942163	0.0209095	false
training	oneLayer	oneLayer - rat 1	0	0.42942163	0.031833783	false
training	oneLayer	oneLayer - rat 1	0	0.43346098	0.0415856	false
training	oneLayer	oneLayer - rat 1	0	0.43346098	0.051986776	false
training	oneLayer	oneLayer - rat 1	0	0.4374847	0.061700985	false
training	oneLayer	oneLayer - rat 1	0	0.4374847	0.07189155	false
training	oneLayer	oneLayer - rat 1	0	0.43354306	0.08140755	false
training	oneLayer	oneLayer - rat 1	0	0.43354306	0.09239339	false
training	oneLayer	oneLayer - rat 1	0	0.42947868	0.102205664	false
training	oneLayer	oneLayer - rat 1	0	0.42947868	0.112958886	false
training	oneLayer	oneLayer - rat 1	0	0.4256375	0.12223227	false
training	oneLayer	oneLayer - rat 1	0	0.4256375	0.13272798	false
training	oneLayer	oneLayer - rat 1	0	0.42175156	0.14210942	false
training	oneLayer	oneLayer - rat 1	0	0.42175156	0.15264136	false
training	oneLayer	oneLayer - rat 1	0	0.4178991	0.16194205	false
training	oneLayer	oneLayer - rat 1	0	0.41789907	0.17264287	false
training	oneLayer	oneLayer - rat 1	0	0.41405863	0.18191457	false
training	oneLayer	oneLayer - rat 1	0	0.40628374	0.18968946	false
training	oneLayer	oneLayer - rat 1	0	0.3968226	0.19360837	false
training	oneLayer	oneLayer - rat 1	0	0.38683152	0.19774681	false
training	oneLayer	oneLayer - rat 1	0	0.37691855	0.20185289	false
training	oneLayer	oneLayer - rat 1	0	0.36696646	0.20597517	false
training	oneLayer	oneLayer - rat 1	0	0.35683185	0.21017306	false
training	oneLayer	oneLayer - rat 1	0	0.34692737	0.21427563	false
training	oneLayer	oneLayer - rat 1	0	0.33684024	0.21845385	false
training	oneLayer	oneLayer - rat 1	0	0.32690766	0.22256805	false
training	oneLayer	oneLayer - rat 1	0	0.31690073	0.22671306	false
training	oneLayer	oneLayer - rat 1	0	0.306971	0.23082608	false
training	oneLayer	oneLayer - rat 1	0	0.2976773	0.23467565	false
training	oneLayer	oneLayer - rat 1	0	0.2876094	0.23884591	false
training	oneLayer	oneLayer - rat 1	0	0.2776896	0.24295482	false
training	oneLayer	oneLayer - rat 1	0	0.26805466	0.24694574	false
training	oneLayer	oneLayer - rat 1	0	0.25854358	0.25088537	false
training	oneLayer	oneLayer - rat 1	0	0.24884915	0.2549009	false
training	oneLayer	oneLayer - rat 1	0	0.23886375	0.259037	false
training	oneLayer	oneLayer - rat 1	0	0.22875822	0.26322284	false
training	oneLayer	oneLayer - rat 1	0	0.2189521	0.26728466	false
training	oneLayer	oneLayer - rat 1	0	0.20881592	0.27148318	false
training	oneLayer	oneLayer - rat 1	0	0.19918084	0.27547416	false
training	oneLayer	oneLayer - rat 1	0	0.18920682	0.27960554	false
training	oneLayer	oneLayer - rat 1	0	0.17919044	0.28375447	false
training	oneLayer	oneLayer - rat 1	0	0.1692799	0.28785953	false
training	oneLayer	oneLayer - rat 1	0	0.15996216	0.29171905	false
training	oneLayer	oneLayer - rat 1	0	0.15004867	0.29582536	false
training	oneLayer	oneLayer - rat 1	0	0.14002861	0.29997578	false
training	oneLayer	oneLayer - rat 1	0	0.13022473	0.3040367	false
training	oneLayer	oneLayer - rat 1	0	0.120312914	0.3081423	false
training	oneLayer	oneLayer - rat 1	0	0.11071065	0.3121197	false
training	oneLayer	oneLayer - rat 1	0	0.10086586	0.3161975	false
training	oneLayer	oneLayer - rat 1	0	0.09098833	0.32028893	false
training	oneLayer	oneLayer - rat 1	0	0.08090994	0.32028893	false
training	oneLayer	oneLayer - rat 1	0	0.07092994	0.32442278	false
training	oneLayer	oneLayer - rat 1	0	0.06009988	0.32442278	false
training	oneLayer	oneLayer - rat 1	0	0.05066465	0.32833096	false
training	oneLayer	oneLayer - rat 1	0	0.039699256	0.32833096	false
training	oneLayer	oneLayer - rat 1	0	0.030262023	0.33224	false
training	oneLayer	oneLayer - rat 1	0	0.019916184	0.33224	false
training	oneLayer	oneLayer - rat 1	0	0.010122066	0.33629683	false
training	oneLayer	oneLayer - rat 1	0	8.768368E-6	0.33629683	false
training	oneLayer	oneLayer - rat 1	0	-0.009541073	0.3402525	false
training	oneLayer	oneLayer - rat 1	0	-0.020162133	0.3402525	false
training	oneLayer	oneLayer - rat 1	0	-0.029898621	0.34428546	false
training	oneLayer	oneLayer - rat 1	0	-0.04067525	0.34428546	false
training	oneLayer	oneLayer - rat 1	0	-0.05056471	0.34838182	false
training	oneLayer	oneLayer - rat 1	0	-0.060796134	0.34838182	false
training	oneLayer	oneLayer - rat 1	0	-0.07081549	0.35253194	false
training	oneLayer	oneLayer - rat 1	0	-0.081454754	0.35253194	false
training	oneLayer	oneLayer - rat 1	0	-0.091601215	0.35673475	false
training	oneLayer	oneLayer - rat 1	0	-0.10183989	0.35673472	false
training	oneLayer	oneLayer - rat 1	0	-0.11110221	0.3605713	false
training	oneLayer	oneLayer - rat 1	0	-0.12149996	0.3605713	false
training	oneLayer	oneLayer - rat 1	0	-0.13134457	0.36464906	false
training	oneLayer	oneLayer - rat 1	0	-0.14179564	0.36464906	false
training	oneLayer	oneLayer - rat 1	0	-0.1513627	0.36861187	false
training	oneLayer	oneLayer - rat 1	0	-0.16159526	0.36861187	false
training	oneLayer	oneLayer - rat 1	0	-0.17166534	0.37278304	false
training	oneLayer	oneLayer - rat 1	0	-0.18262087	0.372783	false
training	oneLayer	oneLayer - rat 1	0	-0.19260399	0.37691817	false
training	oneLayer	oneLayer - rat 1	0	-0.20336853	0.37691817	false
training	oneLayer	oneLayer - rat 1	0	-0.21322489	0.37283552	false
training	oneLayer	oneLayer - rat 1	0	-0.22326945	0.37283552	false
training	oneLayer	oneLayer - rat 1	0	-0.23306227	0.36877918	false
training	oneLayer	oneLayer - rat 1	0	-0.24354106	0.36877918	false
training	oneLayer	oneLayer - rat 1	0	-0.25284562	0.36492512	false
training	oneLayer	oneLayer - rat 1	0	-0.26223361	0.36103648	false
training	oneLayer	oneLayer - rat 1	0	-0.27190253	0.35703146	false
training	oneLayer	oneLayer - rat 1	0	-0.28154805	0.35303617	false
training	oneLayer	oneLayer - rat 1	0	-0.29165116	0.3488513	false
training	oneLayer	oneLayer - rat 1	0	-0.29913515	0.34136733	false
training	oneLayer	oneLayer - rat 1	0	-0.3033157	0.33127454	false
training	oneLayer	oneLayer - rat 1	0	-0.3033157	0.3211739	false
training	oneLayer	oneLayer - rat 1	0	-0.3072781	0.31160784	false
training	oneLayer	oneLayer - rat 1	0	-0.3072781	0.30139264	false
training	oneLayer	oneLayer - rat 1	0	-0.31138656	0.29147395	false
training	oneLayer	oneLayer - rat 1	0	-0.31138653	0.28079316	false
training	oneLayer	oneLayer - rat 1	0	-0.3154985	0.270866	false
training	oneLayer	oneLayer - rat 1	0	-0.3154985	0.26063034	false
training	oneLayer	oneLayer - rat 1	0	-0.31945643	0.25107503	false
training	oneLayer	oneLayer - rat 1	0	-0.31945643	0.2403861	false
training	oneLayer	oneLayer - rat 1	0	-0.3235027	0.23061751	false
training	oneLayer	oneLayer - rat 1	0	-0.3235027	0.22031489	false
training	oneLayer	oneLayer - rat 1	0	-0.32749572	0.21067485	false
training	oneLayer	oneLayer - rat 1	0	-0.32749572	0.20050764	false
training	oneLayer	oneLayer - rat 1	0	-0.33152187	0.19078766	false
training	oneLayer	oneLayer - rat 1	0	-0.33152187	0.18017717	false
training	oneLayer	oneLayer - rat 1	0	-0.33560127	0.17032857	false
training	oneLayer	oneLayer - rat 1	0	-0.33560127	0.1597726	false
training	oneLayer	oneLayer - rat 1	0	-0.33974424	0.14977062	false
training	oneLayer	oneLayer - rat 1	0	-0.3397442	0.13965808	false
training	oneLayer	oneLayer - rat 1	0	-0.3439103	0.12960026	false
training	oneLayer	oneLayer - rat 1	0	-0.3439103	0.11899539	false
training	oneLayer	oneLayer - rat 1	0	-0.34786907	0.10943808	false
training	oneLayer	oneLayer - rat 1	0	-0.34786907	0.09845033	false
training	oneLayer	oneLayer - rat 1	0	-0.3520336	0.08839627	false
training	oneLayer	oneLayer - rat 1	0	-0.3520336	0.07768901	false
training	oneLayer	oneLayer - rat 1	0	-0.3558647	0.068439834	false
training	oneLayer	oneLayer - rat 1	0	-0.3558647	0.0581584	false
training	oneLayer	oneLayer - rat 1	0	-0.36002755	0.048108377	false
training	oneLayer	oneLayer - rat 1	0	-0.36002755	0.037942924	false
training	oneLayer	oneLayer - rat 1	0	-0.3641172	0.028069593	false
training	oneLayer	oneLayer - rat 1	0	-0.3641172	0.017656278	false
training	oneLayer	oneLayer - rat 1	0	-0.36811993	0.007992824	false
training	oneLayer	oneLayer - rat 1	0	-0.36811993	-0.00219329	false
training	oneLayer	oneLayer - rat 1	0	-0.3722266	-0.012107712	false
training	oneLayer	oneLayer - rat 1	0	-0.37961182	-0.019492922	false
training	oneLayer	oneLayer - rat 1	0	-0.38927728	-0.023496494	false
training	oneLayer	oneLayer - rat 1	0	-0.39641973	-0.030638948	false
training	oneLayer	oneLayer - rat 1	0	-0.40584132	-0.03454151	false
training	oneLayer	oneLayer - rat 1	0	-0.41298732	-0.041687522	false
training	oneLayer	oneLayer - rat 1	0	-0.41705385	-0.05150495	false
training	oneLayer	oneLayer - rat 1	0	-0.41705385	-0.062311254	false
training	oneLayer	oneLayer - rat 1	0	-0.42118788	-0.072291754	false
training	oneLayer	oneLayer - rat 1	0	-0.42118788	-0.0831609	false
training	oneLayer	oneLayer - rat 1	0	-0.42502943	-0.09243522	false
training	oneLayer	oneLayer - rat 1	0	-0.42502943	-0.10284017	false
training	oneLayer	oneLayer - rat 1	0	-0.42094776	-0.112694144	false
training	oneLayer	oneLayer - rat 1	0	-0.42094776	-0.12334882	false
training	oneLayer	oneLayer - rat 1	0	-0.41687492	-0.1331815	false
training	oneLayer	oneLayer - rat 1	0	-0.41687492	-0.14417359	false
training	oneLayer	oneLayer - rat 1	0	-0.41285396	-0.15388104	false
training	oneLayer	oneLayer - rat 1	0	-0.41285396	-0.16453455	false
training	oneLayer	oneLayer - rat 1	0	-0.4089777	-0.17389269	false
training	oneLayer	oneLayer - rat 1	0	-0.4089777	-0.18406102	false
training	oneLayer	oneLayer - rat 1	0	-0.4050692	-0.1934969	false
training	oneLayer	oneLayer - rat 1	0	-0.39791572	-0.20065038	false
training	oneLayer	oneLayer - rat 1	0	-0.38865507	-0.20448627	false
training	oneLayer	oneLayer - rat 1	0	-0.37767604	-0.20448625	false
training	oneLayer	oneLayer - rat 1	0	-0.36774635	-0.20037325	false
training	oneLayer	oneLayer - rat 1	0	-0.3601371	-0.19276398	false
training	oneLayer	oneLayer - rat 1	0	-0.3562669	-0.18342046	false
training	oneLayer	oneLayer - rat 1	0	-0.35626692	-0.17329374	false
training	oneLayer	oneLayer - rat 1	0	-0.36042905	-0.16324544	false
training	oneLayer	oneLayer - rat 1	0	-0.36427742	-0.15395467	false
training	oneLayer	oneLayer - rat 1	0	-0.3681739	-0.14454775	false
training	oneLayer	oneLayer - rat 1	0	-0.37226897	-0.1346614	false
training	oneLayer	oneLayer - rat 1	0	-0.37640724	-0.12467075	false
training	oneLayer	oneLayer - rat 1	0	-0.3804408	-0.1149329	false
training	oneLayer	oneLayer - rat 1	0	-0.3843308	-0.105541594	false
training	oneLayer	oneLayer - rat 1	0	-0.38840038	-0.095716834	false
training	oneLayer	oneLayer - rat 1	0	-0.3922961	-0.08631171	false
training	oneLayer	oneLayer - rat 1	0	-0.39639255	-0.07642203	false
training	oneLayer	oneLayer - rat 1	0	-0.4005779	-0.0663177	false
training	oneLayer	oneLayer - rat 1	0	-0.40447706	-0.056904346	false
training	oneLayer	oneLayer - rat 1	0	-0.40844843	-0.047316607	false
training	oneLayer	oneLayer - rat 1	0	-0.4125157	-0.037497345	false
training	oneLayer	oneLayer - rat 1	0	-0.41640273	-0.028113255	false
training	oneLayer	oneLayer - rat 1	0	-0.41640273	-0.018086802	false
training	oneLayer	oneLayer - rat 1	0	-0.4123125	-0.008212081	false
training	oneLayer	oneLayer - rat 1	0	-0.40817308	0.001781333	false
training	oneLayer	oneLayer - rat 1	0	-0.40061298	0.0093414625	false
training	oneLayer	oneLayer - rat 1	0	-0.39643803	0.01942071	false
training	oneLayer	oneLayer - rat 1	0	-0.3890663	0.026792416	false
training	oneLayer	oneLayer - rat 1	0	-0.38522866	0.036057346	false
training	oneLayer	oneLayer - rat 1	0	-0.37747136	0.043814663	false
training	oneLayer	oneLayer - rat 1	0	-0.37357748	0.053215384	false
training	oneLayer	oneLayer - rat 1	0	-0.36594138	0.060851466	false
training	oneLayer	oneLayer - rat 1	0	-0.3619584	0.070467256	false
training	oneLayer	oneLayer - rat 1	0	-0.3544315	0.07799417	false
training	oneLayer	oneLayer - rat 1	0	-0.35032606	0.087905586	false
training	oneLayer	oneLayer - rat 1	0	-0.34283897	0.0953927	false
training	oneLayer	oneLayer - rat 1	0	-0.338959	0.10475976	false
training	oneLayer	oneLayer - rat 1	0	-0.3316295	0.112089254	false
training	oneLayer	oneLayer - rat 1	0	-0.32744578	0.12218971	false
training	oneLayer	oneLayer - rat 1	0	-0.3198244	0.1298111	false
training	oneLayer	oneLayer - rat 1	0	-0.31571227	0.13973865	false
training	oneLayer	oneLayer - rat 1	0	-0.30830994	0.14714101	false
training	oneLayer	oneLayer - rat 1	0	-0.3041273	0.15723881	false
training	oneLayer	oneLayer - rat 1	0	-0.29668796	0.16467814	false
training	oneLayer	oneLayer - rat 1	0	-0.29262388	0.17448977	false
training	oneLayer	oneLayer - rat 1	0	-0.2852588	0.18185484	false
training	oneLayer	oneLayer - rat 1	0	-0.2812861	0.1914458	false
training	oneLayer	oneLayer - rat 1	0	-0.27420938	0.19852252	false
training	oneLayer	oneLayer - rat 1	0	-0.27014717	0.20832956	false
training	oneLayer	oneLayer - rat 1	0	-0.2628281	0.21564864	false
training	oneLayer	oneLayer - rat 1	0	-0.2586955	0.22562557	false
training	oneLayer	oneLayer - rat 1	0	-0.25132194	0.23299918	false
training	oneLayer	oneLayer - rat 1	0	-0.24714479	0.24308373	false
training	oneLayer	oneLayer - rat 1	0	-0.23998077	0.25024775	false
training	oneLayer	oneLayer - rat 1	0	-0.23602784	0.259791	false
training	oneLayer	oneLayer - rat 1	0	-0.22830226	0.26751658	false
training	oneLayer	oneLayer - rat 1	0	-0.224468	0.27677333	false
training	oneLayer	oneLayer - rat 1	0	-0.21727258	0.28396875	false
training	oneLayer	oneLayer - rat 1	0	-0.21332714	0.2934939	false
training	oneLayer	oneLayer - rat 1	0	-0.20577472	0.3010463	false
training	oneLayer	oneLayer - rat 1	0	-0.20174773	0.31076837	false
training	oneLayer	oneLayer - rat 1	0	-0.19450593	0.31801015	false
training	oneLayer	oneLayer - rat 1	0	-0.19054742	0.32756686	false
training	oneLayer	oneLayer - rat 1	0	-0.1829392	0.3351751	false
training	oneLayer	oneLayer - rat 1	0	-0.17887498	0.344987	false
training	oneLayer	oneLayer - rat 1	0	-0.17150226	0.35235974	false
training	oneLayer	oneLayer - rat 1	0	-0.16759503	0.36179265	false
training	oneLayer	oneLayer - rat 1	0	-0.16006528	0.36932242	false
training	oneLayer	oneLayer - rat 1	0	-0.1561431	0.3787914	false
training	oneLayer	oneLayer - rat 1	0	-0.14892974	0.38600475	false
training	oneLayer	oneLayer - rat 1	0	-0.1449353	0.39564824	false
training	oneLayer	oneLayer - rat 1	0	-0.13770318	0.40288037	false
training	oneLayer	oneLayer - rat 1	0	-0.12759747	0.4070663	false
training	oneLayer	oneLayer - rat 1	0	-0.117456086	0.4070663	false
training	oneLayer	oneLayer - rat 1	0	-0.10738879	0.40289629	false
training	oneLayer	oneLayer - rat 1	0	-0.10004874	0.39555624	false
training	oneLayer	oneLayer - rat 1	0	-0.09595674	0.3856773	false
training	oneLayer	oneLayer - rat 1	0	-0.08871933	0.3784399	false
training	oneLayer	oneLayer - rat 1	0	-0.0846179	0.3685382	false
training	oneLayer	oneLayer - rat 1	0	-0.07713608	0.36105636	false
training	oneLayer	oneLayer - rat 1	0	-0.06707713	0.3568898	false
training	oneLayer	oneLayer - rat 1	0	-0.059446223	0.34925893	false
training	oneLayer	oneLayer - rat 1	0	-0.049285512	0.34505022	false
training	oneLayer	oneLayer - rat 1	0	-0.041586965	0.33735168	false
training	oneLayer	oneLayer - rat 1	0	-0.037627626	0.327793	false
training	oneLayer	oneLayer - rat 1	0	-0.030007921	0.32017332	false
training	oneLayer	oneLayer - rat 1	0	-0.025866594	0.31017527	false
training	oneLayer	oneLayer - rat 1	0	-0.018207332	0.302516	false
training	oneLayer	oneLayer - rat 1	0	-0.008420124	0.29846203	false
training	oneLayer	oneLayer - rat 1	0	-0.001067968	0.2911099	false
training	oneLayer	oneLayer - rat 1	0	0.002785848	0.28180596	false
training	oneLayer	oneLayer - rat 1	0	0.009964148	0.2746277	false
training	oneLayer	oneLayer - rat 1	0	0.013833325	0.26528665	false
training	oneLayer	oneLayer - rat 1	0	0.020977888	0.2581421	false
training	oneLayer	oneLayer - rat 1	0	0.030941369	0.25401512	false
training	oneLayer	oneLayer - rat 1	0	0.03845869	0.2464978	false
training	oneLayer	oneLayer - rat 1	0	0.042585865	0.23653392	false
training	oneLayer	oneLayer - rat 1	0	0.04968262	0.22943717	false
training	oneLayer	oneLayer - rat 1	0	0.053606275	0.21996464	false
training	oneLayer	oneLayer - rat 1	0	0.060789134	0.21278179	false
training	oneLayer	oneLayer - rat 1	0	0.07092783	0.20858222	false
training	oneLayer	oneLayer - rat 1	0	0.07847652	0.20103353	false
training	oneLayer	oneLayer - rat 1	0	0.082432985	0.19148178	false
training	oneLayer	oneLayer - rat 1	0	0.09011804	0.18379673	false
training	oneLayer	oneLayer - rat 1	0	0.094304845	0.1736889	false
training	oneLayer	oneLayer - rat 1	0	0.101467654	0.16652611	false
training	oneLayer	oneLayer - rat 1	0	0.11118342	0.16250171	false
training	oneLayer	oneLayer - rat 1	0	0.11877976	0.15490538	false
training	oneLayer	oneLayer - rat 1	0	0.12292857	0.14488931	false
training	oneLayer	oneLayer - rat 1	0	0.13059756	0.13722032	false
training	oneLayer	oneLayer - rat 1	0	0.1344986	0.12780237	false
training	oneLayer	oneLayer - rat 1	0	0.1422244	0.12007658	false
training	oneLayer	oneLayer - rat 1	0	0.15154488	0.11621592	false
training	oneLayer	oneLayer - rat 1	0	0.15901437	0.10874643	false
training	oneLayer	oneLayer - rat 1	0	0.16905047	0.10458935	false
training	oneLayer	oneLayer - rat 1	0	0.17668341	0.09695642	false
training	oneLayer	oneLayer - rat 1	0	0.18683645	0.09275089	false
training	oneLayer	oneLayer - rat 1	0	0.19416863	0.08541874	false
training	oneLayer	oneLayer - rat 1	0	0.20403889	0.081330344	false
training	oneLayer	oneLayer - rat 1	0	0.21150422	0.07386501	false
training	oneLayer	oneLayer - rat 1	0	0.22157332	0.06969426	false
training	oneLayer	oneLayer - rat 1	0	0.22899812	0.06226947	false
training	oneLayer	oneLayer - rat 1	0	0.23827803	0.058425616	false
training	oneLayer	oneLayer - rat 1	0	0.24594422	0.05075943	false
training	oneLayer	oneLayer - rat 1	0	0.25589073	0.04663946	false
training	oneLayer	oneLayer - rat 1	0	0.26339307	0.039137103	false
training	oneLayer	oneLayer - rat 1	0	0.27310717	0.0351134	false
training	oneLayer	oneLayer - rat 1	0	0.28085124	0.027369337	false
training	oneLayer	oneLayer - rat 1	0	0.29100034	0.023165455	false
training	oneLayer	oneLayer - rat 1	0	0.29852805	0.01563775	false
training	oneLayer	oneLayer - rat 1	0	0.30848828	0.011512092	false
training	oneLayer	oneLayer - rat 1	0	0.31587481	0.0041255574	false
training	oneLayer	oneLayer - rat 1	0	0.32516968	2.75501E-4	false
training	oneLayer	oneLayer - rat 1	0	0.33230597	-0.0068607717	false
training	oneLayer	oneLayer - rat 1	0	0.34155485	-0.010691783	false
training	oneLayer	oneLayer - rat 1	0	0.3490296	-0.018166522	false
training	oneLayer	oneLayer - rat 1	0	0.35868502	-0.022165911	false
training	oneLayer	oneLayer - rat 1	0	0.3659172	-0.029398102	false
training	oneLayer	oneLayer - rat 1	0	0.37588447	-0.03352667	false
training	oneLayer	oneLayer - rat 1	0	0.38333198	-0.04097418	false
training	oneLayer	oneLayer - rat 1	0	0.3933553	-0.045125972	false
training	oneLayer	oneLayer - rat 1	0	0.40047118	-0.052241832	false
training	oneLayer	oneLayer - rat 1	0	0.4045088	-0.06198954	false
training	oneLayer	oneLayer - rat 1	0	0.4119084	-0.069389105	false
training	oneLayer	oneLayer - rat 1	0	0.4159216	-0.07907784	false
training	oneLayer	oneLayer - rat 1	0	0.41988683	-0.08865075	false
training	oneLayer	oneLayer - rat 1	0	0.42382798	-0.098165505	false
training	oneLayer	oneLayer - rat 1	0	0.42771873	-0.107558586	false
training	oneLayer	oneLayer - rat 1	0	0.42771873	-0.11783072	false
training	oneLayer	oneLayer - rat 1	0	0.42351925	-0.12796919	false
training	oneLayer	oneLayer - rat 1	0	0.42351925	-0.13883455	false
training	oneLayer	oneLayer - rat 1	0	0.4195986	-0.14829984	false
training	oneLayer	oneLayer - rat 1	0	0.4195986	-0.15870343	false
training	oneLayer	oneLayer - rat 1	0	0.415547	-0.16848485	false
training	oneLayer	oneLayer - rat 1	0	0.415547	-0.17885551	false
training	oneLayer	oneLayer - rat 1	0	0.41171312	-0.18811134	false
training	oneLayer	oneLayer - rat 1	0	0.4045812	-0.19524328	false
training	oneLayer	oneLayer - rat 1	0	0.39511573	-0.199164	false
training	oneLayer	oneLayer - rat 1	0	0.3850415	-0.19916402	false
training	oneLayer	oneLayer - rat 1	0	0.375644	-0.19527145	false
training	oneLayer	oneLayer - rat 1	0	0.3682951	-0.18792255	false
training	oneLayer	oneLayer - rat 1	0	0.36430085	-0.17827956	false
training	oneLayer	oneLayer - rat 1	0	0.36430085	-0.16748804	false
training	oneLayer	oneLayer - rat 1	0	0.36835238	-0.15770675	false
training	oneLayer	oneLayer - rat 1	0	0.37548125	-0.15057787	false
training	oneLayer	oneLayer - rat 1	0	0.37946287	-0.14096543	false
training	oneLayer	oneLayer - rat 1	0	0.38673362	-0.13369465	false
training	oneLayer	oneLayer - rat 1	0	0.390641	-0.1242614	false
training	oneLayer	oneLayer - rat 1	0	0.39820394	-0.11669846	false
training	oneLayer	oneLayer - rat 1	0	0.4021004	-0.107291535	false
training	oneLayer	oneLayer - rat 1	0	0.40977556	-0.09961638	false
training	oneLayer	oneLayer - rat 1	0	0.41397262	-0.08948379	false
training	oneLayer	oneLayer - rat 1	0	0.4178746	-0.08006357	false
training	oneLayer	oneLayer - rat 1	0	0.42190108	-0.07034275	false
training	oneLayer	oneLayer - rat 1	0	0.4258624	-0.060779277	false
training	oneLayer	oneLayer - rat 1	0	0.43003446	-0.050707	false
training	oneLayer	oneLayer - rat 1	0	0.4341196	-0.04084454	false
training	oneLayer	oneLayer - rat 1	0	0.4341196	-0.030661996	false
training	oneLayer	oneLayer - rat 1	0	0.4299489	-0.020592999	false
training	oneLayer	oneLayer - rat 1	0	0.42590505	-0.010830266	false
training	oneLayer	oneLayer - rat 1	0	0.41862103	-0.0035462577	false
training	oneLayer	oneLayer - rat 1	0	0.4087795	5.302253E-4	false
training	oneLayer	oneLayer - rat 1	0	0.39806792	5.302206E-4	false
training	oneLayer	oneLayer - rat 1	0	0.3881642	-0.0035720381	false
training	oneLayer	oneLayer - rat 1	0	0.3804506	-0.011285632	false
training	oneLayer	oneLayer - rat 1	0	0.37068984	-0.015328678	false
training	oneLayer	oneLayer - rat 1	0	0.36314723	-0.022871284	false
training	oneLayer	oneLayer - rat 1	0	0.35333437	-0.026935916	false
training	oneLayer	oneLayer - rat 1	0	0.34619227	-0.034078028	false
training	oneLayer	oneLayer - rat 1	0	0.33614582	-0.03823941	false
training	oneLayer	oneLayer - rat 1	0	0.328516	-0.045869213	false
training	oneLayer	oneLayer - rat 1	0	0.31904328	-0.04979295	false
training	oneLayer	oneLayer - rat 1	0	0.3116996	-0.057136644	false
training	oneLayer	oneLayer - rat 1	0	0.30174583	-0.06125963	false
training	oneLayer	oneLayer - rat 1	0	0.2941578	-0.06884766	false
training	oneLayer	oneLayer - rat 1	0	0.28445363	-0.072867274	false
training	oneLayer	oneLayer - rat 1	0	0.27731156	-0.080009334	false
training	oneLayer	oneLayer - rat 1	0	0.26716745	-0.08421117	false
training	oneLayer	oneLayer - rat 1	0	0.2600836	-0.09129505	false
training	oneLayer	oneLayer - rat 1	0	0.25061375	-0.095217586	false
training	oneLayer	oneLayer - rat 1	0	0.24310549	-0.10272586	false
training	oneLayer	oneLayer - rat 1	0	0.23344536	-0.10672722	false
training	oneLayer	oneLayer - rat 1	0	0.22572055	-0.11445203	false
training	oneLayer	oneLayer - rat 1	0	0.21632385	-0.11834428	false
training	oneLayer	oneLayer - rat 1	0	0.20923729	-0.12543085	false
training	oneLayer	oneLayer - rat 1	0	0.19923994	-0.12957188	false
training	oneLayer	oneLayer - rat 1	0	0.19187798	-0.13693386	false
training	oneLayer	oneLayer - rat 1	0	0.18219332	-0.14094537	false
training	oneLayer	oneLayer - rat 1	0	0.17507657	-0.14806212	false
training	oneLayer	oneLayer - rat 1	0	0.16565596	-0.15196429	false
training	oneLayer	oneLayer - rat 1	0	0.1579223	-0.15969796	false
training	oneLayer	oneLayer - rat 1	0	0.14840773	-0.16363902	false
training	oneLayer	oneLayer - rat 1	0	0.14068362	-0.17136315	false
training	oneLayer	oneLayer - rat 1	0	0.13077538	-0.17546727	false
training	oneLayer	oneLayer - rat 1	0	0.12348894	-0.18275373	false
training	oneLayer	oneLayer - rat 1	0	0.11401608	-0.18667752	false
training	oneLayer	oneLayer - rat 1	0	0.10644378	-0.19424982	false
training	oneLayer	oneLayer - rat 1	0	0.09692575	-0.19819233	false
training	oneLayer	oneLayer - rat 1	0	0.08965215	-0.20546593	false
training	oneLayer	oneLayer - rat 1	0	0.07977479	-0.20955727	false
training	oneLayer	oneLayer - rat 1	0	0.0724227	-0.21690936	false
training	oneLayer	oneLayer - rat 1	0	0.06301921	-0.22080442	false
training	oneLayer	oneLayer - rat 1	0	0.055253536	-0.2285701	false
training	oneLayer	oneLayer - rat 1	0	0.045729883	-0.23251493	false
training	oneLayer	oneLayer - rat 1	0	0.038413186	-0.23983164	false
training	oneLayer	oneLayer - rat 1	0	0.028550858	-0.24391675	false
training	oneLayer	oneLayer - rat 1	0	0.020849884	-0.25161773	false
training	oneLayer	oneLayer - rat 1	0	0.011570445	-0.2554614	false
training	oneLayer	oneLayer - rat 1	0	0.0043491484	-0.2626827	false
training	oneLayer	oneLayer - rat 1	0	-0.0050849332	-0.26659045	false
training	oneLayer	oneLayer - rat 1	0	-0.0125770755	-0.2740826	false
training	oneLayer	oneLayer - rat 1	0	-0.022402925	-0.27815259	false
training	oneLayer	oneLayer - rat 1	0	-0.029870175	-0.28561985	false
training	oneLayer	oneLayer - rat 1	0	-0.039667387	-0.289678	false
training	oneLayer	oneLayer - rat 1	0	-0.047361378	-0.29737198	false
training	oneLayer	oneLayer - rat 1	0	-0.057258133	-0.30147138	false
training	oneLayer	oneLayer - rat 1	0	-0.06496704	-0.3091803	false
training	oneLayer	oneLayer - rat 1	0	-0.074546486	-0.31314823	false
training	oneLayer	oneLayer - rat 1	0	-0.0819196	-0.32052135	false
training	oneLayer	oneLayer - rat 1	0	-0.09157778	-0.3245219	false
training	oneLayer	oneLayer - rat 1	0	-0.09926781	-0.33221194	false
training	oneLayer	oneLayer - rat 1	0	-0.10924053	-0.33634278	false
training	oneLayer	oneLayer - rat 1	0	-0.11651058	-0.34361282	false
training	oneLayer	oneLayer - rat 1	0	-0.12595771	-0.34752595	false
training	oneLayer	oneLayer - rat 1	0	-0.1330475	-0.35461578	false
training	oneLayer	oneLayer - rat 1	0	-0.14230238	-0.35844928	false
training	oneLayer	oneLayer - rat 1	0	-0.14995907	-0.36610597	false
training	oneLayer	oneLayer - rat 1	0	-0.15996802	-0.3702518	false
training	oneLayer	oneLayer - rat 1	0	-0.16714305	-0.37742686	false
training	oneLayer	oneLayer - rat 1	0	-0.17675824	-0.38140962	false
training	oneLayer	oneLayer - rat 1	0	-0.18716493	-0.38140962	false
training	oneLayer	oneLayer - rat 1	0	-0.19641632	-0.37757757	false
training	oneLayer	oneLayer - rat 1	0	-0.2073742	-0.37757757	false
training	oneLayer	oneLayer - rat 1	0	-0.21701919	-0.37358248	false
training	oneLayer	oneLayer - rat 1	0	-0.22716357	-0.37358248	false
training	oneLayer	oneLayer - rat 1	0	-0.23648404	-0.36972183	false
training	oneLayer	oneLayer - rat 1	0	-0.24683405	-0.36972183	false
training	oneLayer	oneLayer - rat 1	0	-0.25674847	-0.36561516	false
training	oneLayer	oneLayer - rat 1	0	-0.2644925	-0.35787112	false
training	oneLayer	oneLayer - rat 1	0	-0.271996	-0.35036764	false
training	oneLayer	oneLayer - rat 1	0	-0.27934054	-0.34302312	false
training	oneLayer	oneLayer - rat 1	0	-0.2865521	-0.33581156	false
training	oneLayer	oneLayer - rat 1	0	-0.29393718	-0.32842648	false
training	oneLayer	oneLayer - rat 1	0	-0.30166578	-0.3206979	false
training	oneLayer	oneLayer - rat 1	0	-0.309299	-0.31306466	false
training	oneLayer	oneLayer - rat 1	0	-0.317015	-0.3053487	false
training	oneLayer	oneLayer - rat 1	0	-0.32421744	-0.29814625	false
training	oneLayer	oneLayer - rat 1	0	-0.33139026	-0.29097345	false
training	oneLayer	oneLayer - rat 1	0	-0.33542764	-0.2812263	false
training	oneLayer	oneLayer - rat 1	0	-0.33936837	-0.27171254	false
training	oneLayer	oneLayer - rat 1	0	-0.34321907	-0.26241618	false
training	oneLayer	oneLayer - rat 1	0	-0.34718007	-0.2528535	false
training	oneLayer	oneLayer - rat 1	0	-0.35121638	-0.24310897	false
training	oneLayer	oneLayer - rat 1	0	-0.35509118	-0.23375437	false
training	oneLayer	oneLayer - rat 1	0	-0.35894296	-0.22445542	false
training	oneLayer	oneLayer - rat 1	0	-0.36285135	-0.21501972	false
training	oneLayer	oneLayer - rat 1	0	-0.36703154	-0.20492785	false
training	oneLayer	oneLayer - rat 1	0	-0.37090492	-0.19557667	false
training	oneLayer	oneLayer - rat 1	0	-0.37484062	-0.18607512	false
training	oneLayer	oneLayer - rat 1	0	-0.37881687	-0.17647555	false
training	oneLayer	oneLayer - rat 1	0	-0.38286582	-0.16670062	false
training	oneLayer	oneLayer - rat 1	0	-0.38701293	-0.15668859	false
training	oneLayer	oneLayer - rat 1	0	-0.39104387	-0.14695705	false
training	oneLayer	oneLayer - rat 1	0	-0.39503375	-0.13732465	false
training	oneLayer	oneLayer - rat 1	0	-0.3989243	-0.12793201	false
training	oneLayer	oneLayer - rat 1	0	-0.4031053	-0.11783824	false
training	oneLayer	oneLayer - rat 1	0	-0.4071662	-0.10803427	false
training	oneLayer	oneLayer - rat 1	0	-0.41134116	-0.09795507	false
training	oneLayer	oneLayer - rat 1	0	-0.41534376	-0.088291965	false
training	oneLayer	oneLayer - rat 1	0	-0.419404	-0.07848972	false
training	oneLayer	oneLayer - rat 1	0	-0.42344943	-0.06872319	false
training	oneLayer	oneLayer - rat 1	0	-0.42741826	-0.05914159	false
training	oneLayer	oneLayer - rat 1	0	-0.43148258	-0.049329437	false
training	oneLayer	oneLayer - rat 1	0	-0.43567356	-0.039211538	false
training	oneLayer	oneLayer - rat 1	0	-0.43567356	-0.028604094	false
training	oneLayer	oneLayer - rat 1	0	-0.43167377	-0.018947717	false
training	oneLayer	oneLayer - rat 1	0	-0.42763215	-0.009190384	false
training	oneLayer	oneLayer - rat 1	0	-0.4205412	-0.0020994085	false
training	oneLayer	oneLayer - rat 1	0	-0.41097137	0.0018645461	false
training	oneLayer	oneLayer - rat 1	0	-0.40070468	0.0018645497	false
training	oneLayer	oneLayer - rat 1	0	-0.391044	-0.002137042	false
training	oneLayer	oneLayer - rat 1	0	-0.38384145	-0.009339552	false
training	oneLayer	oneLayer - rat 1	0	-0.37376693	-0.013512556	false
training	oneLayer	oneLayer - rat 1	0	-0.36631155	-0.020967927	false
training	oneLayer	oneLayer - rat 1	0	-0.35684326	-0.024889823	false
training	oneLayer	oneLayer - rat 1	0	-0.34960976	-0.032123312	false
training	oneLayer	oneLayer - rat 1	0	-0.34019476	-0.03602312	false
training	oneLayer	oneLayer - rat 1	0	-0.33304435	-0.043173537	false
training	oneLayer	oneLayer - rat 1	0	-0.32288635	-0.04738111	false
training	oneLayer	oneLayer - rat 1	0	-0.3157616	-0.05450586	false
training	oneLayer	oneLayer - rat 1	0	-0.30626908	-0.05843779	false
training	oneLayer	oneLayer - rat 1	0	-0.2985209	-0.06618596	false
training	oneLayer	oneLayer - rat 1	0	-0.28902966	-0.07011736	false
training	oneLayer	oneLayer - rat 1	0	-0.2815221	-0.0776249	false
training	oneLayer	oneLayer - rat 1	0	-0.27187538	-0.0816207	false
training	oneLayer	oneLayer - rat 1	0	-0.2642547	-0.08924138	false
training	oneLayer	oneLayer - rat 1	0	-0.2549864	-0.093080424	false
training	oneLayer	oneLayer - rat 1	0	-0.24778736	-0.100279465	false
training	oneLayer	oneLayer - rat 1	0	-0.23778994	-0.10442053	false
training	oneLayer	oneLayer - rat 1	0	-0.2301978	-0.112012655	false
training	oneLayer	oneLayer - rat 1	0	-0.22090243	-0.11586293	false
training	oneLayer	oneLayer - rat 1	0	-0.2132974	-0.123467945	false
training	oneLayer	oneLayer - rat 1	0	-0.20395017	-0.12733969	false
training	oneLayer	oneLayer - rat 1	0	-0.19618012	-0.13510974	false
training	oneLayer	oneLayer - rat 1	0	-0.18644625	-0.13914163	false
training	oneLayer	oneLayer - rat 1	0	-0.17868108	-0.14690681	false
training	oneLayer	oneLayer - rat 1	0	-0.16923219	-0.15082066	false
training	oneLayer	oneLayer - rat 1	0	-0.16183998	-0.15821286	false
training	oneLayer	oneLayer - rat 1	0	-0.15180184	-0.16237079	false
training	oneLayer	oneLayer - rat 1	0	-0.14446211	-0.1697105	false
training	oneLayer	oneLayer - rat 1	0	-0.13445415	-0.17385595	false
training	oneLayer	oneLayer - rat 1	0	-0.12676303	-0.18154705	false
training	oneLayer	oneLayer - rat 1	0	-0.11715485	-0.18552688	false
training	oneLayer	oneLayer - rat 1	0	-0.109762534	-0.1929192	false
training	oneLayer	oneLayer - rat 1	0	-0.10025701	-0.1968565	false
training	oneLayer	oneLayer - rat 1	0	-0.09314221	-0.2039713	false
training	oneLayer	oneLayer - rat 1	0	-0.083489046	-0.20796977	false
training	oneLayer	oneLayer - rat 1	0	-0.07641106	-0.21504775	false
training	oneLayer	oneLayer - rat 1	0	-0.06698469	-0.21895227	false
training	oneLayer	oneLayer - rat 1	0	-0.05978764	-0.22614932	false
training	oneLayer	oneLayer - rat 1	0	-0.05025237	-0.23009895	false
training	oneLayer	oneLayer - rat 1	0	-0.04285621	-0.23749511	false
training	oneLayer	oneLayer - rat 1	0	-0.033288844	-0.24145804	false
training	oneLayer	oneLayer - rat 1	0	-0.026199577	-0.2485473	false
training	oneLayer	oneLayer - rat 1	0	-0.016397228	-0.25260755	false
training	oneLayer	oneLayer - rat 1	0	-0.009245536	-0.25975925	false
training	oneLayer	oneLayer - rat 1	0	4.5051414E-4	-0.26377547	false
training	oneLayer	oneLayer - rat 1	0	0.007956256	-0.2712812	false
training	oneLayer	oneLayer - rat 1	0	0.017868513	-0.27538702	false
training	oneLayer	oneLayer - rat 1	0	0.025038226	-0.2825567	false
training	oneLayer	oneLayer - rat 1	0	0.035117876	-0.28673184	false
training	oneLayer	oneLayer - rat 1	0	0.04226139	-0.29387534	false
training	oneLayer	oneLayer - rat 1	0	0.05196127	-0.29789317	false
training	oneLayer	oneLayer - rat 1	0	0.059165683	-0.30509758	false
training	oneLayer	oneLayer - rat 1	0	0.068630934	-0.3090182	false
training	oneLayer	oneLayer - rat 1	0	0.07604611	-0.31643337	false
training	oneLayer	oneLayer - rat 1	0	0.08603689	-0.3205717	false
training	oneLayer	oneLayer - rat 1	0	0.09366015	-0.32819495	false
training	oneLayer	oneLayer - rat 1	0	0.10368306	-0.33234656	false
training	oneLayer	oneLayer - rat 1	0	0.11102459	-0.3396881	false
training	oneLayer	oneLayer - rat 1	0	0.12112097	-0.34387013	false
training	oneLayer	oneLayer - rat 1	0	0.12879544	-0.35154462	false
training	oneLayer	oneLayer - rat 1	0	0.13855845	-0.3555886	false
training	oneLayer	oneLayer - rat 1	0	0.14566337	-0.3626935	false
training	oneLayer	oneLayer - rat 1	0	0.15569867	-0.36685026	false
training	oneLayer	oneLayer - rat 1	0	0.16311514	-0.3742667	false
training	oneLayer	oneLayer - rat 1	0	0.17311607	-0.37840924	false
training	oneLayer	oneLayer - rat 1	0	0.18366458	-0.37840924	false
training	oneLayer	oneLayer - rat 1	0	0.19324644	-0.38237816	false
training	oneLayer	oneLayer - rat 1	0	0.20325369	-0.38237816	false
training	oneLayer	oneLayer - rat 1	0	0.21265787	-0.37848282	false
training	oneLayer	oneLayer - rat 1	0	0.22281073	-0.37848282	false
training	oneLayer	oneLayer - rat 1	0	0.23237951	-0.3745193	false
training	oneLayer	oneLayer - rat 1	0	0.24012728	-0.36677152	false
training	oneLayer	oneLayer - rat 1	0	0.24420951	-0.3569161	false
training	oneLayer	oneLayer - rat 1	0	0.2480547	-0.347633	false
training	oneLayer	oneLayer - rat 1	0	0.2519637	-0.3381958	false
training	oneLayer	oneLayer - rat 1	0	0.25616184	-0.32806063	false
training	oneLayer	oneLayer - rat 1	0	0.2601728	-0.31837726	false
training	oneLayer	oneLayer - rat 1	0	0.26404968	-0.30901763	false
training	oneLayer	oneLayer - rat 1	0	0.26806352	-0.29932737	false
training	oneLayer	oneLayer - rat 1	0	0.2721259	-0.28951988	false
training	oneLayer	oneLayer - rat 1	0	0.27596435	-0.28025302	false
training	oneLayer	oneLayer - rat 1	0	0.2799165	-0.27071178	false
training	oneLayer	oneLayer - rat 1	0	0.28395602	-0.26095948	false
training	oneLayer	oneLayer - rat 1	0	0.28802645	-0.25113258	false
training	oneLayer	oneLayer - rat 1	0	0.2920238	-0.24148205	false
training	oneLayer	oneLayer - rat 1	0	0.2959366	-0.23203571	false
training	oneLayer	oneLayer - rat 1	0	0.3000333	-0.22214541	false
training	oneLayer	oneLayer - rat 1	0	0.30416733	-0.212165	false
training	oneLayer	oneLayer - rat 1	0	0.30804777	-0.20279676	false
training	oneLayer	oneLayer - rat 1	0	0.31220186	-0.1927679	false
training	oneLayer	oneLayer - rat 1	0	0.31618953	-0.18314078	false
training	oneLayer	oneLayer - rat 1	0	0.32033575	-0.17313091	false
training	oneLayer	oneLayer - rat 1	0	0.3241703	-0.1638735	false
training	oneLayer	oneLayer - rat 1	0	0.32811376	-0.15435308	false
training	oneLayer	oneLayer - rat 1	0	0.332001	-0.14496848	false
training	oneLayer	oneLayer - rat 1	0	0.33584365	-0.13569151	false
training	oneLayer	oneLayer - rat 1	0	0.33979085	-0.12616207	false
training	oneLayer	oneLayer - rat 1	0	0.3438911	-0.1162632	false
training	oneLayer	oneLayer - rat 1	0	0.3480921	-0.106121086	false
training	oneLayer	oneLayer - rat 1	0	0.35224575	-0.09609328	false
training	oneLayer	oneLayer - rat 1	0	0.3599972	-0.08834181	false
training	oneLayer	oneLayer - rat 1	0	0.36415288	-0.078309126	false
training	oneLayer	oneLayer - rat 1	0	0.37168896	-0.07077304	false
training	oneLayer	oneLayer - rat 1	0	0.37569103	-0.06111119	false
training	oneLayer	oneLayer - rat 1	0	0.38336045	-0.053441755	false
training	oneLayer	oneLayer - rat 1	0	0.387359	-0.043788422	false
training	oneLayer	oneLayer - rat 1	0	0.39449987	-0.03664755	false
training	oneLayer	oneLayer - rat 1	0	0.39859372	-0.026764102	false
training	oneLayer	oneLayer - rat 1	0	0.40595782	-0.019399993	false
training	oneLayer	oneLayer - rat 1	0	0.40996596	-0.009723468	false
training	oneLayer	oneLayer - rat 1	0	0.40996596	3.257758E-4	false
training	oneLayer	oneLayer - rat 1	0	0.41412887	0.01037594	false
training	oneLayer	oneLayer - rat 1	0	0.41412887	0.021169288	false
training	oneLayer	oneLayer - rat 1	0	0.41007477	0.030956727	false
training	oneLayer	oneLayer - rat 1	0	0.41007477	0.041423216	false
training	oneLayer	oneLayer - rat 1	0	0.4062371	0.050688148	false
training	oneLayer	oneLayer - rat 1	0	0.4062371	0.060770065	false
training	oneLayer	oneLayer - rat 1	0	0.41016388	0.0702502	false
training	oneLayer	oneLayer - rat 1	0	0.41016388	0.080545396	false
training	oneLayer	oneLayer - rat 1	0	0.40615866	0.090214886	false
training	oneLayer	oneLayer - rat 1	0	0.40615866	0.10035647	false
training	oneLayer	oneLayer - rat 1	0	0.40229458	0.10968514	false
training	oneLayer	oneLayer - rat 1	0	0.40229458	0.12040414	false
training	oneLayer	oneLayer - rat 1	0	0.40631515	0.13011067	false
training	oneLayer	oneLayer - rat 1	0	0.41036248	0.13988183	false
training	oneLayer	oneLayer - rat 1	0	0.41036248	0.15022206	false
training	oneLayer	oneLayer - rat 1	0	0.40621033	0.16024621	false
training	oneLayer	oneLayer - rat 1	0	0.40621033	0.17094482	false
training	oneLayer	oneLayer - rat 1	0	0.40219352	0.18064229	false
training	oneLayer	oneLayer - rat 1	0	0.40219352	0.19106954	false
training	oneLayer	oneLayer - rat 1	0	0.39833522	0.20038432	false
training	oneLayer	oneLayer - rat 1	0	0.3983352	0.21123882	false
training	oneLayer	oneLayer - rat 1	0	0.39443052	0.22066553	false
training	oneLayer	oneLayer - rat 1	0	0.3871373	0.22795877	false
training	oneLayer	oneLayer - rat 1	0	0.37752852	0.23193884	false
training	oneLayer	oneLayer - rat 1	0	0.36654836	0.23193884	false
training	oneLayer	oneLayer - rat 1	0	0.3571637	0.22805159	false
training	oneLayer	oneLayer - rat 1	0	0.347875	0.22420408	false
training	oneLayer	oneLayer - rat 1	0	0.33697698	0.22420406	false
training	oneLayer	oneLayer - rat 1	0	0.32764435	0.22033836	false
training	oneLayer	oneLayer - rat 1	0	0.31731364	0.22033836	false
training	oneLayer	oneLayer - rat 1	0	0.30717528	0.2161389	false
training	oneLayer	oneLayer - rat 1	0	0.2963518	0.2161389	false
training	oneLayer	oneLayer - rat 1	0	0.28700978	0.2122693	false
training	oneLayer	oneLayer - rat 1	0	0.27673498	0.2122693	false
training	oneLayer	oneLayer - rat 1	0	0.2671998	0.20831971	false
training	oneLayer	oneLayer - rat 1	0	0.2572173	0.2041848	false
training	oneLayer	oneLayer - rat 1	0	0.2470766	0.2041848	false
training	oneLayer	oneLayer - rat 1	0	0.23702013	0.20001927	false
training	oneLayer	oneLayer - rat 1	0	0.2269005	0.20001927	false
training	oneLayer	oneLayer - rat 1	0	0.21738444	0.19607759	false
training	oneLayer	oneLayer - rat 1	0	0.2072844	0.191894	false
training	oneLayer	oneLayer - rat 1	0	0.1966587	0.191894	false
training	oneLayer	oneLayer - rat 1	0	0.18722463	0.18798627	false
training	oneLayer	oneLayer - rat 1	0	0.17630224	0.18798625	false
training	oneLayer	oneLayer - rat 1	0	0.1666155	0.18397388	false
training	oneLayer	oneLayer - rat 1	0	0.15734477	0.1801338	false
training	oneLayer	oneLayer - rat 1	0	0.14678064	0.1801338	false
training	oneLayer	oneLayer - rat 1	0	0.13729602	0.17620514	false
training	oneLayer	oneLayer - rat 1	0	0.12706244	0.17620514	false
training	oneLayer	oneLayer - rat 1	0	0.116914734	0.17200182	false
training	oneLayer	oneLayer - rat 1	0	0.10704773	0.16791476	false
training	oneLayer	oneLayer - rat 1	0	0.09648489	0.16791476	false
training	oneLayer	oneLayer - rat 1	0	0.08683644	0.16391824	false
training	oneLayer	oneLayer - rat 1	0	0.07589281	0.16391824	false
training	oneLayer	oneLayer - rat 1	0	0.06658721	0.16006373	false
training	oneLayer	oneLayer - rat 1	0	0.057323147	0.15622641	false
training	oneLayer	oneLayer - rat 1	0	0.047266133	0.15622641	false
training	oneLayer	oneLayer - rat 1	0	0.037980042	0.15237997	false
training	oneLayer	oneLayer - rat 1	0	0.027214725	0.15237997	false
training	oneLayer	oneLayer - rat 1	0	0.017261522	0.14825723	false
training	oneLayer	oneLayer - rat 1	0	0.006772227	0.14825721	false
training	oneLayer	oneLayer - rat 1	0	-0.0031082241	0.14416459	false
training	oneLayer	oneLayer - rat 1	0	-0.013218543	0.13997675	false
training	oneLayer	oneLayer - rat 1	0	-0.024205707	0.13997675	false
training	oneLayer	oneLayer - rat 1	0	-0.034103326	0.13587701	false
training	oneLayer	oneLayer - rat 1	0	-0.044913944	0.13587701	false
training	oneLayer	oneLayer - rat 1	0	-0.054730225	0.13181098	false
training	oneLayer	oneLayer - rat 1	0	-0.06474069	0.13181096	false
training	oneLayer	oneLayer - rat 1	0	-0.07452565	0.12775789	false
training	oneLayer	oneLayer - rat 1	0	-0.085208155	0.12775789	false
training	oneLayer	oneLayer - rat 1	0	-0.09501902	0.12369409	false
training	oneLayer	oneLayer - rat 1	0	-0.105452605	0.12369409	false
training	oneLayer	oneLayer - rat 1	0	-0.11551915	0.11952438	false
training	oneLayer	oneLayer - rat 1	0	-0.12553027	0.11952438	false
training	oneLayer	oneLayer - rat 1	0	-0.13555823	0.11537066	false
training	oneLayer	oneLayer - rat 1	0	-0.14632446	0.11537066	false
training	oneLayer	oneLayer - rat 1	0	-0.15573105	0.111474305	false
training	oneLayer	oneLayer - rat 1	0	-0.16604269	0.111474305	false
training	oneLayer	oneLayer - rat 1	0	-0.17613374	0.107294455	false
training	oneLayer	oneLayer - rat 1	0	-0.18703078	0.10729445	false
training	oneLayer	oneLayer - rat 1	0	-0.19718954	0.10308654	false
training	oneLayer	oneLayer - rat 1	0	-0.2080695	0.10308654	false
training	oneLayer	oneLayer - rat 1	0	-0.21813734	0.0989163	false
training	oneLayer	oneLayer - rat 1	0	-0.22869843	0.09891629	false
training	oneLayer	oneLayer - rat 1	0	-0.23851216	0.09485131	false
training	oneLayer	oneLayer - rat 1	0	-0.24853049	0.09485131	false
training	oneLayer	oneLayer - rat 1	0	-0.25781742	0.09100453	false
training	oneLayer	oneLayer - rat 1	0	-0.26840946	0.09100453	false
training	oneLayer	oneLayer - rat 1	0	-0.27781114	0.087110214	false
training	oneLayer	oneLayer - rat 1	0	-0.2887155	0.08711021	false
training	oneLayer	oneLayer - rat 1	0	-0.29873186	0.0829613	false
training	oneLayer	oneLayer - rat 1	0	-0.30920714	0.0829613	false
training	oneLayer	oneLayer - rat 1	0	-0.31892252	0.07893705	false
training	oneLayer	oneLayer - rat 1	0	-0.3289454	0.078937046	false
training	oneLayer	oneLayer - rat 1	0	-0.33822948	0.075091444	false
training	oneLayer	oneLayer - rat 1	0	-0.34850127	0.075091444	false
training	oneLayer	oneLayer - rat 1	0	-0.35820022	0.071074	false
training	oneLayer	oneLayer - rat 1	0	-0.36895037	0.071074	false
training	oneLayer	oneLayer - rat 1	0	-0.37904468	0.06689278	false
training	oneLayer	oneLayer - rat 1	0	-0.38912582	0.06689278	false
training	oneLayer	oneLayer - rat 1	0	-0.3989236	0.0628344	false
training	oneLayer	oneLayer - rat 1	0	-0.408243	0.058974173	false
training	oneLayer	oneLayer - rat 1	0	-0.41581118	0.051405977	false
training	oneLayer	oneLayer - rat 1	0	-0.42310473	0.044112436	false
training	oneLayer	oneLayer - rat 1	0	-0.4305315	0.03668566	false
training	oneLayer	oneLayer - rat 1	0	-0.43440396	0.027336678	false
training	oneLayer	oneLayer - rat 1	0	-0.43440396	0.01696876	false
training	oneLayer	oneLayer - rat 1	0	-0.43028066	0.0070142583	false
training	oneLayer	oneLayer - rat 1	0	-0.42260548	-6.60897E-4	false
training	oneLayer	oneLayer - rat 1	0	-0.41305438	-0.0046170964	false
training	oneLayer	oneLayer - rat 1	0	-0.40207288	-0.0046170903	false
training	oneLayer	oneLayer - rat 1	0	-0.3919632	-4.2952204E-4	false
training	oneLayer	oneLayer - rat 1	0	-0.38436514	0.007168573	false
training	oneLayer	oneLayer - rat 1	0	-0.38019592	0.017233975	false
training	oneLayer	oneLayer - rat 1	0	-0.37611938	0.027075592	false
training	oneLayer	oneLayer - rat 1	0	-0.37196493	0.03710533	false
training	oneLayer	oneLayer - rat 1	0	-0.36809006	0.04646015	false
training	oneLayer	oneLayer - rat 1	0	-0.36422187	0.05579878	false
training	oneLayer	oneLayer - rat 1	0	-0.36031055	0.065241575	false
training	oneLayer	oneLayer - rat 1	0	-0.35636482	0.074767426	false
training	oneLayer	oneLayer - rat 1	0	-0.35218844	0.08485007	false
training	oneLayer	oneLayer - rat 1	0	-0.348351	0.094114535	false
training	oneLayer	oneLayer - rat 1	0	-0.34448117	0.10345712	false
training	oneLayer	oneLayer - rat 1	0	-0.34049138	0.113089345	false
training	oneLayer	oneLayer - rat 1	0	-0.3364895	0.12275076	false
training	oneLayer	oneLayer - rat 1	0	-0.3323046	0.13285401	false
training	oneLayer	oneLayer - rat 1	0	-0.32810628	0.1429897	false
training	oneLayer	oneLayer - rat 1	0	-0.32392204	0.15309134	false
training	oneLayer	oneLayer - rat 1	0	-0.31992754	0.16273496	false
training	oneLayer	oneLayer - rat 1	0	-0.31992754	0.17336755	false
training	oneLayer	oneLayer - rat 1	0	-0.31576005	0.18342881	false
training	oneLayer	oneLayer - rat 1	0	-0.31576005	0.19398516	false
training	oneLayer	oneLayer - rat 1	0	-0.31172684	0.20372222	false
training	oneLayer	oneLayer - rat 1	0	-0.31172684	0.21378773	false
training	oneLayer	oneLayer - rat 1	0	-0.31592464	0.22392212	false
training	oneLayer	oneLayer - rat 1	0	-0.32356587	0.23156333	false
training	oneLayer	oneLayer - rat 1	0	-0.3335372	0.23569359	false
training	oneLayer	oneLayer - rat 1	0	-0.34425715	0.23569357	false
training	oneLayer	oneLayer - rat 1	0	-0.3538631	0.23171467	false
training	oneLayer	oneLayer - rat 1	0	-0.3636788	0.22764885	false
training	oneLayer	oneLayer - rat 1	0	-0.37304768	0.22376813	false
training	oneLayer	oneLayer - rat 1	0	-0.38036835	0.21644744	false
training	oneLayer	oneLayer - rat 1	0	-0.3879145	0.20890129	false
training	oneLayer	oneLayer - rat 1	0	-0.39540932	0.20140646	false
training	oneLayer	oneLayer - rat 1	0	-0.402982	0.19383378	false
training	oneLayer	oneLayer - rat 1	0	-0.4107367	0.18607904	false
training	oneLayer	oneLayer - rat 1	0	-0.41781154	0.17900422	false
training	oneLayer	oneLayer - rat 1	0	-0.42193338	0.16905318	false
training	oneLayer	oneLayer - rat 1	0	-0.42193338	0.1589063	false
training	oneLayer	oneLayer - rat 1	0	-0.4178583	0.1490682	false
training	oneLayer	oneLayer - rat 1	0	-0.41034237	0.14155228	false
training	oneLayer	oneLayer - rat 1	0	-0.40051192	0.1374804	false
training	oneLayer	oneLayer - rat 1	0	-0.39033556	0.1374804	false
training	oneLayer	oneLayer - rat 1	0	-0.3808522	0.14140855	false
training	oneLayer	oneLayer - rat 1	0	-0.37350726	0.14875348	false
training	oneLayer	oneLayer - rat 1	0	-0.36941838	0.15862492	false
training	oneLayer	oneLayer - rat 1	0	-0.36550528	0.16807203	false
training	oneLayer	oneLayer - rat 1	0	-0.3613151	0.17818801	false
training	oneLayer	oneLayer - rat 1	0	-0.35743284	0.18756062	false
training	oneLayer	oneLayer - rat 1	0	-0.35323521	0.19769463	false
training	oneLayer	oneLayer - rat 1	0	-0.34937033	0.2070253	false
training	oneLayer	oneLayer - rat 1	0	-0.34519672	0.21710128	false
training	oneLayer	oneLayer - rat 1	0	-0.34122342	0.22669375	false
training	oneLayer	oneLayer - rat 1	0	-0.3372915	0.23618619	false
training	oneLayer	oneLayer - rat 1	0	-0.3332111	0.2460372	false
training	oneLayer	oneLayer - rat 1	0	-0.3292408	0.25562236	false
training	oneLayer	oneLayer - rat 1	0	-0.32539287	0.26491216	false
training	oneLayer	oneLayer - rat 1	0	-0.32154185	0.27420932	false
training	oneLayer	oneLayer - rat 1	0	-0.31398016	0.28177103	false
training	oneLayer	oneLayer - rat 1	0	-0.30429178	0.2857841	false
training	oneLayer	oneLayer - rat 1	0	-0.29350427	0.2857841	false
training	oneLayer	oneLayer - rat 1	0	-0.28364977	0.28986597	false
training	oneLayer	oneLayer - rat 1	0	-0.27275673	0.28986597	false
training	oneLayer	oneLayer - rat 1	0	-0.26302812	0.2938957	false
training	oneLayer	oneLayer - rat 1	0	-0.25219917	0.29389572	false
training	oneLayer	oneLayer - rat 1	0	-0.2428497	0.2977684	false
training	oneLayer	oneLayer - rat 1	0	-0.23237163	0.2977684	false
training	oneLayer	oneLayer - rat 1	0	-0.22295989	0.29386994	false
training	oneLayer	oneLayer - rat 1	0	-0.21539019	0.28630027	false
training	oneLayer	oneLayer - rat 1	0	-0.21131395	0.27645934	false
training	oneLayer	oneLayer - rat 1	0	-0.21131393	0.26636755	false
training	oneLayer	oneLayer - rat 1	0	-0.20714942	0.25631353	false
training	oneLayer	oneLayer - rat 1	0	-0.2071494	0.2462442	false
training	oneLayer	oneLayer - rat 1	0	-0.2032712	0.2368814	false
training	oneLayer	oneLayer - rat 1	0	-0.2032712	0.22631842	false
training	oneLayer	oneLayer - rat 1	0	-0.20744959	0.21623087	false
training	oneLayer	oneLayer - rat 1	0	-0.20744957	0.2057508	false
training	oneLayer	oneLayer - rat 1	0	-0.21145958	0.19606976	false
training	oneLayer	oneLayer - rat 1	0	-0.21145958	0.18574026	false
training	oneLayer	oneLayer - rat 1	0	-0.2075482	0.1762974	false
training	oneLayer	oneLayer - rat 1	0	-0.2075482	0.1662567	false
training	oneLayer	oneLayer - rat 1	0	-0.20366295	0.15687689	false
training	oneLayer	oneLayer - rat 1	0	-0.20366295	0.14625008	false
training	oneLayer	oneLayer - rat 1	0	-0.20780046	0.13626121	false
training	oneLayer	oneLayer - rat 1	0	-0.20780046	0.12597574	false
training	oneLayer	oneLayer - rat 1	0	-0.2038678	0.11648148	false
training	oneLayer	oneLayer - rat 1	0	-0.2038678	0.10645451	false
training	oneLayer	oneLayer - rat 1	0	-0.20002365	0.09717394	false
training	oneLayer	oneLayer - rat 1	0	-0.20002364	0.08673311	false
training	oneLayer	oneLayer - rat 1	0	-0.20394795	0.07725898	false
training	oneLayer	oneLayer - rat 1	0	-0.20394795	0.06655627	false
training	oneLayer	oneLayer - rat 1	0	-0.1998877	0.05675397	false
training	oneLayer	oneLayer - rat 1	0	-0.19988768	0.046226542	false
training	oneLayer	oneLayer - rat 1	0	-0.19602872	0.036910217	false
training	oneLayer	oneLayer - rat 1	0	-0.19602872	0.02675603	false
training	oneLayer	oneLayer - rat 1	0	-0.19986439	0.017495884	false
training	oneLayer	oneLayer - rat 1	0	-0.19986439	0.006689214	false
training	oneLayer	oneLayer - rat 1	0	-0.19582053	-0.0030735175	false
training	oneLayer	oneLayer - rat 1	0	-0.19582051	-0.013539475	false
training	oneLayer	oneLayer - rat 1	0	-0.19194649	-0.022892192	false
training	oneLayer	oneLayer - rat 1	0	-0.19194648	-0.033365913	false
training	oneLayer	oneLayer - rat 1	0	-0.18779224	-0.043395095	false
training	oneLayer	oneLayer - rat 1	0	-0.18779224	-0.053731535	false
training	oneLayer	oneLayer - rat 1	0	-0.18362899	-0.063782476	false
training	oneLayer	oneLayer - rat 1	0	-0.18362899	-0.07440502	false
training	oneLayer	oneLayer - rat 1	0	-0.179444	-0.084508464	false
training	oneLayer	oneLayer - rat 1	0	-0.179444	-0.09475651	false
training	oneLayer	oneLayer - rat 1	0	-0.17540613	-0.104504764	false
training	oneLayer	oneLayer - rat 1	0	-0.17540611	-0.1148712	false
training	oneLayer	oneLayer - rat 1	0	-0.17127319	-0.12484895	false
training	oneLayer	oneLayer - rat 1	0	-0.17127319	-0.13509035	false
training	oneLayer	oneLayer - rat 1	0	-0.1671589	-0.14502311	false
training	oneLayer	oneLayer - rat 1	0	-0.16715889	-0.15506847	false
training	oneLayer	oneLayer - rat 1	0	-0.16329384	-0.1643995	false
training	oneLayer	oneLayer - rat 1	0	-0.16329384	-0.17446147	false
training	oneLayer	oneLayer - rat 1	0	-0.15940902	-0.18384025	false
training	oneLayer	oneLayer - rat 1	0	-0.159409	-0.19449916	false
training	oneLayer	oneLayer - rat 1	0	-0.15553813	-0.2038443	false
training	oneLayer	oneLayer - rat 1	0	-0.15553811	-0.21434657	false
training	oneLayer	oneLayer - rat 1	0	-0.1513509	-0.22445537	false
training	oneLayer	oneLayer - rat 1	0	-0.1513509	-0.23528495	false
training	oneLayer	oneLayer - rat 1	0	-0.14746073	-0.24467662	false
training	oneLayer	oneLayer - rat 1	0	-0.14746073	-0.25539303	false
training	oneLayer	oneLayer - rat 1	0	-0.14356905	-0.26478836	false
training	oneLayer	oneLayer - rat 1	0	-0.14356904	-0.2757541	false
training	oneLayer	oneLayer - rat 1	0	-0.13940297	-0.28581187	false
training	oneLayer	oneLayer - rat 1	0	-0.13940296	-0.29615128	false
training	oneLayer	oneLayer - rat 1	0	-0.13525511	-0.30616507	false
training	oneLayer	oneLayer - rat 1	0	-0.1352551	-0.31621042	false
training	oneLayer	oneLayer - rat 1	0	-0.13106017	-0.32633787	false
training	oneLayer	oneLayer - rat 1	0	-0.13106017	-0.3364012	false
training	oneLayer	oneLayer - rat 1	0	-0.12700082	-0.3462013	false
training	oneLayer	oneLayer - rat 1	0	-0.12700082	-0.35677442	false
training	oneLayer	oneLayer - rat 1	0	-0.1228263	-0.36685255	false
training	oneLayer	oneLayer - rat 1	0	-0.1228263	-0.37743583	false
training	oneLayer	oneLayer - rat 1	0	-0.11877915	-0.38720647	false
training	oneLayer	oneLayer - rat 1	0	-0.11115979	-0.39482582	false
training	oneLayer	oneLayer - rat 1	0	-0.107118115	-0.40458328	false
training	oneLayer	oneLayer - rat 1	0	-0.09987658	-0.4118248	false
training	oneLayer	oneLayer - rat 1	0	-0.090509124	-0.4157049	false
training	oneLayer	oneLayer - rat 1	0	-0.07992099	-0.4157049	false
training	oneLayer	oneLayer - rat 1	0	-0.07008768	-0.4116318	false
training	oneLayer	oneLayer - rat 1	0	-0.05972696	-0.4116318	false
training	oneLayer	oneLayer - rat 1	0	-0.04974726	-0.40749806	false
training	oneLayer	oneLayer - rat 1	0	-0.0395993	-0.40749806	false
training	oneLayer	oneLayer - rat 1	0	-0.029447833	-0.40329316	false
training	oneLayer	oneLayer - rat 1	0	-0.019213919	-0.40329316	false
training	oneLayer	oneLayer - rat 1	0	-0.009176407	-0.39913547	false
training	oneLayer	oneLayer - rat 1	0	0.0016352437	-0.39913547	false
training	oneLayer	oneLayer - rat 1	0	0.011555964	-0.39502618	false
training	oneLayer	oneLayer - rat 1	0	0.02214743	-0.39502615	false
training	oneLayer	oneLayer - rat 1	0	0.031776786	-0.39103755	false
training	oneLayer	oneLayer - rat 1	0	0.041843604	-0.39103752	false
training	oneLayer	oneLayer - rat 1	0	0.051940672	-0.38685519	false
training	oneLayer	oneLayer - rat 1	0	0.06212425	-0.38685519	false
training	oneLayer	oneLayer - rat 1	0	0.071724094	-0.38287878	false
training	oneLayer	oneLayer - rat 1	0	0.08209588	-0.38287878	false
training	oneLayer	oneLayer - rat 1	0	0.092165455	-0.3787078	false
training	oneLayer	oneLayer - rat 1	0	0.102917396	-0.3787078	false
training	oneLayer	oneLayer - rat 1	0	0.11250978	-0.3747345	false
training	oneLayer	oneLayer - rat 1	0	0.12264586	-0.3747345	false
training	oneLayer	oneLayer - rat 1	0	0.13240118	-0.37069368	false
training	oneLayer	oneLayer - rat 1	0	0.14277895	-0.37069368	false
training	oneLayer	oneLayer - rat 1	0	0.15293331	-0.3664876	false
training	oneLayer	oneLayer - rat 1	0	0.16325139	-0.3664876	false
training	oneLayer	oneLayer - rat 1	0	0.17294362	-0.36247292	false
training	oneLayer	oneLayer - rat 1	0	0.18315947	-0.36247292	false
training	oneLayer	oneLayer - rat 1	0	0.19254391	-0.35858575	false
training	oneLayer	oneLayer - rat 1	0	0.20302957	-0.35858575	false
training	oneLayer	oneLayer - rat 1	0	0.21270034	-0.35458	false
training	oneLayer	oneLayer - rat 1	0	0.22362539	-0.35458	false
training	oneLayer	oneLayer - rat 1	0	0.23313455	-0.35064113	false
training	oneLayer	oneLayer - rat 1	0	0.2432168	-0.35064113	false
training	oneLayer	oneLayer - rat 1	0	0.25278375	-0.34667838	false
training	oneLayer	oneLayer - rat 1	0	0.26336715	-0.34667838	false
training	oneLayer	oneLayer - rat 1	0	0.2727772	-0.3427806	false
training	oneLayer	oneLayer - rat 1	0	0.2802638	-0.33529398	false
training	oneLayer	oneLayer - rat 1	0	0.28975955	-0.3313607	false
training	oneLayer	oneLayer - rat 1	0	0.29737467	-0.32374555	false
training	oneLayer	oneLayer - rat 1	0	0.30751714	-0.3195444	false
training	oneLayer	oneLayer - rat 1	0	0.31509915	-0.3119624	false
training	oneLayer	oneLayer - rat 1	0	0.32448956	-0.30807275	false
training	oneLayer	oneLayer - rat 1	0	0.3321093	-0.30045298	false
training	oneLayer	oneLayer - rat 1	0	0.34168348	-0.2964872	false
training	oneLayer	oneLayer - rat 1	0	0.3492189	-0.28895178	false
training	oneLayer	oneLayer - rat 1	0	0.35339162	-0.27887794	false
training	oneLayer	oneLayer - rat 1	0	0.35755414	-0.26882875	false
training	oneLayer	oneLayer - rat 1	0	0.36152503	-0.25924215	false
training	oneLayer	oneLayer - rat 1	0	0.3657046	-0.24915175	false
training	oneLayer	oneLayer - rat 1	0	0.3697628	-0.23935434	false
training	oneLayer	oneLayer - rat 1	0	0.37366602	-0.22993115	false
training	oneLayer	oneLayer - rat 1	0	0.3777122	-0.22016276	false
training	oneLayer	oneLayer - rat 1	0	0.38178873	-0.21032113	false
training	oneLayer	oneLayer - rat 1	0	0.385934	-0.20031352	false
training	oneLayer	oneLayer - rat 1	0	0.38979918	-0.19098218	false
training	oneLayer	oneLayer - rat 1	0	0.39388123	-0.18112718	false
training	oneLayer	oneLayer - rat 1	0	0.3978934	-0.17144094	false
training	oneLayer	oneLayer - rat 1	0	0.40186912	-0.16184267	false
training	oneLayer	oneLayer - rat 1	0	0.40570477	-0.1525826	false
training	oneLayer	oneLayer - rat 1	0	0.40960053	-0.14317736	false
training	oneLayer	oneLayer - rat 1	0	0.41349232	-0.1337817	false
training	oneLayer	oneLayer - rat 1	0	0.41751373	-0.12407315	false
training	oneLayer	oneLayer - rat 1	0	0.4215012	-0.11444655	false
training	oneLayer	oneLayer - rat 1	0	0.42534098	-0.10517645	false
training	oneLayer	oneLayer - rat 1	0	0.42936718	-0.09545636	false
training	oneLayer	oneLayer - rat 1	0	0.4333623	-0.08581125	false
training	oneLayer	oneLayer - rat 1	0	0.43745574	-0.07592875	false
training	oneLayer	oneLayer - rat 1	0	0.44161084	-0.06589745	false
training	oneLayer	oneLayer - rat 1	0	0.44552818	-0.05644014	false
training	oneLayer	oneLayer - rat 1	0	0.44945797	-0.046952788	false
training	oneLayer	oneLayer - rat 1	0	0.4535127	-0.037163813	false
training	oneLayer	oneLayer - rat 1	0	0.45351267	-0.026434975	false
training	oneLayer	oneLayer - rat 1	0	0.4493381	-0.016356679	false
training	oneLayer	oneLayer - rat 1	0	0.44933808	-0.005767062	false
training	oneLayer	oneLayer - rat 1	0	0.44533065	0.0039077555	false
training	oneLayer	oneLayer - rat 1	0	0.44533065	0.014343156	false
training	oneLayer	oneLayer - rat 1	0	0.441288	0.024102964	false
training	oneLayer	oneLayer - rat 1	0	0.44128796	0.034843206	false
training	oneLayer	oneLayer - rat 1	0	0.44541186	0.044799138	false
training	oneLayer	oneLayer - rat 1	0	0.44541183	0.054920666	false
training	oneLayer	oneLayer - rat 1	0	0.44129607	0.06485696	false
training	oneLayer	oneLayer - rat 1	0	0.44129607	0.07532229	false
training	oneLayer	oneLayer - rat 1	0	0.4374531	0.084600054	false
training	oneLayer	oneLayer - rat 1	0	0.4374531	0.09468576	false
training	oneLayer	oneLayer - rat 1	0	0.43358952	0.1040132	false
training	oneLayer	oneLayer - rat 1	0	0.43358952	0.11450748	false
training	oneLayer	oneLayer - rat 1	0	0.42961615	0.12410002	false
training	oneLayer	oneLayer - rat 1	0	0.42961615	0.1348623	false
training	oneLayer	oneLayer - rat 1	0	0.42542243	0.14498682	false
training	oneLayer	oneLayer - rat 1	0	0.4254224	0.1558384	false
training	oneLayer	oneLayer - rat 1	0	0.42158625	0.16509973	false
training	oneLayer	oneLayer - rat 1	0	0.42158625	0.17585051	false
training	oneLayer	oneLayer - rat 1	0	0.41773552	0.18514691	false
training	oneLayer	oneLayer - rat 1	0	0.41048628	0.19239615	false
training	oneLayer	oneLayer - rat 1	0	0.40091586	0.19636033	false
training	oneLayer	oneLayer - rat 1	0	0.3908604	0.19636032	false
training	oneLayer	oneLayer - rat 1	0	0.38091284	0.1922399	false
training	oneLayer	oneLayer - rat 1	0	0.37020501	0.19223988	false
training	oneLayer	oneLayer - rat 1	0	0.36051062	0.18822432	false
training	oneLayer	oneLayer - rat 1	0	0.3503094	0.1882243	false
training	oneLayer	oneLayer - rat 1	0	0.34044665	0.184139	false
training	oneLayer	oneLayer - rat 1	0	0.33027595	0.184139	false
training	oneLayer	oneLayer - rat 1	0	0.32075554	0.1801955	false
training	oneLayer	oneLayer - rat 1	0	0.3100431	0.1801955	false
training	oneLayer	oneLayer - rat 1	0	0.3001711	0.17610638	false
training	oneLayer	oneLayer - rat 1	0	0.28997508	0.17610638	false
training	oneLayer	oneLayer - rat 1	0	0.2802905	0.1720949	false
training	oneLayer	oneLayer - rat 1	0	0.27024215	0.17209488	false
training	oneLayer	oneLayer - rat 1	0	0.2603514	0.16799799	false
training	oneLayer	oneLayer - rat 1	0	0.24992312	0.16799799	false
training	oneLayer	oneLayer - rat 1	0	0.24067225	0.16416614	false
training	oneLayer	oneLayer - rat 1	0	0.23008113	0.16416612	false
training	oneLayer	oneLayer - rat 1	0	0.2204537	0.1601783	false
training	oneLayer	oneLayer - rat 1	0	0.20957315	0.16017829	false
training	oneLayer	oneLayer - rat 1	0	0.20009938	0.15625411	false
training	oneLayer	oneLayer - rat 1	0	0.18912382	0.15625411	false
training	oneLayer	oneLayer - rat 1	0	0.17978702	0.15238668	false
training	oneLayer	oneLayer - rat 1	0	0.16942222	0.15238667	false
training	oneLayer	oneLayer - rat 1	0	0.15961951	0.14832623	false
training	oneLayer	oneLayer - rat 1	0	0.14908253	0.14832623	false
training	oneLayer	oneLayer - rat 1	0	0.1395106	0.1443614	false
training	oneLayer	oneLayer - rat 1	0	0.12908255	0.14436139	false
training	oneLayer	oneLayer - rat 1	0	0.11914812	0.1402464	false
training	oneLayer	oneLayer - rat 1	0	0.109125264	0.1402464	false
training	oneLayer	oneLayer - rat 1	0	0.09901833	0.13605995	false
training	oneLayer	oneLayer - rat 1	0	0.0881823	0.13605995	false
training	oneLayer	oneLayer - rat 1	0	0.078205	0.1319272	false
training	oneLayer	oneLayer - rat 1	0	0.06806097	0.1319272	false
training	oneLayer	oneLayer - rat 1	0	0.058209106	0.12784642	false
training	oneLayer	oneLayer - rat 1	0	0.048187234	0.1278464	false
training	oneLayer	oneLayer - rat 1	0	0.038447354	0.123812005	false
training	oneLayer	oneLayer - rat 1	0	0.027790198	0.123812	false
training	oneLayer	oneLayer - rat 1	0	0.018325211	0.119891465	false
training	oneLayer	oneLayer - rat 1	0	0.007727689	0.11989146	false
training	oneLayer	oneLayer - rat 1	0	-0.0017759242	0.11595492	false
training	oneLayer	oneLayer - rat 1	0	-0.012634171	0.11595491	false
training	oneLayer	oneLayer - rat 1	0	-0.022438666	0.11189375	false
training	oneLayer	oneLayer - rat 1	0	-0.033380497	0.11189374	false
training	oneLayer	oneLayer - rat 1	0	-0.04306707	0.10788142	false
training	oneLayer	oneLayer - rat 1	0	-0.053828035	0.10788141	false
training	oneLayer	oneLayer - rat 1	0	-0.06309189	0.10404419	false
training	oneLayer	oneLayer - rat 1	0	-0.07312639	0.10404418	false
training	oneLayer	oneLayer - rat 1	0	-0.08295588	0.09997266	false
training	oneLayer	oneLayer - rat 1	0	-0.0933316	0.09997265	false
training	oneLayer	oneLayer - rat 1	0	-0.103250995	0.09586389	false
training	oneLayer	oneLayer - rat 1	0	-0.11332653	0.095863886	false
training	oneLayer	oneLayer - rat 1	0	-0.12263155	0.09200961	false
training	oneLayer	oneLayer - rat 1	0	-0.13309714	0.092009604	false
training	oneLayer	oneLayer - rat 1	0	-0.14323117	0.08781194	false
training	oneLayer	oneLayer - rat 1	0	-0.15420344	0.08781193	false
training	oneLayer	oneLayer - rat 1	0	-0.1634972	0.08396233	false
training	oneLayer	oneLayer - rat 1	0	-0.17374551	0.08396232	false
training	oneLayer	oneLayer - rat 1	0	-0.18361299	0.07987507	false
training	oneLayer	oneLayer - rat 1	0	-0.19415168	0.07987506	false
training	oneLayer	oneLayer - rat 1	0	-0.20382848	0.07586679	false
training	oneLayer	oneLayer - rat 1	0	-0.21449877	0.07586678	false
training	oneLayer	oneLayer - rat 1	0	-0.22395967	0.07194794	false
training	oneLayer	oneLayer - rat 1	0	-0.23410401	0.07194793	false
training	oneLayer	oneLayer - rat 1	0	-0.2433708	0.06810949	false
training	oneLayer	oneLayer - rat 1	0	-0.25354135	0.06810948	false
training	oneLayer	oneLayer - rat 1	0	-0.26350754	0.06398135	false
training	oneLayer	oneLayer - rat 1	0	-0.2742945	0.06398134	false
training	oneLayer	oneLayer - rat 1	0	-0.28361323	0.06012138	false
training	oneLayer	oneLayer - rat 1	0	-0.2937811	0.060121372	false
training	oneLayer	oneLayer - rat 1	0	-0.303706	0.056010332	false
training	oneLayer	oneLayer - rat 1	0	-0.31382337	0.056010325	false
training	oneLayer	oneLayer - rat 1	0	-0.32392615	0.05182561	false
training	oneLayer	oneLayer - rat 1	0	-0.33466855	0.0518256	false
training	oneLayer	oneLayer - rat 1	0	-0.34456465	0.047726493	false
training	oneLayer	oneLayer - rat 1	0	-0.35477513	0.047726482	false
training	oneLayer	oneLayer - rat 1	0	-0.3640547	0.043882746	false
training	oneLayer	oneLayer - rat 1	0	-0.37482595	0.043882735	false
training	oneLayer	oneLayer - rat 1	0	-0.38447583	0.039885614	false
training	oneLayer	oneLayer - rat 1	0	-0.39546472	0.039885607	false
training	oneLayer	oneLayer - rat 1	0	-0.4047939	0.036021326	false
training	oneLayer	oneLayer - rat 1	0	-0.4141255	0.032156043	false
training	oneLayer	oneLayer - rat 1	0	-0.42188653	0.02439498	false
training	oneLayer	oneLayer - rat 1	0	-0.42899612	0.017285401	false
training	oneLayer	oneLayer - rat 1	0	-0.43287373	0.00792395	false
training	oneLayer	oneLayer - rat 1	0	-0.43287373	-0.0020993615	false
training	oneLayer	oneLayer - rat 1	0	-0.42874935	-0.012056449	false
training	oneLayer	oneLayer - rat 1	0	-0.4216559	-0.019149909	false
training	oneLayer	oneLayer - rat 1	0	-0.41209394	-0.023110583	false
training	oneLayer	oneLayer - rat 1	0	-0.4019431	-0.023110574	false
training	oneLayer	oneLayer - rat 1	0	-0.39257255	-0.019229157	false
training	oneLayer	oneLayer - rat 1	0	-0.38546494	-0.012121554	false
training	oneLayer	oneLayer - rat 1	0	-0.38135615	-0.002202026	false
training	oneLayer	oneLayer - rat 1	0	-0.38135618	0.00801327	false
training	oneLayer	oneLayer - rat 1	0	-0.37741655	0.017524362	false
training	oneLayer	oneLayer - rat 1	0	-0.37741655	0.028491147	false
training	oneLayer	oneLayer - rat 1	0	-0.37331298	0.03839813	false
training	oneLayer	oneLayer - rat 1	0	-0.37331298	0.048831645	false
training	oneLayer	oneLayer - rat 1	0	-0.37737948	0.05864902	false
training	oneLayer	oneLayer - rat 1	0	-0.37737948	0.0694396	false
training	oneLayer	oneLayer - rat 1	0	-0.38157415	0.07956641	false
training	oneLayer	oneLayer - rat 1	0	-0.38157418	0.090067625	false
training	oneLayer	oneLayer - rat 1	0	-0.3775307	0.09982946	false
training	oneLayer	oneLayer - rat 1	0	-0.3775307	0.110631235	false
training	oneLayer	oneLayer - rat 1	0	-0.37369928	0.11988117	false
training	oneLayer	oneLayer - rat 1	0	-0.37369928	0.13075972	false
training	oneLayer	oneLayer - rat 1	0	-0.37785548	0.14079365	false
training	oneLayer	oneLayer - rat 1	0	-0.37785548	0.15127969	false
training	oneLayer	oneLayer - rat 1	0	-0.3818593	0.16094574	false
training	oneLayer	oneLayer - rat 1	0	-0.38185933	0.17141703	false
training	oneLayer	oneLayer - rat 1	0	-0.3778263	0.18115363	false
training	oneLayer	oneLayer - rat 1	0	-0.3778263	0.19124827	false
training	oneLayer	oneLayer - rat 1	0	-0.37389162	0.20074748	false
training	oneLayer	oneLayer - rat 1	0	-0.37389165	0.21135892	false
training	oneLayer	oneLayer - rat 1	0	-0.37003225	0.22067635	false
training	oneLayer	oneLayer - rat 1	0	-0.37003225	0.23104943	false
training	oneLayer	oneLayer - rat 1	0	-0.36607778	0.24059641	false
training	oneLayer	oneLayer - rat 1	0	-0.36190856	0.25066185	false
training	oneLayer	oneLayer - rat 1	0	-0.35799742	0.26010418	false
training	oneLayer	oneLayer - rat 1	0	-0.35390878	0.26997504	false
training	oneLayer	oneLayer - rat 1	0	-0.34975952	0.27999225	false
training	oneLayer	oneLayer - rat 1	0	-0.34975955	0.29020214	false
training	oneLayer	oneLayer - rat 1	0	-0.35393372	0.3002795	false
training	oneLayer	oneLayer - rat 1	0	-0.35393372	0.3002795	false
training	oneLayer	oneLayer - rat 1	0	-0.35393372	0.3002795	false
training	oneLayer	oneLayer - rat 1	0	-0.35393372	0.3002795	false
training	oneLayer	oneLayer - rat 1	0	-0.35393372	0.3002795	false
training	oneLayer	oneLayer - rat 1	0	-0.36320758	0.29643813	false
training	oneLayer	oneLayer - rat 1	0	-0.37060803	0.28903767	false
training	oneLayer	oneLayer - rat 1	0	-0.3745535	0.27951244	false
training	oneLayer	oneLayer - rat 1	0	-0.38197464	0.27209127	false
training	oneLayer	oneLayer - rat 1	0	-0.38609332	0.2621479	false
training	oneLayer	oneLayer - rat 1	0	-0.39384022	0.25440097	false
training	oneLayer	oneLayer - rat 1	0	-0.39777195	0.24490893	false
training	oneLayer	oneLayer - rat 1	0	-0.39777192	0.23402342	false
training	oneLayer	oneLayer - rat 1	0	-0.39384115	0.22453372	false
training	oneLayer	oneLayer - rat 1	0	-0.39384115	0.21429579	false
training	oneLayer	oneLayer - rat 1	0	-0.3899205	0.20483057	false
training	oneLayer	oneLayer - rat 1	0	-0.3899205	0.19460818	false
training	oneLayer	oneLayer - rat 1	0	-0.3860934	0.18536875	false
training	oneLayer	oneLayer - rat 1	0	-0.38609338	0.17534512	false
training	oneLayer	oneLayer - rat 1	0	-0.38197786	0.16540936	false
training	oneLayer	oneLayer - rat 1	0	-0.38197783	0.15476269	false
training	oneLayer	oneLayer - rat 1	0	-0.37806967	0.14532755	false
training	oneLayer	oneLayer - rat 1	0	-0.37806964	0.13478181	false
training	oneLayer	oneLayer - rat 1	0	-0.37390864	0.12473623	false
training	oneLayer	oneLayer - rat 1	0	-0.3739086	0.114703506	false
training	oneLayer	oneLayer - rat 1	0	-0.3778807	0.10511405	false
training	oneLayer	oneLayer - rat 1	0	-0.3778807	0.09426151	false
training	oneLayer	oneLayer - rat 1	0	-0.3818692	0.08463232	false
training	oneLayer	oneLayer - rat 1	0	-0.3818692	0.07365551	false
training	oneLayer	oneLayer - rat 1	0	-0.38594347	0.06381934	false
training	oneLayer	oneLayer - rat 1	0	-0.38594344	0.053005848	false
training	oneLayer	oneLayer - rat 1	0	-0.39009836	0.04297499	false
training	oneLayer	oneLayer - rat 1	0	-0.39009833	0.032056525	false
training	oneLayer	oneLayer - rat 1	0	-0.3941858	0.022188447	false
training	oneLayer	oneLayer - rat 1	0	-0.3941858	0.012129471	false
training	oneLayer	oneLayer - rat 1	0	-0.39815184	0.0025546148	false
training	oneLayer	oneLayer - rat 1	0	-0.39815181	-0.007662937	false
training	oneLayer	oneLayer - rat 1	0	-0.40224215	-0.017537877	false
training	oneLayer	oneLayer - rat 1	0	-0.40224215	-0.027997574	false
training	oneLayer	oneLayer - rat 1	0	-0.4064435	-0.038140584	false
training	oneLayer	oneLayer - rat 1	0	-0.40644348	-0.04867244	false
training	oneLayer	oneLayer - rat 1	0	-0.41064057	-0.058805145	false
training	oneLayer	oneLayer - rat 1	0	-0.41064057	-0.06919681	false
training	oneLayer	oneLayer - rat 1	0	-0.41457522	-0.07869594	false
training	oneLayer	oneLayer - rat 1	0	-0.41457522	-0.08945333	false
training	oneLayer	oneLayer - rat 1	0	-0.4184327	-0.09876616	false
training	oneLayer	oneLayer - rat 1	0	-0.41843268	-0.10932973	false
training	oneLayer	oneLayer - rat 1	0	-0.42249283	-0.119131796	false
training	oneLayer	oneLayer - rat 1	0	-0.42249283	-0.12967694	false
training	oneLayer	oneLayer - rat 1	0	-0.41832712	-0.13973379	false
training	oneLayer	oneLayer - rat 1	0	-0.41832712	-0.1506688	false
training	oneLayer	oneLayer - rat 1	0	-0.41435087	-0.16026825	false
training	oneLayer	oneLayer - rat 1	0	-0.41435087	-0.17081624	false
training	oneLayer	oneLayer - rat 1	0	-0.41027877	-0.18064716	false
training	oneLayer	oneLayer - rat 1	0	-0.41027874	-0.19154017	false
training	oneLayer	oneLayer - rat 1	0	-0.40633687	-0.20105667	false
training	oneLayer	oneLayer - rat 1	0	-0.39869463	-0.20869888	false
training	oneLayer	oneLayer - rat 1	0	-0.38891965	-0.21274781	false
training	oneLayer	oneLayer - rat 1	0	-0.37824428	-0.2127478	false
training	oneLayer	oneLayer - rat 1	0	-0.3690015	-0.2089193	false
training	oneLayer	oneLayer - rat 1	0	-0.3619105	-0.20182829	false
training	oneLayer	oneLayer - rat 1	0	-0.35777667	-0.19184835	false
training	oneLayer	oneLayer - rat 1	0	-0.3577767	-0.18144758	false
training	oneLayer	oneLayer - rat 1	0	-0.3618109	-0.1717082	false
training	oneLayer	oneLayer - rat 1	0	-0.365809	-0.16205592	false
training	oneLayer	oneLayer - rat 1	0	-0.36968568	-0.15269685	false
training	oneLayer	oneLayer - rat 1	0	-0.37364817	-0.1431306	false
training	oneLayer	oneLayer - rat 1	0	-0.37758833	-0.13361822	false
training	oneLayer	oneLayer - rat 1	0	-0.38174722	-0.12357782	false
training	oneLayer	oneLayer - rat 1	0	-0.38559824	-0.114280626	false
training	oneLayer	oneLayer - rat 1	0	-0.38945913	-0.104959615	false
training	oneLayer	oneLayer - rat 1	0	-0.39340705	-0.09542858	false
training	oneLayer	oneLayer - rat 1	0	-0.39744744	-0.08567422	false
training	oneLayer	oneLayer - rat 1	0	-0.40142044	-0.07608256	false
training	oneLayer	oneLayer - rat 1	0	-0.40532357	-0.066659614	false
training	oneLayer	oneLayer - rat 1	0	-0.40937856	-0.056870062	false
training	oneLayer	oneLayer - rat 1	0	-0.41323206	-0.04756692	false
training	oneLayer	oneLayer - rat 1	0	-0.41737628	-0.037561912	false
training	oneLayer	oneLayer - rat 1	0	-0.41737628	-0.027517257	false
training	oneLayer	oneLayer - rat 1	0	-0.41337818	-0.017864913	false
training	oneLayer	oneLayer - rat 1	0	-0.4095399	-0.008598501	false
training	oneLayer	oneLayer - rat 1	0	-0.40243223	-0.0014908066	false
training	oneLayer	oneLayer - rat 1	0	-0.3928231	0.0024894325	false
training	oneLayer	oneLayer - rat 1	0	-0.38204104	0.0024894439	false
training	oneLayer	oneLayer - rat 1	0	-0.37276816	-0.0013514964	false
training	oneLayer	oneLayer - rat 1	0	-0.36181056	-0.0013514849	false
training	oneLayer	oneLayer - rat 1	0	-0.35211328	-0.005368233	false
training	oneLayer	oneLayer - rat 1	0	-0.3412834	-0.0053682216	false
training	oneLayer	oneLayer - rat 1	0	-0.33147395	-0.009431428	false
training	oneLayer	oneLayer - rat 1	0	-0.3212861	-0.009431418	false
training	oneLayer	oneLayer - rat 1	0	-0.31167847	-0.013411029	false
training	oneLayer	oneLayer - rat 1	0	-0.3011757	-0.013411018	false
training	oneLayer	oneLayer - rat 1	0	-0.2919212	-0.017244348	false
training	oneLayer	oneLayer - rat 1	0	-0.2819033	-0.017244337	false
training	oneLayer	oneLayer - rat 1	0	-0.2719883	-0.021351248	false
training	oneLayer	oneLayer - rat 1	0	-0.26185396	-0.021351237	false
training	oneLayer	oneLayer - rat 1	0	-0.25244102	-0.02525019	false
training	oneLayer	oneLayer - rat 1	0	-0.24183685	-0.02525018	false
training	oneLayer	oneLayer - rat 1	0	-0.23217101	-0.029253885	false
training	oneLayer	oneLayer - rat 1	0	-0.22207105	-0.029253876	false
training	oneLayer	oneLayer - rat 1	0	-0.2120361	-0.033410475	false
training	oneLayer	oneLayer - rat 1	0	-0.20130244	-0.033410463	false
training	oneLayer	oneLayer - rat 1	0	-0.1911646	-0.037609678	false
training	oneLayer	oneLayer - rat 1	0	-0.18114159	-0.03760967	false
training	oneLayer	oneLayer - rat 1	0	-0.17100935	-0.041806567	false
training	oneLayer	oneLayer - rat 1	0	-0.16011187	-0.041806556	false
training	oneLayer	oneLayer - rat 1	0	-0.15059529	-0.045748442	false
training	oneLayer	oneLayer - rat 1	0	-0.13991894	-0.04574843	false
training	oneLayer	oneLayer - rat 1	0	-0.12980305	-0.04993856	false
training	oneLayer	oneLayer - rat 1	0	-0.118898295	-0.04993855	false
training	oneLayer	oneLayer - rat 1	0	-0.10878293	-0.054128453	false
training	oneLayer	oneLayer - rat 1	0	-0.09827468	-0.054128442	false
training	oneLayer	oneLayer - rat 1	0	-0.08844938	-0.058198202	false
training	oneLayer	oneLayer - rat 1	0	-0.07784379	-0.05819819	false
training	oneLayer	oneLayer - rat 1	0	-0.06844209	-0.06209249	false
training	oneLayer	oneLayer - rat 1	0	-0.05813759	-0.06209248	false
training	oneLayer	oneLayer - rat 1	0	-0.048258476	-0.06618453	false
training	oneLayer	oneLayer - rat 1	0	-0.037432723	-0.06618452	false
training	oneLayer	oneLayer - rat 1	0	-0.027433697	-0.07032624	false
training	oneLayer	oneLayer - rat 1	0	-0.016921727	-0.070326224	false
training	oneLayer	oneLayer - rat 1	0	-0.0070829475	-0.07440157	false
training	oneLayer	oneLayer - rat 1	0	0.0034651037	-0.07440156	false
training	oneLayer	oneLayer - rat 1	0	0.013528402	-0.078569904	false
training	oneLayer	oneLayer - rat 1	0	0.024233153	-0.07856989	false
training	oneLayer	oneLayer - rat 1	0	0.033860978	-0.08255786	false
training	oneLayer	oneLayer - rat 1	0	0.044830684	-0.08255784	false
training	oneLayer	oneLayer - rat 1	0	0.054278675	-0.08647132	false
training	oneLayer	oneLayer - rat 1	0	0.06524486	-0.086471304	false
training	oneLayer	oneLayer - rat 1	0	0.075307325	-0.0906393	false
training	oneLayer	oneLayer - rat 1	0	0.08593451	-0.09063929	false
training	oneLayer	oneLayer - rat 1	0	0.096065804	-0.0948358	false
training	oneLayer	oneLayer - rat 1	0	0.106319524	-0.09483579	false
training	oneLayer	oneLayer - rat 1	0	0.11631816	-0.09897735	false
training	oneLayer	oneLayer - rat 1	0	0.12724024	-0.098977335	false
training	oneLayer	oneLayer - rat 1	0	0.13736226	-0.10317	false
training	oneLayer	oneLayer - rat 1	0	0.14751136	-0.103169985	false
training	oneLayer	oneLayer - rat 1	0	0.1575549	-0.107330136	false
training	oneLayer	oneLayer - rat 1	0	0.16842236	-0.10733013	false
training	oneLayer	oneLayer - rat 1	0	0.1781233	-0.11134837	false
training	oneLayer	oneLayer - rat 1	0	0.18859802	-0.11134836	false
training	oneLayer	oneLayer - rat 1	0	0.19800171	-0.10745321	false
training	oneLayer	oneLayer - rat 1	0	0.20561408	-0.099840835	false
training	oneLayer	oneLayer - rat 1	0	0.21523523	-0.0958556	false
training	oneLayer	oneLayer - rat 1	0	0.2225727	-0.088518135	false
training	oneLayer	oneLayer - rat 1	0	0.23195252	-0.08463287	false
training	oneLayer	oneLayer - rat 1	0	0.23934373	-0.07724164	false
training	oneLayer	oneLayer - rat 1	0	0.24928692	-0.07312303	false
training	oneLayer	oneLayer - rat 1	0	0.2593346	-0.073123015	false
training	oneLayer	oneLayer - rat 1	0	0.26889947	-0.07708491	false
training	oneLayer	oneLayer - rat 1	0	0.2798655	-0.0770849	false
training	oneLayer	oneLayer - rat 1	0	0.28956035	-0.07306914	false
training	oneLayer	oneLayer - rat 1	0	0.29991442	-0.073069125	false
training	oneLayer	oneLayer - rat 1	0	0.3100499	-0.068870865	false
training	oneLayer	oneLayer - rat 1	0	0.3201382	-0.06887085	false
training	oneLayer	oneLayer - rat 1	0	0.32956013	-0.06496815	false
training	oneLayer	oneLayer - rat 1	0	0.3400304	-0.06496814	false
training	oneLayer	oneLayer - rat 1	0	0.34988764	-0.060885128	false
training	oneLayer	oneLayer - rat 1	0	0.36038002	-0.060885116	false
training	oneLayer	oneLayer - rat 1	0	0.37040943	-0.056730784	false
training	oneLayer	oneLayer - rat 1	0	0.3813589	-0.056730773	false
training	oneLayer	oneLayer - rat 1	0	0.39120737	-0.052651398	false
training	oneLayer	oneLayer - rat 1	0	0.4012697	-0.05265139	false
training	oneLayer	oneLayer - rat 1	0	0.4111908	-0.048541926	false
training	oneLayer	oneLayer - rat 1	0	0.4183132	-0.041419506	false
training	oneLayer	oneLayer - rat 1	0	0.42223358	-0.031954877	false
training	oneLayer	oneLayer - rat 1	0	0.42223358	-0.021114124	false
training	oneLayer	oneLayer - rat 1	0	0.41810086	-0.011136918	false
training	oneLayer	oneLayer - rat 1	0	0.41394663	-0.0011077569	false
training	oneLayer	oneLayer - rat 1	0	0.40621278	0.0066260714	false
training	oneLayer	oneLayer - rat 1	0	0.39628768	0.010737171	false
training	oneLayer	oneLayer - rat 1	0	0.38603786	0.010737159	false
training	oneLayer	oneLayer - rat 1	0	0.37588868	0.006533207	false
training	oneLayer	oneLayer - rat 1	0	0.36549953	0.0065331953	false
training	oneLayer	oneLayer - rat 1	0	0.35620132	0.002681751	false
training	oneLayer	oneLayer - rat 1	0	0.34599444	0.0026817394	false
training	oneLayer	oneLayer - rat 1	0	0.33626145	0.0067132586	false
training	oneLayer	oneLayer - rat 1	0	0.32613572	0.006713247	false
training	oneLayer	oneLayer - rat 1	0	0.31598026	0.0025066903	false
training	oneLayer	oneLayer - rat 1	0	0.30514902	0.002506678	false
training	oneLayer	oneLayer - rat 1	0	0.2956695	-0.0014198768	false
training	oneLayer	oneLayer - rat 1	0	0.2848584	-0.0014198892	false
training	oneLayer	oneLayer - rat 1	0	0.274824	0.0027364795	false
training	oneLayer	oneLayer - rat 1	0	0.2645149	0.0027364679	false
training	oneLayer	oneLayer - rat 1	0	0.25493765	-0.0012305634	false
training	oneLayer	oneLayer - rat 1	0	0.24491414	-0.0012305748	false
training	oneLayer	oneLayer - rat 1	0	0.23543121	-0.0051585496	false
training	oneLayer	oneLayer - rat 1	0	0.22454846	-0.0051585617	false
training	oneLayer	oneLayer - rat 1	0	0.21464558	-0.0010566704	false
training	oneLayer	oneLayer - rat 1	0	0.20421092	-0.0010566823	false
training	oneLayer	oneLayer - rat 1	0	0.194607	-0.0050347676	false
training	oneLayer	oneLayer - rat 1	0	0.18378098	-0.00503478	false
training	oneLayer	oneLayer - rat 1	0	0.17365542	-0.00922894	false
training	oneLayer	oneLayer - rat 1	0	0.16288577	-0.009228952	false
training	oneLayer	oneLayer - rat 1	0	0.1536372	-0.005398083	false
training	oneLayer	oneLayer - rat 1	0	0.14345787	-0.005398094	false
training	oneLayer	oneLayer - rat 1	0	0.13389494	-0.009359206	false
training	oneLayer	oneLayer - rat 1	0	0.12298108	-0.009359219	false
training	oneLayer	oneLayer - rat 1	0	0.113678224	-0.013212598	false
training	oneLayer	oneLayer - rat 1	0	0.10360674	-0.01321261	false
training	oneLayer	oneLayer - rat 1	0	0.09396806	-0.009220154	false
training	oneLayer	oneLayer - rat 1	0	0.08349144	-0.009220166	false
training	oneLayer	oneLayer - rat 1	0	0.07373129	-0.013262962	false
training	oneLayer	oneLayer - rat 1	0	0.06307432	-0.013262974	false
training	oneLayer	oneLayer - rat 1	0	0.053064536	-0.017409176	false
training	oneLayer	oneLayer - rat 1	0	0.04292551	-0.017409187	false
training	oneLayer	oneLayer - rat 1	0	0.033364408	-0.0134488605	false
training	oneLayer	oneLayer - rat 1	0	0.023298854	-0.013448872	false
training	oneLayer	oneLayer - rat 1	0	0.013349231	-0.017570155	false
training	oneLayer	oneLayer - rat 1	0	0.0031241206	-0.017570166	false
training	oneLayer	oneLayer - rat 1	0	-0.006654859	-0.021620765	false
training	oneLayer	oneLayer - rat 1	0	-0.017015655	-0.021620777	false
training	oneLayer	oneLayer - rat 1	0	-0.026953723	-0.017504307	false
training	oneLayer	oneLayer - rat 1	0	-0.037888385	-0.01750432	false
training	oneLayer	oneLayer - rat 1	0	-0.047984183	-0.02168615	false
training	oneLayer	oneLayer - rat 1	0	-0.05856998	-0.021686161	false
training	oneLayer	oneLayer - rat 1	0	-0.068522595	-0.025808683	false
training	oneLayer	oneLayer - rat 1	0	-0.07943403	-0.025808696	false
training	oneLayer	oneLayer - rat 1	0	-0.08936754	-0.021694113	false
training	oneLayer	oneLayer - rat 1	0	-0.09976263	-0.021694126	false
training	oneLayer	oneLayer - rat 1	0	-0.109019436	-0.025528431	false
training	oneLayer	oneLayer - rat 1	0	-0.11933471	-0.025528442	false
training	oneLayer	oneLayer - rat 1	0	-0.12883283	-0.029462706	false
training	oneLayer	oneLayer - rat 1	0	-0.13916272	-0.029462717	false
training	oneLayer	oneLayer - rat 1	0	-0.14849354	-0.033327684	false
training	oneLayer	oneLayer - rat 1	0	-0.15870121	-0.033327695	false
training	oneLayer	oneLayer - rat 1	0	-0.16878638	-0.037505124	false
training	oneLayer	oneLayer - rat 1	0	-0.17925413	-0.037505135	false
training	oneLayer	oneLayer - rat 1	0	-0.18898113	-0.041534204	false
training	oneLayer	oneLayer - rat 1	0	-0.19932233	-0.041534215	false
training	oneLayer	oneLayer - rat 1	0	-0.20866321	-0.045403346	false
training	oneLayer	oneLayer - rat 1	0	-0.21909039	-0.04540336	false
training	oneLayer	oneLayer - rat 1	0	-0.22867395	-0.049373012	false
training	oneLayer	oneLayer - rat 1	0	-0.23958959	-0.049373023	false
training	oneLayer	oneLayer - rat 1	0	-0.24959107	-0.053515784	false
training	oneLayer	oneLayer - rat 1	0	-0.2605825	-0.053515796	false
training	oneLayer	oneLayer - rat 1	0	-0.26988924	-0.057370782	false
training	oneLayer	oneLayer - rat 1	0	-0.28046754	-0.057370793	false
training	oneLayer	oneLayer - rat 1	0	-0.29045466	-0.0615076	false
training	oneLayer	oneLayer - rat 1	0	-0.30104226	-0.061507612	false
training	oneLayer	oneLayer - rat 1	0	-0.3111613	-0.06569908	false
training	oneLayer	oneLayer - rat 1	0	-0.32165703	-0.065699086	false
training	oneLayer	oneLayer - rat 1	0	-0.3310897	-0.061791956	false
training	oneLayer	oneLayer - rat 1	0	-0.3411864	-0.06179197	false
training	oneLayer	oneLayer - rat 1	0	-0.35092512	-0.057758078	false
training	oneLayer	oneLayer - rat 1	0	-0.3616325	-0.05775809	false
training	oneLayer	oneLayer - rat 1	0	-0.37123802	-0.05377937	false
training	oneLayer	oneLayer - rat 1	0	-0.38221008	-0.053779382	false
training	oneLayer	oneLayer - rat 1	0	-0.39145726	-0.049949087	false
training	oneLayer	oneLayer - rat 1	0	-0.40202123	-0.0499491	false
training	oneLayer	oneLayer - rat 1	0	-0.4117379	-0.045924343	false
training	oneLayer	oneLayer - rat 1	0	-0.41898268	-0.038679566	false
training	oneLayer	oneLayer - rat 1	0	-0.4229683	-0.029057452	false
training	oneLayer	oneLayer - rat 1	0	-0.4229683	-0.018075936	false
training	oneLayer	oneLayer - rat 1	0	-0.418842	-0.008114116	false
training	oneLayer	oneLayer - rat 1	0	-0.4113506	-6.227197E-4	false
training	oneLayer	oneLayer - rat 1	0	-0.4071601	0.009494107	false
training	oneLayer	oneLayer - rat 1	0	-0.39964643	0.017007787	false
training	oneLayer	oneLayer - rat 1	0	-0.39558786	0.026806097	false
training	oneLayer	oneLayer - rat 1	0	-0.38831308	0.034080874	false
training	oneLayer	oneLayer - rat 1	0	-0.38427818	0.04382204	false
training	oneLayer	oneLayer - rat 1	0	-0.37690592	0.05119433	false
training	oneLayer	oneLayer - rat 1	0	-0.36716607	0.055228714	false
training	oneLayer	oneLayer - rat 1	0	-0.3568415	0.055228725	false
training	oneLayer	oneLayer - rat 1	0	-0.34701374	0.051157948	false
training	oneLayer	oneLayer - rat 1	0	-0.33971158	0.043855797	false
training	oneLayer	oneLayer - rat 1	0	-0.33587784	0.034600332	false
training	oneLayer	oneLayer - rat 1	0	-0.32822677	0.026949285	false
training	oneLayer	oneLayer - rat 1	0	-0.32433817	0.017561417	false
training	oneLayer	oneLayer - rat 1	0	-0.317023	0.010246262	false
training	oneLayer	oneLayer - rat 1	0	-0.31289846	2.887377E-4	false
training	oneLayer	oneLayer - rat 1	0	-0.30571017	-0.006899536	false
training	oneLayer	oneLayer - rat 1	0	-0.30183455	-0.01625606	false
training	oneLayer	oneLayer - rat 1	0	-0.2947256	-0.023364993	false
training	oneLayer	oneLayer - rat 1	0	-0.29088116	-0.032646306	false
training	oneLayer	oneLayer - rat 1	0	-0.28378856	-0.03973888	false
training	oneLayer	oneLayer - rat 1	0	-0.2798952	-0.04913826	false
training	oneLayer	oneLayer - rat 1	0	-0.2723764	-0.056657054	false
training	oneLayer	oneLayer - rat 1	0	-0.26839414	-0.066271	false
training	oneLayer	oneLayer - rat 1	0	-0.26124611	-0.07341902	false
training	oneLayer	oneLayer - rat 1	0	-0.25714108	-0.08332941	false
training	oneLayer	oneLayer - rat 1	0	-0.2496503	-0.09082018	false
training	oneLayer	oneLayer - rat 1	0	-0.24574342	-0.10025218	false
training	oneLayer	oneLayer - rat 1	0	-0.2386678	-0.10732779	false
training	oneLayer	oneLayer - rat 1	0	-0.23477353	-0.116729364	false
training	oneLayer	oneLayer - rat 1	0	-0.22702783	-0.124475054	false
training	oneLayer	oneLayer - rat 1	0	-0.22294092	-0.13434169	false
training	oneLayer	oneLayer - rat 1	0	-0.21558243	-0.14170016	false
training	oneLayer	oneLayer - rat 1	0	-0.2113956	-0.15180802	false
training	oneLayer	oneLayer - rat 1	0	-0.20386511	-0.1593385	false
training	oneLayer	oneLayer - rat 1	0	-0.19970673	-0.16937767	false
training	oneLayer	oneLayer - rat 1	0	-0.19243422	-0.17665017	false
training	oneLayer	oneLayer - rat 1	0	-0.18843783	-0.18629827	false
training	oneLayer	oneLayer - rat 1	0	-0.18116038	-0.19357571	false
training	oneLayer	oneLayer - rat 1	0	-0.17726685	-0.20297551	false
training	oneLayer	oneLayer - rat 1	0	-0.16971506	-0.21052727	false
training	oneLayer	oneLayer - rat 1	0	-0.16564654	-0.22034952	false
training	oneLayer	oneLayer - rat 1	0	-0.15838334	-0.22761272	false
training	oneLayer	oneLayer - rat 1	0	-0.15430689	-0.23745409	false
training	oneLayer	oneLayer - rat 1	0	-0.14654176	-0.2452192	false
training	oneLayer	oneLayer - rat 1	0	-0.14264071	-0.25463712	false
training	oneLayer	oneLayer - rat 1	0	-0.13504364	-0.2622342	false
training	oneLayer	oneLayer - rat 1	0	-0.1310722	-0.27182207	false
training	oneLayer	oneLayer - rat 1	0	-0.12391866	-0.27897558	false
training	oneLayer	oneLayer - rat 1	0	-0.119716935	-0.28911942	false
training	oneLayer	oneLayer - rat 1	0	-0.11198153	-0.2968548	false
training	oneLayer	oneLayer - rat 1	0	-0.10789993	-0.30670863	false
training	oneLayer	oneLayer - rat 1	0	-0.10023165	-0.3143769	false
training	oneLayer	oneLayer - rat 1	0	-0.096124575	-0.32429224	false
training	oneLayer	oneLayer - rat 1	0	-0.08875179	-0.331665	false
training	oneLayer	oneLayer - rat 1	0	-0.08486538	-0.3410476	false
training	oneLayer	oneLayer - rat 1	0	-0.07746433	-0.34844863	false
training	oneLayer	oneLayer - rat 1	0	-0.07343954	-0.35816532	false
training	oneLayer	oneLayer - rat 1	0	-0.06586131	-0.36574352	false
training	oneLayer	oneLayer - rat 1	0	-0.062033378	-0.37498495	false
training	oneLayer	oneLayer - rat 1	0	-0.0544395	-0.38257882	false
training	oneLayer	oneLayer - rat 1	0	-0.05038137	-0.39237598	false
training	oneLayer	oneLayer - rat 1	0	-0.042924207	-0.3998331	false
training	oneLayer	oneLayer - rat 1	0	-0.038970213	-0.4093789	false
training	oneLayer	oneLayer - rat 1	0	-0.031736214	-0.41661286	false
training	oneLayer	oneLayer - rat 1	0	-0.022021975	-0.42063662	false
training	oneLayer	oneLayer - rat 1	0	-0.014252167	-0.42840642	false
training	oneLayer	oneLayer - rat 1	0	-0.0045923996	-0.43240762	false
training	oneLayer	oneLayer - rat 1	0	0.0056524896	-0.4324076	false
training	oneLayer	oneLayer - rat 1	0	0.015606181	-0.42828465	false
training	oneLayer	oneLayer - rat 1	0	0.02653097	-0.42828462	false
training	oneLayer	oneLayer - rat 1	0	0.03632088	-0.4242295	false
training	oneLayer	oneLayer - rat 1	0	0.04369173	-0.41685864	false
training	oneLayer	oneLayer - rat 1	0	0.04755972	-0.40752044	false
training	oneLayer	oneLayer - rat 1	0	0.05478888	-0.40029126	false
training	oneLayer	oneLayer - rat 1	0	0.058846515	-0.39049524	false
training	oneLayer	oneLayer - rat 1	0	0.06653345	-0.3828083	false
training	oneLayer	oneLayer - rat 1	0	0.07062781	-0.37292358	false
training	oneLayer	oneLayer - rat 1	0	0.0777934	-0.365758	false
training	oneLayer	oneLayer - rat 1	0	0.08761575	-0.36168942	false
training	oneLayer	oneLayer - rat 1	0	0.09527001	-0.35403514	false
training	oneLayer	oneLayer - rat 1	0	0.105006754	-0.35000205	false
training	oneLayer	oneLayer - rat 1	0	0.11223563	-0.34277317	false
training	oneLayer	oneLayer - rat 1	0	0.12215861	-0.33866292	false
training	oneLayer	oneLayer - rat 1	0	0.12942639	-0.33139512	false
training	oneLayer	oneLayer - rat 1	0	0.13933618	-0.32729033	false
training	oneLayer	oneLayer - rat 1	0	0.14684644	-0.31978005	false
training	oneLayer	oneLayer - rat 1	0	0.15641317	-0.3158174	false
training	oneLayer	oneLayer - rat 1	0	0.16414055	-0.30808997	false
training	oneLayer	oneLayer - rat 1	0	0.17390525	-0.3040453	false
training	oneLayer	oneLayer - rat 1	0	0.18109469	-0.29685584	false
training	oneLayer	oneLayer - rat 1	0	0.1911886	-0.2926748	false
training	oneLayer	oneLayer - rat 1	0	0.1986191	-0.2852443	false
training	oneLayer	oneLayer - rat 1	0	0.20818809	-0.28128067	false
training	oneLayer	oneLayer - rat 1	0	0.21539569	-0.27407303	false
training	oneLayer	oneLayer - rat 1	0	0.22546032	-0.2699041	false
training	oneLayer	oneLayer - rat 1	0	0.23288311	-0.2624813	false
training	oneLayer	oneLayer - rat 1	0	0.24250007	-0.25849783	false
training	oneLayer	oneLayer - rat 1	0	0.24994886	-0.251049	false
training	oneLayer	oneLayer - rat 1	0	0.25981367	-0.24696286	false
training	oneLayer	oneLayer - rat 1	0	0.26706612	-0.23971039	false
training	oneLayer	oneLayer - rat 1	0	0.2771471	-0.2355347	false
training	oneLayer	oneLayer - rat 1	0	0.28462023	-0.22806157	false
training	oneLayer	oneLayer - rat 1	0	0.29464915	-0.22390744	false
training	oneLayer	oneLayer - rat 1	0	0.30193645	-0.21662015	false
training	oneLayer	oneLayer - rat 1	0	0.31123158	-0.21276996	false
training	oneLayer	oneLayer - rat 1	0	0.31837142	-0.20563012	false
training	oneLayer	oneLayer - rat 1	0	0.32763955	-0.20179114	false
training	oneLayer	oneLayer - rat 1	0	0.33503243	-0.19439822	false
training	oneLayer	oneLayer - rat 1	0	0.344845	-0.19033372	false
training	oneLayer	oneLayer - rat 1	0	0.35216996	-0.18300872	false
training	oneLayer	oneLayer - rat 1	0	0.36215204	-0.178874	false
training	oneLayer	oneLayer - rat 1	0	0.3692695	-0.17175654	false
training	oneLayer	oneLayer - rat 1	0	0.37858337	-0.16789858	false
training	oneLayer	oneLayer - rat 1	0	0.38594094	-0.16054098	false
training	oneLayer	oneLayer - rat 1	0	0.3900259	-0.15067896	false
training	oneLayer	oneLayer - rat 1	0	0.39726776	-0.14343712	false
training	oneLayer	oneLayer - rat 1	0	0.40117484	-0.13400452	false
training	oneLayer	oneLayer - rat 1	0	0.4087074	-0.12647195	false
training	oneLayer	oneLayer - rat 1	0	0.41279247	-0.11660972	false
training	oneLayer	oneLayer - rat 1	0	0.420183	-0.10921917	false
training	oneLayer	oneLayer - rat 1	0	0.42423895	-0.09942721	false
training	oneLayer	oneLayer - rat 1	0	0.43138206	-0.09228408	false
training	oneLayer	oneLayer - rat 1	0	0.4352746	-0.08288666	false
training	oneLayer	oneLayer - rat 1	0	0.43921286	-0.07337885	false
training	oneLayer	oneLayer - rat 1	0	0.44322085	-0.063702606	false
training	oneLayer	oneLayer - rat 1	0	0.4473703	-0.053684983	false
training	oneLayer	oneLayer - rat 1	0	0.4514929	-0.04373206	false
training	oneLayer	oneLayer - rat 1	0	0.4514929	-0.033035867	false
training	oneLayer	oneLayer - rat 1	0	0.44739622	-0.023145631	false
training	oneLayer	oneLayer - rat 1	0	0.44022647	-0.0159759	false
training	oneLayer	oneLayer - rat 1	0	0.43031168	-0.011869067	false
training	oneLayer	oneLayer - rat 1	0	0.42254016	-0.0040975558	false
training	oneLayer	oneLayer - rat 1	0	0.41276595	-4.897087E-5	false
training	oneLayer	oneLayer - rat 1	0	0.4051133	0.007603676	false
training	oneLayer	oneLayer - rat 1	0	0.3956879	0.011507784	false
training	oneLayer	oneLayer - rat 1	0	0.38856694	0.018628746	false
training	oneLayer	oneLayer - rat 1	0	0.37846723	0.022812165	false
training	oneLayer	oneLayer - rat 1	0	0.37108406	0.030195335	false
training	oneLayer	oneLayer - rat 1	0	0.36180466	0.03403898	false
training	oneLayer	oneLayer - rat 1	0	0.35455775	0.04128586	false
training	oneLayer	oneLayer - rat 1	0	0.34466887	0.045381963	false
training	oneLayer	oneLayer - rat 1	0	0.33741	0.052640785	false
training	oneLayer	oneLayer - rat 1	0	0.32747117	0.05675758	false
training	oneLayer	oneLayer - rat 1	0	0.32019815	0.06403058	false
training	oneLayer	oneLayer - rat 1	0	0.3108581	0.06789934	false
training	oneLayer	oneLayer - rat 1	0	0.3002623	0.067899324	false
training	oneLayer	oneLayer - rat 1	0	0.2902127	0.063736625	false
training	oneLayer	oneLayer - rat 1	0	0.28275195	0.05627587	false
training	oneLayer	oneLayer - rat 1	0	0.27350435	0.052445382	false
training	oneLayer	oneLayer - rat 1	0	0.26593992	0.044880938	false
training	oneLayer	oneLayer - rat 1	0	0.25638214	0.040921964	false
training	oneLayer	oneLayer - rat 1	0	0.24901135	0.033551153	false
training	oneLayer	oneLayer - rat 1	0	0.23889686	0.029361578	false
training	oneLayer	oneLayer - rat 1	0	0.23174693	0.022211632	false
training	oneLayer	oneLayer - rat 1	0	0.22215837	0.018239906	false
training	oneLayer	oneLayer - rat 1	0	0.2144354	0.01051692	false
training	oneLayer	oneLayer - rat 1	0	0.20512874	0.0066619664	false
training	oneLayer	oneLayer - rat 1	0	0.19790186	-5.649379E-4	false
training	oneLayer	oneLayer - rat 1	0	0.18830715	-0.004539208	false
training	oneLayer	oneLayer - rat 1	0	0.1775521	-0.00453922	false
training	oneLayer	oneLayer - rat 1	0	0.16780025	-0.008578587	false
training	oneLayer	oneLayer - rat 1	0	0.15726934	-0.008578599	false
training	oneLayer	oneLayer - rat 1	0	0.14753577	-0.0126103945	false
training	oneLayer	oneLayer - rat 1	0	0.13732328	-0.012610407	false
training	oneLayer	oneLayer - rat 1	0	0.12772597	-0.016585754	false
training	oneLayer	oneLayer - rat 1	0	0.11765494	-0.016585765	false
training	oneLayer	oneLayer - rat 1	0	0.10798241	-0.02059227	false
training	oneLayer	oneLayer - rat 1	0	0.09788408	-0.020592282	false
training	oneLayer	oneLayer - rat 1	0	0.08858688	-0.024443319	false
training	oneLayer	oneLayer - rat 1	0	0.07833009	-0.02444333	false
training	oneLayer	oneLayer - rat 1	0	0.06904177	-0.02829069	false
training	oneLayer	oneLayer - rat 1	0	0.058672946	-0.028290702	false
training	oneLayer	oneLayer - rat 1	0	0.04901331	-0.032291867	false
training	oneLayer	oneLayer - rat 1	0	0.03815563	-0.03229188	false
training	oneLayer	oneLayer - rat 1	0	0.0285487	-0.036271214	false
training	oneLayer	oneLayer - rat 1	0	0.018326031	-0.036271226	false
training	oneLayer	oneLayer - rat 1	0	0.008831173	-0.040204138	false
training	oneLayer	oneLayer - rat 1	0	-0.0016683087	-0.04020415	false
training	oneLayer	oneLayer - rat 1	0	-0.011273094	-0.044182595	false
training	oneLayer	oneLayer - rat 1	0	-0.022153988	-0.044182606	false
training	oneLayer	oneLayer - rat 1	0	-0.031630203	-0.048107795	false
training	oneLayer	oneLayer - rat 1	0	-0.041860044	-0.048107807	false
training	oneLayer	oneLayer - rat 1	0	-0.051165286	-0.05196218	false
training	oneLayer	oneLayer - rat 1	0	-0.06165708	-0.05196219	false
training	oneLayer	oneLayer - rat 1	0	-0.07151779	-0.056046642	false
training	oneLayer	oneLayer - rat 1	0	-0.081855476	-0.056046654	false
training	oneLayer	oneLayer - rat 1	0	-0.09196215	-0.06023299	false
training	oneLayer	oneLayer - rat 1	0	-0.10210785	-0.060233	false
training	oneLayer	oneLayer - rat 1	0	-0.11156999	-0.06415236	false
training	oneLayer	oneLayer - rat 1	0	-0.12172034	-0.06415237	false
training	oneLayer	oneLayer - rat 1	0	-0.1312276	-0.068090424	false
training	oneLayer	oneLayer - rat 1	0	-0.14196469	-0.06809043	false
training	oneLayer	oneLayer - rat 1	0	-0.15204872	-0.07226739	false
training	oneLayer	oneLayer - rat 1	0	-0.16262959	-0.0722674	false
training	oneLayer	oneLayer - rat 1	0	-0.17278409	-0.07647354	false
training	oneLayer	oneLayer - rat 1	0	-0.18316077	-0.07647356	false
training	oneLayer	oneLayer - rat 1	0	-0.19291903	-0.08051557	false
training	oneLayer	oneLayer - rat 1	0	-0.20341812	-0.080515586	false
training	oneLayer	oneLayer - rat 1	0	-0.21347469	-0.08468116	false
training	oneLayer	oneLayer - rat 1	0	-0.2236003	-0.084681176	false
training	oneLayer	oneLayer - rat 1	0	-0.2336275	-0.088834584	false
training	oneLayer	oneLayer - rat 1	0	-0.24411723	-0.0888346	false
training	oneLayer	oneLayer - rat 1	0	-0.25338426	-0.08499608	false
training	oneLayer	oneLayer - rat 1	0	-0.26056638	-0.07781398	false
training	oneLayer	oneLayer - rat 1	0	-0.27040446	-0.07373893	false
training	oneLayer	oneLayer - rat 1	0	-0.28079203	-0.07373895	false
training	oneLayer	oneLayer - rat 1	0	-0.2904878	-0.06972284	false
training	oneLayer	oneLayer - rat 1	0	-0.3008637	-0.069722846	false
training	oneLayer	oneLayer - rat 1	0	-0.31015003	-0.06587635	false
training	oneLayer	oneLayer - rat 1	0	-0.3175554	-0.058470994	false
training	oneLayer	oneLayer - rat 1	0	-0.327438	-0.054377493	false
training	oneLayer	oneLayer - rat 1	0	-0.33797336	-0.054377504	false
training	oneLayer	oneLayer - rat 1	0	-0.34807867	-0.050191768	false
training	oneLayer	oneLayer - rat 1	0	-0.35899776	-0.05019178	false
training	oneLayer	oneLayer - rat 1	0	-0.3691196	-0.045999188	false
training	oneLayer	oneLayer - rat 1	0	-0.37918413	-0.0459992	false
training	oneLayer	oneLayer - rat 1	0	-0.38873246	-0.042044155	false
training	oneLayer	oneLayer - rat 1	0	-0.39932206	-0.04204417	false
training	oneLayer	oneLayer - rat 1	0	-0.40892988	-0.038064495	false
training	oneLayer	oneLayer - rat 1	0	-0.41651	-0.030484399	false
training	oneLayer	oneLayer - rat 1	0	-0.42066318	-0.020457799	false
training	oneLayer	oneLayer - rat 1	0	-0.4280304	-0.013090569	false
training	oneLayer	oneLayer - rat 1	0	-0.4322214	-0.0029726252	false
training	oneLayer	oneLayer - rat 1	0	-0.4322214	0.0073819207	false
training	oneLayer	oneLayer - rat 1	0	-0.43619114	0.016965652	false
training	oneLayer	oneLayer - rat 1	0	-0.43619117	0.027701719	false
training	oneLayer	oneLayer - rat 1	0	-0.4322301	0.037264623	false
training	oneLayer	oneLayer - rat 1	0	-0.4281636	0.047082067	false
training	oneLayer	oneLayer - rat 1	0	-0.4242784	0.056461703	false
training	oneLayer	oneLayer - rat 1	0	-0.42013758	0.06645862	false
training	oneLayer	oneLayer - rat 1	0	-0.4159916	0.076467924	false
training	oneLayer	oneLayer - rat 1	0	-0.41181877	0.08654207	false
training	oneLayer	oneLayer - rat 1	0	-0.40790713	0.0959856	false
training	oneLayer	oneLayer - rat 1	0	-0.40371582	0.10610435	false
training	oneLayer	oneLayer - rat 1	0	-0.39981657	0.11551799	false
training	oneLayer	oneLayer - rat 1	0	-0.39580974	0.12519142	false
training	oneLayer	oneLayer - rat 1	0	-0.3916235	0.13529791	false
training	oneLayer	oneLayer - rat 1	0	-0.3877755	0.14458779	false
training	oneLayer	oneLayer - rat 1	0	-0.383583	0.15470946	false
training	oneLayer	oneLayer - rat 1	0	-0.37968102	0.16412967	false
training	oneLayer	oneLayer - rat 1	0	-0.3756696	0.17381415	false
training	oneLayer	oneLayer - rat 1	0	-0.37150985	0.18385673	false
training	oneLayer	oneLayer - rat 1	0	-0.36733338	0.1939396	false
training	oneLayer	oneLayer - rat 1	0	-0.3632642	0.20376351	false
training	oneLayer	oneLayer - rat 1	0	-0.35932103	0.21328323	false
training	oneLayer	oneLayer - rat 1	0	-0.3554442	0.22264276	false
training	oneLayer	oneLayer - rat 1	0	-0.35147303	0.23223	false
training	oneLayer	oneLayer - rat 1	0	-0.34738505	0.24209927	false
training	oneLayer	oneLayer - rat 1	0	-0.34343022	0.25164714	false
training	oneLayer	oneLayer - rat 1	0	-0.3395077	0.26111692	false
training	oneLayer	oneLayer - rat 1	0	-0.3353058	0.27126125	false
training	oneLayer	oneLayer - rat 1	0	-0.3314654	0.28053284	false
training	oneLayer	oneLayer - rat 1	0	-0.32731774	0.2905462	false
training	oneLayer	oneLayer - rat 1	0	-0.31976402	0.29809994	false
training	oneLayer	oneLayer - rat 1	0	-0.31028527	0.30202618	false
training	oneLayer	oneLayer - rat 1	0	-0.29963902	0.30202618	false
training	oneLayer	oneLayer - rat 1	0	-0.2898053	0.29795295	false
training	oneLayer	oneLayer - rat 1	0	-0.2823791	0.29052678	false
training	oneLayer	oneLayer - rat 1	0	-0.27296883	0.2866289	false
training	oneLayer	oneLayer - rat 1	0	-0.2653105	0.2789706	false
training	oneLayer	oneLayer - rat 1	0	-0.25589126	0.27506903	false
training	oneLayer	oneLayer - rat 1	0	-0.24848224	0.26766002	false
training	oneLayer	oneLayer - rat 1	0	-0.23867615	0.2635982	false
training	oneLayer	oneLayer - rat 1	0	-0.23139608	0.25631815	false
training	oneLayer	oneLayer - rat 1	0	-0.22140865	0.25218123	false
training	oneLayer	oneLayer - rat 1	0	-0.21411934	0.24489194	false
training	oneLayer	oneLayer - rat 1	0	-0.2042669	0.24081095	false
training	oneLayer	oneLayer - rat 1	0	-0.19709285	0.23363689	false
training	oneLayer	oneLayer - rat 1	0	-0.18717448	0.22952859	false
training	oneLayer	oneLayer - rat 1	0	-0.17960942	0.22196354	false
training	oneLayer	oneLayer - rat 1	0	-0.17017727	0.21805662	false
training	oneLayer	oneLayer - rat 1	0	-0.16288568	0.21076506	false
training	oneLayer	oneLayer - rat 1	0	-0.15342	0.20684426	false
training	oneLayer	oneLayer - rat 1	0	-0.14630695	0.19973122	false
training	oneLayer	oneLayer - rat 1	0	-0.13680099	0.19579373	false
training	oneLayer	oneLayer - rat 1	0	-0.12914005	0.18813281	false
training	oneLayer	oneLayer - rat 1	0	-0.118986905	0.18392725	false
training	oneLayer	oneLayer - rat 1	0	-0.11187577	0.17681612	false
training	oneLayer	oneLayer - rat 1	0	-0.10200825	0.17272888	false
training	oneLayer	oneLayer - rat 1	0	-0.09492832	0.16564895	false
training	oneLayer	oneLayer - rat 1	0	-0.0853344	0.16167504	false
training	oneLayer	oneLayer - rat 1	0	-0.078120425	0.15446109	false
training	oneLayer	oneLayer - rat 1	0	-0.06882215	0.15060961	false
training	oneLayer	oneLayer - rat 1	0	-0.061277397	0.14306489	false
training	oneLayer	oneLayer - rat 1	0	-0.05185194	0.13916074	false
training	oneLayer	oneLayer - rat 1	0	-0.044408284	0.1317171	false
training	oneLayer	oneLayer - rat 1	0	-0.035067547	0.12784806	false
training	oneLayer	oneLayer - rat 1	0	-0.027741311	0.12052183	false
training	oneLayer	oneLayer - rat 1	0	-0.018497406	0.11669289	false
training	oneLayer	oneLayer - rat 1	0	-0.011045727	0.109241225	false
training	oneLayer	oneLayer - rat 1	0	-0.0016714333	0.10535828	false
training	oneLayer	oneLayer - rat 1	0	0.005524591	0.09816227	false
training	oneLayer	oneLayer - rat 1	0	0.015552067	0.094008766	false
training	oneLayer	oneLayer - rat 1	0	0.022750681	0.086810164	false
training	oneLayer	oneLayer - rat 1	0	0.032158203	0.08291345	false
training	oneLayer	oneLayer - rat 1	0	0.039917815	0.07515386	false
training	oneLayer	oneLayer - rat 1	0	0.049861364	0.07103512	false
training	oneLayer	oneLayer - rat 1	0	0.057156183	0.06374031	false
training	oneLayer	oneLayer - rat 1	0	0.06689049	0.05970824	false
training	oneLayer	oneLayer - rat 1	0	0.073990285	0.05260846	false
training	oneLayer	oneLayer - rat 1	0	0.08323848	0.048777744	false
training	oneLayer	oneLayer - rat 1	0	0.09063824	0.041377995	false
training	oneLayer	oneLayer - rat 1	0	0.10069324	0.03721309	false
training	oneLayer	oneLayer - rat 1	0	0.1082824	0.029623952	false
training	oneLayer	oneLayer - rat 1	0	0.11819631	0.025517488	false
training	oneLayer	oneLayer - rat 1	0	0.12589929	0.017814534	false
training	oneLayer	oneLayer - rat 1	0	0.13588758	0.01367726	false
training	oneLayer	oneLayer - rat 1	0	0.14296219	0.0066026514	false
training	oneLayer	oneLayer - rat 1	0	0.15283576	0.0025128985	false
training	oneLayer	oneLayer - rat 1	0	0.1600992	-0.0047505233	false
training	oneLayer	oneLayer - rat 1	0	0.16988963	-0.008805838	false
training	oneLayer	oneLayer - rat 1	0	0.17722476	-0.016140955	false
training	oneLayer	oneLayer - rat 1	0	0.18720736	-0.020275874	false
training	oneLayer	oneLayer - rat 1	0	0.19479263	-0.02786112	false
training	oneLayer	oneLayer - rat 1	0	0.20486666	-0.032033913	false
training	oneLayer	oneLayer - rat 1	0	0.2119411	-0.03910833	false
training	oneLayer	oneLayer - rat 1	0	0.22207859	-0.043307405	false
training	oneLayer	oneLayer - rat 1	0	0.22965308	-0.05088187	false
training	oneLayer	oneLayer - rat 1	0	0.23905386	-0.054775793	false
training	oneLayer	oneLayer - rat 1	0	0.2461511	-0.06187302	false
training	oneLayer	oneLayer - rat 1	0	0.25593087	-0.065923914	false
training	oneLayer	oneLayer - rat 1	0	0.2636149	-0.07360792	false
training	oneLayer	oneLayer - rat 1	0	0.27290714	-0.077456884	false
training	oneLayer	oneLayer - rat 1	0	0.2800072	-0.08455696	false
training	oneLayer	oneLayer - rat 1	0	0.28981206	-0.08861825	false
training	oneLayer	oneLayer - rat 1	0	0.2974836	-0.09628976	false
training	oneLayer	oneLayer - rat 1	0	0.3067387	-0.100123346	false
training	oneLayer	oneLayer - rat 1	0	0.31434935	-0.10773397	false
training	oneLayer	oneLayer - rat 1	0	0.32442293	-0.11190658	false
training	oneLayer	oneLayer - rat 1	0	0.33183727	-0.119320884	false
training	oneLayer	oneLayer - rat 1	0	0.3416159	-0.12337131	false
training	oneLayer	oneLayer - rat 1	0	0.3489259	-0.13068129	false
training	oneLayer	oneLayer - rat 1	0	0.35817444	-0.13451216	false
training	oneLayer	oneLayer - rat 1	0	0.3657808	-0.1421185	false
training	oneLayer	oneLayer - rat 1	0	0.3751293	-0.14599077	false
training	oneLayer	oneLayer - rat 1	0	0.38259208	-0.15345351	false
training	oneLayer	oneLayer - rat 1	0	0.38653606	-0.16297515	false
training	oneLayer	oneLayer - rat 1	0	0.3865361	-0.1732001	false
training	oneLayer	oneLayer - rat 1	0	0.38244435	-0.18307848	false
training	oneLayer	oneLayer - rat 1	0	0.38244435	-0.19355045	false
training	oneLayer	oneLayer - rat 1	0	0.3785263	-0.20300947	false
training	oneLayer	oneLayer - rat 1	0	0.37852633	-0.21352495	false
training	oneLayer	oneLayer - rat 1	0	0.3745295	-0.2231741	false
training	oneLayer	oneLayer - rat 1	0	0.37452954	-0.23399693	false
training	oneLayer	oneLayer - rat 1	0	0.37061462	-0.24344836	false
training	oneLayer	oneLayer - rat 1	0	0.36294943	-0.25111356	false
training	oneLayer	oneLayer - rat 1	0	0.35361424	-0.25498036	false
training	oneLayer	oneLayer - rat 1	0	0.34284973	-0.25498036	false
training	oneLayer	oneLayer - rat 1	0	0.33289587	-0.25085735	false
training	oneLayer	oneLayer - rat 1	0	0.32545006	-0.24341154	false
training	oneLayer	oneLayer - rat 1	0	0.32135895	-0.23353478	false
training	oneLayer	oneLayer - rat 1	0	0.32135895	-0.22299871	false
training	oneLayer	oneLayer - rat 1	0	0.32554802	-0.21288536	false
training	oneLayer	oneLayer - rat 1	0	0.32974246	-0.20275907	false
training	oneLayer	oneLayer - rat 1	0	0.33361247	-0.19341603	false
training	oneLayer	oneLayer - rat 1	0	0.33770666	-0.18353175	false
training	oneLayer	oneLayer - rat 1	0	0.3415649	-0.17421709	false
training	oneLayer	oneLayer - rat 1	0	0.34551293	-0.16468568	false
training	oneLayer	oneLayer - rat 1	0	0.34951046	-0.15503477	false
training	oneLayer	oneLayer - rat 1	0	0.35355923	-0.1452602	false
training	oneLayer	oneLayer - rat 1	0	0.35755333	-0.13561754	false
training	oneLayer	oneLayer - rat 1	0	0.361617	-0.12580694	false
training	oneLayer	oneLayer - rat 1	0	0.365796	-0.11571788	false
training	oneLayer	oneLayer - rat 1	0	0.36966327	-0.106381446	false
training	oneLayer	oneLayer - rat 1	0	0.37373215	-0.09655829	false
training	oneLayer	oneLayer - rat 1	0	0.37763992	-0.0871241	false
training	oneLayer	oneLayer - rat 1	0	0.38176024	-0.07717672	false
training	oneLayer	oneLayer - rat 1	0	0.3857408	-0.06756679	false
training	oneLayer	oneLayer - rat 1	0	0.38970464	-0.05799716	false
training	oneLayer	oneLayer - rat 1	0	0.39741743	-0.050284375	false
training	oneLayer	oneLayer - rat 1	0	0.4075726	-0.046077948	false
training	oneLayer	oneLayer - rat 1	0	0.41532737	-0.03832316	false
training	oneLayer	oneLayer - rat 1	0	0.41945946	-0.02834744	false
training	oneLayer	oneLayer - rat 1	0	0.41945943	-0.017490659	false
training	oneLayer	oneLayer - rat 1	0	0.41547158	-0.007863122	false
training	oneLayer	oneLayer - rat 1	0	0.40809327	-4.848487E-4	false
training	oneLayer	oneLayer - rat 1	0	0.39799002	0.0037000498	false
training	oneLayer	oneLayer - rat 1	0	0.3870132	0.0037000393	false
training	oneLayer	oneLayer - rat 1	0	0.37735125	-3.0208338E-4	false
training	oneLayer	oneLayer - rat 1	0	0.3667949	-3.0209354E-4	false
training	oneLayer	oneLayer - rat 1	0	0.35680157	-0.004441494	false
training	oneLayer	oneLayer - rat 1	0	0.3463003	-0.004441504	false
training	oneLayer	oneLayer - rat 1	0	0.33690077	-0.008334925	false
training	oneLayer	oneLayer - rat 1	0	0.32601282	-0.008334936	false
training	oneLayer	oneLayer - rat 1	0	0.31624398	-0.012381337	false
training	oneLayer	oneLayer - rat 1	0	0.3057676	-0.012381347	false
training	oneLayer	oneLayer - rat 1	0	0.29640788	-0.016258279	false
training	oneLayer	oneLayer - rat 1	0	0.285575	-0.01625829	false
training	oneLayer	oneLayer - rat 1	0	0.27593794	-0.020250104	false
training	oneLayer	oneLayer - rat 1	0	0.26500413	-0.020250114	false
training	oneLayer	oneLayer - rat 1	0	0.2552896	-0.024274006	false
training	oneLayer	oneLayer - rat 1	0	0.24516088	-0.024274018	false
training	oneLayer	oneLayer - rat 1	0	0.23547621	-0.028285546	false
training	oneLayer	oneLayer - rat 1	0	0.22525863	-0.028285556	false
training	oneLayer	oneLayer - rat 1	0	0.21565254	-0.032264538	false
training	oneLayer	oneLayer - rat 1	0	0.20509975	-0.03226455	false
training	oneLayer	oneLayer - rat 1	0	0.19503236	-0.036434606	false
training	oneLayer	oneLayer - rat 1	0	0.18466692	-0.036434617	false
training	oneLayer	oneLayer - rat 1	0	0.17529364	-0.04031717	false
training	oneLayer	oneLayer - rat 1	0	0.16524455	-0.04031718	false
training	oneLayer	oneLayer - rat 1	0	0.15517104	-0.04448978	false
training	oneLayer	oneLayer - rat 1	0	0.14482008	-0.044489786	false
training	oneLayer	oneLayer - rat 1	0	0.1347981	-0.04864104	false
training	oneLayer	oneLayer - rat 1	0	0.124303676	-0.04864105	false
training	oneLayer	oneLayer - rat 1	0	0.11432352	-0.052774977	false
training	oneLayer	oneLayer - rat 1	0	0.10347405	-0.052774988	false
training	oneLayer	oneLayer - rat 1	0	0.09409752	-0.056658886	false
training	oneLayer	oneLayer - rat 1	0	0.083860114	-0.056658898	false
training	oneLayer	oneLayer - rat 1	0	0.07453191	-0.060522776	false
training	oneLayer	oneLayer - rat 1	0	0.06375448	-0.060522787	false
training	oneLayer	oneLayer - rat 1	0	0.0543397	-0.064422525	false
training	oneLayer	oneLayer - rat 1	0	0.043733362	-0.06442253	false
training	oneLayer	oneLayer - rat 1	0	0.03435036	-0.06830911	false
training	oneLayer	oneLayer - rat 1	0	0.024064882	-0.06830912	false
training	oneLayer	oneLayer - rat 1	0	0.014549285	-0.07225062	false
training	oneLayer	oneLayer - rat 1	0	0.004318436	-0.072250634	false
training	oneLayer	oneLayer - rat 1	0	-0.0053777043	-0.076266915	false
training	oneLayer	oneLayer - rat 1	0	-0.016360395	-0.07626693	false
training	oneLayer	oneLayer - rat 1	0	-0.026092237	-0.080298	false
training	oneLayer	oneLayer - rat 1	0	-0.03679289	-0.08029801	false
training	oneLayer	oneLayer - rat 1	0	-0.046575405	-0.08435007	false
training	oneLayer	oneLayer - rat 1	0	-0.057066794	-0.08435008	false
training	oneLayer	oneLayer - rat 1	0	-0.066538565	-0.08827343	false
training	oneLayer	oneLayer - rat 1	0	-0.077057205	-0.088273436	false
training	oneLayer	oneLayer - rat 1	0	-0.08638454	-0.09213696	false
training	oneLayer	oneLayer - rat 1	0	-0.0963982	-0.092136964	false
training	oneLayer	oneLayer - rat 1	0	-0.10626739	-0.096224934	false
training	oneLayer	oneLayer - rat 1	0	-0.11674582	-0.09622494	false
training	oneLayer	oneLayer - rat 1	0	-0.12689272	-0.10042793	false
training	oneLayer	oneLayer - rat 1	0	-0.13717543	-0.10042794	false
training	oneLayer	oneLayer - rat 1	0	-0.14693911	-0.10447221	false
training	oneLayer	oneLayer - rat 1	0	-0.1570968	-0.10447222	false
training	oneLayer	oneLayer - rat 1	0	-0.16673328	-0.10846379	false
training	oneLayer	oneLayer - rat 1	0	-0.17757407	-0.1084638	false
training	oneLayer	oneLayer - rat 1	0	-0.18722977	-0.11246333	false
training	oneLayer	oneLayer - rat 1	0	-0.19739869	-0.11246335	false
training	oneLayer	oneLayer - rat 1	0	-0.20675589	-0.10858747	false
training	oneLayer	oneLayer - rat 1	0	-0.21449193	-0.10085145	false
training	oneLayer	oneLayer - rat 1	0	-0.22378337	-0.09700282	false
training	oneLayer	oneLayer - rat 1	0	-0.23134299	-0.08944322	false
training	oneLayer	oneLayer - rat 1	0	-0.2414723	-0.08524753	false
training	oneLayer	oneLayer - rat 1	0	-0.25165626	-0.08524754	false
training	oneLayer	oneLayer - rat 1	0	-0.26161894	-0.08112088	false
training	oneLayer	oneLayer - rat 1	0	-0.2720821	-0.081120886	false
training	oneLayer	oneLayer - rat 1	0	-0.28190443	-0.07705235	false
training	oneLayer	oneLayer - rat 1	0	-0.29211235	-0.077052355	false
training	oneLayer	oneLayer - rat 1	0	-0.3022063	-0.07287132	false
training	oneLayer	oneLayer - rat 1	0	-0.3131133	-0.072871335	false
training	oneLayer	oneLayer - rat 1	0	-0.3231907	-0.068697155	false
training	oneLayer	oneLayer - rat 1	0	-0.3336292	-0.06869716	false
training	oneLayer	oneLayer - rat 1	0	-0.3430513	-0.06479441	false
training	oneLayer	oneLayer - rat 1	0	-0.35309547	-0.064794414	false
training	oneLayer	oneLayer - rat 1	0	-0.36274177	-0.06079879	false
training	oneLayer	oneLayer - rat 1	0	-0.37349233	-0.0607988	false
training	oneLayer	oneLayer - rat 1	0	-0.38305497	-0.05683784	false
training	oneLayer	oneLayer - rat 1	0	-0.39325413	-0.05683785	false
training	oneLayer	oneLayer - rat 1	0	-0.40287438	-0.052853018	false
training	oneLayer	oneLayer - rat 1	0	-0.4099677	-0.045759723	false
training	oneLayer	oneLayer - rat 1	0	-0.4176934	-0.038034026	false
training	oneLayer	oneLayer - rat 1	0	-0.421735	-0.028276805	false
training	oneLayer	oneLayer - rat 1	0	-0.4289803	-0.021031521	false
training	oneLayer	oneLayer - rat 1	0	-0.4328787	-0.011619907	false
training	oneLayer	oneLayer - rat 1	0	-0.4328787	-0.0011584501	false
training	oneLayer	oneLayer - rat 1	0	-0.42878458	0.0087257195	false
training	oneLayer	oneLayer - rat 1	0	-0.42477065	0.018416205	false
training	oneLayer	oneLayer - rat 1	0	-0.42056116	0.028578833	false
training	oneLayer	oneLayer - rat 1	0	-0.4165801	0.038189955	false
training	oneLayer	oneLayer - rat 1	0	-0.41262823	0.047730632	false
training	oneLayer	oneLayer - rat 1	0	-0.4085233	0.05764091	false
training	oneLayer	oneLayer - rat 1	0	-0.40448603	0.06738775	false
training	oneLayer	oneLayer - rat 1	0	-0.4004524	0.07712575	false
training	oneLayer	oneLayer - rat 1	0	-0.39649975	0.086668395	false
training	oneLayer	oneLayer - rat 1	0	-0.3923532	0.09667907	false
training	oneLayer	oneLayer - rat 1	0	-0.38835412	0.106333695	false
training	oneLayer	oneLayer - rat 1	0	-0.38438067	0.11592649	false
training	oneLayer	oneLayer - rat 1	0	-0.38034692	0.12566485	false
training	oneLayer	oneLayer - rat 1	0	-0.37631547	0.13539763	false
training	oneLayer	oneLayer - rat 1	0	-0.37231305	0.14506035	false
training	oneLayer	oneLayer - rat 1	0	-0.36814952	0.15511206	false
training	oneLayer	oneLayer - rat 1	0	-0.36422977	0.16457522	false
training	oneLayer	oneLayer - rat 1	0	-0.36037353	0.17388499	false
training	oneLayer	oneLayer - rat 1	0	-0.35631928	0.18367282	false
training	oneLayer	oneLayer - rat 1	0	-0.35232854	0.19330737	false
training	oneLayer	oneLayer - rat 1	0	-0.3483765	0.20284845	false
training	oneLayer	oneLayer - rat 1	0	-0.34445584	0.2123138	false
training	oneLayer	oneLayer - rat 1	0	-0.34062347	0.221566	false
training	oneLayer	oneLayer - rat 1	0	-0.33655798	0.23138095	false
training	oneLayer	oneLayer - rat 1	0	-0.3323999	0.2414195	false
training	oneLayer	oneLayer - rat 1	0	-0.32836536	0.25115976	false
training	oneLayer	oneLayer - rat 1	0	-0.32430807	0.26095498	false
training	oneLayer	oneLayer - rat 1	0	-0.32042986	0.2703178	false
training	oneLayer	oneLayer - rat 1	0	-0.3204299	0.28061473	false
training	oneLayer	oneLayer - rat 1	0	-0.3204299	0.29077375	false
training	oneLayer	oneLayer - rat 1	0	-0.31656763	0.3000981	false
training	oneLayer	oneLayer - rat 1	0	-0.31267253	0.30950177	false
training	oneLayer	oneLayer - rat 1	0	-0.30881286	0.31881985	false
training	oneLayer	oneLayer - rat 1	0	-0.30482057	0.32845807	false
training	oneLayer	oneLayer - rat 1	0	-0.30092376	0.33786586	false
training	oneLayer	oneLayer - rat 1	0	-0.29359144	0.34519818	false
training	oneLayer	oneLayer - rat 1	0	-0.289418	0.35527372	false
training	oneLayer	oneLayer - rat 1	0	-0.28168237	0.36300936	false
training	oneLayer	oneLayer - rat 1	0	-0.27176842	0.36711589	false
training	oneLayer	oneLayer - rat 1	0	-0.26123902	0.36711589	false
training	oneLayer	oneLayer - rat 1	0	-0.2516227	0.3631327	false
training	oneLayer	oneLayer - rat 1	0	-0.2444847	0.3559947	false
training	oneLayer	oneLayer - rat 1	0	-0.24060446	0.346627	false
training	oneLayer	oneLayer - rat 1	0	-0.24060445	0.33591986	false
training	oneLayer	oneLayer - rat 1	0	-0.24478696	0.32582238	false
training	oneLayer	oneLayer - rat 1	0	-0.24478695	0.31545857	false
training	oneLayer	oneLayer - rat 1	0	-0.24862465	0.3061935	false
training	oneLayer	oneLayer - rat 1	0	-0.24862464	0.2956898	false
training	oneLayer	oneLayer - rat 1	0	-0.2525344	0.2862508	false
training	oneLayer	oneLayer - rat 1	0	-0.26023093	0.27855423	false
training	oneLayer	oneLayer - rat 1	0	-0.26436475	0.2685743	false
training	oneLayer	oneLayer - rat 1	0	-0.27190468	0.26103437	false
training	oneLayer	oneLayer - rat 1	0	-0.2758099	0.25160623	false
training	oneLayer	oneLayer - rat 1	0	-0.2758099	0.24155994	false
training	oneLayer	oneLayer - rat 1	0	-0.27977636	0.23198405	false
training	oneLayer	oneLayer - rat 1	0	-0.27977636	0.2212636	false
training	oneLayer	oneLayer - rat 1	0	-0.2837641	0.21163636	false
training	oneLayer	oneLayer - rat 1	0	-0.28376406	0.20129229	false
training	oneLayer	oneLayer - rat 1	0	-0.2876194	0.19198468	false
training	oneLayer	oneLayer - rat 1	0	-0.28761938	0.18098745	false
training	oneLayer	oneLayer - rat 1	0	-0.2915317	0.17154223	false
training	oneLayer	oneLayer - rat 1	0	-0.2915317	0.16138111	false
training	oneLayer	oneLayer - rat 1	0	-0.29560387	0.15155	false
training	oneLayer	oneLayer - rat 1	0	-0.3027811	0.14437276	false
training	oneLayer	oneLayer - rat 1	0	-0.31223392	0.14045727	false
training	oneLayer	oneLayer - rat 1	0	-0.31978148	0.13290969	false
training	oneLayer	oneLayer - rat 1	0	-0.32904485	0.12907267	false
training	oneLayer	oneLayer - rat 1	0	-0.33645588	0.12166162	false
training	oneLayer	oneLayer - rat 1	0	-0.34053653	0.11181	false
training	oneLayer	oneLayer - rat 1	0	-0.34053653	0.10122353	false
training	oneLayer	oneLayer - rat 1	0	-0.34462142	0.09136173	false
training	oneLayer	oneLayer - rat 1	0	-0.3516958	0.08428734	false
training	oneLayer	oneLayer - rat 1	0	-0.3556984	0.07462414	false
training	oneLayer	oneLayer - rat 1	0	-0.36322993	0.067092605	false
training	oneLayer	oneLayer - rat 1	0	-0.36743072	0.056951024	false
training	oneLayer	oneLayer - rat 1	0	-0.375041	0.049340703	false
training	oneLayer	oneLayer - rat 1	0	-0.37919566	0.03931047	false
training	oneLayer	oneLayer - rat 1	0	-0.38663808	0.031868044	false
training	oneLayer	oneLayer - rat 1	0	-0.39059865	0.022306316	false
training	oneLayer	oneLayer - rat 1	0	-0.3982475	0.014657454	false
training	oneLayer	oneLayer - rat 1	0	-0.40791887	0.010651445	false
training	oneLayer	oneLayer - rat 1	0	-0.41553703	0.0030332487	false
training	oneLayer	oneLayer - rat 1	0	-0.41968167	-0.006972812	false
training	oneLayer	oneLayer - rat 1	0	-0.41968167	-0.017301682	false
training	oneLayer	oneLayer - rat 1	0	-0.41573876	-0.0268207	false
training	oneLayer	oneLayer - rat 1	0	-0.40808704	-0.034472395	false
training	oneLayer	oneLayer - rat 1	0	-0.3982813	-0.038534056	false
training	oneLayer	oneLayer - rat 1	0	-0.39077827	-0.04603707	false
training	oneLayer	oneLayer - rat 1	0	-0.38119206	-0.050007798	false
training	oneLayer	oneLayer - rat 1	0	-0.3737134	-0.057486452	false
training	oneLayer	oneLayer - rat 1	0	-0.3642681	-0.061398815	false
training	oneLayer	oneLayer - rat 1	0	-0.3568298	-0.0688371	false
training	oneLayer	oneLayer - rat 1	0	-0.34719044	-0.072829835	false
training	oneLayer	oneLayer - rat 1	0	-0.34003714	-0.07998314	false
training	oneLayer	oneLayer - rat 1	0	-0.3302354	-0.084043145	false
training	oneLayer	oneLayer - rat 1	0	-0.3229557	-0.09132283	false
training	oneLayer	oneLayer - rat 1	0	-0.31310755	-0.095402054	false
training	oneLayer	oneLayer - rat 1	0	-0.3054727	-0.1030369	false
training	oneLayer	oneLayer - rat 1	0	-0.29574782	-0.10706506	false
training	oneLayer	oneLayer - rat 1	0	-0.288253	-0.11455988	false
training	oneLayer	oneLayer - rat 1	0	-0.2788348	-0.11846103	false
training	oneLayer	oneLayer - rat 1	0	-0.27145904	-0.12583676	false
training	oneLayer	oneLayer - rat 1	0	-0.2618101	-0.12983347	false
training	oneLayer	oneLayer - rat 1	0	-0.25416148	-0.13748208	false
training	oneLayer	oneLayer - rat 1	0	-0.24449636	-0.14148548	false
training	oneLayer	oneLayer - rat 1	0	-0.23695117	-0.14903067	false
training	oneLayer	oneLayer - rat 1	0	-0.22725178	-0.15304828	false
training	oneLayer	oneLayer - rat 1	0	-0.22001223	-0.16028781	false
training	oneLayer	oneLayer - rat 1	0	-0.21018817	-0.16435707	false
training	oneLayer	oneLayer - rat 1	0	-0.20256908	-0.17197615	false
training	oneLayer	oneLayer - rat 1	0	-0.19253562	-0.17613213	false
training	oneLayer	oneLayer - rat 1	0	-0.1849858	-0.18368194	false
training	oneLayer	oneLayer - rat 1	0	-0.17522593	-0.18772459	false
training	oneLayer	oneLayer - rat 1	0	-0.16765781	-0.19529271	false
training	oneLayer	oneLayer - rat 1	0	-0.15758409	-0.19946536	false
training	oneLayer	oneLayer - rat 1	0	-0.150287	-0.20676243	false
training	oneLayer	oneLayer - rat 1	0	-0.1409592	-0.21062613	false
training	oneLayer	oneLayer - rat 1	0	-0.13388179	-0.21770352	false
training	oneLayer	oneLayer - rat 1	0	-0.124599345	-0.22154842	false
training	oneLayer	oneLayer - rat 1	0	-0.11734428	-0.22880347	false
training	oneLayer	oneLayer - rat 1	0	-0.107780986	-0.23276472	false
training	oneLayer	oneLayer - rat 1	0	-0.100582495	-0.23996319	false
training	oneLayer	oneLayer - rat 1	0	-0.09102996	-0.24391997	false
training	oneLayer	oneLayer - rat 1	0	-0.083511576	-0.25143835	false
training	oneLayer	oneLayer - rat 1	0	-0.07378561	-0.25546697	false
training	oneLayer	oneLayer - rat 1	0	-0.06624116	-0.2630114	false
training	oneLayer	oneLayer - rat 1	0	-0.05614869	-0.26719183	false
training	oneLayer	oneLayer - rat 1	0	-0.048542608	-0.2747979	false
training	oneLayer	oneLayer - rat 1	0	-0.038735047	-0.2788603	false
training	oneLayer	oneLayer - rat 1	0	-0.031522047	-0.2860733	false
training	oneLayer	oneLayer - rat 1	0	-0.02208236	-0.28998333	false
training	oneLayer	oneLayer - rat 1	0	-0.014981494	-0.29708418	false
training	oneLayer	oneLayer - rat 1	0	-0.00510863	-0.30117366	false
training	oneLayer	oneLayer - rat 1	0	0.0019784893	-0.30826077	false
training	oneLayer	oneLayer - rat 1	0	0.011703875	-0.31228912	false
training	oneLayer	oneLayer - rat 1	0	0.019198082	-0.31978333	false
training	oneLayer	oneLayer - rat 1	0	0.02900849	-0.32384694	false
training	oneLayer	oneLayer - rat 1	0	0.036782935	-0.33162135	false
training	oneLayer	oneLayer - rat 1	0	0.04660998	-0.33569184	false
training	oneLayer	oneLayer - rat 1	0	0.05415475	-0.3432366	false
training	oneLayer	oneLayer - rat 1	0	0.064013824	-0.34732035	false
training	oneLayer	oneLayer - rat 1	0	0.07135749	-0.354664	false
training	oneLayer	oneLayer - rat 1	0	0.08072345	-0.35854352	false
training	oneLayer	oneLayer - rat 1	0	0.0884941	-0.36631414	false
training	oneLayer	oneLayer - rat 1	0	0.09812435	-0.37030312	false
training	oneLayer	oneLayer - rat 1	0	0.10538777	-0.37756652	false
training	oneLayer	oneLayer - rat 1	0	0.11492394	-0.38151652	false
training	oneLayer	oneLayer - rat 1	0	0.121996306	-0.38858888	false
training	oneLayer	oneLayer - rat 1	0	0.13154055	-0.3925422	false
training	oneLayer	oneLayer - rat 1	0	0.1422741	-0.3925422	false
training	oneLayer	oneLayer - rat 1	0	0.15151854	-0.3963714	false
training	oneLayer	oneLayer - rat 1	0	0.1616774	-0.39637136	false
training	oneLayer	oneLayer - rat 1	0	0.17144789	-0.3923243	false
training	oneLayer	oneLayer - rat 1	0	0.17901562	-0.38475654	false
training	oneLayer	oneLayer - rat 1	0	0.18290485	-0.3753671	false
training	oneLayer	oneLayer - rat 1	0	0.18696102	-0.3655746	false
training	oneLayer	oneLayer - rat 1	0	0.19096215	-0.355915	false
training	oneLayer	oneLayer - rat 1	0	0.19492903	-0.3463381	false
training	oneLayer	oneLayer - rat 1	0	0.19912812	-0.33620057	false
training	oneLayer	oneLayer - rat 1	0	0.20298992	-0.32687733	false
training	oneLayer	oneLayer - rat 1	0	0.20689385	-0.3174524	false
training	oneLayer	oneLayer - rat 1	0	0.21104354	-0.30743414	false
training	oneLayer	oneLayer - rat 1	0	0.21517569	-0.2974582	false
training	oneLayer	oneLayer - rat 1	0	0.21906997	-0.28805655	false
training	oneLayer	oneLayer - rat 1	0	0.22299573	-0.2785789	false
training	oneLayer	oneLayer - rat 1	0	0.22711101	-0.2686437	false
training	oneLayer	oneLayer - rat 1	0	0.231135	-0.25892895	false
training	oneLayer	oneLayer - rat 1	0	0.23518287	-0.24915648	false
training	oneLayer	oneLayer - rat 1	0	0.23937947	-0.23902498	false
training	oneLayer	oneLayer - rat 1	0	0.2435161	-0.22903824	false
training	oneLayer	oneLayer - rat 1	0	0.24748912	-0.21944648	false
training	oneLayer	oneLayer - rat 1	0	0.25158277	-0.20956348	false
training	oneLayer	oneLayer - rat 1	0	0.25560245	-0.19985914	false
training	oneLayer	oneLayer - rat 1	0	0.25954416	-0.19034295	false
training	oneLayer	oneLayer - rat 1	0	0.26671645	-0.18317065	false
training	oneLayer	oneLayer - rat 1	0	0.27606982	-0.17929634	false
training	oneLayer	oneLayer - rat 1	0	0.28326944	-0.17209673	false
training	oneLayer	oneLayer - rat 1	0	0.2931349	-0.16801031	false
training	oneLayer	oneLayer - rat 1	0	0.30026457	-0.16088063	false
training	oneLayer	oneLayer - rat 1	0	0.30970746	-0.15696925	false
training	oneLayer	oneLayer - rat 1	0	0.3168961	-0.14978059	false
training	oneLayer	oneLayer - rat 1	0	0.3269059	-0.14563438	false
training	oneLayer	oneLayer - rat 1	0	0.33410427	-0.138436	false
training	oneLayer	oneLayer - rat 1	0	0.34423122	-0.13424128	false
training	oneLayer	oneLayer - rat 1	0	0.35152504	-0.12694743	false
training	oneLayer	oneLayer - rat 1	0	0.3614104	-0.122852765	false
training	oneLayer	oneLayer - rat 1	0	0.3691072	-0.11515597	false
training	oneLayer	oneLayer - rat 1	0	0.3785943	-0.11122627	false
training	oneLayer	oneLayer - rat 1	0	0.3863344	-0.10348619	false
training	oneLayer	oneLayer - rat 1	0	0.39564696	-0.09962878	false
training	oneLayer	oneLayer - rat 1	0	0.40307185	-0.0922039	false
training	oneLayer	oneLayer - rat 1	0	0.41295007	-0.08811219	false
training	oneLayer	oneLayer - rat 1	0	0.4207107	-0.08035154	false
training	oneLayer	oneLayer - rat 1	0	0.42462572	-0.07089984	false
training	oneLayer	oneLayer - rat 1	0	0.42876872	-0.060897734	false
training	oneLayer	oneLayer - rat 1	0	0.43275547	-0.051272847	false
training	oneLayer	oneLayer - rat 1	0	0.43668818	-0.041778415	false
training	oneLayer	oneLayer - rat 1	0	0.4408503	-0.03173021	false
training	oneLayer	oneLayer - rat 1	0	0.44085026	-0.021406034	false
training	oneLayer	oneLayer - rat 1	0	0.44504774	-0.011272394	false
training	oneLayer	oneLayer - rat 1	0	0.44504774	-4.3542488E-4	false
training	oneLayer	oneLayer - rat 1	0	0.44910312	0.009355122	false
training	oneLayer	oneLayer - rat 1	0	0.4491031	0.019479143	false
training	oneLayer	oneLayer - rat 1	0	0.44514143	0.02904339	false
training	oneLayer	oneLayer - rat 1	0	0.44514143	0.039747678	false
training	oneLayer	oneLayer - rat 1	0	0.44107568	0.049563214	false
training	oneLayer	oneLayer - rat 1	0	0.44107568	0.060157236	false
training	oneLayer	oneLayer - rat 1	0	0.4371319	0.069678344	false
training	oneLayer	oneLayer - rat 1	0	0.43713188	0.080048956	false
training	oneLayer	oneLayer - rat 1	0	0.43300563	0.09001059	false
training	oneLayer	oneLayer - rat 1	0	0.43300563	0.10023521	false
training	oneLayer	oneLayer - rat 1	0	0.42890444	0.110136285	false
training	oneLayer	oneLayer - rat 1	0	0.42890444	0.120360345	false
training	oneLayer	oneLayer - rat 1	0	0.42501736	0.1297446	false
training	oneLayer	oneLayer - rat 1	0	0.42501733	0.13987318	false
training	oneLayer	oneLayer - rat 1	0	0.4211165	0.14929062	false
training	oneLayer	oneLayer - rat 1	0	0.42111647	0.15948309	false
training	oneLayer	oneLayer - rat 1	0	0.4171603	0.16903411	false
training	oneLayer	oneLayer - rat 1	0	0.4171603	0.17952128	false
training	oneLayer	oneLayer - rat 1	0	0.41295245	0.18967995	false
training	oneLayer	oneLayer - rat 1	0	0.4055006	0.19713178	false
training	oneLayer	oneLayer - rat 1	0	0.40145186	0.20690624	false
training	oneLayer	oneLayer - rat 1	0	0.39382517	0.21453294	false
training	oneLayer	oneLayer - rat 1	0	0.38962767	0.22466658	false
training	oneLayer	oneLayer - rat 1	0	0.38212982	0.23216438	false
training	oneLayer	oneLayer - rat 1	0	0.37814307	0.24178925	false
training	oneLayer	oneLayer - rat 1	0	0.37061837	0.24931392	false
training	oneLayer	oneLayer - rat 1	0	0.36676073	0.2586271	false
training	oneLayer	oneLayer - rat 1	0	0.3595108	0.26587698	false
training	oneLayer	oneLayer - rat 1	0	0.35547423	0.2756221	false
training	oneLayer	oneLayer - rat 1	0	0.34780857	0.28328773	false
training	oneLayer	oneLayer - rat 1	0	0.34386906	0.29279858	false
training	oneLayer	oneLayer - rat 1	0	0.33612424	0.3005434	false
training	oneLayer	oneLayer - rat 1	0	0.33194223	0.3106396	false
training	oneLayer	oneLayer - rat 1	0	0.32462698	0.31795484	false
training	oneLayer	oneLayer - rat 1	0	0.3145637	0.32212317	false
training	oneLayer	oneLayer - rat 1	0	0.3039646	0.32212317	false
training	oneLayer	oneLayer - rat 1	0	0.29415587	0.31806025	false
training	oneLayer	oneLayer - rat 1	0	0.28333586	0.31806025	false
training	oneLayer	oneLayer - rat 1	0	0.27358368	0.31402075	false
training	oneLayer	oneLayer - rat 1	0	0.26282096	0.31402072	false
training	oneLayer	oneLayer - rat 1	0	0.25285807	0.30989397	false
training	oneLayer	oneLayer - rat 1	0	0.24258049	0.30989397	false
training	oneLayer	oneLayer - rat 1	0	0.23313414	0.30598113	false
training	oneLayer	oneLayer - rat 1	0	0.22302634	0.30598113	false
training	oneLayer	oneLayer - rat 1	0	0.213497	0.30203393	false
training	oneLayer	oneLayer - rat 1	0	0.20328218	0.30203393	false
training	oneLayer	oneLayer - rat 1	0	0.19326957	0.29788655	false
training	oneLayer	oneLayer - rat 1	0	0.18309166	0.29788655	false
training	oneLayer	oneLayer - rat 1	0	0.1731598	0.2937726	false
training	oneLayer	oneLayer - rat 1	0	0.16235453	0.2937726	false
training	oneLayer	oneLayer - rat 1	0	0.15304889	0.28991807	false
training	oneLayer	oneLayer - rat 1	0	0.1427878	0.28991807	false
training	oneLayer	oneLayer - rat 1	0	0.1333908	0.2860257	false
training	oneLayer	oneLayer - rat 1	0	0.12313962	0.28602567	false
training	oneLayer	oneLayer - rat 1	0	0.1131478	0.28188694	false
training	oneLayer	oneLayer - rat 1	0	0.10313902	0.2818869	false
training	oneLayer	oneLayer - rat 1	0	0.09388812	0.27805507	false
training	oneLayer	oneLayer - rat 1	0	0.083759785	0.27805504	false
training	oneLayer	oneLayer - rat 1	0	0.0736572	0.2738704	false
training	oneLayer	oneLayer - rat 1	0	0.06313499	0.2738704	false
training	oneLayer	oneLayer - rat 1	0	0.053222775	0.2697646	false
training	oneLayer	oneLayer - rat 1	0	0.04316447	0.2697646	false
training	oneLayer	oneLayer - rat 1	0	0.03340979	0.26572406	false
training	oneLayer	oneLayer - rat 1	0	0.02275018	0.26572406	false
training	oneLayer	oneLayer - rat 1	0	0.012787076	0.2615972	false
training	oneLayer	oneLayer - rat 1	0	0.0027199292	0.2615972	false
training	oneLayer	oneLayer - rat 1	0	-0.007252078	0.25746664	false
training	oneLayer	oneLayer - rat 1	0	-0.017882409	0.2574666	false
training	oneLayer	oneLayer - rat 1	0	-0.027688546	0.25340477	false
training	oneLayer	oneLayer - rat 1	0	-0.038145225	0.25340477	false
training	oneLayer	oneLayer - rat 1	0	-0.048115205	0.24927506	false
training	oneLayer	oneLayer - rat 1	0	-0.058972325	0.24927504	false
training	oneLayer	oneLayer - rat 1	0	-0.06906567	0.24509424	false
training	oneLayer	oneLayer - rat 1	0	-0.079522416	0.24509422	false
training	oneLayer	oneLayer - rat 1	0	-0.08945777	0.24097885	false
training	oneLayer	oneLayer - rat 1	0	-0.10008932	0.24097885	false
training	oneLayer	oneLayer - rat 1	0	-0.11009107	0.23683597	false
training	oneLayer	oneLayer - rat 1	0	-0.120668046	0.23683597	false
training	oneLayer	oneLayer - rat 1	0	-0.13003093	0.24071419	false
training	oneLayer	oneLayer - rat 1	0	-0.14026052	0.24071418	false
training	oneLayer	oneLayer - rat 1	0	-0.15025611	0.24485448	false
training	oneLayer	oneLayer - rat 1	0	-0.16110346	0.24485447	false
training	oneLayer	oneLayer - rat 1	0	-0.17117245	0.24902518	false
training	oneLayer	oneLayer - rat 1	0	-0.18148382	0.24902517	false
training	oneLayer	oneLayer - rat 1	0	-0.19154872	0.24485613	false
training	oneLayer	oneLayer - rat 1	0	-0.20200334	0.24485612	false
training	oneLayer	oneLayer - rat 1	0	-0.21205455	0.24069276	false
training	oneLayer	oneLayer - rat 1	0	-0.22287804	0.24069275	false
training	oneLayer	oneLayer - rat 1	0	-0.2326671	0.23663798	false
training	oneLayer	oneLayer - rat 1	0	-0.24282399	0.23663796	false
training	oneLayer	oneLayer - rat 1	0	-0.2524514	0.23265016	false
training	oneLayer	oneLayer - rat 1	0	-0.26297557	0.23265015	false
training	oneLayer	oneLayer - rat 1	0	-0.2726686	0.22863515	false
training	oneLayer	oneLayer - rat 1	0	-0.28305647	0.22863515	false
training	oneLayer	oneLayer - rat 1	0	-0.29262215	0.2246729	false
training	oneLayer	oneLayer - rat 1	0	-0.30360815	0.22467288	false
training	oneLayer	oneLayer - rat 1	0	-0.31351915	0.2205676	false
training	oneLayer	oneLayer - rat 1	0	-0.3240523	0.2205676	false
training	oneLayer	oneLayer - rat 1	0	-0.33374962	0.21655083	false
training	oneLayer	oneLayer - rat 1	0	-0.34390345	0.21655081	false
training	oneLayer	oneLayer - rat 1	0	-0.35334367	0.21264054	false
training	oneLayer	oneLayer - rat 1	0	-0.36268023	0.20877318	false
training	oneLayer	oneLayer - rat 1	0	-0.37207437	0.204882	false
training	oneLayer	oneLayer - rat 1	0	-0.38173383	0.20088091	false
training	oneLayer	oneLayer - rat 1	0	-0.38927785	0.19333689	false
training	oneLayer	oneLayer - rat 1	0	-0.39647388	0.1861408	false
training	oneLayer	oneLayer - rat 1	0	-0.4040685	0.17854619	false
training	oneLayer	oneLayer - rat 1	0	-0.41152126	0.17109342	false
training	oneLayer	oneLayer - rat 1	0	-0.41881147	0.16380318	false
training	oneLayer	oneLayer - rat 1	0	-0.42635694	0.15625769	false
training	oneLayer	oneLayer - rat 1	0	-0.43032026	0.1466894	false
training	oneLayer	oneLayer - rat 1	0	-0.43032023	0.13589482	false
training	oneLayer	oneLayer - rat 1	0	-0.42645746	0.12656926	false
training	oneLayer	oneLayer - rat 1	0	-0.4193187	0.119430505	false
training	oneLayer	oneLayer - rat 1	0	-0.40946737	0.11534996	false
training	oneLayer	oneLayer - rat 1	0	-0.39852554	0.11534997	false
training	oneLayer	oneLayer - rat 1	0	-0.38848516	0.11950885	false
training	oneLayer	oneLayer - rat 1	0	-0.38118818	0.12680586	false
training	oneLayer	oneLayer - rat 1	0	-0.37717152	0.13650295	false
training	oneLayer	oneLayer - rat 1	0	-0.37717152	0.14669865	false
training	oneLayer	oneLayer - rat 1	0	-0.37311664	0.15648803	false
training	oneLayer	oneLayer - rat 1	0	-0.37311667	0.16712072	false
training	oneLayer	oneLayer - rat 1	0	-0.36901736	0.17701735	false
training	oneLayer	oneLayer - rat 1	0	-0.36901736	0.1876794	false
training	oneLayer	oneLayer - rat 1	0	-0.37315735	0.19767416	false
training	oneLayer	oneLayer - rat 1	0	-0.37315735	0.20858675	false
training	oneLayer	oneLayer - rat 1	0	-0.3692479	0.21802503	false
training	oneLayer	oneLayer - rat 1	0	-0.3692479	0.22882041	false
training	oneLayer	oneLayer - rat 1	0	-0.36534697	0.23823816	false
training	oneLayer	oneLayer - rat 1	0	-0.36534697	0.24875173	false
training	oneLayer	oneLayer - rat 1	0	-0.36124375	0.2586578	false
training	oneLayer	oneLayer - rat 1	0	-0.35736376	0.26802495	false
training	oneLayer	oneLayer - rat 1	0	-0.35317624	0.27813458	false
training	oneLayer	oneLayer - rat 1	0	-0.34914532	0.2878661	false
training	oneLayer	oneLayer - rat 1	0	-0.34206864	0.2949428	false
training	oneLayer	oneLayer - rat 1	0	-0.3380545	0.30463374	false
training	oneLayer	oneLayer - rat 1	0	-0.3307236	0.31196466	false
training	oneLayer	oneLayer - rat 1	0	-0.32684007	0.32134044	false
training	oneLayer	oneLayer - rat 1	0	-0.3195306	0.3286499	false
training	oneLayer	oneLayer - rat 1	0	-0.3099607	0.33261392	false
training	oneLayer	oneLayer - rat 1	0	-0.29945087	0.33261392	false
training	oneLayer	oneLayer - rat 1	0	-0.2898371	0.3286318	false
training	oneLayer	oneLayer - rat 1	0	-0.28270268	0.32149738	false
training	oneLayer	oneLayer - rat 1	0	-0.2787196	0.31188142	false
training	oneLayer	oneLayer - rat 1	0	-0.2787196	0.3009828	false
training	oneLayer	oneLayer - rat 1	0	-0.28268188	0.291417	false
training	oneLayer	oneLayer - rat 1	0	-0.28268185	0.28085828	false
training	oneLayer	oneLayer - rat 1	0	-0.28686064	0.27076977	false
training	oneLayer	oneLayer - rat 1	0	-0.28686064	0.2598828	false
training	oneLayer	oneLayer - rat 1	0	-0.2907823	0.2504151	false
training	oneLayer	oneLayer - rat 1	0	-0.29078227	0.23946671	false
training	oneLayer	oneLayer - rat 1	0	-0.2947107	0.22998264	false
training	oneLayer	oneLayer - rat 1	0	-0.2947107	0.21924967	false
training	oneLayer	oneLayer - rat 1	0	-0.29865375	0.20973025	false
training	oneLayer	oneLayer - rat 1	0	-0.29865372	0.19903949	false
training	oneLayer	oneLayer - rat 1	0	-0.30252084	0.18970345	false
training	oneLayer	oneLayer - rat 1	0	-0.3025208	0.17901224	false
training	oneLayer	oneLayer - rat 1	0	-0.30641085	0.16962084	false
training	oneLayer	oneLayer - rat 1	0	-0.30641085	0.15959616	false
training	oneLayer	oneLayer - rat 1	0	-0.31034908	0.15008838	false
training	oneLayer	oneLayer - rat 1	0	-0.31034908	0.14007165	false
training	oneLayer	oneLayer - rat 1	0	-0.3144976	0.13005623	false
training	oneLayer	oneLayer - rat 1	0	-0.32188568	0.12266815	false
training	oneLayer	oneLayer - rat 1	0	-0.33174822	0.11858293	false
training	oneLayer	oneLayer - rat 1	0	-0.33926472	0.11106641	false
training	oneLayer	oneLayer - rat 1	0	-0.3432431	0.10146174	false
training	oneLayer	oneLayer - rat 1	0	-0.35035366	0.09435117	false
training	oneLayer	oneLayer - rat 1	0	-0.35455698	0.084203385	false
training	oneLayer	oneLayer - rat 1	0	-0.36196956	0.07679082	false
training	oneLayer	oneLayer - rat 1	0	-0.3661748	0.06663845	false
training	oneLayer	oneLayer - rat 1	0	-0.37345436	0.059358858	false
training	oneLayer	oneLayer - rat 1	0	-0.37749982	0.04959225	false
training	oneLayer	oneLayer - rat 1	0	-0.38479993	0.04229212	false
training	oneLayer	oneLayer - rat 1	0	-0.388988	0.03218123	false
training	oneLayer	oneLayer - rat 1	0	-0.39627197	0.024897212	false
training	oneLayer	oneLayer - rat 1	0	-0.4001553	0.015522035	false
training	oneLayer	oneLayer - rat 1	0	-0.4076535	0.008023798	false
training	oneLayer	oneLayer - rat 1	0	-0.4118467	-0.0020994835	false
training	oneLayer	oneLayer - rat 1	0	-0.4118467	-0.012452086	false
training	oneLayer	oneLayer - rat 1	0	-0.40798014	-0.021786764	false
training	oneLayer	oneLayer - rat 1	0	-0.40073192	-0.029034968	false
training	oneLayer	oneLayer - rat 1	0	-0.39075252	-0.03316855	false
training	oneLayer	oneLayer - rat 1	0	-0.37992337	-0.03316854	false
training	oneLayer	oneLayer - rat 1	0	-0.37063283	-0.0370168	false
training	oneLayer	oneLayer - rat 1	0	-0.35980994	-0.03701679	false
training	oneLayer	oneLayer - rat 1	0	-0.35024363	-0.040979274	false
training	oneLayer	oneLayer - rat 1	0	-0.33927295	-0.040979262	false
training	oneLayer	oneLayer - rat 1	0	-0.3298906	-0.044865545	false
training	oneLayer	oneLayer - rat 1	0	-0.31889734	-0.04486553	false
training	oneLayer	oneLayer - rat 1	0	-0.30889544	-0.04900845	false
training	oneLayer	oneLayer - rat 1	0	-0.29806414	-0.04900844	false
training	oneLayer	oneLayer - rat 1	0	-0.28856885	-0.05294151	false
training	oneLayer	oneLayer - rat 1	0	-0.27808627	-0.052941497	false
training	oneLayer	oneLayer - rat 1	0	-0.26794273	-0.057143077	false
training	oneLayer	oneLayer - rat 1	0	-0.25769526	-0.05714307	false
training	oneLayer	oneLayer - rat 1	0	-0.24831164	-0.061029878	false
training	oneLayer	oneLayer - rat 1	0	-0.23768441	-0.061029866	false
training	oneLayer	oneLayer - rat 1	0	-0.22790553	-0.0650804	false
training	oneLayer	oneLayer - rat 1	0	-0.2178524	-0.06508039	false
training	oneLayer	oneLayer - rat 1	0	-0.20833564	-0.06902235	false
training	oneLayer	oneLayer - rat 1	0	-0.19796985	-0.06902234	false
training	oneLayer	oneLayer - rat 1	0	-0.18840733	-0.07298325	false
training	oneLayer	oneLayer - rat 1	0	-0.17786859	-0.07298324	false
training	oneLayer	oneLayer - rat 1	0	-0.16795912	-0.07708786	false
training	oneLayer	oneLayer - rat 1	0	-0.15705869	-0.07708785	false
training	oneLayer	oneLayer - rat 1	0	-0.1477687	-0.08093587	false
training	oneLayer	oneLayer - rat 1	0	-0.13725944	-0.080935866	false
training	oneLayer	oneLayer - rat 1	0	-0.12777396	-0.08486487	false
training	oneLayer	oneLayer - rat 1	0	-0.11762692	-0.084864855	false
training	oneLayer	oneLayer - rat 1	0	-0.10790866	-0.088890284	false
training	oneLayer	oneLayer - rat 1	0	-0.097772814	-0.08889027	false
training	oneLayer	oneLayer - rat 1	0	-0.08800572	-0.09293592	false
training	oneLayer	oneLayer - rat 1	0	-0.07752097	-0.09293591	false
training	oneLayer	oneLayer - rat 1	0	-0.06737397	-0.09713892	false
training	oneLayer	oneLayer - rat 1	0	-0.05709959	-0.09713891	false
training	oneLayer	oneLayer - rat 1	0	-0.04782131	-0.10098209	false
training	oneLayer	oneLayer - rat 1	0	-0.03733345	-0.10098208	false
training	oneLayer	oneLayer - rat 1	0	-0.027458075	-0.10507258	false
training	oneLayer	oneLayer - rat 1	0	-0.016960626	-0.10507257	false
training	oneLayer	oneLayer - rat 1	0	-0.0070962296	-0.10915852	false
training	oneLayer	oneLayer - rat 1	0	0.0038772204	-0.109158516	false
training	oneLayer	oneLayer - rat 1	0	0.013690604	-0.11322334	false
training	oneLayer	oneLayer - rat 1	0	0.024666179	-0.11322333	false
training	oneLayer	oneLayer - rat 1	0	0.034827705	-0.117432356	false
training	oneLayer	oneLayer - rat 1	0	0.045626312	-0.11743235	false
training	oneLayer	oneLayer - rat 1	0	0.055309035	-0.12144305	false
training	oneLayer	oneLayer - rat 1	0	0.06620553	-0.12144303	false
training	oneLayer	oneLayer - rat 1	0	0.07607876	-0.12553264	false
training	oneLayer	oneLayer - rat 1	0	0.086911626	-0.12553264	false
training	oneLayer	oneLayer - rat 1	0	0.09683958	-0.12964492	false
training	oneLayer	oneLayer - rat 1	0	0.10743104	-0.1296449	false
training	oneLayer	oneLayer - rat 1	0	0.117233306	-0.13370512	false
training	oneLayer	oneLayer - rat 1	0	0.12757349	-0.13370511	false
training	oneLayer	oneLayer - rat 1	0	0.13734463	-0.13775244	false
training	oneLayer	oneLayer - rat 1	0	0.1482374	-0.13775243	false
training	oneLayer	oneLayer - rat 1	0	0.15803711	-0.14181158	false
training	oneLayer	oneLayer - rat 1	0	0.16810606	-0.14181158	false
training	oneLayer	oneLayer - rat 1	0	0.17826588	-0.1460199	false
training	oneLayer	oneLayer - rat 1	0	0.18829973	-0.14601989	false
training	oneLayer	oneLayer - rat 1	0	0.19804473	-0.15005639	false
training	oneLayer	oneLayer - rat 1	0	0.2082493	-0.15005638	false
training	oneLayer	oneLayer - rat 1	0	0.21756804	-0.15391631	false
training	oneLayer	oneLayer - rat 1	0	0.22778402	-0.1539163	false
training	oneLayer	oneLayer - rat 1	0	0.23721588	-0.15782309	false
training	oneLayer	oneLayer - rat 1	0	0.24734633	-0.15782309	false
training	oneLayer	oneLayer - rat 1	0	0.2574048	-0.16198942	false
training	oneLayer	oneLayer - rat 1	0	0.26767832	-0.1619894	false
training	oneLayer	oneLayer - rat 1	0	0.27735215	-0.16599643	false
training	oneLayer	oneLayer - rat 1	0	0.28832558	-0.16599642	false
training	oneLayer	oneLayer - rat 1	0	0.29836816	-0.17015618	false
training	oneLayer	oneLayer - rat 1	0	0.3083858	-0.17015617	false
training	oneLayer	oneLayer - rat 1	0	0.3177107	-0.17401865	false
training	oneLayer	oneLayer - rat 1	0	0.3278488	-0.17401864	false
training	oneLayer	oneLayer - rat 1	0	0.3376918	-0.17809574	false
training	oneLayer	oneLayer - rat 1	0	0.34806225	-0.17809574	false
training	oneLayer	oneLayer - rat 1	0	0.3573177	-0.18192945	false
training	oneLayer	oneLayer - rat 1	0	0.36799952	-0.18192944	false
training	oneLayer	oneLayer - rat 1	0	0.3781621	-0.17771997	false
training	oneLayer	oneLayer - rat 1	0	0.385882	-0.17000006	false
training	oneLayer	oneLayer - rat 1	0	0.38987502	-0.16035998	false
training	oneLayer	oneLayer - rat 1	0	0.39394456	-0.15053521	false
training	oneLayer	oneLayer - rat 1	0	0.39780903	-0.14120553	false
training	oneLayer	oneLayer - rat 1	0	0.4019584	-0.13118799	false
training	oneLayer	oneLayer - rat 1	0	0.40583393	-0.12183164	false
training	oneLayer	oneLayer - rat 1	0	0.40998635	-0.11180681	false
training	oneLayer	oneLayer - rat 1	0	0.41407117	-0.10194514	false
training	oneLayer	oneLayer - rat 1	0	0.4182382	-0.09188504	false
training	oneLayer	oneLayer - rat 1	0	0.42228502	-0.082115054	false
training	oneLayer	oneLayer - rat 1	0	0.42626458	-0.07250755	false
training	oneLayer	oneLayer - rat 1	0	0.43031374	-0.06273199	false
training	oneLayer	oneLayer - rat 1	0	0.4342745	-0.053169847	false
training	oneLayer	oneLayer - rat 1	0	0.43845978	-0.043065615	false
training	oneLayer	oneLayer - rat 1	0	0.43845978	-0.032971535	false
training	oneLayer	oneLayer - rat 1	0	0.43440604	-0.023185015	false
training	oneLayer	oneLayer - rat 1	0	0.42694545	-0.015724424	false
training	oneLayer	oneLayer - rat 1	0	0.4193486	-0.008127597	false
training	oneLayer	oneLayer - rat 1	0	0.40963173	-0.004102743	false
training	oneLayer	oneLayer - rat 1	0	0.39872772	-0.004102756	false
training	oneLayer	oneLayer - rat 1	0	0.38926327	-0.008023068	false
training	oneLayer	oneLayer - rat 1	0	0.3784905	-0.00802308	false
training	oneLayer	oneLayer - rat 1	0	0.36923575	-0.011856525	false
training	oneLayer	oneLayer - rat 1	0	0.35849145	-0.011856537	false
training	oneLayer	oneLayer - rat 1	0	0.34910995	-0.007970611	false
training	oneLayer	oneLayer - rat 1	0	0.3382031	-0.007970623	false
training	oneLayer	oneLayer - rat 1	0	0.3281572	-0.0038094893	false
training	oneLayer	oneLayer - rat 1	0	0.31746715	-0.0038095014	false
training	oneLayer	oneLayer - rat 1	0	0.30760708	-0.007893687	false
training	oneLayer	oneLayer - rat 1	0	0.29670018	-0.007893699	false
training	oneLayer	oneLayer - rat 1	0	0.2869493	-0.011932654	false
training	oneLayer	oneLayer - rat 1	0	0.27647004	-0.0119326655	false
training	oneLayer	oneLayer - rat 1	0	0.26667407	-0.0159903	false
training	oneLayer	oneLayer - rat 1	0	0.25596523	-0.015990311	false
training	oneLayer	oneLayer - rat 1	0	0.24610098	-0.020076226	false
training	oneLayer	oneLayer - rat 1	0	0.23546663	-0.02007624	false
training	oneLayer	oneLayer - rat 1	0	0.22585212	-0.024058716	false
training	oneLayer	oneLayer - rat 1	0	0.21503745	-0.02405873	false
training	oneLayer	oneLayer - rat 1	0	0.20536771	-0.028064078	false
training	oneLayer	oneLayer - rat 1	0	0.19445536	-0.028064089	false
training	oneLayer	oneLayer - rat 1	0	0.18469362	-0.032107547	false
training	oneLayer	oneLayer - rat 1	0	0.17429975	-0.032107558	false
training	oneLayer	oneLayer - rat 1	0	0.16421314	-0.036285583	false
training	oneLayer	oneLayer - rat 1	0	0.15388909	-0.036285594	false
training	oneLayer	oneLayer - rat 1	0	0.1438269	-0.040453505	false
training	oneLayer	oneLayer - rat 1	0	0.13378489	-0.040453516	false
training	oneLayer	oneLayer - rat 1	0	0.124473155	-0.044310573	false
training	oneLayer	oneLayer - rat 1	0	0.11356704	-0.044310585	false
training	oneLayer	oneLayer - rat 1	0	0.10399621	-0.048274964	false
training	oneLayer	oneLayer - rat 1	0	0.0936605	-0.048274975	false
training	oneLayer	oneLayer - rat 1	0	0.0839807	-0.052284498	false
training	oneLayer	oneLayer - rat 1	0	0.073942564	-0.05228451	false
training	oneLayer	oneLayer - rat 1	0	0.06445165	-0.056215785	false
training	oneLayer	oneLayer - rat 1	0	0.054154936	-0.0562158	false
training	oneLayer	oneLayer - rat 1	0	0.044229947	-0.060326878	false
training	oneLayer	oneLayer - rat 1	0	0.033955194	-0.06032689	false
training	oneLayer	oneLayer - rat 1	0	0.024597067	-0.064203165	false
training	oneLayer	oneLayer - rat 1	0	0.0142878685	-0.06420318	false
training	oneLayer	oneLayer - rat 1	0	0.0046125385	-0.06821084	false
training	oneLayer	oneLayer - rat 1	0	-0.00593717	-0.068210855	false
training	oneLayer	oneLayer - rat 1	0	-0.01566385	-0.072239794	false
training	oneLayer	oneLayer - rat 1	0	-0.026006402	-0.0722398	false
training	oneLayer	oneLayer - rat 1	0	-0.03610829	-0.07642415	false
training	oneLayer	oneLayer - rat 1	0	-0.04659626	-0.07642417	false
training	oneLayer	oneLayer - rat 1	0	-0.05638495	-0.08047879	false
training	oneLayer	oneLayer - rat 1	0	-0.06706368	-0.0804788	false
training	oneLayer	oneLayer - rat 1	0	-0.07704731	-0.08461417	false
training	oneLayer	oneLayer - rat 1	0	-0.087837845	-0.08461418	false
training	oneLayer	oneLayer - rat 1	0	-0.09761625	-0.08866454	false
training	oneLayer	oneLayer - rat 1	0	-0.10830672	-0.088664554	false
training	oneLayer	oneLayer - rat 1	0	-0.11837084	-0.092833266	false
training	oneLayer	oneLayer - rat 1	0	-0.12922043	-0.09283327	false
training	oneLayer	oneLayer - rat 1	0	-0.13908225	-0.09691819	false
training	oneLayer	oneLayer - rat 1	0	-0.149653	-0.096918195	false
training	oneLayer	oneLayer - rat 1	0	-0.15899229	-0.10078667	false
training	oneLayer	oneLayer - rat 1	0	-0.16919582	-0.10078668	false
training	oneLayer	oneLayer - rat 1	0	-0.17859797	-0.104681194	false
training	oneLayer	oneLayer - rat 1	0	-0.18928108	-0.10468121	false
training	oneLayer	oneLayer - rat 1	0	-0.19922821	-0.108801454	false
training	oneLayer	oneLayer - rat 1	0	-0.20980799	-0.10880147	false
training	oneLayer	oneLayer - rat 1	0	-0.21913138	-0.10493961	false
training	oneLayer	oneLayer - rat 1	0	-0.22636518	-0.09770582	false
training	oneLayer	oneLayer - rat 1	0	-0.23355424	-0.09051677	false
training	oneLayer	oneLayer - rat 1	0	-0.2409145	-0.08315653	false
training	oneLayer	oneLayer - rat 1	0	-0.25095746	-0.07899662	false
training	oneLayer	oneLayer - rat 1	0	-0.25855207	-0.07140202	false
training	oneLayer	oneLayer - rat 1	0	-0.26826224	-0.067379944	false
training	oneLayer	oneLayer - rat 1	0	-0.27548498	-0.060157232	false
training	oneLayer	oneLayer - rat 1	0	-0.28538546	-0.056056328	false
training	oneLayer	oneLayer - rat 1	0	-0.29282215	-0.048619643	false
training	oneLayer	oneLayer - rat 1	0	-0.30281633	-0.044479936	false
training	oneLayer	oneLayer - rat 1	0	-0.3099876	-0.037308674	false
training	oneLayer	oneLayer - rat 1	0	-0.31956664	-0.033340927	false
training	oneLayer	oneLayer - rat 1	0	-0.32696518	-0.025942396	false
training	oneLayer	oneLayer - rat 1	0	-0.33690152	-0.02182665	false
training	oneLayer	oneLayer - rat 1	0	-0.34414685	-0.01458132	false
training	oneLayer	oneLayer - rat 1	0	-0.35368383	-0.010630987	false
training	oneLayer	oneLayer - rat 1	0	-0.36128244	-0.0030323935	false
training	oneLayer	oneLayer - rat 1	0	-0.3712474	0.0010952165	false
training	oneLayer	oneLayer - rat 1	0	-0.38125354	0.0010952051	false
training	oneLayer	oneLayer - rat 1	0	-0.39109865	-0.0029827862	false
training	oneLayer	oneLayer - rat 1	0	-0.40154868	-0.002982798	false
training	oneLayer	oneLayer - rat 1	0	-0.41144398	0.0011159661	false
training	oneLayer	oneLayer - rat 1	0	-0.4186487	0.008320643	false
training	oneLayer	oneLayer - rat 1	0	-0.42277327	0.018278275	false
training	oneLayer	oneLayer - rat 1	0	-0.4227733	0.02901596	false
training	oneLayer	oneLayer - rat 1	0	-0.4186334	0.039010562	false
training	oneLayer	oneLayer - rat 1	0	-0.41458508	0.0487841	false
training	oneLayer	oneLayer - rat 1	0	-0.40718806	0.056181163	false
training	oneLayer	oneLayer - rat 1	0	-0.40316528	0.065893	false
training	oneLayer	oneLayer - rat 1	0	-0.39554518	0.073513106	false
training	oneLayer	oneLayer - rat 1	0	-0.39160675	0.083021365	false
training	oneLayer	oneLayer - rat 1	0	-0.3841674	0.09046074	false
training	oneLayer	oneLayer - rat 1	0	-0.38025016	0.09991784	false
training	oneLayer	oneLayer - rat 1	0	-0.37316033	0.10700766	false
training	oneLayer	oneLayer - rat 1	0	-0.36924604	0.11645766	false
training	oneLayer	oneLayer - rat 1	0	-0.3621644	0.12353932	false
training	oneLayer	oneLayer - rat 1	0	-0.35823372	0.13302888	false
training	oneLayer	oneLayer - rat 1	0	-0.3507134	0.1405492	false
training	oneLayer	oneLayer - rat 1	0	-0.3465616	0.15057257	false
training	oneLayer	oneLayer - rat 1	0	-0.33928922	0.15784496	false
training	oneLayer	oneLayer - rat 1	0	-0.3352129	0.1676861	false
training	oneLayer	oneLayer - rat 1	0	-0.3275909	0.17530812	false
training	oneLayer	oneLayer - rat 1	0	-0.32366875	0.18477707	false
training	oneLayer	oneLayer - rat 1	0	-0.3165707	0.19187512	false
training	oneLayer	oneLayer - rat 1	0	-0.31244218	0.20184228	false
training	oneLayer	oneLayer - rat 1	0	-0.30468494	0.20959955	false
training	oneLayer	oneLayer - rat 1	0	-0.30077142	0.21904767	false
training	oneLayer	oneLayer - rat 1	0	-0.2934805	0.22633861	false
training	oneLayer	oneLayer - rat 1	0	-0.2895344	0.23586532	false
training	oneLayer	oneLayer - rat 1	0	-0.28235623	0.2430435	false
training	oneLayer	oneLayer - rat 1	0	-0.27821657	0.25303757	false
training	oneLayer	oneLayer - rat 1	0	-0.2705794	0.26067477	false
training	oneLayer	oneLayer - rat 1	0	-0.26673973	0.2699446	false
training	oneLayer	oneLayer - rat 1	0	-0.25930613	0.2773782	false
training	oneLayer	oneLayer - rat 1	0	-0.2551669	0.28737122	false
training	oneLayer	oneLayer - rat 1	0	-0.24759619	0.29494193	false
training	oneLayer	oneLayer - rat 1	0	-0.24348858	0.30485865	false
training	oneLayer	oneLayer - rat 1	0	-0.2363209	0.31202635	false
training	oneLayer	oneLayer - rat 1	0	-0.232476	0.32130876	false
training	oneLayer	oneLayer - rat 1	0	-0.22531585	0.32846895	false
training	oneLayer	oneLayer - rat 1	0	-0.2213651	0.33800694	false
training	oneLayer	oneLayer - rat 1	0	-0.2140024	0.34536964	false
training	oneLayer	oneLayer - rat 1	0	-0.2101151	0.35475445	false
training	oneLayer	oneLayer - rat 1	0	-0.20287283	0.36199674	false
training	oneLayer	oneLayer - rat 1	0	-0.19351377	0.3658734	false
training	oneLayer	oneLayer - rat 1	0	-0.18319799	0.3658734	false
training	oneLayer	oneLayer - rat 1	0	-0.17356902	0.36188498	false
training	oneLayer	oneLayer - rat 1	0	-0.1662598	0.35457575	false
training	oneLayer	oneLayer - rat 1	0	-0.16233787	0.34510744	false
training	oneLayer	oneLayer - rat 1	0	-0.15522249	0.33799207	false
training	oneLayer	oneLayer - rat 1	0	-0.15134932	0.32864144	false
training	oneLayer	oneLayer - rat 1	0	-0.14387998	0.32117212	false
training	oneLayer	oneLayer - rat 1	0	-0.13975808	0.311221	false
training	oneLayer	oneLayer - rat 1	0	-0.13264276	0.3041057	false
training	oneLayer	oneLayer - rat 1	0	-0.12851304	0.2941357	false
training	oneLayer	oneLayer - rat 1	0	-0.12091404	0.28653672	false
training	oneLayer	oneLayer - rat 1	0	-0.11681799	0.276648	false
training	oneLayer	oneLayer - rat 1	0	-0.10930742	0.26913744	false
training	oneLayer	oneLayer - rat 1	0	-0.10518551	0.2591863	false
training	oneLayer	oneLayer - rat 1	0	-0.09749155	0.25149235	false
training	oneLayer	oneLayer - rat 1	0	-0.0936234	0.24215384	false
training	oneLayer	oneLayer - rat 1	0	-0.08635093	0.23488139	false
training	oneLayer	oneLayer - rat 1	0	-0.08247224	0.22551744	false
training	oneLayer	oneLayer - rat 1	0	-0.07524074	0.21828595	false
training	oneLayer	oneLayer - rat 1	0	-0.071358435	0.20891327	false
training	oneLayer	oneLayer - rat 1	0	-0.06365042	0.20120527	false
training	oneLayer	oneLayer - rat 1	0	-0.054402564	0.19737469	false
training	oneLayer	oneLayer - rat 1	0	-0.046911683	0.18988381	false
training	oneLayer	oneLayer - rat 1	0	-0.037082918	0.18581262	false
training	oneLayer	oneLayer - rat 1	0	-0.029971646	0.17870137	false
training	oneLayer	oneLayer - rat 1	0	-0.020003015	0.17457223	false
training	oneLayer	oneLayer - rat 1	0	-0.012702711	0.16727194	false
training	oneLayer	oneLayer - rat 1	0	-0.0034071524	0.16342162	false
training	oneLayer	oneLayer - rat 1	0	0.0036970796	0.1563174	false
training	oneLayer	oneLayer - rat 1	0	0.013556344	0.15223357	false
training	oneLayer	oneLayer - rat 1	0	0.020856187	0.14493373	false
training	oneLayer	oneLayer - rat 1	0	0.030114226	0.14109895	false
training	oneLayer	oneLayer - rat 1	0	0.037796583	0.13341661	false
training	oneLayer	oneLayer - rat 1	0	0.047497608	0.12939832	false
training	oneLayer	oneLayer - rat 1	0	0.054579947	0.122315995	false
training	oneLayer	oneLayer - rat 1	0	0.06464965	0.118145	false
training	oneLayer	oneLayer - rat 1	0	0.07179607	0.11099859	false
training	oneLayer	oneLayer - rat 1	0	0.0817675	0.106868304	false
training	oneLayer	oneLayer - rat 1	0	0.08908336	0.09955246	false
training	oneLayer	oneLayer - rat 1	0	0.098372065	0.095704965	false
training	oneLayer	oneLayer - rat 1	0	0.10601818	0.08805887	false
training	oneLayer	oneLayer - rat 1	0	0.11596513	0.08393872	false
training	oneLayer	oneLayer - rat 1	0	0.12329798	0.07660587	false
training	oneLayer	oneLayer - rat 1	0	0.13343552	0.07240678	false
training	oneLayer	oneLayer - rat 1	0	0.14120252	0.064639784	false
training	oneLayer	oneLayer - rat 1	0	0.15077776	0.060673606	false
training	oneLayer	oneLayer - rat 1	0	0.15847874	0.052972645	false
training	oneLayer	oneLayer - rat 1	0	0.16862425	0.048770245	false
training	oneLayer	oneLayer - rat 1	0	0.17590962	0.041484896	false
training	oneLayer	oneLayer - rat 1	0	0.18557127	0.037482925	false
training	oneLayer	oneLayer - rat 1	0	0.1931495	0.029904695	false
training	oneLayer	oneLayer - rat 1	0	0.20322411	0.02573167	false
training	oneLayer	oneLayer - rat 1	0	0.21034224	0.018613556	false
training	oneLayer	oneLayer - rat 1	0	0.21988575	0.014660518	false
training	oneLayer	oneLayer - rat 1	0	0.22746608	0.0070802104	false
training	oneLayer	oneLayer - rat 1	0	0.23690741	0.0031694907	false
training	oneLayer	oneLayer - rat 1	0	0.24454975	-0.004472833	false
training	oneLayer	oneLayer - rat 1	0	0.2544973	-0.008593221	false
training	oneLayer	oneLayer - rat 1	0	0.2654492	-0.00859321	false
training	oneLayer	oneLayer - rat 1	0	0.2753225	-0.012682862	false
training	oneLayer	oneLayer - rat 1	0	0.2860448	-0.0126828505	false
training	oneLayer	oneLayer - rat 1	0	0.2957373	-0.016697593	false
training	oneLayer	oneLayer - rat 1	0	0.30602568	-0.016697582	false
training	oneLayer	oneLayer - rat 1	0	0.31581712	-0.020753318	false
training	oneLayer	oneLayer - rat 1	0	0.32627836	-0.020753307	false
training	oneLayer	oneLayer - rat 1	0	0.33626497	-0.02488988	false
training	oneLayer	oneLayer - rat 1	0	0.34704494	-0.02488987	false
training	oneLayer	oneLayer - rat 1	0	0.35632548	-0.028733985	false
training	oneLayer	oneLayer - rat 1	0	0.36713934	-0.028733974	false
training	oneLayer	oneLayer - rat 1	0	0.3764964	-0.03260978	false
training	oneLayer	oneLayer - rat 1	0	0.38724554	-0.03260977	false
training	oneLayer	oneLayer - rat 1	0	0.3972556	-0.036756057	false
training	oneLayer	oneLayer - rat 1	0	0.40744895	-0.036756046	false
training	oneLayer	oneLayer - rat 1	0	0.4168031	-0.032881424	false
training	oneLayer	oneLayer - rat 1	0	0.42436573	-0.025318768	false
training	oneLayer	oneLayer - rat 1	0	0.42834044	-0.01572292	false
training	oneLayer	oneLayer - rat 1	0	0.43244827	-0.0058057234	false
training	oneLayer	oneLayer - rat 1	0	0.43244827	0.004419028	false
training	oneLayer	oneLayer - rat 1	0	0.42856663	0.013790063	false
training	oneLayer	oneLayer - rat 1	0	0.42123935	0.02111734	false
training	oneLayer	oneLayer - rat 1	0	0.41703606	0.03126494	false
training	oneLayer	oneLayer - rat 1	0	0.4093964	0.038904574	false
training	oneLayer	oneLayer - rat 1	0	0.40552148	0.0482594	false
training	oneLayer	oneLayer - rat 1	0	0.40552148	0.059109356	false
training	oneLayer	oneLayer - rat 1	0	0.40168488	0.06837168	false
training	oneLayer	oneLayer - rat 1	0	0.3942526	0.07580397	false
training	oneLayer	oneLayer - rat 1	0	0.3902331	0.08550786	false
training	oneLayer	oneLayer - rat 1	0	0.3826956	0.09304534	false
training	oneLayer	oneLayer - rat 1	0	0.37882996	0.102377824	false
training	oneLayer	oneLayer - rat 1	0	0.37882993	0.1128127	false
training	oneLayer	oneLayer - rat 1	0	0.38294896	0.122756965	false
training	oneLayer	oneLayer - rat 1	0	0.38294896	0.13362208	false
training	oneLayer	oneLayer - rat 1	0	0.38696486	0.14331731	false
training	oneLayer	oneLayer - rat 1	0	0.39098802	0.15303014	false
training	oneLayer	oneLayer - rat 1	0	0.39098802	0.16346955	false
training	oneLayer	oneLayer - rat 1	0	0.38690957	0.17331575	false
training	oneLayer	oneLayer - rat 1	0	0.38690954	0.18398267	false
training	oneLayer	oneLayer - rat 1	0	0.38278487	0.19394054	false
training	oneLayer	oneLayer - rat 1	0	0.37501678	0.2017086	false
training	oneLayer	oneLayer - rat 1	0	0.37091398	0.21161361	false
training	oneLayer	oneLayer - rat 1	0	0.36361027	0.21891731	false
training	oneLayer	oneLayer - rat 1	0	0.3597296	0.22828606	false
training	oneLayer	oneLayer - rat 1	0	0.3597296	0.23907278	false
training	oneLayer	oneLayer - rat 1	0	0.35552213	0.24923043	false
training	oneLayer	oneLayer - rat 1	0	0.35552213	0.26007405	false
training	oneLayer	oneLayer - rat 1	0	0.35151225	0.26975468	false
training	oneLayer	oneLayer - rat 1	0	0.34388977	0.27737716	false
training	oneLayer	oneLayer - rat 1	0	0.33999768	0.28677344	false
training	oneLayer	oneLayer - rat 1	0	0.33261004	0.29416105	false
training	oneLayer	oneLayer - rat 1	0	0.32874107	0.30350158	false
training	oneLayer	oneLayer - rat 1	0	0.3212204	0.31102222	false
training	oneLayer	oneLayer - rat 1	0	0.317164	0.32081524	false
training	oneLayer	oneLayer - rat 1	0	0.30957776	0.32840145	false
training	oneLayer	oneLayer - rat 1	0	0.29947197	0.3325874	false
training	oneLayer	oneLayer - rat 1	0	0.28866926	0.33258736	false
training	oneLayer	oneLayer - rat 1	0	0.27874675	0.32847732	false
training	oneLayer	oneLayer - rat 1	0	0.26937464	0.32459524	false
training	oneLayer	oneLayer - rat 1	0	0.25999066	0.32070827	false
training	oneLayer	oneLayer - rat 1	0	0.2501187	0.31661916	false
training	oneLayer	oneLayer - rat 1	0	0.23942505	0.31661913	false
training	oneLayer	oneLayer - rat 1	0	0.22926676	0.31241143	false
training	oneLayer	oneLayer - rat 1	0	0.21921729	0.31241143	false
training	oneLayer	oneLayer - rat 1	0	0.20966065	0.3084529	false
training	oneLayer	oneLayer - rat 1	0	0.1988666	0.3084529	false
training	oneLayer	oneLayer - rat 1	0	0.18948671	0.3045676	false
training	oneLayer	oneLayer - rat 1	0	0.17901686	0.3045676	false
training	oneLayer	oneLayer - rat 1	0	0.1695542	0.30064803	false
training	oneLayer	oneLayer - rat 1	0	0.15901121	0.30064803	false
training	oneLayer	oneLayer - rat 1	0	0.14961682	0.2967567	false
training	oneLayer	oneLayer - rat 1	0	0.13938905	0.2967567	false
training	oneLayer	oneLayer - rat 1	0	0.1301299	0.29292142	false
training	oneLayer	oneLayer - rat 1	0	0.1196141	0.29292142	false
training	oneLayer	oneLayer - rat 1	0	0.110261306	0.28904736	false
training	oneLayer	oneLayer - rat 1	0	0.09935849	0.28904733	false
training	oneLayer	oneLayer - rat 1	0	0.089463755	0.2849488	false
training	oneLayer	oneLayer - rat 1	0	0.079330616	0.2849488	false
training	oneLayer	oneLayer - rat 1	0	0.06936679	0.28082162	false
training	oneLayer	oneLayer - rat 1	0	0.058761198	0.2808216	false
training	oneLayer	oneLayer - rat 1	0	0.049102955	0.27682102	false
training	oneLayer	oneLayer - rat 1	0	0.0384522	0.27682102	false
training	oneLayer	oneLayer - rat 1	0	0.029008113	0.27290913	false
training	oneLayer	oneLayer - rat 1	0	0.018494852	0.2729091	false
training	oneLayer	oneLayer - rat 1	0	0.009110759	0.26902208	false
training	oneLayer	oneLayer - rat 1	0	-0.0010284812	0.26902208	false
training	oneLayer	oneLayer - rat 1	0	-0.01067836	0.26502493	false
training	oneLayer	oneLayer - rat 1	0	-0.021384096	0.26502493	false
training	oneLayer	oneLayer - rat 1	0	-0.030877003	0.26109284	false
training	oneLayer	oneLayer - rat 1	0	-0.041726496	0.2610928	false
training	oneLayer	oneLayer - rat 1	0	-0.051221885	0.25715968	false
training	oneLayer	oneLayer - rat 1	0	-0.06138062	0.25715968	false
training	oneLayer	oneLayer - rat 1	0	-0.07138652	0.25301507	false
training	oneLayer	oneLayer - rat 1	0	-0.08180984	0.25301507	false
training	oneLayer	oneLayer - rat 1	0	-0.0911916	0.249129	false
training	oneLayer	oneLayer - rat 1	0	-0.10170096	0.249129	false
training	oneLayer	oneLayer - rat 1	0	-0.11101343	0.24527162	false
training	oneLayer	oneLayer - rat 1	0	-0.121309645	0.24527162	false
training	oneLayer	oneLayer - rat 1	0	-0.13070416	0.24138027	false
training	oneLayer	oneLayer - rat 1	0	-0.14142671	0.24138026	false
training	oneLayer	oneLayer - rat 1	0	-0.15140635	0.24551395	false
training	oneLayer	oneLayer - rat 1	0	-0.16221647	0.24551393	false
training	oneLayer	oneLayer - rat 1	0	-0.17178129	0.2494758	false
training	oneLayer	oneLayer - rat 1	0	-0.18236268	0.24947579	false
training	oneLayer	oneLayer - rat 1	0	-0.19196923	0.25345495	false
training	oneLayer	oneLayer - rat 1	0	-0.20289995	0.25345492	false
training	oneLayer	oneLayer - rat 1	0	-0.21297884	0.25762975	false
training	oneLayer	oneLayer - rat 1	0	-0.22364546	0.25762972	false
training	oneLayer	oneLayer - rat 1	0	-0.23360409	0.26175472	false
training	oneLayer	oneLayer - rat 1	0	-0.2438237	0.2617547	false
training	oneLayer	oneLayer - rat 1	0	-0.25319287	0.26563552	false
training	oneLayer	oneLayer - rat 1	0	-0.26345173	0.26563552	false
training	oneLayer	oneLayer - rat 1	0	-0.27281913	0.2695156	false
training	oneLayer	oneLayer - rat 1	0	-0.28317896	0.2695156	false
training	oneLayer	oneLayer - rat 1	0	-0.29267523	0.27344906	false
training	oneLayer	oneLayer - rat 1	0	-0.3027092	0.27344906	false
training	oneLayer	oneLayer - rat 1	0	-0.31212702	0.27735004	false
training	oneLayer	oneLayer - rat 1	0	-0.3192942	0.2845172	false
training	oneLayer	oneLayer - rat 1	0	-0.32313	0.2937776	false
training	oneLayer	oneLayer - rat 1	0	-0.32313	0.30443856	false
training	oneLayer	oneLayer - rat 1	0	-0.31902266	0.31435466	false
training	oneLayer	oneLayer - rat 1	0	-0.31149697	0.32188034	false
training	oneLayer	oneLayer - rat 1	0	-0.30190518	0.3258534	false
training	oneLayer	oneLayer - rat 1	0	-0.29100397	0.3258534	false
training	oneLayer	oneLayer - rat 1	0	-0.2812227	0.32180187	false
training	oneLayer	oneLayer - rat 1	0	-0.2736209	0.3142001	false
training	oneLayer	oneLayer - rat 1	0	-0.26975906	0.3048768	false
training	oneLayer	oneLayer - rat 1	0	-0.26235262	0.29747036	false
training	oneLayer	oneLayer - rat 1	0	-0.25814936	0.28732288	false
training	oneLayer	oneLayer - rat 1	0	-0.2509948	0.28016832	false
training	oneLayer	oneLayer - rat 1	0	-0.24138291	0.27618697	false
training	oneLayer	oneLayer - rat 1	0	-0.23419118	0.26899526	false
training	oneLayer	oneLayer - rat 1	0	-0.22405344	0.26479608	false
training	oneLayer	oneLayer - rat 1	0	-0.21656282	0.25730547	false
training	oneLayer	oneLayer - rat 1	0	-0.2068897	0.25329876	false
training	oneLayer	oneLayer - rat 1	0	-0.19918948	0.24559855	false
training	oneLayer	oneLayer - rat 1	0	-0.18953541	0.24159971	false
training	oneLayer	oneLayer - rat 1	0	-0.18188016	0.23394448	false
training	oneLayer	oneLayer - rat 1	0	-0.1725828	0.23009339	false
training	oneLayer	oneLayer - rat 1	0	-0.16484451	0.22235513	false
training	oneLayer	oneLayer - rat 1	0	-0.15502174	0.21828641	false
training	oneLayer	oneLayer - rat 1	0	-0.14786652	0.2111312	false
training	oneLayer	oneLayer - rat 1	0	-0.13847879	0.20724268	false
training	oneLayer	oneLayer - rat 1	0	-0.13124666	0.20001057	false
training	oneLayer	oneLayer - rat 1	0	-0.121195346	0.1958472	false
training	oneLayer	oneLayer - rat 1	0	-0.11371209	0.18836395	false
training	oneLayer	oneLayer - rat 1	0	-0.10384175	0.18427554	false
training	oneLayer	oneLayer - rat 1	0	-0.09652015	0.17695396	false
training	oneLayer	oneLayer - rat 1	0	-0.08650693	0.17280635	false
training	oneLayer	oneLayer - rat 1	0	-0.07916956	0.16546899	false
training	oneLayer	oneLayer - rat 1	0	-0.069729604	0.16155885	false
training	oneLayer	oneLayer - rat 1	0	-0.062395565	0.15422483	false
training	oneLayer	oneLayer - rat 1	0	-0.05284678	0.1502696	false
training	oneLayer	oneLayer - rat 1	0	-0.04534282	0.14276566	false
training	oneLayer	oneLayer - rat 1	0	-0.036029972	0.13890816	false
training	oneLayer	oneLayer - rat 1	0	-0.028388133	0.13126634	false
training	oneLayer	oneLayer - rat 1	0	-0.018939676	0.12735267	false
training	oneLayer	oneLayer - rat 1	0	-0.011485814	0.119898826	false
training	oneLayer	oneLayer - rat 1	0	-0.0021944942	0.11605024	false
training	oneLayer	oneLayer - rat 1	0	0.005508274	0.10834749	false
training	oneLayer	oneLayer - rat 1	0	0.015108777	0.10437085	false
training	oneLayer	oneLayer - rat 1	0	0.022350956	0.09712868	false
training	oneLayer	oneLayer - rat 1	0	0.032177676	0.09305833	false
training	oneLayer	oneLayer - rat 1	0	0.039523385	0.085712634	false
training	oneLayer	oneLayer - rat 1	0	0.049499303	0.08158049	false
training	oneLayer	oneLayer - rat 1	0	0.05672844	0.07435136	false
training	oneLayer	oneLayer - rat 1	0	0.06687951	0.070146665	false
training	oneLayer	oneLayer - rat 1	0	0.07395932	0.06306687	false
training	oneLayer	oneLayer - rat 1	0	0.083945654	0.05893041	false
training	oneLayer	oneLayer - rat 1	0	0.091024466	0.05185161	false
training	oneLayer	oneLayer - rat 1	0	0.100467056	0.047940373	false
training	oneLayer	oneLayer - rat 1	0	0.107572265	0.040835183	false
training	oneLayer	oneLayer - rat 1	0	0.11734136	0.036788702	false
training	oneLayer	oneLayer - rat 1	0	0.12501244	0.029117636	false
training	oneLayer	oneLayer - rat 1	0	0.134418	0.025221737	false
training	oneLayer	oneLayer - rat 1	0	0.14191397	0.01772579	false
training	oneLayer	oneLayer - rat 1	0	0.15178457	0.013637266	false
training	oneLayer	oneLayer - rat 1	0	0.15921438	0.0062074605	false
training	oneLayer	oneLayer - rat 1	0	0.1685063	0.0023586338	false
training	oneLayer	oneLayer - rat 1	0	0.17617147	-0.0053065117	false
training	oneLayer	oneLayer - rat 1	0	0.1856984	-0.00925269	false
training	oneLayer	oneLayer - rat 1	0	0.19610965	-0.0092526795	false
training	oneLayer	oneLayer - rat 1	0	0.2062187	-0.00506536	false
training	oneLayer	oneLayer - rat 1	0	0.21646312	-0.0050653494	false
training	oneLayer	oneLayer - rat 1	0	0.22656779	-0.00925083	false
training	oneLayer	oneLayer - rat 1	0	0.23717378	-0.009250819	false
training	oneLayer	oneLayer - rat 1	0	0.24701262	-0.013326186	false
training	oneLayer	oneLayer - rat 1	0	0.2578891	-0.013326175	false
training	oneLayer	oneLayer - rat 1	0	0.2674006	-0.017265966	false
training	oneLayer	oneLayer - rat 1	0	0.27799827	-0.017265955	false
training	oneLayer	oneLayer - rat 1	0	0.28739172	-0.02115684	false
training	oneLayer	oneLayer - rat 1	0	0.29751903	-0.021156829	false
training	oneLayer	oneLayer - rat 1	0	0.30696413	-0.025069108	false
training	oneLayer	oneLayer - rat 1	0	0.3176271	-0.025069097	false
training	oneLayer	oneLayer - rat 1	0	0.3274646	-0.02914392	false
training	oneLayer	oneLayer - rat 1	0	0.33747128	-0.029143909	false
training	oneLayer	oneLayer - rat 1	0	0.34676898	-0.03299513	false
training	oneLayer	oneLayer - rat 1	0	0.3577109	-0.03299512	false
training	oneLayer	oneLayer - rat 1	0	0.36729568	-0.03696526	false
training	oneLayer	oneLayer - rat 1	0	0.37806812	-0.036965247	false
training	oneLayer	oneLayer - rat 1	0	0.38741946	-0.033091784	false
training	oneLayer	oneLayer - rat 1	0	0.39797395	-0.033091772	false
training	oneLayer	oneLayer - rat 1	0	0.40797845	-0.03723575	false
training	oneLayer	oneLayer - rat 1	0	0.4150534	-0.044310696	false
training	oneLayer	oneLayer - rat 1	0	0.41919285	-0.054304205	false
training	oneLayer	oneLayer - rat 1	0	0.41919285	-0.06527178	false
training	oneLayer	oneLayer - rat 1	0	0.42304486	-0.07457129	false
training	oneLayer	oneLayer - rat 1	0	0.42304486	-0.08498125	false
training	oneLayer	oneLayer - rat 1	0	0.4269139	-0.09432182	false
training	oneLayer	oneLayer - rat 1	0	0.4269139	-0.10492192	false
training	oneLayer	oneLayer - rat 1	0	0.42274576	-0.114984654	false
training	oneLayer	oneLayer - rat 1	0	0.4227458	-0.1256662	false
training	oneLayer	oneLayer - rat 1	0	0.41884342	-0.13508739	false
training	oneLayer	oneLayer - rat 1	0	0.41884342	-0.14570357	false
training	oneLayer	oneLayer - rat 1	0	0.41478518	-0.15550108	false
training	oneLayer	oneLayer - rat 1	0	0.41478518	-0.16554476	false
training	oneLayer	oneLayer - rat 1	0	0.4105764	-0.17570564	false
training	oneLayer	oneLayer - rat 1	0	0.41057643	-0.18638737	false
training	oneLayer	oneLayer - rat 1	0	0.40649828	-0.19623289	false
training	oneLayer	oneLayer - rat 1	0	0.39904222	-0.20368896	false
training	oneLayer	oneLayer - rat 1	0	0.39510855	-0.21318574	false
training	oneLayer	oneLayer - rat 1	0	0.38774034	-0.22055395	false
training	oneLayer	oneLayer - rat 1	0	0.38384616	-0.22995536	false
training	oneLayer	oneLayer - rat 1	0	0.3763854	-0.23741616	false
training	oneLayer	oneLayer - rat 1	0	0.37255082	-0.24667367	false
training	oneLayer	oneLayer - rat 1	0	0.36547115	-0.25375333	false
training	oneLayer	oneLayer - rat 1	0	0.3615574	-0.26320207	false
training	oneLayer	oneLayer - rat 1	0	0.35423005	-0.27052942	false
training	oneLayer	oneLayer - rat 1	0	0.35004485	-0.28063342	false
training	oneLayer	oneLayer - rat 1	0	0.34242117	-0.2882571	false
training	oneLayer	oneLayer - rat 1	0	0.33844575	-0.2978546	false
training	oneLayer	oneLayer - rat 1	0	0.33119142	-0.30510896	false
training	oneLayer	oneLayer - rat 1	0	0.3272865	-0.31453627	false
training	oneLayer	oneLayer - rat 1	0	0.31988826	-0.32193452	false
training	oneLayer	oneLayer - rat 1	0	0.3105731	-0.325793	false
training	oneLayer	oneLayer - rat 1	0	0.29994258	-0.32579303	false
training	oneLayer	oneLayer - rat 1	0	0.29063094	-0.321936	false
training	oneLayer	oneLayer - rat 1	0	0.28331733	-0.31462243	false
training	oneLayer	oneLayer - rat 1	0	0.2793401	-0.30502054	false
training	oneLayer	oneLayer - rat 1	0	0.2793401	-0.29405442	false
training	oneLayer	oneLayer - rat 1	0	0.2833691	-0.2843275	false
training	oneLayer	oneLayer - rat 1	0	0.28727323	-0.2749021	false
training	oneLayer	oneLayer - rat 1	0	0.29123172	-0.26534536	false
training	oneLayer	oneLayer - rat 1	0	0.29530102	-0.25552118	false
training	oneLayer	oneLayer - rat 1	0	0.2992151	-0.24607173	false
training	oneLayer	oneLayer - rat 1	0	0.30310017	-0.23669232	false
training	oneLayer	oneLayer - rat 1	0	0.3070729	-0.22710131	false
training	oneLayer	oneLayer - rat 1	0	0.31091267	-0.21783125	false
training	oneLayer	oneLayer - rat 1	0	0.3151077	-0.20770355	false
training	oneLayer	oneLayer - rat 1	0	0.31930172	-0.19757827	false
training	oneLayer	oneLayer - rat 1	0	0.3234737	-0.1875062	false
training	oneLayer	oneLayer - rat 1	0	0.32730123	-0.17826565	false
training	oneLayer	oneLayer - rat 1	0	0.33127162	-0.16868027	false
training	oneLayer	oneLayer - rat 1	0	0.33516222	-0.15928748	false
training	oneLayer	oneLayer - rat 1	0	0.3392128	-0.14950852	false
training	oneLayer	oneLayer - rat 1	0	0.34325552	-0.13974854	false
training	oneLayer	oneLayer - rat 1	0	0.3474167	-0.12970251	false
training	oneLayer	oneLayer - rat 1	0	0.3514177	-0.120043226	false
training	oneLayer	oneLayer - rat 1	0	0.35532334	-0.110614136	false
training	oneLayer	oneLayer - rat 1	0	0.3594338	-0.100690566	false
training	oneLayer	oneLayer - rat 1	0	0.36332697	-0.0912916	false
training	oneLayer	oneLayer - rat 1	0	0.36732647	-0.081635915	false
training	oneLayer	oneLayer - rat 1	0	0.37454632	-0.074416064	false
training	oneLayer	oneLayer - rat 1	0	0.38443655	-0.070319384	false
training	oneLayer	oneLayer - rat 1	0	0.39470524	-0.07031938	false
training	oneLayer	oneLayer - rat 1	0	0.40430355	-0.0742951	false
training	oneLayer	oneLayer - rat 1	0	0.41140932	-0.08140087	false
training	oneLayer	oneLayer - rat 1	0	0.41549748	-0.091270566	false
training	oneLayer	oneLayer - rat 1	0	0.41549748	-0.102044486	false
training	oneLayer	oneLayer - rat 1	0	0.41965476	-0.112081006	false
training	oneLayer	oneLayer - rat 1	0	0.4196548	-0.12216288	false
training	oneLayer	oneLayer - rat 1	0	0.41570967	-0.13168724	false
training	oneLayer	oneLayer - rat 1	0	0.40844864	-0.13894828	false
training	oneLayer	oneLayer - rat 1	0	0.40455604	-0.14834589	false
training	oneLayer	oneLayer - rat 1	0	0.39744875	-0.15545316	false
training	oneLayer	oneLayer - rat 1	0	0.39340714	-0.1652105	false
training	oneLayer	oneLayer - rat 1	0	0.38583758	-0.17278007	false
training	oneLayer	oneLayer - rat 1	0	0.38195515	-0.1821531	false
training	oneLayer	oneLayer - rat 1	0	0.37453657	-0.1895717	false
training	oneLayer	oneLayer - rat 1	0	0.3705537	-0.19918725	false
training	oneLayer	oneLayer - rat 1	0	0.36284837	-0.2068926	false
training	oneLayer	oneLayer - rat 1	0	0.35886973	-0.21649791	false
training	oneLayer	oneLayer - rat 1	0	0.35886973	-0.22657429	false
training	oneLayer	oneLayer - rat 1	0	0.3549848	-0.23595335	false
training	oneLayer	oneLayer - rat 1	0	0.3473976	-0.24354056	false
training	oneLayer	oneLayer - rat 1	0	0.34325385	-0.25354445	false
training	oneLayer	oneLayer - rat 1	0	0.34325388	-0.2645241	false
training	oneLayer	oneLayer - rat 1	0	0.33932987	-0.2739975	false
training	oneLayer	oneLayer - rat 1	0	0.3316075	-0.2817199	false
training	oneLayer	oneLayer - rat 1	0	0.32773098	-0.29107866	false
training	oneLayer	oneLayer - rat 1	0	0.32034463	-0.298465	false
training	oneLayer	oneLayer - rat 1	0	0.31650653	-0.307731	false
training	oneLayer	oneLayer - rat 1	0	0.3087418	-0.31549576	false
training	oneLayer	oneLayer - rat 1	0	0.30462787	-0.3254277	false
training	oneLayer	oneLayer - rat 1	0	0.2973045	-0.33275107	false
training	oneLayer	oneLayer - rat 1	0	0.29342216	-0.3421239	false
training	oneLayer	oneLayer - rat 1	0	0.2857013	-0.34984478	false
training	oneLayer	oneLayer - rat 1	0	0.27559942	-0.35402912	false
training	oneLayer	oneLayer - rat 1	0	0.26511946	-0.35402915	false
training	oneLayer	oneLayer - rat 1	0	0.25584704	-0.35018837	false
training	oneLayer	oneLayer - rat 1	0	0.2485613	-0.34290266	false
training	oneLayer	oneLayer - rat 1	0	0.24467458	-0.3335193	false
training	oneLayer	oneLayer - rat 1	0	0.24467456	-0.32301497	false
training	oneLayer	oneLayer - rat 1	0	0.24877003	-0.31312764	false
training	oneLayer	oneLayer - rat 1	0	0.25651044	-0.30538723	false
training	oneLayer	oneLayer - rat 1	0	0.26629817	-0.301333	false
training	oneLayer	oneLayer - rat 1	0	0.27658904	-0.30133298	false
training	oneLayer	oneLayer - rat 1	0	0.2866298	-0.29717398	false
training	oneLayer	oneLayer - rat 1	0	0.29686484	-0.29717395	false
training	oneLayer	oneLayer - rat 1	0	0.3062526	-0.29328543	false
training	oneLayer	oneLayer - rat 1	0	0.3136018	-0.28593624	false
training	oneLayer	oneLayer - rat 1	0	0.32333001	-0.28190666	false
training	oneLayer	oneLayer - rat 1	0	0.3306197	-0.274617	false
training	oneLayer	oneLayer - rat 1	0	0.34066907	-0.27045438	false
training	oneLayer	oneLayer - rat 1	0	0.34801355	-0.2631099	false
training	oneLayer	oneLayer - rat 1	0	0.35806164	-0.25894782	false
training	oneLayer	oneLayer - rat 1	0	0.36546198	-0.2515475	false
training	oneLayer	oneLayer - rat 1	0	0.36954114	-0.24169946	false
training	oneLayer	oneLayer - rat 1	0	0.37731385	-0.23392676	false
training	oneLayer	oneLayer - rat 1	0	0.38130173	-0.22429913	false
training	oneLayer	oneLayer - rat 1	0	0.38895184	-0.21664901	false
training	oneLayer	oneLayer - rat 1	0	0.3929551	-0.20698425	false
training	oneLayer	oneLayer - rat 1	0	0.40069607	-0.19924328	false
training	oneLayer	oneLayer - rat 1	0	0.4046543	-0.18968731	false
training	oneLayer	oneLayer - rat 1	0	0.41216454	-0.18217705	false
training	oneLayer	oneLayer - rat 1	0	0.4163031	-0.17218569	false
training	oneLayer	oneLayer - rat 1	0	0.42390567	-0.1645831	false
training	oneLayer	oneLayer - rat 1	0	0.42793685	-0.1548509	false
training	oneLayer	oneLayer - rat 1	0	0.43187523	-0.14534286	false
training	oneLayer	oneLayer - rat 1	0	0.4358687	-0.13570169	false
training	oneLayer	oneLayer - rat 1	0	0.43976822	-0.12628742	false
training	oneLayer	oneLayer - rat 1	0	0.443669	-0.11687012	false
training	oneLayer	oneLayer - rat 1	0	0.4478614	-0.10674873	false
training	oneLayer	oneLayer - rat 1	0	0.4517599	-0.09733686	false
training	oneLayer	oneLayer - rat 1	0	0.45575643	-0.087688364	false
training	oneLayer	oneLayer - rat 1	0	0.4597803	-0.0779739	false
training	oneLayer	oneLayer - rat 1	0	0.4636897	-0.06853567	false
training	oneLayer	oneLayer - rat 1	0	0.4636897	-0.058360115	false
training	oneLayer	oneLayer - rat 1	0	0.4636897	-0.047400333	false
training	oneLayer	oneLayer - rat 1	0	0.4636897	-0.036630075	false
training	oneLayer	oneLayer - rat 1	0	0.46368968	-0.026138281	false
training	oneLayer	oneLayer - rat 1	0	0.46368968	-0.015384473	false
training	oneLayer	oneLayer - rat 1	0	0.46368968	-0.005173465	false
training	oneLayer	oneLayer - rat 1	0	0.46368968	0.005714797	false
training	oneLayer	oneLayer - rat 1	0	0.46368966	0.015854752	false
training	oneLayer	oneLayer - rat 1	0	0.46368966	0.026545638	false
training	oneLayer	oneLayer - rat 1	0	0.46368966	0.0372783	false
training	oneLayer	oneLayer - rat 1	0	0.46368966	0.04781449	false
training	oneLayer	oneLayer - rat 1	0	0.46368963	0.058309752	false
training	oneLayer	oneLayer - rat 1	0	0.46368963	0.0689029	false
training	oneLayer	oneLayer - rat 1	0	0.46368963	0.07931932	false
training	oneLayer	oneLayer - rat 1	0	0.46368963	0.08932617	false
training	oneLayer	oneLayer - rat 1	0	0.45979282	0.09873381	false
training	oneLayer	oneLayer - rat 1	0	0.45232034	0.1062063	false
training	oneLayer	oneLayer - rat 1	0	0.4429441	0.11009005	false
training	oneLayer	oneLayer - rat 1	0	0.43245897	0.11009004	false
training	oneLayer	oneLayer - rat 1	0	0.42293194	0.11403625	false
training	oneLayer	oneLayer - rat 1	0	0.41197062	0.11403624	false
training	oneLayer	oneLayer - rat 1	0	0.40191323	0.10987033	false
training	oneLayer	oneLayer - rat 1	0	0.39174408	0.10987032	false
training	oneLayer	oneLayer - rat 1	0	0.38159937	0.10566823	false
training	oneLayer	oneLayer - rat 1	0	0.37132597	0.105668224	false
training	oneLayer	oneLayer - rat 1	0	0.3612012	0.1014744	false
training	oneLayer	oneLayer - rat 1	0	0.35344625	0.093719445	false
training	oneLayer	oneLayer - rat 1	0	0.3434107	0.08956258	false
training	oneLayer	oneLayer - rat 1	0	0.3357897	0.08194156	false
training	oneLayer	oneLayer - rat 1	0	0.3257357	0.07777704	false
training	oneLayer	oneLayer - rat 1	0	0.3181003	0.07014163	false
training	oneLayer	oneLayer - rat 1	0	0.3082178	0.06604815	false
training	oneLayer	oneLayer - rat 1	0	0.30069435	0.058524683	false
training	oneLayer	oneLayer - rat 1	0	0.2907595	0.054409526	false
training	oneLayer	oneLayer - rat 1	0	0.28340054	0.047050543	false
training	oneLayer	oneLayer - rat 1	0	0.27329922	0.042866435	false
training	oneLayer	oneLayer - rat 1	0	0.2661064	0.0356736	false
training	oneLayer	oneLayer - rat 1	0	0.25628304	0.031604633	false
training	oneLayer	oneLayer - rat 1	0	0.24904484	0.024366405	false
training	oneLayer	oneLayer - rat 1	0	0.2395066	0.02041553	false
training	oneLayer	oneLayer - rat 1	0	0.23179954	0.012708453	false
training	oneLayer	oneLayer - rat 1	0	0.22230303	0.008774865	false
training	oneLayer	oneLayer - rat 1	0	0.21511662	0.0015884397	false
training	oneLayer	oneLayer - rat 1	0	0.20568395	-0.0023187115	false
training	oneLayer	oneLayer - rat 1	0	0.19490832	-0.00231872	false
training	oneLayer	oneLayer - rat 1	0	0.18492056	-0.0064557926	false
training	oneLayer	oneLayer - rat 1	0	0.17456226	-0.0064558005	false
training	oneLayer	oneLayer - rat 1	0	0.16506489	-0.010389754	false
training	oneLayer	oneLayer - rat 1	0	0.15468256	-0.010389761	false
training	oneLayer	oneLayer - rat 1	0	0.14537622	-0.014244584	false
training	oneLayer	oneLayer - rat 1	0	0.13481179	-0.014244593	false
training	oneLayer	oneLayer - rat 1	0	0.12484075	-0.018374741	false
training	oneLayer	oneLayer - rat 1	0	0.11414372	-0.01837475	false
training	oneLayer	oneLayer - rat 1	0	0.1040699	-0.02254747	false
training	oneLayer	oneLayer - rat 1	0	0.093283445	-0.02254748	false
training	oneLayer	oneLayer - rat 1	0	0.08353373	-0.026585953	false
training	oneLayer	oneLayer - rat 1	0	0.07312377	-0.026585963	false
training	oneLayer	oneLayer - rat 1	0	0.06310993	-0.030733842	false
training	oneLayer	oneLayer - rat 1	0	0.052981097	-0.03073385	false
training	oneLayer	oneLayer - rat 1	0	0.043235786	-0.0347705	false
training	oneLayer	oneLayer - rat 1	0	0.032550994	-0.034770507	false
training	oneLayer	oneLayer - rat 1	0	0.022797242	-0.03881065	false
training	oneLayer	oneLayer - rat 1	0	0.01272694	-0.038810663	false
training	oneLayer	oneLayer - rat 1	0	0.0033059511	-0.04271297	false
training	oneLayer	oneLayer - rat 1	0	-0.0071773184	-0.04271298	false
training	oneLayer	oneLayer - rat 1	0	-0.01704494	-0.046800293	false
training	oneLayer	oneLayer - rat 1	0	-0.027541015	-0.0468003	false
training	oneLayer	oneLayer - rat 1	0	-0.037597477	-0.05096583	false
training	oneLayer	oneLayer - rat 1	0	-0.048293356	-0.05096584	false
training	oneLayer	oneLayer - rat 1	0	-0.058449913	-0.055172835	false
training	oneLayer	oneLayer - rat 1	0	-0.068852946	-0.055172842	false
training	oneLayer	oneLayer - rat 1	0	-0.07820954	-0.05904848	false
training	oneLayer	oneLayer - rat 1	0	-0.08837803	-0.05904849	false
training	oneLayer	oneLayer - rat 1	0	-0.09835288	-0.063180216	false
training	oneLayer	oneLayer - rat 1	0	-0.10903381	-0.06318022	false
training	oneLayer	oneLayer - rat 1	0	-0.118960485	-0.067292	false
training	oneLayer	oneLayer - rat 1	0	-0.12910096	-0.067292005	false
training	oneLayer	oneLayer - rat 1	0	-0.13863488	-0.07124109	false
training	oneLayer	oneLayer - rat 1	0	-0.14935431	-0.071241096	false
training	oneLayer	oneLayer - rat 1	0	-0.1592634	-0.07534559	false
training	oneLayer	oneLayer - rat 1	0	-0.16945767	-0.0753456	false
training	oneLayer	oneLayer - rat 1	0	-0.17879456	-0.079213075	false
training	oneLayer	oneLayer - rat 1	0	-0.18935554	-0.07921308	false
training	oneLayer	oneLayer - rat 1	0	-0.19882809	-0.08313675	false
training	oneLayer	oneLayer - rat 1	0	-0.20923123	-0.08313676	false
training	oneLayer	oneLayer - rat 1	0	-0.21883164	-0.087113395	false
training	oneLayer	oneLayer - rat 1	0	-0.2289195	-0.0871134	false
training	oneLayer	oneLayer - rat 1	0	-0.23876904	-0.09119322	false
training	oneLayer	oneLayer - rat 1	0	-0.24897869	-0.09119323	false
training	oneLayer	oneLayer - rat 1	0	-0.25885773	-0.08710121	false
training	oneLayer	oneLayer - rat 1	0	-0.26626682	-0.07969212	false
training	oneLayer	oneLayer - rat 1	0	-0.27343625	-0.07252272	false
training	oneLayer	oneLayer - rat 1	0	-0.28277496	-0.0686545	false
training	oneLayer	oneLayer - rat 1	0	-0.29026222	-0.061167248	false
training	oneLayer	oneLayer - rat 1	0	-0.2995659	-0.05731355	false
training	oneLayer	oneLayer - rat 1	0	-0.30996656	-0.057313558	false
training	oneLayer	oneLayer - rat 1	0	-0.31968814	-0.061340377	false
training	oneLayer	oneLayer - rat 1	0	-0.33025423	-0.061340384	false
training	oneLayer	oneLayer - rat 1	0	-0.34023318	-0.05720698	false
training	oneLayer	oneLayer - rat 1	0	-0.35027814	-0.057206992	false
training	oneLayer	oneLayer - rat 1	0	-0.35997224	-0.053191572	false
training	oneLayer	oneLayer - rat 1	0	-0.3708019	-0.05319158	false
training	oneLayer	oneLayer - rat 1	0	-0.3809639	-0.048982356	false
training	oneLayer	oneLayer - rat 1	0	-0.39154902	-0.048982363	false
training	oneLayer	oneLayer - rat 1	0	-0.401351	-0.044922262	false
training	oneLayer	oneLayer - rat 1	0	-0.4085043	-0.037768953	false
training	oneLayer	oneLayer - rat 1	0	-0.41613385	-0.03013943	false
training	oneLayer	oneLayer - rat 1	0	-0.42012656	-0.020500224	false
training	oneLayer	oneLayer - rat 1	0	-0.42012656	-0.010269367	false
training	oneLayer	oneLayer - rat 1	0	-0.42012656	6.051723E-4	false
training	oneLayer	oneLayer - rat 1	0	-0.41624585	0.009974091	false
training	oneLayer	oneLayer - rat 1	0	-0.40907934	0.017140614	false
training	oneLayer	oneLayer - rat 1	0	-0.39904478	0.021297073	false
training	oneLayer	oneLayer - rat 1	0	-0.3886873	0.02129708	false
training	oneLayer	oneLayer - rat 1	0	-0.37876254	0.017186113	false
training	oneLayer	oneLayer - rat 1	0	-0.3716318	0.010055392	false
training	oneLayer	oneLayer - rat 1	0	-0.36175063	0.0059624864	false
training	oneLayer	oneLayer - rat 1	0	-0.35119024	0.005962494	false
training	oneLayer	oneLayer - rat 1	0	-0.34109527	0.0017810366	false
training	oneLayer	oneLayer - rat 1	0	-0.33093786	0.0017810437	false
training	oneLayer	oneLayer - rat 1	0	-0.3216163	-0.0020800668	false
training	oneLayer	oneLayer - rat 1	0	-0.31153548	-0.0020800596	false
training	oneLayer	oneLayer - rat 1	0	-0.30163458	-0.006181141	false
training	oneLayer	oneLayer - rat 1	0	-0.29111838	-0.0061811334	false
training	oneLayer	oneLayer - rat 1	0	-0.2815187	-0.010157438	false
training	oneLayer	oneLayer - rat 1	0	-0.27075842	-0.010157431	false
training	oneLayer	oneLayer - rat 1	0	-0.2612457	-0.014097718	false
training	oneLayer	oneLayer - rat 1	0	-0.25035673	-0.014097709	false
training	oneLayer	oneLayer - rat 1	0	-0.24071193	-0.018092707	false
training	oneLayer	oneLayer - rat 1	0	-0.22998619	-0.0180927	false
training	oneLayer	oneLayer - rat 1	0	-0.22053613	-0.022007039	false
training	oneLayer	oneLayer - rat 1	0	-0.20994906	-0.022007031	false
training	oneLayer	oneLayer - rat 1	0	-0.20019206	-0.026048506	false
training	oneLayer	oneLayer - rat 1	0	-0.18991153	-0.026048498	false
training	oneLayer	oneLayer - rat 1	0	-0.18011966	-0.030104415	false
training	oneLayer	oneLayer - rat 1	0	-0.16985533	-0.03010441	false
training	oneLayer	oneLayer - rat 1	0	-0.16028216	-0.03406974	false
training	oneLayer	oneLayer - rat 1	0	-0.14942272	-0.03406973	false
training	oneLayer	oneLayer - rat 1	0	-0.14000537	-0.037970517	false
training	oneLayer	oneLayer - rat 1	0	-0.12978233	-0.03797051	false
training	oneLayer	oneLayer - rat 1	0	-0.11990436	-0.042062093	false
training	oneLayer	oneLayer - rat 1	0	-0.10977642	-0.042062085	false
training	oneLayer	oneLayer - rat 1	0	-0.100330055	-0.04597489	false
training	oneLayer	oneLayer - rat 1	0	-0.090320125	-0.045974884	false
training	oneLayer	oneLayer - rat 1	0	-0.08029639	-0.05012684	false
training	oneLayer	oneLayer - rat 1	0	-0.07024383	-0.050126836	false
training	oneLayer	oneLayer - rat 1	0	-0.060299333	-0.05424597	false
training	oneLayer	oneLayer - rat 1	0	-0.049850892	-0.054245964	false
training	oneLayer	oneLayer - rat 1	0	-0.040254373	-0.058220968	false
training	oneLayer	oneLayer - rat 1	0	-0.030153515	-0.05822096	false
training	oneLayer	oneLayer - rat 1	0	-0.020612627	-0.062172916	false
training	oneLayer	oneLayer - rat 1	0	-0.009901999	-0.06217291	false
training	oneLayer	oneLayer - rat 1	0	-2.4325777E-4	-0.06617368	false
training	oneLayer	oneLayer - rat 1	0	0.010630735	-0.06617367	false
training	oneLayer	oneLayer - rat 1	0	0.020103795	-0.070097536	false
training	oneLayer	oneLayer - rat 1	0	0.030622717	-0.07009753	false
training	oneLayer	oneLayer - rat 1	0	0.04052617	-0.07419967	false
training	oneLayer	oneLayer - rat 1	0	0.05077336	-0.07419966	false
training	oneLayer	oneLayer - rat 1	0	0.0601778	-0.0780951	false
training	oneLayer	oneLayer - rat 1	0	0.0702057	-0.07809509	false
training	oneLayer	oneLayer - rat 1	0	0.0797231	-0.08203732	false
training	oneLayer	oneLayer - rat 1	0	0.09027497	-0.082037315	false
training	oneLayer	oneLayer - rat 1	0	0.10029579	-0.08618806	false
training	oneLayer	oneLayer - rat 1	0	0.110668354	-0.086188056	false
training	oneLayer	oneLayer - rat 1	0	0.120130405	-0.09010736	false
training	oneLayer	oneLayer - rat 1	0	0.13088247	-0.09010735	false
training	oneLayer	oneLayer - rat 1	0	0.14046837	-0.09407796	false
training	oneLayer	oneLayer - rat 1	0	0.15107061	-0.09407795	false
training	oneLayer	oneLayer - rat 1	0	0.16095084	-0.09817047	false
training	oneLayer	oneLayer - rat 1	0	0.17192242	-0.09817046	false
training	oneLayer	oneLayer - rat 1	0	0.18204366	-0.10236281	false
training	oneLayer	oneLayer - rat 1	0	0.19223766	-0.102362804	false
training	oneLayer	oneLayer - rat 1	0	0.20230202	-0.10653159	false
training	oneLayer	oneLayer - rat 1	0	0.21286814	-0.10653158	false
training	oneLayer	oneLayer - rat 1	0	0.22215007	-0.10268687	false
training	oneLayer	oneLayer - rat 1	0	0.23253788	-0.10268686	false
training	oneLayer	oneLayer - rat 1	0	0.24200837	-0.09876405	false
training	oneLayer	oneLayer - rat 1	0	0.24940039	-0.09137202	false
training	oneLayer	oneLayer - rat 1	0	0.25937766	-0.08723929	false
training	oneLayer	oneLayer - rat 1	0	0.26649904	-0.080117896	false
training	oneLayer	oneLayer - rat 1	0	0.27051905	-0.070412695	false
training	oneLayer	oneLayer - rat 1	0	0.2778064	-0.06312536	false
training	oneLayer	oneLayer - rat 1	0	0.2872059	-0.05923194	false
training	oneLayer	oneLayer - rat 1	0	0.2979862	-0.059231933	false
training	oneLayer	oneLayer - rat 1	0	0.308071	-0.06340919	false
training	oneLayer	oneLayer - rat 1	0	0.3186064	-0.06340918	false
training	oneLayer	oneLayer - rat 1	0	0.32785434	-0.05957856	false
training	oneLayer	oneLayer - rat 1	0	0.33852044	-0.059578553	false
training	oneLayer	oneLayer - rat 1	0	0.34820366	-0.05556762	false
training	oneLayer	oneLayer - rat 1	0	0.3583624	-0.05556761	false
training	oneLayer	oneLayer - rat 1	0	0.36788893	-0.05162158	false
training	oneLayer	oneLayer - rat 1	0	0.37882468	-0.05162157	false
training	oneLayer	oneLayer - rat 1	0	0.3884138	-0.04764963	false
training	oneLayer	oneLayer - rat 1	0	0.39873686	-0.047649622	false
training	oneLayer	oneLayer - rat 1	0	0.40864754	-0.04354447	false
training	oneLayer	oneLayer - rat 1	0	0.41625166	-0.035940353	false
training	oneLayer	oneLayer - rat 1	0	0.42018044	-0.02645538	false
training	oneLayer	oneLayer - rat 1	0	0.42775884	-0.018876988	false
training	oneLayer	oneLayer - rat 1	0	0.43165112	-0.009480144	false
training	oneLayer	oneLayer - rat 1	0	0.43165112	6.2949647E-4	false
training	oneLayer	oneLayer - rat 1	0	0.42779955	0.009928003	false
training	oneLayer	oneLayer - rat 1	0	0.42053315	0.017194387	false
training	oneLayer	oneLayer - rat 1	0	0.4133379	0.024389623	false
training	oneLayer	oneLayer - rat 1	0	0.40361446	0.028417194	false
training	oneLayer	oneLayer - rat 1	0	0.3927866	0.028417185	false
training	oneLayer	oneLayer - rat 1	0	0.38270903	0.024242911	false
training	oneLayer	oneLayer - rat 1	0	0.37555254	0.01708641	false
training	oneLayer	oneLayer - rat 1	0	0.36578578	0.013040878	false
training	oneLayer	oneLayer - rat 1	0	0.35861483	0.005869926	false
training	oneLayer	oneLayer - rat 1	0	0.34856346	0.0017065032	false
training	oneLayer	oneLayer - rat 1	0	0.34086698	-0.005990004	false
training	oneLayer	oneLayer - rat 1	0	0.3308402	-0.010143234	false
training	oneLayer	oneLayer - rat 1	0	0.32056305	-0.010143242	false
training	oneLayer	oneLayer - rat 1	0	0.31103432	-0.0140901795	false
training	oneLayer	oneLayer - rat 1	0	0.30055192	-0.014090188	false
training	oneLayer	oneLayer - rat 1	0	0.29066718	-0.018184593	false
training	oneLayer	oneLayer - rat 1	0	0.28058362	-0.0181846	false
training	oneLayer	oneLayer - rat 1	0	0.27113515	-0.022098282	false
training	oneLayer	oneLayer - rat 1	0	0.2607256	-0.022098292	false
training	oneLayer	oneLayer - rat 1	0	0.25106087	-0.02610155	false
training	oneLayer	oneLayer - rat 1	0	0.24078849	-0.026101558	false
training	oneLayer	oneLayer - rat 1	0	0.23071072	-0.030275919	false
training	oneLayer	oneLayer - rat 1	0	0.2201796	-0.030275928	false
training	oneLayer	oneLayer - rat 1	0	0.21066488	-0.034217063	false
training	oneLayer	oneLayer - rat 1	0	0.20033297	-0.03421707	false
training	oneLayer	oneLayer - rat 1	0	0.190394	-0.038333938	false
training	oneLayer	oneLayer - rat 1	0	0.18012773	-0.038333945	false
training	oneLayer	oneLayer - rat 1	0	0.17030916	-0.042400934	false
training	oneLayer	oneLayer - rat 1	0	0.15981854	-0.04240094	false
training	oneLayer	oneLayer - rat 1	0	0.15025939	-0.04636048	false
training	oneLayer	oneLayer - rat 1	0	0.13935545	-0.04636049	false
training	oneLayer	oneLayer - rat 1	0	0.12977272	-0.050329797	false
training	oneLayer	oneLayer - rat 1	0	0.11960429	-0.050329804	false
training	oneLayer	oneLayer - rat 1	0	0.110275224	-0.05419404	false
training	oneLayer	oneLayer - rat 1	0	0.09934731	-0.054194048	false
training	oneLayer	oneLayer - rat 1	0	0.0897438	-0.058171958	false
training	oneLayer	oneLayer - rat 1	0	0.07928794	-0.05817197	false
training	oneLayer	oneLayer - rat 1	0	0.069818564	-0.062094323	false
training	oneLayer	oneLayer - rat 1	0	0.059025858	-0.06209433	false
training	oneLayer	oneLayer - rat 1	0	0.049155008	-0.06618298	false
training	oneLayer	oneLayer - rat 1	0	0.038188566	-0.066182986	false
training	oneLayer	oneLayer - rat 1	0	0.02884994	-0.07005118	false
training	oneLayer	oneLayer - rat 1	0	0.018753553	-0.070051186	false
training	oneLayer	oneLayer - rat 1	0	0.008835815	-0.07415926	false
training	oneLayer	oneLayer - rat 1	0	-0.0019713228	-0.07415927	false
training	oneLayer	oneLayer - rat 1	0	-0.012058555	-0.07833754	false
training	oneLayer	oneLayer - rat 1	0	-0.022821032	-0.07833756	false
training	oneLayer	oneLayer - rat 1	0	-0.032062322	-0.082165435	false
training	oneLayer	oneLayer - rat 1	0	-0.043013643	-0.08216544	false
training	oneLayer	oneLayer - rat 1	0	-0.052779578	-0.08621063	false
training	oneLayer	oneLayer - rat 1	0	-0.063635476	-0.08621064	false
training	oneLayer	oneLayer - rat 1	0	-0.07300809	-0.09009291	false
training	oneLayer	oneLayer - rat 1	0	-0.08368352	-0.09009292	false
training	oneLayer	oneLayer - rat 1	0	-0.09367069	-0.09422975	false
training	oneLayer	oneLayer - rat 1	0	-0.10459449	-0.09422976	false
training	oneLayer	oneLayer - rat 1	0	-0.114445016	-0.09830999	false
training	oneLayer	oneLayer - rat 1	0	-0.12456762	-0.098309994	false
training	oneLayer	oneLayer - rat 1	0	-0.13431355	-0.102346905	false
training	oneLayer	oneLayer - rat 1	0	-0.14452575	-0.10234691	false
training	oneLayer	oneLayer - rat 1	0	-0.1541526	-0.10633449	false
training	oneLayer	oneLayer - rat 1	0	-0.16444081	-0.1063345	false
training	oneLayer	oneLayer - rat 1	0	-0.17443562	-0.11047449	false
training	oneLayer	oneLayer - rat 1	0	-0.18527089	-0.110474505	false
training	oneLayer	oneLayer - rat 1	0	-0.19471906	-0.10656095	false
training	oneLayer	oneLayer - rat 1	0	-0.20525582	-0.10656096	false
training	oneLayer	oneLayer - rat 1	0	-0.21475558	-0.10262604	false
training	oneLayer	oneLayer - rat 1	0	-0.22547735	-0.10262605	false
training	oneLayer	oneLayer - rat 1	0	-0.23545884	-0.098491594	false
training	oneLayer	oneLayer - rat 1	0	-0.24639955	-0.0984916	false
training	oneLayer	oneLayer - rat 1	0	-0.25570795	-0.09463595	false
training	oneLayer	oneLayer - rat 1	0	-0.26611662	-0.094635956	false
training	oneLayer	oneLayer - rat 1	0	-0.27619082	-0.0904631	false
training	oneLayer	oneLayer - rat 1	0	-0.28669944	-0.09046311	false
training	oneLayer	oneLayer - rat 1	0	-0.2960598	-0.08658593	false
training	oneLayer	oneLayer - rat 1	0	-0.3067746	-0.08658595	false
training	oneLayer	oneLayer - rat 1	0	-0.31693476	-0.08237747	false
training	oneLayer	oneLayer - rat 1	0	-0.32764813	-0.08237748	false
training	oneLayer	oneLayer - rat 1	0	-0.33779657	-0.07817386	false
training	oneLayer	oneLayer - rat 1	0	-0.34821403	-0.07817387	false
training	oneLayer	oneLayer - rat 1	0	-0.35768083	-0.07425261	false
training	oneLayer	oneLayer - rat 1	0	-0.36832294	-0.07425262	false
training	oneLayer	oneLayer - rat 1	0	-0.37828124	-0.07012777	false
training	oneLayer	oneLayer - rat 1	0	-0.38832763	-0.07012778	false
training	oneLayer	oneLayer - rat 1	0	-0.39848307	-0.06592127	false
training	oneLayer	oneLayer - rat 1	0	-0.40590143	-0.058502913	false
training	oneLayer	oneLayer - rat 1	0	-0.41362423	-0.050780114	false
training	oneLayer	oneLayer - rat 1	0	-0.42134458	-0.04305979	false
training	oneLayer	oneLayer - rat 1	0	-0.428996	-0.035408366	false
training	oneLayer	oneLayer - rat 1	0	-0.43319815	-0.025263468	false
training	oneLayer	oneLayer - rat 1	0	-0.43319818	-0.014312822	false
training	oneLayer	oneLayer - rat 1	0	-0.42907023	-0.0043470934	false
training	oneLayer	oneLayer - rat 1	0	-0.4215889	0.0031342756	false
training	oneLayer	oneLayer - rat 1	0	-0.4117192	0.0072224354	false
training	oneLayer	oneLayer - rat 1	0	-0.4009841	0.007222443	false
training	oneLayer	oneLayer - rat 1	0	-0.39171785	0.0033842423	false
training	oneLayer	oneLayer - rat 1	0	-0.38411525	-0.0042183553	false
training	oneLayer	oneLayer - rat 1	0	-0.3745391	-0.008184905	false
training	oneLayer	oneLayer - rat 1	0	-0.36407617	-0.008184898	false
training	oneLayer	oneLayer - rat 1	0	-0.35421056	-0.012271354	false
training	oneLayer	oneLayer - rat 1	0	-0.34396988	-0.012271347	false
training	oneLayer	oneLayer - rat 1	0	-0.33449122	-0.016197523	false
training	oneLayer	oneLayer - rat 1	0	-0.32445127	-0.016197518	false
training	oneLayer	oneLayer - rat 1	0	-0.3146734	-0.020247648	false
training	oneLayer	oneLayer - rat 1	0	-0.30404362	-0.02024764	false
training	oneLayer	oneLayer - rat 1	0	-0.29478657	-0.024082026	false
training	oneLayer	oneLayer - rat 1	0	-0.28428012	-0.024082018	false
training	oneLayer	oneLayer - rat 1	0	-0.27441767	-0.028167173	false
training	oneLayer	oneLayer - rat 1	0	-0.26406413	-0.028167166	false
training	oneLayer	oneLayer - rat 1	0	-0.25461397	-0.032081544	false
training	oneLayer	oneLayer - rat 1	0	-0.24425519	-0.032081537	false
training	oneLayer	oneLayer - rat 1	0	-0.23457043	-0.03609309	false
training	oneLayer	oneLayer - rat 1	0	-0.22403228	-0.036093082	false
training	oneLayer	oneLayer - rat 1	0	-0.21396524	-0.04026298	false
training	oneLayer	oneLayer - rat 1	0	-0.20317768	-0.04026297	false
training	oneLayer	oneLayer - rat 1	0	-0.19322482	-0.044385567	false
training	oneLayer	oneLayer - rat 1	0	-0.18284069	-0.04438556	false
training	oneLayer	oneLayer - rat 1	0	-0.17286055	-0.048519466	false
training	oneLayer	oneLayer - rat 1	0	-0.16194439	-0.04851946	false
training	oneLayer	oneLayer - rat 1	0	-0.15256742	-0.05240352	false
training	oneLayer	oneLayer - rat 1	0	-0.14247684	-0.052403513	false
training	oneLayer	oneLayer - rat 1	0	-0.1325409	-0.05651911	false
training	oneLayer	oneLayer - rat 1	0	-0.122012354	-0.056519102	false
training	oneLayer	oneLayer - rat 1	0	-0.11270415	-0.06037468	false
training	oneLayer	oneLayer - rat 1	0	-0.10181577	-0.060374673	false
training	oneLayer	oneLayer - rat 1	0	-0.09223782	-0.06434198	false
training	oneLayer	oneLayer - rat 1	0	-0.081536256	-0.06434197	false
training	oneLayer	oneLayer - rat 1	0	-0.07180208	-0.06837399	false
training	oneLayer	oneLayer - rat 1	0	-0.061437875	-0.068373986	false
training	oneLayer	oneLayer - rat 1	0	-0.051351994	-0.07255169	false
training	oneLayer	oneLayer - rat 1	0	-0.040647484	-0.07255168	false
training	oneLayer	oneLayer - rat 1	0	-0.031300645	-0.07642326	false
training	oneLayer	oneLayer - rat 1	0	-0.021124624	-0.07642325	false
training	oneLayer	oneLayer - rat 1	0	-0.011007235	-0.08061401	false
training	oneLayer	oneLayer - rat 1	0	-8.861248E-4	-0.080614	false
training	oneLayer	oneLayer - rat 1	0	0.009105991	-0.08475286	false
training	oneLayer	oneLayer - rat 1	0	0.019383863	-0.08475285	false
training	oneLayer	oneLayer - rat 1	0	0.029466761	-0.08892932	false
training	oneLayer	oneLayer - rat 1	0	0.039855618	-0.08892931	false
training	oneLayer	oneLayer - rat 1	0	0.049275264	-0.092831045	false
training	oneLayer	oneLayer - rat 1	0	0.06005807	-0.09283104	false
training	oneLayer	oneLayer - rat 1	0	0.06950499	-0.096744075	false
training	oneLayer	oneLayer - rat 1	0	0.07993309	-0.09674407	false
training	oneLayer	oneLayer - rat 1	0	0.08990103	-0.10087291	false
training	oneLayer	oneLayer - rat 1	0	0.100192845	-0.100872904	false
training	oneLayer	oneLayer - rat 1	0	0.10949923	-0.10472773	false
training	oneLayer	oneLayer - rat 1	0	0.11969867	-0.10472772	false
training	oneLayer	oneLayer - rat 1	0	0.12912692	-0.10863303	false
training	oneLayer	oneLayer - rat 1	0	0.1394972	-0.10863302	false
training	oneLayer	oneLayer - rat 1	0	0.14932953	-0.11270569	false
training	oneLayer	oneLayer - rat 1	0	0.16024485	-0.112705685	false
training	oneLayer	oneLayer - rat 1	0	0.16996376	-0.116731375	false
training	oneLayer	oneLayer - rat 1	0	0.18025889	-0.11673137	false
training	oneLayer	oneLayer - rat 1	0	0.190348	-0.112552315	false
training	oneLayer	oneLayer - rat 1	0	0.19743821	-0.1054621	false
training	oneLayer	oneLayer - rat 1	0	0.20754516	-0.101275645	false
training	oneLayer	oneLayer - rat 1	0	0.21470764	-0.09411316	false
training	oneLayer	oneLayer - rat 1	0	0.22454432	-0.09003867	false
training	oneLayer	oneLayer - rat 1	0	0.23492569	-0.090038665	false
training	oneLayer	oneLayer - rat 1	0	0.24432506	-0.08614531	false
training	oneLayer	oneLayer - rat 1	0	0.25478503	-0.086145304	false
training	oneLayer	oneLayer - rat 1	0	0.26484093	-0.081980005	false
training	oneLayer	oneLayer - rat 1	0	0.27545783	-0.08198	false
training	oneLayer	oneLayer - rat 1	0	0.2847856	-0.078116305	false
training	oneLayer	oneLayer - rat 1	0	0.29483497	-0.0781163	false
training	oneLayer	oneLayer - rat 1	0	0.30440116	-0.07415385	false
training	oneLayer	oneLayer - rat 1	0	0.31503445	-0.07415384	false
training	oneLayer	oneLayer - rat 1	0	0.32468995	-0.0701544	false
training	oneLayer	oneLayer - rat 1	0	0.33495626	-0.07015439	false
training	oneLayer	oneLayer - rat 1	0	0.34438777	-0.066247724	false
training	oneLayer	oneLayer - rat 1	0	0.35527322	-0.06624772	false
training	oneLayer	oneLayer - rat 1	0	0.36497542	-0.06222892	false
training	oneLayer	oneLayer - rat 1	0	0.37578928	-0.062228914	false
training	oneLayer	oneLayer - rat 1	0	0.38575548	-0.058100782	false
training	oneLayer	oneLayer - rat 1	0	0.39643103	-0.058100775	false
training	oneLayer	oneLayer - rat 1	0	0.40571734	-0.05425424	false
training	oneLayer	oneLayer - rat 1	0	0.413257	-0.046714593	false
training	oneLayer	oneLayer - rat 1	0	0.4173157	-0.03691598	false
training	oneLayer	oneLayer - rat 1	0	0.4173157	-0.02600493	false
training	oneLayer	oneLayer - rat 1	0	0.4212162	-0.016588314	false
training	oneLayer	oneLayer - rat 1	0	0.42848468	-0.0093198065	false
training	oneLayer	oneLayer - rat 1	0	0.4324407	2.3093227E-4	false
training	oneLayer	oneLayer - rat 1	0	0.4324407	0.010959149	false
training	oneLayer	oneLayer - rat 1	0	0.43659577	0.020990405	false
training	oneLayer	oneLayer - rat 1	0	0.43659577	0.031030009	false
training	oneLayer	oneLayer - rat 1	0	0.4406672	0.04085939	false
training	oneLayer	oneLayer - rat 1	0	0.4406672	0.05156186	false
training	oneLayer	oneLayer - rat 1	0	0.4406672	0.061960094	false
training	oneLayer	oneLayer - rat 1	0	0.4406672	0.07240431	false
training	oneLayer	oneLayer - rat 1	0	0.44066718	0.08260139	false
training	oneLayer	oneLayer - rat 1	0	0.44066718	0.09310574	false
training	oneLayer	oneLayer - rat 1	0	0.44066718	0.1040314	false
training	oneLayer	oneLayer - rat 1	0	0.44066718	0.11411716	false
training	oneLayer	oneLayer - rat 1	0	0.44066715	0.1247421	false
training	oneLayer	oneLayer - rat 1	0	0.44066715	0.13490565	false
training	oneLayer	oneLayer - rat 1	0	0.44066715	0.14511429	false
training	oneLayer	oneLayer - rat 1	0	0.43647793	0.1552279	false
training	oneLayer	oneLayer - rat 1	0	0.42920133	0.16250448	false
training	oneLayer	oneLayer - rat 1	0	0.42164892	0.17005691	false
training	oneLayer	oneLayer - rat 1	0	0.41230875	0.17392571	false
training	oneLayer	oneLayer - rat 1	0	0.40195736	0.17392571	false
training	oneLayer	oneLayer - rat 1	0	0.3919247	0.16977005	false
training	oneLayer	oneLayer - rat 1	0	0.38453504	0.16238038	false
training	oneLayer	oneLayer - rat 1	0	0.3748273	0.15835927	false
training	oneLayer	oneLayer - rat 1	0	0.36752498	0.15105695	false
training	oneLayer	oneLayer - rat 1	0	0.3578426	0.14704637	false
training	oneLayer	oneLayer - rat 1	0	0.3507294	0.13993318	false
training	oneLayer	oneLayer - rat 1	0	0.34095687	0.13588525	false
training	oneLayer	oneLayer - rat 1	0	0.33365804	0.12858641	false
training	oneLayer	oneLayer - rat 1	0	0.3237432	0.12447954	false
training	oneLayer	oneLayer - rat 1	0	0.31627318	0.11700952	false
training	oneLayer	oneLayer - rat 1	0	0.30640352	0.112921365	false
training	oneLayer	oneLayer - rat 1	0	0.2993018	0.10581964	false
training	oneLayer	oneLayer - rat 1	0	0.2896648	0.10182786	false
training	oneLayer	oneLayer - rat 1	0	0.28209728	0.09426031	false
training	oneLayer	oneLayer - rat 1	0	0.27199373	0.09007527	false
training	oneLayer	oneLayer - rat 1	0	0.26445326	0.0825348	false
training	oneLayer	oneLayer - rat 1	0	0.2544787	0.07840319	false
training	oneLayer	oneLayer - rat 1	0	0.24685468	0.07077915	false
training	oneLayer	oneLayer - rat 1	0	0.23681	0.06661851	false
training	oneLayer	oneLayer - rat 1	0	0.22930993	0.059118416	false
training	oneLayer	oneLayer - rat 1	0	0.21945605	0.055036798	false
training	oneLayer	oneLayer - rat 1	0	0.21177053	0.047351267	false
training	oneLayer	oneLayer - rat 1	0	0.20218429	0.04338051	false
training	oneLayer	oneLayer - rat 1	0	0.19463888	0.035835087	false
training	oneLayer	oneLayer - rat 1	0	0.1849009	0.031801473	false
training	oneLayer	oneLayer - rat 1	0	0.17760152	0.02450207	false
training	oneLayer	oneLayer - rat 1	0	0.16802327	0.020534625	false
training	oneLayer	oneLayer - rat 1	0	0.16064303	0.013154365	false
training	oneLayer	oneLayer - rat 1	0	0.15138085	0.009317837	false
training	oneLayer	oneLayer - rat 1	0	0.14406952	0.0020065003	false
training	oneLayer	oneLayer - rat 1	0	0.13431339	-0.0020346283	false
training	oneLayer	oneLayer - rat 1	0	0.12388858	-0.0020346367	false
training	oneLayer	oneLayer - rat 1	0	0.11391479	-0.0061659287	false
training	oneLayer	oneLayer - rat 1	0	0.10375607	-0.0061659366	false
training	oneLayer	oneLayer - rat 1	0	0.094398506	-0.0100419745	false
training	oneLayer	oneLayer - rat 1	0	0.08439652	-0.010041983	false
training	oneLayer	oneLayer - rat 1	0	0.07467409	-0.014069154	false
training	oneLayer	oneLayer - rat 1	0	0.0641032	-0.014069161	false
training	oneLayer	oneLayer - rat 1	0	0.054380078	-0.018096618	false
training	oneLayer	oneLayer - rat 1	0	0.043977905	-0.018096628	false
training	oneLayer	oneLayer - rat 1	0	0.03451571	-0.022016006	false
training	oneLayer	oneLayer - rat 1	0	0.023669722	-0.022016015	false
training	oneLayer	oneLayer - rat 1	0	0.013978757	-0.026030153	false
training	oneLayer	oneLayer - rat 1	0	0.0038826272	-0.02603016	false
training	oneLayer	oneLayer - rat 1	0	-0.0061546015	-0.030187726	false
training	oneLayer	oneLayer - rat 1	0	-0.017107816	-0.030187735	false
training	oneLayer	oneLayer - rat 1	0	-0.02654469	-0.034096625	false
training	oneLayer	oneLayer - rat 1	0	-0.03687647	-0.034096632	false
training	oneLayer	oneLayer - rat 1	0	-0.046825793	-0.038217787	false
training	oneLayer	oneLayer - rat 1	0	-0.057797875	-0.038217794	false
training	oneLayer	oneLayer - rat 1	0	-0.06744797	-0.042215005	false
training	oneLayer	oneLayer - rat 1	0	-0.07750375	-0.042215012	false
training	oneLayer	oneLayer - rat 1	0	-0.08703997	-0.046165053	false
training	oneLayer	oneLayer - rat 1	0	-0.09731594	-0.04616506	false
training	oneLayer	oneLayer - rat 1	0	-0.10717649	-0.050249446	false
training	oneLayer	oneLayer - rat 1	0	-0.11725013	-0.050249454	false
training	oneLayer	oneLayer - rat 1	0	-0.12718935	-0.05436642	false
training	oneLayer	oneLayer - rat 1	0	-0.13781388	-0.054366432	false
training	oneLayer	oneLayer - rat 1	0	-0.14708774	-0.0582078	false
training	oneLayer	oneLayer - rat 1	0	-0.15751123	-0.05820781	false
training	oneLayer	oneLayer - rat 1	0	-0.16696295	-0.062122844	false
training	oneLayer	oneLayer - rat 1	0	-0.17759238	-0.06212285	false
training	oneLayer	oneLayer - rat 1	0	-0.18690115	-0.06597868	false
training	oneLayer	oneLayer - rat 1	0	-0.19779408	-0.06597869	false
training	oneLayer	oneLayer - rat 1	0	-0.20768167	-0.070074275	false
training	oneLayer	oneLayer - rat 1	0	-0.21834284	-0.07007428	false
training	oneLayer	oneLayer - rat 1	0	-0.22784093	-0.07400853	false
training	oneLayer	oneLayer - rat 1	0	-0.2380134	-0.07400854	false
training	oneLayer	oneLayer - rat 1	0	-0.24754651	-0.07795729	false
training	oneLayer	oneLayer - rat 1	0	-0.25802252	-0.077957295	false
training	oneLayer	oneLayer - rat 1	0	-0.26781395	-0.082013056	false
training	oneLayer	oneLayer - rat 1	0	-0.2780005	-0.08201306	false
training	oneLayer	oneLayer - rat 1	0	-0.28798798	-0.07787613	false
training	oneLayer	oneLayer - rat 1	0	-0.29880467	-0.077876136	false
training	oneLayer	oneLayer - rat 1	0	-0.30837926	-0.073910214	false
training	oneLayer	oneLayer - rat 1	0	-0.31933436	-0.07391022	false
training	oneLayer	oneLayer - rat 1	0	-0.32883254	-0.06997595	false
training	oneLayer	oneLayer - rat 1	0	-0.33929703	-0.06997596	false
training	oneLayer	oneLayer - rat 1	0	-0.3489337	-0.06598432	false
training	oneLayer	oneLayer - rat 1	0	-0.35893455	-0.06598433	false
training	oneLayer	oneLayer - rat 1	0	-0.36827028	-0.06211736	false
training	oneLayer	oneLayer - rat 1	0	-0.3783733	-0.06211737	false
training	oneLayer	oneLayer - rat 1	0	-0.38807717	-0.0580979	false
training	oneLayer	oneLayer - rat 1	0	-0.39848047	-0.058097906	false
training	oneLayer	oneLayer - rat 1	0	-0.40824327	-0.054054044	false
training	oneLayer	oneLayer - rat 1	0	-0.41553792	-0.046759397	false
training	oneLayer	oneLayer - rat 1	0	-0.42265272	-0.0396446	false
training	oneLayer	oneLayer - rat 1	0	-0.42679974	-0.029632859	false
training	oneLayer	oneLayer - rat 1	0	-0.42679974	-0.019405307	false
training	oneLayer	oneLayer - rat 1	0	-0.42260683	-0.009282693	false
training	oneLayer	oneLayer - rat 1	0	-0.41846952	7.056525E-4	false
training	oneLayer	oneLayer - rat 1	0	-0.41427177	0.010839922	false
training	oneLayer	oneLayer - rat 1	0	-0.41033465	0.020345066	false
training	oneLayer	oneLayer - rat 1	0	-0.40646955	0.029676232	false
training	oneLayer	oneLayer - rat 1	0	-0.40247026	0.039331418	false
training	oneLayer	oneLayer - rat 1	0	-0.39837155	0.049226545	false
training	oneLayer	oneLayer - rat 1	0	-0.3943049	0.059044324	false
training	oneLayer	oneLayer - rat 1	0	-0.39035228	0.06858682	false
training	oneLayer	oneLayer - rat 1	0	-0.38645974	0.07798426	false
training	oneLayer	oneLayer - rat 1	0	-0.3823748	0.08784625	false
training	oneLayer	oneLayer - rat 1	0	-0.3782851	0.09771963	false
training	oneLayer	oneLayer - rat 1	0	-0.37425002	0.10746119	false
training	oneLayer	oneLayer - rat 1	0	-0.37011552	0.11744282	false
training	oneLayer	oneLayer - rat 1	0	-0.36624125	0.12679617	false
training	oneLayer	oneLayer - rat 1	0	-0.36231682	0.1362706	false
training	oneLayer	oneLayer - rat 1	0	-0.35821092	0.14618309	false
training	oneLayer	oneLayer - rat 1	0	-0.35437912	0.1554339	false
training	oneLayer	oneLayer - rat 1	0	-0.3504341	0.16495809	false
training	oneLayer	oneLayer - rat 1	0	-0.34637374	0.17476065	false
training	oneLayer	oneLayer - rat 1	0	-0.34222353	0.18478017	false
training	oneLayer	oneLayer - rat 1	0	-0.338371	0.19408102	false
training	oneLayer	oneLayer - rat 1	0	-0.33446413	0.20351304	false
training	oneLayer	oneLayer - rat 1	0	-0.33044934	0.21320564	false
training	oneLayer	oneLayer - rat 1	0	-0.3265669	0.2225787	false
training	oneLayer	oneLayer - rat 1	0	-0.32271072	0.23188831	false
training	oneLayer	oneLayer - rat 1	0	-0.3187786	0.24138132	false
training	oneLayer	oneLayer - rat 1	0	-0.31877863	0.25209066	false
training	oneLayer	oneLayer - rat 1	0	-0.314874	0.26151732	false
training	oneLayer	oneLayer - rat 1	0	-0.314874	0.2721031	false
training	oneLayer	oneLayer - rat 1	0	-0.31103665	0.2813673	false
training	oneLayer	oneLayer - rat 1	0	-0.30338413	0.28901985	false
training	oneLayer	oneLayer - rat 1	0	-0.29947123	0.2984664	false
training	oneLayer	oneLayer - rat 1	0	-0.2921837	0.30575395	false
training	oneLayer	oneLayer - rat 1	0	-0.2826244	0.30971354	false
training	oneLayer	oneLayer - rat 1	0	-0.27228346	0.30971357	false
training	oneLayer	oneLayer - rat 1	0	-0.26270083	0.3057443	false
training	oneLayer	oneLayer - rat 1	0	-0.25543463	0.29847813	false
training	oneLayer	oneLayer - rat 1	0	-0.25132927	0.28856695	false
training	oneLayer	oneLayer - rat 1	0	-0.24359016	0.28082785	false
training	oneLayer	oneLayer - rat 1	0	-0.23374146	0.2767484	false
training	oneLayer	oneLayer - rat 1	0	-0.22632241	0.26932934	false
training	oneLayer	oneLayer - rat 1	0	-0.21625559	0.26515955	false
training	oneLayer	oneLayer - rat 1	0	-0.20886338	0.25776735	false
training	oneLayer	oneLayer - rat 1	0	-0.19887748	0.25363106	false
training	oneLayer	oneLayer - rat 1	0	-0.19122681	0.2459804	false
training	oneLayer	oneLayer - rat 1	0	-0.18142687	0.24192114	false
training	oneLayer	oneLayer - rat 1	0	-0.17382497	0.23431925	false
training	oneLayer	oneLayer - rat 1	0	-0.16456665	0.23048434	false
training	oneLayer	oneLayer - rat 1	0	-0.15719672	0.22311442	false
training	oneLayer	oneLayer - rat 1	0	-0.14734331	0.21903302	false
training	oneLayer	oneLayer - rat 1	0	-0.1400173	0.21170701	false
training	oneLayer	oneLayer - rat 1	0	-0.13039167	0.20771995	false
training	oneLayer	oneLayer - rat 1	0	-0.1230088	0.2003371	false
training	oneLayer	oneLayer - rat 1	0	-0.11305934	0.1962159	false
training	oneLayer	oneLayer - rat 1	0	-0.10531066	0.18846723	false
training	oneLayer	oneLayer - rat 1	0	-0.09575367	0.1845086	false
training	oneLayer	oneLayer - rat 1	0	-0.0881781	0.17693304	false
training	oneLayer	oneLayer - rat 1	0	-0.078131855	0.17277175	false
training	oneLayer	oneLayer - rat 1	0	-0.07067435	0.16531427	false
training	oneLayer	oneLayer - rat 1	0	-0.060802054	0.16122504	false
training	oneLayer	oneLayer - rat 1	0	-0.053027924	0.15345092	false
training	oneLayer	oneLayer - rat 1	0	-0.043713637	0.14959282	false
training	oneLayer	oneLayer - rat 1	0	-0.036589682	0.14246887	false
training	oneLayer	oneLayer - rat 1	0	-0.026971886	0.13848506	false
training	oneLayer	oneLayer - rat 1	0	-0.019566813	0.13108	false
training	oneLayer	oneLayer - rat 1	0	-0.010203342	0.12720153	false
training	oneLayer	oneLayer - rat 1	0	-0.0024869847	0.119485185	false
training	oneLayer	oneLayer - rat 1	0	0.006898657	0.11559753	false
training	oneLayer	oneLayer - rat 1	0	0.014314081	0.10818212	false
training	oneLayer	oneLayer - rat 1	0	0.02357226	0.10434726	false
training	oneLayer	oneLayer - rat 1	0	0.030805405	0.09711412	false
training	oneLayer	oneLayer - rat 1	0	0.040401157	0.09313944	false
training	oneLayer	oneLayer - rat 1	0	0.048073575	0.08546703	false
training	oneLayer	oneLayer - rat 1	0	0.057361756	0.08161975	false
training	oneLayer	oneLayer - rat 1	0	0.06491628	0.07406523	false
training	oneLayer	oneLayer - rat 1	0	0.07489232	0.06993303	false
training	oneLayer	oneLayer - rat 1	0	0.0822812	0.06254416	false
training	oneLayer	oneLayer - rat 1	0	0.09168686	0.058648214	false
training	oneLayer	oneLayer - rat 1	0	0.09930456	0.05103053	false
training	oneLayer	oneLayer - rat 1	0	0.10937395	0.04685966	false
training	oneLayer	oneLayer - rat 1	0	0.11705262	0.039180998	false
training	oneLayer	oneLayer - rat 1	0	0.12671894	0.035177086	false
training	oneLayer	oneLayer - rat 1	0	0.13413164	0.027764404	false
training	oneLayer	oneLayer - rat 1	0	0.14400679	0.023673987	false
training	oneLayer	oneLayer - rat 1	0	0.15131041	0.016370371	false
training	oneLayer	oneLayer - rat 1	0	0.16103204	0.012343554	false
training	oneLayer	oneLayer - rat 1	0	0.16849795	0.004877652	false
training	oneLayer	oneLayer - rat 1	0	0.17849629	7.3621393E-4	false
training	oneLayer	oneLayer - rat 1	0	0.18604015	-0.0068076416	false
training	oneLayer	oneLayer - rat 1	0	0.19544989	-0.0107052745	false
training	oneLayer	oneLayer - rat 1	0	0.20629083	-0.010705267	false
training	oneLayer	oneLayer - rat 1	0	0.21626936	-0.014838501	false
training	oneLayer	oneLayer - rat 1	0	0.22678328	-0.014838493	false
training	oneLayer	oneLayer - rat 1	0	0.23616536	-0.01872467	false
training	oneLayer	oneLayer - rat 1	0	0.2465614	-0.018724665	false
training	oneLayer	oneLayer - rat 1	0	0.2562524	-0.022738805	false
training	oneLayer	oneLayer - rat 1	0	0.26658934	-0.022738798	false
training	oneLayer	oneLayer - rat 1	0	0.27621624	-0.02672638	false
training	oneLayer	oneLayer - rat 1	0	0.28622144	-0.026726373	false
training	oneLayer	oneLayer - rat 1	0	0.29573593	-0.030667396	false
training	oneLayer	oneLayer - rat 1	0	0.30591032	-0.03066739	false
training	oneLayer	oneLayer - rat 1	0	0.31519052	-0.03451138	false
training	oneLayer	oneLayer - rat 1	0	0.3256576	-0.034511372	false
training	oneLayer	oneLayer - rat 1	0	0.33510968	-0.03842654	false
training	oneLayer	oneLayer - rat 1	0	0.34582636	-0.038426533	false
training	oneLayer	oneLayer - rat 1	0	0.35563204	-0.042488173	false
training	oneLayer	oneLayer - rat 1	0	0.36589265	-0.042488165	false
training	oneLayer	oneLayer - rat 1	0	0.37525395	-0.038610585	false
training	oneLayer	oneLayer - rat 1	0	0.3861988	-0.038610578	false
training	oneLayer	oneLayer - rat 1	0	0.39574856	-0.03465493	false
training	oneLayer	oneLayer - rat 1	0	0.40588978	-0.034654923	false
training	oneLayer	oneLayer - rat 1	0	0.4156489	-0.030612545	false
training	oneLayer	oneLayer - rat 1	0	0.42284867	-0.02341279	false
training	oneLayer	oneLayer - rat 1	0	0.4269551	-0.013498958	false
training	oneLayer	oneLayer - rat 1	0	0.4269551	-0.002574529	false
training	oneLayer	oneLayer - rat 1	0	0.42286277	0.0073051713	false
training	oneLayer	oneLayer - rat 1	0	0.42286277	0.01732236	false
training	oneLayer	oneLayer - rat 1	0	0.41877437	0.02719259	false
training	oneLayer	oneLayer - rat 1	0	0.4115053	0.034461644	false
training	oneLayer	oneLayer - rat 1	0	0.40754318	0.04402706	false
training	oneLayer	oneLayer - rat 1	0	0.4000553	0.051514942	false
training	oneLayer	oneLayer - rat 1	0	0.39587992	0.06159514	false
training	oneLayer	oneLayer - rat 1	0	0.39587992	0.07255369	false
training	oneLayer	oneLayer - rat 1	0	0.3916762	0.08270239	false
training	oneLayer	oneLayer - rat 1	0	0.3842181	0.09016046	false
training	oneLayer	oneLayer - rat 1	0	0.38027784	0.09967306	false
training	oneLayer	oneLayer - rat 1	0	0.372911	0.10703989	false
training	oneLayer	oneLayer - rat 1	0	0.368823	0.11690922	false
training	oneLayer	oneLayer - rat 1	0	0.36882296	0.12778115	false
training	oneLayer	oneLayer - rat 1	0	0.3728939	0.13760926	false
training	oneLayer	oneLayer - rat 1	0	0.3728939	0.14827104	false
training	oneLayer	oneLayer - rat 1	0	0.37698418	0.15814592	false
training	oneLayer	oneLayer - rat 1	0	0.38083184	0.16743498	false
training	oneLayer	oneLayer - rat 1	0	0.38083184	0.1777321	false
training	oneLayer	oneLayer - rat 1	0	0.38488945	0.1875281	false
training	oneLayer	oneLayer - rat 1	0	0.38488945	0.19761914	false
training	oneLayer	oneLayer - rat 1	0	0.38104618	0.20689763	false
training	oneLayer	oneLayer - rat 1	0	0.38104615	0.2176704	false
training	oneLayer	oneLayer - rat 1	0	0.3769997	0.22743936	false
training	oneLayer	oneLayer - rat 1	0	0.36940956	0.23502949	false
training	oneLayer	oneLayer - rat 1	0	0.36539382	0.24472438	false
training	oneLayer	oneLayer - rat 1	0	0.35775426	0.25236392	false
training	oneLayer	oneLayer - rat 1	0	0.35359803	0.2623979	false
training	oneLayer	oneLayer - rat 1	0	0.34632877	0.26966715	false
training	oneLayer	oneLayer - rat 1	0	0.34241453	0.27911693	false
training	oneLayer	oneLayer - rat 1	0	0.33510968	0.28642178	false
training	oneLayer	oneLayer - rat 1	0	0.33094278	0.29648152	false
training	oneLayer	oneLayer - rat 1	0	0.32349032	0.30393398	false
training	oneLayer	oneLayer - rat 1	0	0.3196557	0.31319153	false
training	oneLayer	oneLayer - rat 1	0	0.31211948	0.32072774	false
training	oneLayer	oneLayer - rat 1	0	0.30804226	0.330571	false
training	oneLayer	oneLayer - rat 1	0	0.30028728	0.33832598	false
training	oneLayer	oneLayer - rat 1	0	0.2904353	0.34240678	false
training	oneLayer	oneLayer - rat 1	0	0.2795358	0.34240678	false
training	oneLayer	oneLayer - rat 1	0	0.2695165	0.33825663	false
training	oneLayer	oneLayer - rat 1	0	0.25997317	0.33430365	false
training	oneLayer	oneLayer - rat 1	0	0.25068402	0.33045596	false
training	oneLayer	oneLayer - rat 1	0	0.24092032	0.3264117	false
training	oneLayer	oneLayer - rat 1	0	0.23161827	0.32255864	false
training	oneLayer	oneLayer - rat 1	0	0.22170839	0.31845382	false
training	oneLayer	oneLayer - rat 1	0	0.21161571	0.31845382	false
training	oneLayer	oneLayer - rat 1	0	0.20185268	0.31440982	false
training	oneLayer	oneLayer - rat 1	0	0.19094011	0.31440982	false
training	oneLayer	oneLayer - rat 1	0	0.18155096	0.3105207	false
training	oneLayer	oneLayer - rat 1	0	0.17091198	0.3105207	false
training	oneLayer	oneLayer - rat 1	0	0.16086607	0.30635953	false
training	oneLayer	oneLayer - rat 1	0	0.15035161	0.30635953	false
training	oneLayer	oneLayer - rat 1	0	0.14103518	0.30250052	false
training	oneLayer	oneLayer - rat 1	0	0.13061556	0.30250052	false
training	oneLayer	oneLayer - rat 1	0	0.12133085	0.29865465	false
training	oneLayer	oneLayer - rat 1	0	0.110396154	0.29865465	false
training	oneLayer	oneLayer - rat 1	0	0.10095243	0.2947429	false
training	oneLayer	oneLayer - rat 1	0	0.09028708	0.2947429	false
training	oneLayer	oneLayer - rat 1	0	0.08039468	0.29064533	false
training	oneLayer	oneLayer - rat 1	0	0.06949559	0.29064533	false
training	oneLayer	oneLayer - rat 1	0	0.060033992	0.2867262	false
training	oneLayer	oneLayer - rat 1	0	0.049300518	0.28672618	false
training	oneLayer	oneLayer - rat 1	0	0.039163113	0.28252712	false
training	oneLayer	oneLayer - rat 1	0	0.028794117	0.28252712	false
training	oneLayer	oneLayer - rat 1	0	0.018801425	0.278388	false
training	oneLayer	oneLayer - rat 1	0	0.008477818	0.278388	false
training	oneLayer	oneLayer - rat 1	0	-0.001296896	0.27433917	false
training	oneLayer	oneLayer - rat 1	0	-0.011741565	0.27433914	false
training	oneLayer	oneLayer - rat 1	0	-0.021577625	0.27026492	false
training	oneLayer	oneLayer - rat 1	0	-0.031700134	0.2702649	false
training	oneLayer	oneLayer - rat 1	0	-0.04131169	0.26628366	false
training	oneLayer	oneLayer - rat 1	0	-0.051405255	0.26628366	false
training	oneLayer	oneLayer - rat 1	0	-0.061086062	0.26227373	false
training	oneLayer	oneLayer - rat 1	0	-0.07199119	0.26227373	false
training	oneLayer	oneLayer - rat 1	0	-0.081431	0.2583636	false
training	oneLayer	oneLayer - rat 1	0	-0.09210516	0.2583636	false
training	oneLayer	oneLayer - rat 1	0	-0.10206761	0.25423703	false
training	oneLayer	oneLayer - rat 1	0	-0.11244044	0.254237	false
training	oneLayer	oneLayer - rat 1	0	-0.12259485	0.2500309	false
training	oneLayer	oneLayer - rat 1	0	-0.13330016	0.25003088	false
training	oneLayer	oneLayer - rat 1	0	-0.14285575	0.24607283	false
training	oneLayer	oneLayer - rat 1	0	-0.15349138	0.24607281	false
training	oneLayer	oneLayer - rat 1	0	-0.16311233	0.25005794	false
training	oneLayer	oneLayer - rat 1	0	-0.17382537	0.25005794	false
training	oneLayer	oneLayer - rat 1	0	-0.1838421	0.254207	false
training	oneLayer	oneLayer - rat 1	0	-0.1945345	0.25420696	false
training	oneLayer	oneLayer - rat 1	0	-0.20447032	0.2583225	false
training	oneLayer	oneLayer - rat 1	0	-0.21469994	0.2583225	false
training	oneLayer	oneLayer - rat 1	0	-0.22406916	0.26220337	false
training	oneLayer	oneLayer - rat 1	0	-0.23452994	0.26220334	false
training	oneLayer	oneLayer - rat 1	0	-0.24388699	0.26607916	false
training	oneLayer	oneLayer - rat 1	0	-0.25440633	0.26607916	false
training	oneLayer	oneLayer - rat 1	0	-0.26400137	0.27005354	false
training	oneLayer	oneLayer - rat 1	0	-0.27407146	0.27005354	false
training	oneLayer	oneLayer - rat 1	0	-0.28406334	0.2741923	false
training	oneLayer	oneLayer - rat 1	0	-0.29415795	0.2741923	false
training	oneLayer	oneLayer - rat 1	0	-0.30399328	0.27826622	false
training	oneLayer	oneLayer - rat 1	0	-0.3147874	0.27826622	false
training	oneLayer	oneLayer - rat 1	0	-0.32429117	0.27432963	false
training	oneLayer	oneLayer - rat 1	0	-0.33158466	0.2670361	false
training	oneLayer	oneLayer - rat 1	0	-0.33563212	0.25726464	false
training	oneLayer	oneLayer - rat 1	0	-0.34298563	0.24991113	false
training	oneLayer	oneLayer - rat 1	0	-0.34711784	0.23993509	false
training	oneLayer	oneLayer - rat 1	0	-0.3543736	0.23267931	false
training	oneLayer	oneLayer - rat 1	0	-0.3584032	0.22295097	false
training	oneLayer	oneLayer - rat 1	0	-0.3584032	0.21287183	false
training	oneLayer	oneLayer - rat 1	0	-0.36244875	0.20310496	false
training	oneLayer	oneLayer - rat 1	0	-0.36244875	0.19238782	false
training	oneLayer	oneLayer - rat 1	0	-0.36661685	0.18232511	false
training	oneLayer	oneLayer - rat 1	0	-0.36661685	0.17209952	false
training	oneLayer	oneLayer - rat 1	0	-0.37046906	0.1627994	false
training	oneLayer	oneLayer - rat 1	0	-0.37046906	0.15263379	false
training	oneLayer	oneLayer - rat 1	0	-0.3745011	0.1428995	false
training	oneLayer	oneLayer - rat 1	0	-0.3745011	0.13197266	false
training	oneLayer	oneLayer - rat 1	0	-0.3785381	0.122226484	false
training	oneLayer	oneLayer - rat 1	0	-0.37853807	0.11169653	false
training	oneLayer	oneLayer - rat 1	0	-0.3825217	0.10207921	false
training	oneLayer	oneLayer - rat 1	0	-0.3825217	0.09148925	false
training	oneLayer	oneLayer - rat 1	0	-0.38642973	0.08205439	false
training	oneLayer	oneLayer - rat 1	0	-0.38642973	0.071252346	false
training	oneLayer	oneLayer - rat 1	0	-0.39027297	0.061973903	false
training	oneLayer	oneLayer - rat 1	0	-0.39027295	0.05161954	false
training	oneLayer	oneLayer - rat 1	0	-0.3942941	0.04191158	false
training	oneLayer	oneLayer - rat 1	0	-0.40197644	0.03422924	false
training	oneLayer	oneLayer - rat 1	0	-0.4058374	0.024908107	false
training	oneLayer	oneLayer - rat 1	0	-0.41339737	0.017348085	false
training	oneLayer	oneLayer - rat 1	0	-0.4205958	0.010149653	false
training	oneLayer	oneLayer - rat 1	0	-0.4279452	0.0028002532	false
training	oneLayer	oneLayer - rat 1	0	-0.4318468	-0.0066190762	false
training	oneLayer	oneLayer - rat 1	0	-0.4318468	-0.016990285	false
training	oneLayer	oneLayer - rat 1	0	-0.4277771	-0.026815306	false
training	oneLayer	oneLayer - rat 1	0	-0.42007357	-0.034518857	false
training	oneLayer	oneLayer - rat 1	0	-0.410672	-0.0384131	false
training	oneLayer	oneLayer - rat 1	0	-0.3999685	-0.03841309	false
training	oneLayer	oneLayer - rat 1	0	-0.38985395	-0.034223497	false
training	oneLayer	oneLayer - rat 1	0	-0.3827587	-0.027128253	false
training	oneLayer	oneLayer - rat 1	0	-0.3787014	-0.017332979	false
training	oneLayer	oneLayer - rat 1	0	-0.37468022	-0.0076249703	false
training	oneLayer	oneLayer - rat 1	0	-0.37075296	0.0018562487	false
training	oneLayer	oneLayer - rat 1	0	-0.36673018	0.011568124	false
training	oneLayer	oneLayer - rat 1	0	-0.3626676	0.02137617	false
training	oneLayer	oneLayer - rat 1	0	-0.35857415	0.03125859	false
training	oneLayer	oneLayer - rat 1	0	-0.35460496	0.040841136	false
training	oneLayer	oneLayer - rat 1	0	-0.3504901	0.050775316	false
training	oneLayer	oneLayer - rat 1	0	-0.346422	0.060596615	false
training	oneLayer	oneLayer - rat 1	0	-0.34257647	0.06988052	false
training	oneLayer	oneLayer - rat 1	0	-0.33844972	0.07984342	false
training	oneLayer	oneLayer - rat 1	0	-0.33455527	0.089245476	false
training	oneLayer	oneLayer - rat 1	0	-0.33059704	0.09880149	false
training	oneLayer	oneLayer - rat 1	0	-0.3263908	0.1089563	false
training	oneLayer	oneLayer - rat 1	0	-0.32241178	0.11856249	false
training	oneLayer	oneLayer - rat 1	0	-0.31852713	0.12794088	false
training	oneLayer	oneLayer - rat 1	0	-0.31852716	0.13832583	false
training	oneLayer	oneLayer - rat 1	0	-0.3144497	0.14816967	false
training	oneLayer	oneLayer - rat 1	0	-0.31444973	0.158928	false
training	oneLayer	oneLayer - rat 1	0	-0.31847426	0.16864413	false
training	oneLayer	oneLayer - rat 1	0	-0.3184743	0.17926908	false
training	oneLayer	oneLayer - rat 1	0	-0.32238284	0.1887051	false
training	oneLayer	oneLayer - rat 1	0	-0.32238284	0.19969657	false
training	oneLayer	oneLayer - rat 1	0	-0.31822228	0.20974104	false
training	oneLayer	oneLayer - rat 1	0	-0.3182223	0.22029121	false
training	oneLayer	oneLayer - rat 1	0	-0.31401289	0.23045367	false
training	oneLayer	oneLayer - rat 1	0	-0.30988285	0.24042448	false
training	oneLayer	oneLayer - rat 1	0	-0.30988285	0.25069597	false
training	oneLayer	oneLayer - rat 1	0	-0.30594665	0.26019886	false
training	oneLayer	oneLayer - rat 1	0	-0.30594665	0.2711595	false
training	oneLayer	oneLayer - rat 1	0	-0.30195135	0.28080505	false
training	oneLayer	oneLayer - rat 1	0	-0.29483503	0.2879214	false
training	oneLayer	oneLayer - rat 1	0	-0.28521487	0.2919062	false
training	oneLayer	oneLayer - rat 1	0	-0.274799	0.2919062	false
training	oneLayer	oneLayer - rat 1	0	-0.26545432	0.2957769	false
training	oneLayer	oneLayer - rat 1	0	-0.25507334	0.29577693	false
training	oneLayer	oneLayer - rat 1	0	-0.24576195	0.29192	false
training	oneLayer	oneLayer - rat 1	0	-0.23837997	0.28453806	false
training	oneLayer	oneLayer - rat 1	0	-0.22892144	0.28062022	false
training	oneLayer	oneLayer - rat 1	0	-0.2211887	0.2728875	false
training	oneLayer	oneLayer - rat 1	0	-0.21122438	0.26876014	false
training	oneLayer	oneLayer - rat 1	0	-0.20353228	0.26106805	false
training	oneLayer	oneLayer - rat 1	0	-0.19369847	0.25699475	false
training	oneLayer	oneLayer - rat 1	0	-0.18628445	0.24958076	false
training	oneLayer	oneLayer - rat 1	0	-0.17635098	0.24546619	false
training	oneLayer	oneLayer - rat 1	0	-0.16921368	0.2383289	false
training	oneLayer	oneLayer - rat 1	0	-0.1596509	0.23436788	false
training	oneLayer	oneLayer - rat 1	0	-0.15239659	0.22711357	false
training	oneLayer	oneLayer - rat 1	0	-0.14259483	0.22305356	false
training	oneLayer	oneLayer - rat 1	0	-0.13525651	0.21571524	false
training	oneLayer	oneLayer - rat 1	0	-0.12530701	0.21159405	false
training	oneLayer	oneLayer - rat 1	0	-0.11780523	0.20409228	false
training	oneLayer	oneLayer - rat 1	0	-0.10764856	0.19988525	false
training	oneLayer	oneLayer - rat 1	0	-0.100364186	0.19260089	false
training	oneLayer	oneLayer - rat 1	0	-0.09049113	0.18851136	false
training	oneLayer	oneLayer - rat 1	0	-0.082807384	0.18082762	false
training	oneLayer	oneLayer - rat 1	0	-0.073478565	0.1769635	false
training	oneLayer	oneLayer - rat 1	0	-0.06601537	0.16950032	false
training	oneLayer	oneLayer - rat 1	0	-0.05605767	0.16537571	false
training	oneLayer	oneLayer - rat 1	0	-0.048342433	0.1576605	false
training	oneLayer	oneLayer - rat 1	0	-0.03834549	0.15351963	false
training	oneLayer	oneLayer - rat 1	0	-0.030621955	0.14579612	false
training	oneLayer	oneLayer - rat 1	0	-0.020944402	0.14178754	false
training	oneLayer	oneLayer - rat 1	0	-0.013406142	0.1342493	false
training	oneLayer	oneLayer - rat 1	0	-0.0038167322	0.13027725	false
training	oneLayer	oneLayer - rat 1	0	0.0033816178	0.12307891	false
training	oneLayer	oneLayer - rat 1	0	0.013532885	0.118874125	false
training	oneLayer	oneLayer - rat 1	0	0.021292198	0.11111483	false
training	oneLayer	oneLayer - rat 1	0	0.030592557	0.1072625	false
training	oneLayer	oneLayer - rat 1	0	0.037745107	0.100109965	false
training	oneLayer	oneLayer - rat 1	0	0.047013737	0.09627078	false
training	oneLayer	oneLayer - rat 1	0	0.05415995	0.08912458	false
training	oneLayer	oneLayer - rat 1	0	0.06365375	0.08519213	false
training	oneLayer	oneLayer - rat 1	0	0.071153946	0.07769195	false
training	oneLayer	oneLayer - rat 1	0	0.08070473	0.07373589	false
training	oneLayer	oneLayer - rat 1	0	0.08779564	0.066645	false
training	oneLayer	oneLayer - rat 1	0	0.09724499	0.06273095	false
training	oneLayer	oneLayer - rat 1	0	0.104834974	0.055140987	false
training	oneLayer	oneLayer - rat 1	0	0.114862	0.050987665	false
training	oneLayer	oneLayer - rat 1	0	0.12206072	0.043788962	false
training	oneLayer	oneLayer - rat 1	0	0.13159266	0.03984071	false
training	oneLayer	oneLayer - rat 1	0	0.13920905	0.032224335	false
training	oneLayer	oneLayer - rat 1	0	0.1490458	0.028149832	false
training	oneLayer	oneLayer - rat 1	0	0.15652652	0.020669129	false
training	oneLayer	oneLayer - rat 1	0	0.16630027	0.01662072	false
training	oneLayer	oneLayer - rat 1	0	0.17383453	0.009086467	false
training	oneLayer	oneLayer - rat 1	0	0.1833596	0.0051410664	false
training	oneLayer	oneLayer - rat 1	0	0.19072582	-0.0022251394	false
training	oneLayer	oneLayer - rat 1	0	0.20080915	-0.006401788	false
training	oneLayer	oneLayer - rat 1	0	0.2114313	-0.0064017787	false
training	oneLayer	oneLayer - rat 1	0	0.22130029	-0.002313901	false
training	oneLayer	oneLayer - rat 1	0	0.23196009	-0.0023138917	false
training	oneLayer	oneLayer - rat 1	0	0.2418613	-0.0064151012	false
training	oneLayer	oneLayer - rat 1	0	0.25280112	-0.006415092	false
training	oneLayer	oneLayer - rat 1	0	0.2625675	-0.010460451	false
training	oneLayer	oneLayer - rat 1	0	0.27298853	-0.010460442	false
training	oneLayer	oneLayer - rat 1	0	0.28304118	-0.0146243675	false
training	oneLayer	oneLayer - rat 1	0	0.2931595	-0.014624358	false
training	oneLayer	oneLayer - rat 1	0	0.30317762	-0.018773975	false
training	oneLayer	oneLayer - rat 1	0	0.31340548	-0.018773966	false
training	oneLayer	oneLayer - rat 1	0	0.3227746	-0.02265477	false
training	oneLayer	oneLayer - rat 1	0	0.333029	-0.02265476	false
training	oneLayer	oneLayer - rat 1	0	0.34303114	-0.026797771	false
training	oneLayer	oneLayer - rat 1	0	0.35311192	-0.026797762	false
training	oneLayer	oneLayer - rat 1	0	0.36256412	-0.030712977	false
training	oneLayer	oneLayer - rat 1	0	0.37330255	-0.030712968	false
training	oneLayer	oneLayer - rat 1	0	0.3827489	-0.034625772	false
training	oneLayer	oneLayer - rat 1	0	0.3937467	-0.03462576	false
training	oneLayer	oneLayer - rat 1	0	0.4030304	-0.030780312	false
training	oneLayer	oneLayer - rat 1	0	0.41019636	-0.023614345	false
training	oneLayer	oneLayer - rat 1	0	0.4141639	-0.014035827	false
training	oneLayer	oneLayer - rat 1	0	0.42149606	-0.006703652	false
training	oneLayer	oneLayer - rat 1	0	0.42569244	0.0034272976	false
training	oneLayer	oneLayer - rat 1	0	0.4256924	0.013471624	false
training	oneLayer	oneLayer - rat 1	0	0.42149684	0.023600606	false
training	oneLayer	oneLayer - rat 1	0	0.41410333	0.030994099	false
training	oneLayer	oneLayer - rat 1	0	0.40635845	0.038738973	false
training	oneLayer	oneLayer - rat 1	0	0.396988	0.042620327	false
training	oneLayer	oneLayer - rat 1	0	0.3861253	0.042620316	false
training	oneLayer	oneLayer - rat 1	0	0.37642992	0.03860435	false
training	oneLayer	oneLayer - rat 1	0	0.3692314	0.031405833	false
training	oneLayer	oneLayer - rat 1	0	0.35981217	0.027504249	false
training	oneLayer	oneLayer - rat 1	0	0.35271034	0.020402398	false
training	oneLayer	oneLayer - rat 1	0	0.34287944	0.016330294	false
training	oneLayer	oneLayer - rat 1	0	0.33529547	0.008746304	false
training	oneLayer	oneLayer - rat 1	0	0.3258552	0.0048360014	false
training	oneLayer	oneLayer - rat 1	0	0.31810024	-0.0029189691	false
training	oneLayer	oneLayer - rat 1	0	0.30836618	-0.006950961	false
training	oneLayer	oneLayer - rat 1	0	0.29782218	-0.006950971	false
training	oneLayer	oneLayer - rat 1	0	0.28766876	-0.011156668	false
training	oneLayer	oneLayer - rat 1	0	0.27711314	-0.011156678	false
training	oneLayer	oneLayer - rat 1	0	0.26732257	-0.0152120795	false
training	oneLayer	oneLayer - rat 1	0	0.25671744	-0.01521209	false
training	oneLayer	oneLayer - rat 1	0	0.24703114	-0.019224297	false
training	oneLayer	oneLayer - rat 1	0	0.23669556	-0.019224307	false
training	oneLayer	oneLayer - rat 1	0	0.2273633	-0.023089867	false
training	oneLayer	oneLayer - rat 1	0	0.21703538	-0.023089876	false
training	oneLayer	oneLayer - rat 1	0	0.20698184	-0.027254201	false
training	oneLayer	oneLayer - rat 1	0	0.19656405	-0.02725421	false
training	oneLayer	oneLayer - rat 1	0	0.18699388	-0.031218313	false
training	oneLayer	oneLayer - rat 1	0	0.17698397	-0.031218322	false
training	oneLayer	oneLayer - rat 1	0	0.1674442	-0.035169832	false
training	oneLayer	oneLayer - rat 1	0	0.15703757	-0.035169844	false
training	oneLayer	oneLayer - rat 1	0	0.1474979	-0.039121315	false
training	oneLayer	oneLayer - rat 1	0	0.13744868	-0.039121326	false
training	oneLayer	oneLayer - rat 1	0	0.1275039	-0.0432406	false
training	oneLayer	oneLayer - rat 1	0	0.11659665	-0.04324061	false
training	oneLayer	oneLayer - rat 1	0	0.10643952	-0.04744784	false
training	oneLayer	oneLayer - rat 1	0	0.09618543	-0.047447853	false
training	oneLayer	oneLayer - rat 1	0	0.08654747	-0.051440038	false
training	oneLayer	oneLayer - rat 1	0	0.07574795	-0.051440045	false
training	oneLayer	oneLayer - rat 1	0	0.06619729	-0.055396073	false
training	oneLayer	oneLayer - rat 1	0	0.05540331	-0.055396084	false
training	oneLayer	oneLayer - rat 1	0	0.045806743	-0.05937112	false
training	oneLayer	oneLayer - rat 1	0	0.035357155	-0.059371132	false
training	oneLayer	oneLayer - rat 1	0	0.02560493	-0.06341065	false
training	oneLayer	oneLayer - rat 1	0	0.014859137	-0.063410655	false
training	oneLayer	oneLayer - rat 1	0	0.005609839	-0.067241855	false
training	oneLayer	oneLayer - rat 1	0	-0.004782429	-0.06724186	false
training	oneLayer	oneLayer - rat 1	0	-0.014134373	-0.071115576	false
training	oneLayer	oneLayer - rat 1	0	-0.024179615	-0.07111558	false
training	oneLayer	oneLayer - rat 1	0	-0.034095585	-0.075222924	false
training	oneLayer	oneLayer - rat 1	0	-0.044348296	-0.07522294	false
training	oneLayer	oneLayer - rat 1	0	-0.05416465	-0.07928902	false
training	oneLayer	oneLayer - rat 1	0	-0.065039515	-0.07928903	false
training	oneLayer	oneLayer - rat 1	0	-0.07444179	-0.08318359	false
training	oneLayer	oneLayer - rat 1	0	-0.085404836	-0.0831836	false
training	oneLayer	oneLayer - rat 1	0	-0.09502395	-0.08716798	false
training	oneLayer	oneLayer - rat 1	0	-0.10512266	-0.087167986	false
training	oneLayer	oneLayer - rat 1	0	-0.115201674	-0.09134286	false
training	oneLayer	oneLayer - rat 1	0	-0.12579839	-0.091342874	false
training	oneLayer	oneLayer - rat 1	0	-0.1351902	-0.0952331	false
training	oneLayer	oneLayer - rat 1	0	-0.14614353	-0.09523311	false
training	oneLayer	oneLayer - rat 1	0	-0.15604319	-0.099333696	false
training	oneLayer	oneLayer - rat 1	0	-0.16671096	-0.0993337	false
training	oneLayer	oneLayer - rat 1	0	-0.17625776	-0.10328814	false
training	oneLayer	oneLayer - rat 1	0	-0.18673405	-0.103288144	false
training	oneLayer	oneLayer - rat 1	0	-0.19619921	-0.10720875	false
training	oneLayer	oneLayer - rat 1	0	-0.20690866	-0.107208766	false
training	oneLayer	oneLayer - rat 1	0	-0.21687572	-0.10308028	false
training	oneLayer	oneLayer - rat 1	0	-0.22709498	-0.10308029	false
training	oneLayer	oneLayer - rat 1	0	-0.23706746	-0.09894957	false
training	oneLayer	oneLayer - rat 1	0	-0.24780285	-0.098949574	false
training	oneLayer	oneLayer - rat 1	0	-0.25788987	-0.09477141	false
training	oneLayer	oneLayer - rat 1	0	-0.26876625	-0.094771415	false
training	oneLayer	oneLayer - rat 1	0	-0.27888843	-0.09057868	false
training	oneLayer	oneLayer - rat 1	0	-0.2891265	-0.09057869	false
training	oneLayer	oneLayer - rat 1	0	-0.29864532	-0.08663588	false
training	oneLayer	oneLayer - rat 1	0	-0.30964312	-0.086635895	false
training	oneLayer	oneLayer - rat 1	0	-0.31893715	-0.082786195	false
training	oneLayer	oneLayer - rat 1	0	-0.32912913	-0.08278621	false
training	oneLayer	oneLayer - rat 1	0	-0.33849758	-0.07890569	false
training	oneLayer	oneLayer - rat 1	0	-0.3492295	-0.078905694	false
training	oneLayer	oneLayer - rat 1	0	-0.35937688	-0.07470252	false
training	oneLayer	oneLayer - rat 1	0	-0.3695974	-0.07470253	false
training	oneLayer	oneLayer - rat 1	0	-0.3793142	-0.07067771	false
training	oneLayer	oneLayer - rat 1	0	-0.38952836	-0.07067772	false
training	oneLayer	oneLayer - rat 1	0	-0.39904916	-0.06673408	false
training	oneLayer	oneLayer - rat 1	0	-0.40677458	-0.05900869	false
training	oneLayer	oneLayer - rat 1	0	-0.4142225	-0.051560782	false
training	oneLayer	oneLayer - rat 1	0	-0.42146686	-0.044316445	false
training	oneLayer	oneLayer - rat 1	0	-0.42859867	-0.037184633	false
training	oneLayer	oneLayer - rat 1	0	-0.4326887	-0.02731047	false
training	oneLayer	oneLayer - rat 1	0	-0.4326887	-0.017160937	false
training	oneLayer	oneLayer - rat 1	0	-0.42858097	-0.007243979	false
training	oneLayer	oneLayer - rat 1	0	-0.4213948	-5.778185E-5	false
training	oneLayer	oneLayer - rat 1	0	-0.41137028	0.0040945183	false
training	oneLayer	oneLayer - rat 1	0	-0.40422025	0.0112445755	false
training	oneLayer	oneLayer - rat 1	0	-0.39431873	0.015345924	false
training	oneLayer	oneLayer - rat 1	0	-0.38360742	0.015345933	false
training	oneLayer	oneLayer - rat 1	0	-0.37356764	0.011187323	false
training	oneLayer	oneLayer - rat 1	0	-0.36632758	0.0039473036	false
training	oneLayer	oneLayer - rat 1	0	-0.35652453	-1.1324823E-4	false
training	oneLayer	oneLayer - rat 1	0	-0.3489043	-0.0077334703	false
training	oneLayer	oneLayer - rat 1	0	-0.33963847	-0.01157149	false
training	oneLayer	oneLayer - rat 1	0	-0.3289583	-0.011571481	false
training	oneLayer	oneLayer - rat 1	0	-0.31895554	-0.01571475	false
training	oneLayer	oneLayer - rat 1	0	-0.30881357	-0.01571474	false
training	oneLayer	oneLayer - rat 1	0	-0.29885527	-0.019839596	false
training	oneLayer	oneLayer - rat 1	0	-0.2882878	-0.019839587	false
training	oneLayer	oneLayer - rat 1	0	-0.2787013	-0.023810416	false
training	oneLayer	oneLayer - rat 1	0	-0.26841608	-0.023810407	false
training	oneLayer	oneLayer - rat 1	0	-0.25906712	-0.027682861	false
training	oneLayer	oneLayer - rat 1	0	-0.24897389	-0.027682854	false
training	oneLayer	oneLayer - rat 1	0	-0.23947793	-0.0316162	false
training	oneLayer	oneLayer - rat 1	0	-0.22889665	-0.031616192	false
training	oneLayer	oneLayer - rat 1	0	-0.21915793	-0.035650086	false
training	oneLayer	oneLayer - rat 1	0	-0.20846231	-0.03565008	false
training	oneLayer	oneLayer - rat 1	0	-0.1988558	-0.039629214	false
training	oneLayer	oneLayer - rat 1	0	-0.18843243	-0.039629202	false
training	oneLayer	oneLayer - rat 1	0	-0.17902005	-0.043527927	false
training	oneLayer	oneLayer - rat 1	0	-0.16802804	-0.043527916	false
training	oneLayer	oneLayer - rat 1	0	-0.15837847	-0.04752489	false
training	oneLayer	oneLayer - rat 1	0	-0.14768632	-0.047524884	false
training	oneLayer	oneLayer - rat 1	0	-0.13838953	-0.05137573	false
training	oneLayer	oneLayer - rat 1	0	-0.12831067	-0.05137572	false
training	oneLayer	oneLayer - rat 1	0	-0.118600145	-0.05539794	false
training	oneLayer	oneLayer - rat 1	0	-0.10810912	-0.055397928	false
training	oneLayer	oneLayer - rat 1	0	-0.09842668	-0.059408516	false
training	oneLayer	oneLayer - rat 1	0	-0.08766563	-0.05940851	false
training	oneLayer	oneLayer - rat 1	0	-0.0783831	-0.06325345	false
training	oneLayer	oneLayer - rat 1	0	-0.067957975	-0.06325344	false
training	oneLayer	oneLayer - rat 1	0	-0.058557894	-0.06714707	false
training	oneLayer	oneLayer - rat 1	0	-0.04821297	-0.06714706	false
training	oneLayer	oneLayer - rat 1	0	-0.038161658	-0.071310446	false
training	oneLayer	oneLayer - rat 1	0	-0.027270064	-0.07131043	false
training	oneLayer	oneLayer - rat 1	0	-0.017985906	-0.07515605	false
training	oneLayer	oneLayer - rat 1	0	-0.0077818455	-0.07515604	false
training	oneLayer	oneLayer - rat 1	0	0.0014586805	-0.07898358	false
training	oneLayer	oneLayer - rat 1	0	0.0118252365	-0.07898357	false
training	oneLayer	oneLayer - rat 1	0	0.02122518	-0.082877144	false
training	oneLayer	oneLayer - rat 1	0	0.031341385	-0.08287714	false
training	oneLayer	oneLayer - rat 1	0	0.04146557	-0.0870707	false
training	oneLayer	oneLayer - rat 1	0	0.05220319	-0.08707069	false
training	oneLayer	oneLayer - rat 1	0	0.062273763	-0.09124205	false
training	oneLayer	oneLayer - rat 1	0	0.07253761	-0.09124204	false
training	oneLayer	oneLayer - rat 1	0	0.08239657	-0.095325746	false
training	oneLayer	oneLayer - rat 1	0	0.092398636	-0.09532574	false
training	oneLayer	oneLayer - rat 1	0	0.10169694	-0.09917721	false
training	oneLayer	oneLayer - rat 1	0	0.11216313	-0.0991772	false
training	oneLayer	oneLayer - rat 1	0	0.121408	-0.10300654	false
training	oneLayer	oneLayer - rat 1	0	0.13163391	-0.103006534	false
training	oneLayer	oneLayer - rat 1	0	0.14119618	-0.10696735	false
training	oneLayer	oneLayer - rat 1	0	0.15132086	-0.10696734	false
training	oneLayer	oneLayer - rat 1	0	0.16091588	-0.110941716	false
training	oneLayer	oneLayer - rat 1	0	0.17137904	-0.11094171	false
training	oneLayer	oneLayer - rat 1	0	0.18077232	-0.11483252	false
training	oneLayer	oneLayer - rat 1	0	0.19119057	-0.114832506	false
training	oneLayer	oneLayer - rat 1	0	0.20062096	-0.1109263	false
training	oneLayer	oneLayer - rat 1	0	0.2077725	-0.103774756	false
training	oneLayer	oneLayer - rat 1	0	0.21750064	-0.099745214	false
training	oneLayer	oneLayer - rat 1	0	0.22848946	-0.0997452	false
training	oneLayer	oneLayer - rat 1	0	0.23796868	-0.095818765	false
training	oneLayer	oneLayer - rat 1	0	0.24805479	-0.09581876	false
training	oneLayer	oneLayer - rat 1	0	0.25757018	-0.09187734	false
training	oneLayer	oneLayer - rat 1	0	0.26787794	-0.091877334	false
training	oneLayer	oneLayer - rat 1	0	0.2778999	-0.08772609	false
training	oneLayer	oneLayer - rat 1	0	0.28874528	-0.08772608	false
training	oneLayer	oneLayer - rat 1	0	0.2988858	-0.08352573	false
training	oneLayer	oneLayer - rat 1	0	0.30935976	-0.08352572	false
training	oneLayer	oneLayer - rat 1	0	0.3188098	-0.079611376	false
training	oneLayer	oneLayer - rat 1	0	0.32920638	-0.07961137	false
training	oneLayer	oneLayer - rat 1	0	0.3384763	-0.07577162	false
training	oneLayer	oneLayer - rat 1	0	0.34881485	-0.075771615	false
training	oneLayer	oneLayer - rat 1	0	0.35889807	-0.071595006	false
training	oneLayer	oneLayer - rat 1	0	0.36890757	-0.071595	false
training	oneLayer	oneLayer - rat 1	0	0.37829605	-0.06770615	false
training	oneLayer	oneLayer - rat 1	0	0.38838047	-0.067706145	false
training	oneLayer	oneLayer - rat 1	0	0.39804706	-0.0637021	false
training	oneLayer	oneLayer - rat 1	0	0.40528533	-0.056463838	false
training	oneLayer	oneLayer - rat 1	0	0.4092428	-0.046909582	false
training	oneLayer	oneLayer - rat 1	0	0.41343862	-0.036780003	false
training	oneLayer	oneLayer - rat 1	0	0.41739723	-0.027222995	false
training	oneLayer	oneLayer - rat 1	0	0.41739723	-0.016276706	false
training	oneLayer	oneLayer - rat 1	0	0.41344246	-0.0067290906	false
training	oneLayer	oneLayer - rat 1	0	0.40584645	8.6691685E-4	false
training	oneLayer	oneLayer - rat 1	0	0.40171897	0.010831478	false
training	oneLayer	oneLayer - rat 1	0	0.39451644	0.018034004	false
training	oneLayer	oneLayer - rat 1	0	0.39036843	0.02804812	false
training	oneLayer	oneLayer - rat 1	0	0.39036843	0.03825471	false
training	oneLayer	oneLayer - rat 1	0	0.3864823	0.04763664	false
training	oneLayer	oneLayer - rat 1	0	0.3794105	0.054708406	false
training	oneLayer	oneLayer - rat 1	0	0.37528098	0.06467799	false
training	oneLayer	oneLayer - rat 1	0	0.36758024	0.0723787	false
training	oneLayer	oneLayer - rat 1	0	0.36346725	0.08230837	false
training	oneLayer	oneLayer - rat 1	0	0.36346722	0.093282014	false
training	oneLayer	oneLayer - rat 1	0	0.3674232	0.1028326	false
training	oneLayer	oneLayer - rat 1	0	0.36742318	0.11310468	false
training	oneLayer	oneLayer - rat 1	0	0.363419	0.12277159	false
training	oneLayer	oneLayer - rat 1	0	0.363419	0.13332662	false
training	oneLayer	oneLayer - rat 1	0	0.35931322	0.14323883	false
training	oneLayer	oneLayer - rat 1	0	0.35175946	0.15079257	false
training	oneLayer	oneLayer - rat 1	0	0.34789518	0.16012178	false
training	oneLayer	oneLayer - rat 1	0	0.3405957	0.16742125	false
training	oneLayer	oneLayer - rat 1	0	0.3366778	0.17687987	false
training	oneLayer	oneLayer - rat 1	0	0.32937396	0.1841837	false
training	oneLayer	oneLayer - rat 1	0	0.3254517	0.19365278	false
training	oneLayer	oneLayer - rat 1	0	0.3183058	0.20079868	false
training	oneLayer	oneLayer - rat 1	0	0.31438035	0.21027552	false
training	oneLayer	oneLayer - rat 1	0	0.30686456	0.21779129	false
training	oneLayer	oneLayer - rat 1	0	0.30286437	0.22744857	false
training	oneLayer	oneLayer - rat 1	0	0.29535496	0.23495796	false
training	oneLayer	oneLayer - rat 1	0	0.29135922	0.24460456	false
training	oneLayer	oneLayer - rat 1	0	0.28413817	0.2518256	false
training	oneLayer	oneLayer - rat 1	0	0.28020483	0.26132149	false
training	oneLayer	oneLayer - rat 1	0	0.27304277	0.26848355	false
training	oneLayer	oneLayer - rat 1	0	0.26887015	0.27855712	false
training	oneLayer	oneLayer - rat 1	0	0.26115626	0.28627098	false
training	oneLayer	oneLayer - rat 1	0	0.25717586	0.29588053	false
training	oneLayer	oneLayer - rat 1	0	0.24962944	0.30342692	false
training	oneLayer	oneLayer - rat 1	0	0.24575377	0.3127836	false
training	oneLayer	oneLayer - rat 1	0	0.23800586	0.3205315	false
training	oneLayer	oneLayer - rat 1	0	0.23384929	0.33056632	false
training	oneLayer	oneLayer - rat 1	0	0.2264417	0.3379739	false
training	oneLayer	oneLayer - rat 1	0	0.22235586	0.34783795	false
training	oneLayer	oneLayer - rat 1	0	0.21477498	0.3554188	false
training	oneLayer	oneLayer - rat 1	0	0.21060759	0.3654798	false
training	oneLayer	oneLayer - rat 1	0	0.20288803	0.3731993	false
training	oneLayer	oneLayer - rat 1	0	0.19897054	0.38265693	false
training	oneLayer	oneLayer - rat 1	0	0.1917195	0.38990796	false
training	oneLayer	oneLayer - rat 1	0	0.18233259	0.39379615	false
training	oneLayer	oneLayer - rat 1	0	0.17204097	0.39379615	false
training	oneLayer	oneLayer - rat 1	0	0.1625357	0.39773333	false
training	oneLayer	oneLayer - rat 1	0	0.151821	0.39773333	false
training	oneLayer	oneLayer - rat 1	0	0.1424351	0.40162107	false
training	oneLayer	oneLayer - rat 1	0	0.1321363	0.40162107	false
training	oneLayer	oneLayer - rat 1	0	0.12275888	0.39773682	false
training	oneLayer	oneLayer - rat 1	0	0.11292515	0.39366353	false
training	oneLayer	oneLayer - rat 1	0	0.10284281	0.38948727	false
training	oneLayer	oneLayer - rat 1	0	0.09279476	0.38532522	false
training	oneLayer	oneLayer - rat 1	0	0.083460465	0.38145882	false
training	oneLayer	oneLayer - rat 1	0	0.07351492	0.37733924	false
training	oneLayer	oneLayer - rat 1	0	0.06393415	0.37337074	false
training	oneLayer	oneLayer - rat 1	0	0.054206714	0.3693415	false
training	oneLayer	oneLayer - rat 1	0	0.044800572	0.36544535	false
training	oneLayer	oneLayer - rat 1	0	0.035357285	0.3615338	false
training	oneLayer	oneLayer - rat 1	0	0.025566641	0.35747835	false
training	oneLayer	oneLayer - rat 1	0	0.015956726	0.35349777	false
training	oneLayer	oneLayer - rat 1	0	0.006463573	0.3495656	false
training	oneLayer	oneLayer - rat 1	0	-0.0034138898	0.34547418	false
training	oneLayer	oneLayer - rat 1	0	-0.01267259	0.3416391	false
training	oneLayer	oneLayer - rat 1	0	-0.022360321	0.3376263	false
training	oneLayer	oneLayer - rat 1	0	-0.032356817	0.3334856	false
training	oneLayer	oneLayer - rat 1	0	-0.041605003	0.32965487	false
training	oneLayer	oneLayer - rat 1	0	-0.05167595	0.32548335	false
training	oneLayer	oneLayer - rat 1	0	-0.06156597	0.32138675	false
training	oneLayer	oneLayer - rat 1	0	-0.07108594	0.31744343	false
training	oneLayer	oneLayer - rat 1	0	-0.08174415	0.31744343	false
training	oneLayer	oneLayer - rat 1	0	-0.09129006	0.31348938	false
training	oneLayer	oneLayer - rat 1	0	-0.10210838	0.31348935	false
training	oneLayer	oneLayer - rat 1	0	-0.11171817	0.31746987	false
training	oneLayer	oneLayer - rat 1	0	-0.12193309	0.31746984	false
training	oneLayer	oneLayer - rat 1	0	-0.13202927	0.31328785	false
training	oneLayer	oneLayer - rat 1	0	-0.14290491	0.31328785	false
training	oneLayer	oneLayer - rat 1	0	-0.15303685	0.30909106	false
training	oneLayer	oneLayer - rat 1	0	-0.16323489	0.30909103	false
training	oneLayer	oneLayer - rat 1	0	-0.17337283	0.3132903	false
training	oneLayer	oneLayer - rat 1	0	-0.18376033	0.3132903	false
training	oneLayer	oneLayer - rat 1	0	-0.1939054	0.30908805	false
training	oneLayer	oneLayer - rat 1	0	-0.20469664	0.30908805	false
training	oneLayer	oneLayer - rat 1	0	-0.21457529	0.30499616	false
training	oneLayer	oneLayer - rat 1	0	-0.22460237	0.30499616	false
training	oneLayer	oneLayer - rat 1	0	-0.23439689	0.3009391	false
training	oneLayer	oneLayer - rat 1	0	-0.24525146	0.3009391	false
training	oneLayer	oneLayer - rat 1	0	-0.25525036	0.29679742	false
training	oneLayer	oneLayer - rat 1	0	-0.26561278	0.2967974	false
training	oneLayer	oneLayer - rat 1	0	-0.27534455	0.30082843	false
training	oneLayer	oneLayer - rat 1	0	-0.28568214	0.3008284	false
training	oneLayer	oneLayer - rat 1	0	-0.29510957	0.29692343	false
training	oneLayer	oneLayer - rat 1	0	-0.3024293	0.28960368	false
training	oneLayer	oneLayer - rat 1	0	-0.30645764	0.2798784	false
training	oneLayer	oneLayer - rat 1	0	-0.31415024	0.27218577	false
training	oneLayer	oneLayer - rat 1	0	-0.3181656	0.26249182	false
training	oneLayer	oneLayer - rat 1	0	-0.3257448	0.2549126	false
training	oneLayer	oneLayer - rat 1	0	-0.32960233	0.24559972	false
training	oneLayer	oneLayer - rat 1	0	-0.3296023	0.23502614	false
training	oneLayer	oneLayer - rat 1	0	-0.3336887	0.2251607	false
training	oneLayer	oneLayer - rat 1	0	-0.33368868	0.21483631	false
training	oneLayer	oneLayer - rat 1	0	-0.3376704	0.20522358	false
training	oneLayer	oneLayer - rat 1	0	-0.3376704	0.1951464	false
training	oneLayer	oneLayer - rat 1	0	-0.3416847	0.18545496	false
training	oneLayer	oneLayer - rat 1	0	-0.3416847	0.17489737	false
training	oneLayer	oneLayer - rat 1	0	-0.34588963	0.16474573	false
training	oneLayer	oneLayer - rat 1	0	-0.34588963	0.15472616	false
training	oneLayer	oneLayer - rat 1	0	-0.35002825	0.14473458	false
training	oneLayer	oneLayer - rat 1	0	-0.35002825	0.13437882	false
training	oneLayer	oneLayer - rat 1	0	-0.3540728	0.124614336	false
training	oneLayer	oneLayer - rat 1	0	-0.3540728	0.11420359	false
training	oneLayer	oneLayer - rat 1	0	-0.35792306	0.10490818	false
training	oneLayer	oneLayer - rat 1	0	-0.35792306	0.09439509	false
training	oneLayer	oneLayer - rat 1	0	-0.36199477	0.08456509	false
training	oneLayer	oneLayer - rat 1	0	-0.36907712	0.07748272	false
training	oneLayer	oneLayer - rat 1	0	-0.37322718	0.067463554	false
training	oneLayer	oneLayer - rat 1	0	-0.38079914	0.05989157	false
training	oneLayer	oneLayer - rat 1	0	-0.3849728	0.04981544	false
training	oneLayer	oneLayer - rat 1	0	-0.39241344	0.04237481	false
training	oneLayer	oneLayer - rat 1	0	-0.39637652	0.032807022	false
training	oneLayer	oneLayer - rat 1	0	-0.4037591	0.025424436	false
training	oneLayer	oneLayer - rat 1	0	-0.40759632	0.01616052	false
training	oneLayer	oneLayer - rat 1	0	-0.40759632	0.005451933	false
training	oneLayer	oneLayer - rat 1	0	-0.40344056	-0.00458091	false
training	oneLayer	oneLayer - rat 1	0	-0.39630634	-0.011715136	false
training	oneLayer	oneLayer - rat 1	0	-0.38665935	-0.015711026	false
training	oneLayer	oneLayer - rat 1	0	-0.37624153	-0.015711015	false
training	oneLayer	oneLayer - rat 1	0	-0.3666423	-0.019687137	false
training	oneLayer	oneLayer - rat 1	0	-0.35576668	-0.019687125	false
training	oneLayer	oneLayer - rat 1	0	-0.34648493	-0.023531742	false
training	oneLayer	oneLayer - rat 1	0	-0.33596098	-0.023531731	false
training	oneLayer	oneLayer - rat 1	0	-0.3261327	-0.027602723	false
training	oneLayer	oneLayer - rat 1	0	-0.31553382	-0.027602712	false
training	oneLayer	oneLayer - rat 1	0	-0.3056064	-0.031714767	false
training	oneLayer	oneLayer - rat 1	0	-0.29534325	-0.031714756	false
training	oneLayer	oneLayer - rat 1	0	-0.2861001	-0.035543386	false
training	oneLayer	oneLayer - rat 1	0	-0.275123	-0.035543375	false
training	oneLayer	oneLayer - rat 1	0	-0.26563364	-0.03947399	false
training	oneLayer	oneLayer - rat 1	0	-0.25539318	-0.03947398	false
training	oneLayer	oneLayer - rat 1	0	-0.24615166	-0.043301933	false
training	oneLayer	oneLayer - rat 1	0	-0.23601025	-0.04330192	false
training	oneLayer	oneLayer - rat 1	0	-0.22610946	-0.047402952	false
training	oneLayer	oneLayer - rat 1	0	-0.21598427	-0.04740294	false
training	oneLayer	oneLayer - rat 1	0	-0.20644449	-0.051354438	false
training	oneLayer	oneLayer - rat 1	0	-0.19596247	-0.051354427	false
training	oneLayer	oneLayer - rat 1	0	-0.1858009	-0.05556348	false
training	oneLayer	oneLayer - rat 1	0	-0.17544731	-0.05556347	false
training	oneLayer	oneLayer - rat 1	0	-0.16608296	-0.0594423	false
training	oneLayer	oneLayer - rat 1	0	-0.15571682	-0.05944229	false
training	oneLayer	oneLayer - rat 1	0	-0.14645709	-0.06327778	false
training	oneLayer	oneLayer - rat 1	0	-0.136457	-0.06327777	false
training	oneLayer	oneLayer - rat 1	0	-0.12718002	-0.06712041	false
training	oneLayer	oneLayer - rat 1	0	-0.11648345	-0.067120396	false
training	oneLayer	oneLayer - rat 1	0	-0.10658263	-0.07122144	false
training	oneLayer	oneLayer - rat 1	0	-0.09560075	-0.071221426	false
training	oneLayer	oneLayer - rat 1	0	-0.08566075	-0.0753387	false
training	oneLayer	oneLayer - rat 1	0	-0.07487107	-0.075338684	false
training	oneLayer	oneLayer - rat 1	0	-0.06490826	-0.079465404	false
training	oneLayer	oneLayer - rat 1	0	-0.05465351	-0.07946539	false
training	oneLayer	oneLayer - rat 1	0	-0.045012996	-0.08345861	false
training	oneLayer	oneLayer - rat 1	0	-0.034505337	-0.0834586	false
training	oneLayer	oneLayer - rat 1	0	-0.025067337	-0.08736794	false
training	oneLayer	oneLayer - rat 1	0	-0.015026121	-0.08736793	false
training	oneLayer	oneLayer - rat 1	0	-0.005265398	-0.09141094	false
training	oneLayer	oneLayer - rat 1	0	0.0056320643	-0.09141093	false
training	oneLayer	oneLayer - rat 1	0	0.015549378	-0.0955188	false
training	oneLayer	oneLayer - rat 1	0	0.025605552	-0.09551879	false
training	oneLayer	oneLayer - rat 1	0	0.035440106	-0.09959238	false
training	oneLayer	oneLayer - rat 1	0	0.04564063	-0.09959237	false
training	oneLayer	oneLayer - rat 1	0	0.055237632	-0.10356757	false
training	oneLayer	oneLayer - rat 1	0	0.06554312	-0.10356756	false
training	oneLayer	oneLayer - rat 1	0	0.07502485	-0.10749501	false
training	oneLayer	oneLayer - rat 1	0	0.085462935	-0.107494995	false
training	oneLayer	oneLayer - rat 1	0	0.09554064	-0.11166931	false
training	oneLayer	oneLayer - rat 1	0	0.10599982	-0.1116693	false
training	oneLayer	oneLayer - rat 1	0	0.116032496	-0.11582496	false
training	oneLayer	oneLayer - rat 1	0	0.12676255	-0.115824945	false
training	oneLayer	oneLayer - rat 1	0	0.13625276	-0.11975591	false
training	oneLayer	oneLayer - rat 1	0	0.14656621	-0.1197559	false
training	oneLayer	oneLayer - rat 1	0	0.15609467	-0.123702705	false
training	oneLayer	oneLayer - rat 1	0	0.1668196	-0.12370269	false
training	oneLayer	oneLayer - rat 1	0	0.1766802	-0.11961828	false
training	oneLayer	oneLayer - rat 1	0	0.18688947	-0.11961827	false
training	oneLayer	oneLayer - rat 1	0	0.19705175	-0.115408905	false
training	oneLayer	oneLayer - rat 1	0	0.20773508	-0.11540889	false
training	oneLayer	oneLayer - rat 1	0	0.21718381	-0.111495085	false
training	oneLayer	oneLayer - rat 1	0	0.22796051	-0.11149507	false
training	oneLayer	oneLayer - rat 1	0	0.2378068	-0.10741659	false
training	oneLayer	oneLayer - rat 1	0	0.24787267	-0.107416585	false
training	oneLayer	oneLayer - rat 1	0	0.2575401	-0.10341219	false
training	oneLayer	oneLayer - rat 1	0	0.2677518	-0.10341217	false
training	oneLayer	oneLayer - rat 1	0	0.27727655	-0.09946689	false
training	oneLayer	oneLayer - rat 1	0	0.2878625	-0.09946688	false
training	oneLayer	oneLayer - rat 1	0	0.29792362	-0.095299415	false
training	oneLayer	oneLayer - rat 1	0	0.30843014	-0.09529941	false
training	oneLayer	oneLayer - rat 1	0	0.3178943	-0.09137922	false
training	oneLayer	oneLayer - rat 1	0	0.3280595	-0.0913792	false
training	oneLayer	oneLayer - rat 1	0	0.33785528	-0.08732165	false
training	oneLayer	oneLayer - rat 1	0	0.34810722	-0.08732164	false
training	oneLayer	oneLayer - rat 1	0	0.357648	-0.08336971	false
training	oneLayer	oneLayer - rat 1	0	0.36846998	-0.083369695	false
training	oneLayer	oneLayer - rat 1	0	0.37806326	-0.07939601	false
training	oneLayer	oneLayer - rat 1	0	0.38579822	-0.07166106	false
training	oneLayer	oneLayer - rat 1	0	0.39580938	-0.06751428	false
training	oneLayer	oneLayer - rat 1	0	0.40343073	-0.059892923	false
training	oneLayer	oneLayer - rat 1	0	0.41314986	-0.05586712	false
training	oneLayer	oneLayer - rat 1	0	0.42092466	-0.048092283	false
training	oneLayer	oneLayer - rat 1	0	0.42493626	-0.038407393	false
training	oneLayer	oneLayer - rat 1	0	0.42493626	-0.02744576	false
training	oneLayer	oneLayer - rat 1	0	0.42877474	-0.018178832	false
training	oneLayer	oneLayer - rat 1	0	0.4287747	-0.0074927215	false
training	oneLayer	oneLayer - rat 1	0	0.42459473	0.0025986803	false
training	oneLayer	oneLayer - rat 1	0	0.4173942	0.009799183	false
training	oneLayer	oneLayer - rat 1	0	0.41347066	0.019271448	false
training	oneLayer	oneLayer - rat 1	0	0.4063684	0.026373668	false
training	oneLayer	oneLayer - rat 1	0	0.4025177	0.035670023	false
training	oneLayer	oneLayer - rat 1	0	0.39537796	0.042809777	false
training	oneLayer	oneLayer - rat 1	0	0.39128375	0.052694008	false
training	oneLayer	oneLayer - rat 1	0	0.38352728	0.060450457	false
training	oneLayer	oneLayer - rat 1	0	0.37955627	0.07003729	false
training	oneLayer	oneLayer - rat 1	0	0.37238294	0.077210605	false
training	oneLayer	oneLayer - rat 1	0	0.3682335	0.08722823	false
training	oneLayer	oneLayer - rat 1	0	0.36063272	0.09482899	false
training	oneLayer	oneLayer - rat 1	0	0.3566281	0.104497015	false
training	oneLayer	oneLayer - rat 1	0	0.34939176	0.11173333	false
training	oneLayer	oneLayer - rat 1	0	0.34525844	0.12171197	false
training	oneLayer	oneLayer - rat 1	0	0.3377751	0.1291953	false
training	oneLayer	oneLayer - rat 1	0	0.33389458	0.1385637	false
training	oneLayer	oneLayer - rat 1	0	0.32629263	0.14616561	false
training	oneLayer	oneLayer - rat 1	0	0.32240012	0.15556294	false
training	oneLayer	oneLayer - rat 1	0	0.31483522	0.16312781	false
training	oneLayer	oneLayer - rat 1	0	0.3109852	0.17242256	false
training	oneLayer	oneLayer - rat 1	0	0.3037107	0.17969707	false
training	oneLayer	oneLayer - rat 1	0	0.2997624	0.18922907	false
training	oneLayer	oneLayer - rat 1	0	0.2924163	0.19657515	false
training	oneLayer	oneLayer - rat 1	0	0.28842995	0.20619904	false
training	oneLayer	oneLayer - rat 1	0	0.28075173	0.21387723	false
training	oneLayer	oneLayer - rat 1	0	0.27666858	0.22373477	false
training	oneLayer	oneLayer - rat 1	0	0.26925826	0.23114507	false
training	oneLayer	oneLayer - rat 1	0	0.2653323	0.24062316	false
training	oneLayer	oneLayer - rat 1	0	0.25813586	0.24781959	false
training	oneLayer	oneLayer - rat 1	0	0.2540903	0.25758636	false
training	oneLayer	oneLayer - rat 1	0	0.24690257	0.2647741	false
training	oneLayer	oneLayer - rat 1	0	0.24305984	0.27405122	false
training	oneLayer	oneLayer - rat 1	0	0.2353229	0.28178817	false
training	oneLayer	oneLayer - rat 1	0	0.23142289	0.29120356	false
training	oneLayer	oneLayer - rat 1	0	0.22422285	0.2984036	false
training	oneLayer	oneLayer - rat 1	0	0.2202908	0.30789638	false
training	oneLayer	oneLayer - rat 1	0	0.21295047	0.3152367	false
training	oneLayer	oneLayer - rat 1	0	0.20901662	0.32473382	false
training	oneLayer	oneLayer - rat 1	0	0.2018422	0.33190823	false
training	oneLayer	oneLayer - rat 1	0	0.19800963	0.34116083	false
training	oneLayer	oneLayer - rat 1	0	0.19043177	0.34873867	false
training	oneLayer	oneLayer - rat 1	0	0.18634924	0.35859475	false
training	oneLayer	oneLayer - rat 1	0	0.17893796	0.36600602	false
training	oneLayer	oneLayer - rat 1	0	0.17475355	0.37610805	false
training	oneLayer	oneLayer - rat 1	0	0.16752777	0.3833338	false
training	oneLayer	oneLayer - rat 1	0	0.16343717	0.39320934	false
training	oneLayer	oneLayer - rat 1	0	0.15609407	0.40055242	false
training	oneLayer	oneLayer - rat 1	0	0.14619194	0.404654	false
training	oneLayer	oneLayer - rat 1	0	0.13527541	0.404654	false
training	oneLayer	oneLayer - rat 1	0	0.12603281	0.4084824	false
training	oneLayer	oneLayer - rat 1	0	0.11537887	0.40848237	false
training	oneLayer	oneLayer - rat 1	0	0.10550657	0.4125716	false
training	oneLayer	oneLayer - rat 1	0	0.095290095	0.41257158	false
training	oneLayer	oneLayer - rat 1	0	0.08581621	0.4164958	false
training	oneLayer	oneLayer - rat 1	0	0.075667925	0.41649577	false
training	oneLayer	oneLayer - rat 1	0	0.06609185	0.41252923	false
training	oneLayer	oneLayer - rat 1	0	0.056228347	0.40844363	false
training	oneLayer	oneLayer - rat 1	0	0.046951964	0.40460122	false
training	oneLayer	oneLayer - rat 1	0	0.037340444	0.40061995	false
training	oneLayer	oneLayer - rat 1	0	0.027456114	0.39652574	false
training	oneLayer	oneLayer - rat 1	0	0.017756563	0.39250803	false
training	oneLayer	oneLayer - rat 1	0	0.0081566395	0.3885316	false
training	oneLayer	oneLayer - rat 1	0	-0.0012607591	0.38463077	false
training	oneLayer	oneLayer - rat 1	0	-0.010786298	0.38068515	false
training	oneLayer	oneLayer - rat 1	0	-0.020536589	0.37664643	false
training	oneLayer	oneLayer - rat 1	0	-0.03032449	0.37259215	false
training	oneLayer	oneLayer - rat 1	0	-0.039978385	0.36859336	false
training	oneLayer	oneLayer - rat 1	0	-0.04925445	0.36475107	false
training	oneLayer	oneLayer - rat 1	0	-0.058908183	0.36075234	false
training	oneLayer	oneLayer - rat 1	0	-0.068647526	0.35671818	false
training	oneLayer	oneLayer - rat 1	0	-0.078694895	0.3525564	false
training	oneLayer	oneLayer - rat 1	0	-0.08875282	0.34839025	false
training	oneLayer	oneLayer - rat 1	0	-0.09839774	0.3443952	false
training	oneLayer	oneLayer - rat 1	0	-0.107999556	0.34041798	false
training	oneLayer	oneLayer - rat 1	0	-0.11737624	0.33653402	false
training	oneLayer	oneLayer - rat 1	0	-0.12671591	0.33266538	false
training	oneLayer	oneLayer - rat 1	0	-0.13662362	0.32856146	false
training	oneLayer	oneLayer - rat 1	0	-0.14602202	0.3246685	false
training	oneLayer	oneLayer - rat 1	0	-0.15610218	0.32049316	false
training	oneLayer	oneLayer - rat 1	0	-0.16569528	0.31651953	false
training	oneLayer	oneLayer - rat 1	0	-0.17578122	0.31651953	false
training	oneLayer	oneLayer - rat 1	0	-0.1857286	0.31239918	false
training	oneLayer	oneLayer - rat 1	0	-0.19667694	0.31239918	false
training	oneLayer	oneLayer - rat 1	0	-0.20676242	0.3082216	false
training	oneLayer	oneLayer - rat 1	0	-0.2170818	0.3082216	false
training	oneLayer	oneLayer - rat 1	0	-0.22666456	0.3121909	false
training	oneLayer	oneLayer - rat 1	0	-0.23756367	0.3121909	false
training	oneLayer	oneLayer - rat 1	0	-0.24687478	0.31604767	false
training	oneLayer	oneLayer - rat 1	0	-0.2578325	0.31604764	false
training	oneLayer	oneLayer - rat 1	0	-0.26772287	0.31195092	false
training	oneLayer	oneLayer - rat 1	0	-0.27792957	0.3119509	false
training	oneLayer	oneLayer - rat 1	0	-0.28798887	0.3077842	false
training	oneLayer	oneLayer - rat 1	0	-0.2986293	0.30778417	false
training	oneLayer	oneLayer - rat 1	0	-0.30795756	0.30392027	false
training	oneLayer	oneLayer - rat 1	0	-0.31506675	0.29681107	false
training	oneLayer	oneLayer - rat 1	0	-0.3243411	0.29296952	false
training	oneLayer	oneLayer - rat 1	0	-0.33154133	0.28576925	false
training	oneLayer	oneLayer - rat 1	0	-0.3409205	0.28188425	false
training	oneLayer	oneLayer - rat 1	0	-0.34802672	0.274778	false
training	oneLayer	oneLayer - rat 1	0	-0.35756493	0.27082714	false
training	oneLayer	oneLayer - rat 1	0	-0.3650322	0.26335987	false
training	oneLayer	oneLayer - rat 1	0	-0.36923623	0.25321034	false
training	oneLayer	oneLayer - rat 1	0	-0.36923623	0.24270768	false
training	oneLayer	oneLayer - rat 1	0	-0.36537948	0.2333967	false
training	oneLayer	oneLayer - rat 1	0	-0.3576576	0.22567484	false
training	oneLayer	oneLayer - rat 1	0	-0.34814832	0.22173597	false
training	oneLayer	oneLayer - rat 1	0	-0.34106973	0.2146574	false
training	oneLayer	oneLayer - rat 1	0	-0.33176816	0.21080457	false
training	oneLayer	oneLayer - rat 1	0	-0.32457876	0.2036152	false
training	oneLayer	oneLayer - rat 1	0	-0.31489462	0.19960392	false
training	oneLayer	oneLayer - rat 1	0	-0.30716434	0.19187365	false
training	oneLayer	oneLayer - rat 1	0	-0.29746312	0.18785529	false
training	oneLayer	oneLayer - rat 1	0	-0.2900516	0.1804438	false
training	oneLayer	oneLayer - rat 1	0	-0.28021905	0.17637104	false
training	oneLayer	oneLayer - rat 1	0	-0.27250013	0.16865213	false
training	oneLayer	oneLayer - rat 1	0	-0.26301408	0.16472289	false
training	oneLayer	oneLayer - rat 1	0	-0.25528166	0.15699047	false
training	oneLayer	oneLayer - rat 1	0	-0.24515086	0.15279418	false
training	oneLayer	oneLayer - rat 1	0	-0.23742908	0.14507242	false
training	oneLayer	oneLayer - rat 1	0	-0.22776689	0.14107022	false
training	oneLayer	oneLayer - rat 1	0	-0.22040915	0.1337125	false
training	oneLayer	oneLayer - rat 1	0	-0.21033873	0.12954122	false
training	oneLayer	oneLayer - rat 1	0	-0.20272946	0.12193196	false
training	oneLayer	oneLayer - rat 1	0	-0.19281581	0.11782561	false
training	oneLayer	oneLayer - rat 1	0	-0.18557869	0.1105885	false
training	oneLayer	oneLayer - rat 1	0	-0.17591722	0.1065866	false
training	oneLayer	oneLayer - rat 1	0	-0.16861567	0.09928506	false
training	oneLayer	oneLayer - rat 1	0	-0.15853162	0.09510813	false
training	oneLayer	oneLayer - rat 1	0	-0.15141918	0.08799569	false
training	oneLayer	oneLayer - rat 1	0	-0.1413704	0.083833374	false
training	oneLayer	oneLayer - rat 1	0	-0.13389601	0.076359004	false
training	oneLayer	oneLayer - rat 1	0	-0.123991795	0.07225656	false
training	oneLayer	oneLayer - rat 1	0	-0.11688267	0.065147445	false
training	oneLayer	oneLayer - rat 1	0	-0.10727534	0.06116797	false
training	oneLayer	oneLayer - rat 1	0	-0.09953234	0.05342499	false
training	oneLayer	oneLayer - rat 1	0	-0.09009526	0.049516037	false
training	oneLayer	oneLayer - rat 1	0	-0.08247285	0.04189365	false
training	oneLayer	oneLayer - rat 1	0	-0.07301553	0.037976317	false
training	oneLayer	oneLayer - rat 1	0	-0.06593467	0.03089547	false
training	oneLayer	oneLayer - rat 1	0	-0.056313694	0.026910344	false
training	oneLayer	oneLayer - rat 1	0	-0.048648585	0.01924525	false
training	oneLayer	oneLayer - rat 1	0	-0.03913511	0.015304654	false
training	oneLayer	oneLayer - rat 1	0	-0.03170139	0.007870954	false
training	oneLayer	oneLayer - rat 1	0	-0.02154559	0.003664299	false
training	oneLayer	oneLayer - rat 1	0	-0.014127322	-0.0037539524	false
training	oneLayer	oneLayer - rat 1	0	-0.0040547927	-0.007926116	false
training	oneLayer	oneLayer - rat 1	0	0.006819068	-0.007926103	false
training	oneLayer	oneLayer - rat 1	0	0.016244093	-0.011830063	false
training	oneLayer	oneLayer - rat 1	0	0.026592929	-0.01183005	false
training	oneLayer	oneLayer - rat 1	0	0.036106855	-0.015770834	false
training	oneLayer	oneLayer - rat 1	0	0.046868823	-0.01577082	false
training	oneLayer	oneLayer - rat 1	0	0.056995913	-0.019965585	false
training	oneLayer	oneLayer - rat 1	0	0.067115	-0.019965572	false
training	oneLayer	oneLayer - rat 1	0	0.07725151	-0.024164235	false
training	oneLayer	oneLayer - rat 1	0	0.08786705	-0.024164222	false
training	oneLayer	oneLayer - rat 1	0	0.09737019	-0.028100535	false
training	oneLayer	oneLayer - rat 1	0	0.10764432	-0.028100524	false
training	oneLayer	oneLayer - rat 1	0	0.11717896	-0.03204989	false
training	oneLayer	oneLayer - rat 1	0	0.12779821	-0.032049876	false
training	oneLayer	oneLayer - rat 1	0	0.13714987	-0.035923447	false
training	oneLayer	oneLayer - rat 1	0	0.14802332	-0.035923433	false
training	oneLayer	oneLayer - rat 1	0	0.15775876	-0.03995597	false
training	oneLayer	oneLayer - rat 1	0	0.1678423	-0.03995596	false
training	oneLayer	oneLayer - rat 1	0	0.1773213	-0.043882277	false
training	oneLayer	oneLayer - rat 1	0	0.18734185	-0.043882262	false
training	oneLayer	oneLayer - rat 1	0	0.19730751	-0.048010156	false
training	oneLayer	oneLayer - rat 1	0	0.20804277	-0.04801014	false
training	oneLayer	oneLayer - rat 1	0	0.21787654	-0.052083403	false
training	oneLayer	oneLayer - rat 1	0	0.22790574	-0.05208339	false
training	oneLayer	oneLayer - rat 1	0	0.23800062	-0.05626481	false
training	oneLayer	oneLayer - rat 1	0	0.24830532	-0.0562648	false
training	oneLayer	oneLayer - rat 1	0	0.25843182	-0.060459312	false
training	oneLayer	oneLayer - rat 1	0	0.26912072	-0.060459297	false
training	oneLayer	oneLayer - rat 1	0	0.2790071	-0.064554356	false
training	oneLayer	oneLayer - rat 1	0	0.28914392	-0.06455435	false
training	oneLayer	oneLayer - rat 1	0	0.2991252	-0.06868871	false
training	oneLayer	oneLayer - rat 1	0	0.3093267	-0.0686887	false
training	oneLayer	oneLayer - rat 1	0	0.3193129	-0.06455226	false
training	oneLayer	oneLayer - rat 1	0	0.32970178	-0.06455225	false
training	oneLayer	oneLayer - rat 1	0	0.33953622	-0.060478672	false
training	oneLayer	oneLayer - rat 1	0	0.3502823	-0.06047866	false
training	oneLayer	oneLayer - rat 1	0	0.3602106	-0.05636622	false
training	oneLayer	oneLayer - rat 1	0	0.37112606	-0.056366205	false
training	oneLayer	oneLayer - rat 1	0	0.3808143	-0.052353185	false
training	oneLayer	oneLayer - rat 1	0	0.39117515	-0.05235317	false
training	oneLayer	oneLayer - rat 1	0	0.40049702	-0.048491914	false
training	oneLayer	oneLayer - rat 1	0	0.40767825	-0.041310668	false
training	oneLayer	oneLayer - rat 1	0	0.41164902	-0.031724397	false
training	oneLayer	oneLayer - rat 1	0	0.411649	-0.021068946	false
training	oneLayer	oneLayer - rat 1	0	0.40757594	-0.01123578	false
training	oneLayer	oneLayer - rat 1	0	0.40010324	-0.00376309	false
training	oneLayer	oneLayer - rat 1	0	0.39272645	0.0036136804	false
training	oneLayer	oneLayer - rat 1	0	0.3827021	0.0077658864	false
training	oneLayer	oneLayer - rat 1	0	0.37270066	0.0077658733	false
training	oneLayer	oneLayer - rat 1	0	0.3630733	0.0037780749	false
training	oneLayer	oneLayer - rat 1	0	0.3556426	-0.0036526627	false
training	oneLayer	oneLayer - rat 1	0	0.35167527	-0.013230622	false
training	oneLayer	oneLayer - rat 1	0	0.3440753	-0.020830626	false
training	oneLayer	oneLayer - rat 1	0	0.334118	-0.024955086	false
training	oneLayer	oneLayer - rat 1	0	0.3264874	-0.032585725	false
training	oneLayer	oneLayer - rat 1	0	0.31663153	-0.036668163	false
training	oneLayer	oneLayer - rat 1	0	0.30901498	-0.044284735	false
training	oneLayer	oneLayer - rat 1	0	0.29950017	-0.048225917	false
training	oneLayer	oneLayer - rat 1	0	0.289064	-0.04822593	false
training	oneLayer	oneLayer - rat 1	0	0.2789456	-0.05241712	false
training	oneLayer	oneLayer - rat 1	0	0.26890045	-0.052417137	false
training	oneLayer	oneLayer - rat 1	0	0.25880077	-0.056600578	false
training	oneLayer	oneLayer - rat 1	0	0.24869058	-0.056600593	false
training	oneLayer	oneLayer - rat 1	0	0.23886992	-0.060668454	false
training	oneLayer	oneLayer - rat 1	0	0.22850746	-0.06066847	false
training	oneLayer	oneLayer - rat 1	0	0.2192383	-0.064507894	false
training	oneLayer	oneLayer - rat 1	0	0.20920849	-0.06450791	false
training	oneLayer	oneLayer - rat 1	0	0.19933832	-0.06859628	false
training	oneLayer	oneLayer - rat 1	0	0.18893677	-0.068596296	false
training	oneLayer	oneLayer - rat 1	0	0.17939207	-0.07254986	false
training	oneLayer	oneLayer - rat 1	0	0.16900268	-0.07254987	false
training	oneLayer	oneLayer - rat 1	0	0.15918289	-0.07661737	false
training	oneLayer	oneLayer - rat 1	0	0.14910969	-0.07661738	false
training	oneLayer	oneLayer - rat 1	0	0.1390698	-0.08077606	false
training	oneLayer	oneLayer - rat 1	0	0.12882246	-0.08077607	false
training	oneLayer	oneLayer - rat 1	0	0.11930856	-0.08471688	false
training	oneLayer	oneLayer - rat 1	0	0.10858709	-0.084716894	false
training	oneLayer	oneLayer - rat 1	0	0.099079415	-0.088655114	false
training	oneLayer	oneLayer - rat 1	0	0.08864791	-0.08865513	false
training	oneLayer	oneLayer - rat 1	0	0.07933508	-0.092512645	false
training	oneLayer	oneLayer - rat 1	0	0.06857279	-0.09251265	false
training	oneLayer	oneLayer - rat 1	0	0.059005238	-0.09647568	false
training	oneLayer	oneLayer - rat 1	0	0.048660733	-0.09647569	false
training	oneLayer	oneLayer - rat 1	0	0.038618352	-0.1006354	false
training	oneLayer	oneLayer - rat 1	0	0.028008426	-0.10063542	false
training	oneLayer	oneLayer - rat 1	0	0.01822152	-0.1046893	false
training	oneLayer	oneLayer - rat 1	0	0.008175365	-0.104689315	false
training	oneLayer	oneLayer - rat 1	0	-0.0012033257	-0.10857411	false
training	oneLayer	oneLayer - rat 1	0	-0.011481275	-0.10857412	false
training	oneLayer	oneLayer - rat 1	0	-0.02112727	-0.11256964	false
training	oneLayer	oneLayer - rat 1	0	-0.031651247	-0.11256965	false
training	oneLayer	oneLayer - rat 1	0	-0.041234262	-0.11653908	false
training	oneLayer	oneLayer - rat 1	0	-0.051380284	-0.11653909	false
training	oneLayer	oneLayer - rat 1	0	-0.061023306	-0.12053338	false
training	oneLayer	oneLayer - rat 1	0	-0.071870826	-0.12053339	false
training	oneLayer	oneLayer - rat 1	0	-0.08188754	-0.12468247	false
training	oneLayer	oneLayer - rat 1	0	-0.091952495	-0.124682486	false
training	oneLayer	oneLayer - rat 1	0	-0.101844884	-0.12878007	false
training	oneLayer	oneLayer - rat 1	0	-0.112395085	-0.12878008	false
training	oneLayer	oneLayer - rat 1	0	-0.12220155	-0.13284206	false
training	oneLayer	oneLayer - rat 1	0	-0.1326788	-0.13284208	false
training	oneLayer	oneLayer - rat 1	0	-0.14225248	-0.12887654	false
training	oneLayer	oneLayer - rat 1	0	-0.15271582	-0.12887655	false
training	oneLayer	oneLayer - rat 1	0	-0.16200326	-0.12502958	false
training	oneLayer	oneLayer - rat 1	0	-0.17277712	-0.1250296	false
training	oneLayer	oneLayer - rat 1	0	-0.18267506	-0.120929755	false
training	oneLayer	oneLayer - rat 1	0	-0.19296212	-0.12092976	false
training	oneLayer	oneLayer - rat 1	0	-0.20281938	-0.11684678	false
training	oneLayer	oneLayer - rat 1	0	-0.21378843	-0.11684679	false
training	oneLayer	oneLayer - rat 1	0	-0.22372718	-0.11273004	false
training	oneLayer	oneLayer - rat 1	0	-0.23454441	-0.112730056	false
training	oneLayer	oneLayer - rat 1	0	-0.24389443	-0.10885717	false
training	oneLayer	oneLayer - rat 1	0	-0.2544189	-0.108857185	false
training	oneLayer	oneLayer - rat 1	0	-0.26397315	-0.104899704	false
training	oneLayer	oneLayer - rat 1	0	-0.2742292	-0.10489972	false
training	oneLayer	oneLayer - rat 1	0	-0.28425813	-0.10074561	false
training	oneLayer	oneLayer - rat 1	0	-0.29460514	-0.100745626	false
training	oneLayer	oneLayer - rat 1	0	-0.3047538	-0.096541926	false
training	oneLayer	oneLayer - rat 1	0	-0.31486282	-0.09654193	false
training	oneLayer	oneLayer - rat 1	0	-0.3249818	-0.092350535	false
training	oneLayer	oneLayer - rat 1	0	-0.33562064	-0.09235055	false
training	oneLayer	oneLayer - rat 1	0	-0.34504175	-0.08844821	false
training	oneLayer	oneLayer - rat 1	0	-0.3553483	-0.08844822	false
training	oneLayer	oneLayer - rat 1	0	-0.36492756	-0.08448037	false
training	oneLayer	oneLayer - rat 1	0	-0.3750034	-0.08448038	false
training	oneLayer	oneLayer - rat 1	0	-0.3843807	-0.080596186	false
training	oneLayer	oneLayer - rat 1	0	-0.39199123	-0.07298569	false
training	oneLayer	oneLayer - rat 1	0	-0.39946482	-0.06551211	false
training	oneLayer	oneLayer - rat 1	0	-0.40721422	-0.0577627	false
training	oneLayer	oneLayer - rat 1	0	-0.41448298	-0.05049398	false
training	oneLayer	oneLayer - rat 1	0	-0.4218111	-0.043165863	false
training	oneLayer	oneLayer - rat 1	0	-0.429095	-0.03588201	false
training	oneLayer	oneLayer - rat 1	0	-0.43330026	-0.025729636	false
training	oneLayer	oneLayer - rat 1	0	-0.43330026	-0.014909315	false
training	oneLayer	oneLayer - rat 1	0	-0.42931297	-0.0052831313	false
training	oneLayer	oneLayer - rat 1	0	-0.42527688	0.0044609183	false
training	oneLayer	oneLayer - rat 1	0	-0.42110202	0.01453999	false
training	oneLayer	oneLayer - rat 1	0	-0.41704494	0.024334678	false
training	oneLayer	oneLayer - rat 1	0	-0.41306055	0.03395385	false
training	oneLayer	oneLayer - rat 1	0	-0.40897164	0.043825366	false
training	oneLayer	oneLayer - rat 1	0	-0.40501773	0.053371	false
training	oneLayer	oneLayer - rat 1	0	-0.40099072	0.063093126	false
training	oneLayer	oneLayer - rat 1	0	-0.39713162	0.072409846	false
training	oneLayer	oneLayer - rat 1	0	-0.39311275	0.082112305	false
training	oneLayer	oneLayer - rat 1	0	-0.38916248	0.09164909	false
training	oneLayer	oneLayer - rat 1	0	-0.38520887	0.10119395	false
training	oneLayer	oneLayer - rat 1	0	-0.38109756	0.11111963	false
training	oneLayer	oneLayer - rat 1	0	-0.37712052	0.120721035	false
training	oneLayer	oneLayer - rat 1	0	-0.37295145	0.13078614	false
training	oneLayer	oneLayer - rat 1	0	-0.36911234	0.14005457	false
training	oneLayer	oneLayer - rat 1	0	-0.36520764	0.14948142	false
training	oneLayer	oneLayer - rat 1	0	-0.36124057	0.15905881	false
training	oneLayer	oneLayer - rat 1	0	-0.35730904	0.16855039	false
training	oneLayer	oneLayer - rat 1	0	-0.35312757	0.17864536	false
training	oneLayer	oneLayer - rat 1	0	-0.3489463	0.18873988	false
training	oneLayer	oneLayer - rat 1	0	-0.34501866	0.19822212	false
training	oneLayer	oneLayer - rat 1	0	-0.34102073	0.20787397	false
training	oneLayer	oneLayer - rat 1	0	-0.33693418	0.21773982	false
training	oneLayer	oneLayer - rat 1	0	-0.33298126	0.22728302	false
training	oneLayer	oneLayer - rat 1	0	-0.32915118	0.23652971	false
training	oneLayer	oneLayer - rat 1	0	-0.3252861	0.24586087	false
training	oneLayer	oneLayer - rat 1	0	-0.32138336	0.255283	false
training	oneLayer	oneLayer - rat 1	0	-0.317433	0.26481998	false
training	oneLayer	oneLayer - rat 1	0	-0.31743303	0.27576575	false
training	oneLayer	oneLayer - rat 1	0	-0.31353053	0.28518724	false
training	oneLayer	oneLayer - rat 1	0	-0.3096246	0.29461697	false
training	oneLayer	oneLayer - rat 1	0	-0.30207902	0.3021626	false
training	oneLayer	oneLayer - rat 1	0	-0.29789475	0.31226438	false
training	oneLayer	oneLayer - rat 1	0	-0.29072976	0.31942937	false
training	oneLayer	oneLayer - rat 1	0	-0.28680208	0.3289117	false
training	oneLayer	oneLayer - rat 1	0	-0.27946493	0.33624887	false
training	oneLayer	oneLayer - rat 1	0	-0.27559328	0.34559587	false
training	oneLayer	oneLayer - rat 1	0	-0.26821923	0.35296994	false
training	oneLayer	oneLayer - rat 1	0	-0.25810882	0.35715783	false
training	oneLayer	oneLayer - rat 1	0	-0.25060895	0.3646577	false
training	oneLayer	oneLayer - rat 1	0	-0.24124505	0.36853638	false
training	oneLayer	oneLayer - rat 1	0	-0.23368397	0.37609747	false
training	oneLayer	oneLayer - rat 1	0	-0.22353703	0.3803005	false
training	oneLayer	oneLayer - rat 1	0	-0.2160233	0.38781422	false
training	oneLayer	oneLayer - rat 1	0	-0.20663786	0.39170182	false
training	oneLayer	oneLayer - rat 1	0	-0.19938111	0.3989586	false
training	oneLayer	oneLayer - rat 1	0	-0.18964685	0.40299067	false
training	oneLayer	oneLayer - rat 1	0	-0.18220238	0.41043517	false
training	oneLayer	oneLayer - rat 1	0	-0.17292461	0.41427815	false
training	oneLayer	oneLayer - rat 1	0	-0.16573106	0.42147171	false
training	oneLayer	oneLayer - rat 1	0	-0.15578634	0.42559096	false
training	oneLayer	oneLayer - rat 1	0	-0.14541806	0.425591	false
training	oneLayer	oneLayer - rat 1	0	-0.13599491	0.4216878	false
training	oneLayer	oneLayer - rat 1	0	-0.1287098	0.4144027	false
training	oneLayer	oneLayer - rat 1	0	-0.12459236	0.40446237	false
training	oneLayer	oneLayer - rat 1	0	-0.11743583	0.39730588	false
training	oneLayer	oneLayer - rat 1	0	-0.10759739	0.39323068	false
training	oneLayer	oneLayer - rat 1	0	-0.100129075	0.38576236	false
training	oneLayer	oneLayer - rat 1	0	-0.09088735	0.38193434	false
training	oneLayer	oneLayer - rat 1	0	-0.080148384	0.38193434	false
training	oneLayer	oneLayer - rat 1	0	-0.070682935	0.37801364	false
training	oneLayer	oneLayer - rat 1	0	-0.06014644	0.37801364	false
training	oneLayer	oneLayer - rat 1	0	-0.05021713	0.3739008	false
training	oneLayer	oneLayer - rat 1	0	-0.04255526	0.36623895	false
training	oneLayer	oneLayer - rat 1	0	-0.038638964	0.35678422	false
training	oneLayer	oneLayer - rat 1	0	-0.031353652	0.34949893	false
training	oneLayer	oneLayer - rat 1	0	-0.027179394	0.33942142	false
training	oneLayer	oneLayer - rat 1	0	-0.019491931	0.33173397	false
training	oneLayer	oneLayer - rat 1	0	-0.015620623	0.3223878	false
training	oneLayer	oneLayer - rat 1	0	-0.007971585	0.3147388	false
training	oneLayer	oneLayer - rat 1	0	-0.004080386	0.30534464	false
training	oneLayer	oneLayer - rat 1	0	0.0036624067	0.29760188	false
training	oneLayer	oneLayer - rat 1	0	0.007847358	0.28749856	false
training	oneLayer	oneLayer - rat 1	0	0.015517463	0.27982846	false
training	oneLayer	oneLayer - rat 1	0	0.019538399	0.2701211	false
training	oneLayer	oneLayer - rat 1	0	0.026943516	0.262716	false
training	oneLayer	oneLayer - rat 1	0	0.030840375	0.25330818	false
training	oneLayer	oneLayer - rat 1	0	0.038407486	0.24574108	false
training	oneLayer	oneLayer - rat 1	0	0.04254028	0.23576368	false
training	oneLayer	oneLayer - rat 1	0	0.0497636	0.22854038	false
training	oneLayer	oneLayer - rat 1	0	0.05388913	0.2185805	false
training	oneLayer	oneLayer - rat 1	0	0.061494697	0.21097495	false
training	oneLayer	oneLayer - rat 1	0	0.065430485	0.20147316	false
training	oneLayer	oneLayer - rat 1	0	0.07311845	0.1937852	false
training	oneLayer	oneLayer - rat 1	0	0.07731531	0.18365313	false
training	oneLayer	oneLayer - rat 1	0	0.084761135	0.17620732	false
training	oneLayer	oneLayer - rat 1	0	0.088889934	0.16623954	false
training	oneLayer	oneLayer - rat 1	0	0.09620232	0.15892717	false
training	oneLayer	oneLayer - rat 1	0	0.10004309	0.14965478	false
training	oneLayer	oneLayer - rat 1	0	0.107356206	0.14234167	false
training	oneLayer	oneLayer - rat 1	0	0.11129395	0.13283516	false
training	oneLayer	oneLayer - rat 1	0	0.11883369	0.12529543	false
training	oneLayer	oneLayer - rat 1	0	0.128772	0.12117886	false
training	oneLayer	oneLayer - rat 1	0	0.13647862	0.11347227	false
training	oneLayer	oneLayer - rat 1	0	0.14579092	0.109615	false
training	oneLayer	oneLayer - rat 1	0	0.15293996	0.10246598	false
training	oneLayer	oneLayer - rat 1	0	0.16288555	0.0983464	false
training	oneLayer	oneLayer - rat 1	0	0.17040636	0.0908256	false
training	oneLayer	oneLayer - rat 1	0	0.17978828	0.0869395	false
training	oneLayer	oneLayer - rat 1	0	0.1869103	0.079817496	false
training	oneLayer	oneLayer - rat 1	0	0.19616015	0.075986095	false
training	oneLayer	oneLayer - rat 1	0	0.20387131	0.06827495	false
training	oneLayer	oneLayer - rat 1	0	0.21398936	0.064083934	false
training	oneLayer	oneLayer - rat 1	0	0.22117634	0.056896973	false
training	oneLayer	oneLayer - rat 1	0	0.23129167	0.052707084	false
training	oneLayer	oneLayer - rat 1	0	0.23862794	0.045370817	false
training	oneLayer	oneLayer - rat 1	0	0.24826172	0.04138039	false
training	oneLayer	oneLayer - rat 1	0	0.25563127	0.034010857	false
training	oneLayer	oneLayer - rat 1	0	0.2652153	0.03004103	false
training	oneLayer	oneLayer - rat 1	0	0.27286318	0.022393188	false
training	oneLayer	oneLayer - rat 1	0	0.28299725	0.018195527	false
training	oneLayer	oneLayer - rat 1	0	0.29027805	0.010914757	false
training	oneLayer	oneLayer - rat 1	0	0.30004337	0.00686984	false
training	oneLayer	oneLayer - rat 1	0	0.30725288	-3.3966426E-4	false
training	oneLayer	oneLayer - rat 1	0	0.3169921	-0.0043737637	false
training	oneLayer	oneLayer - rat 1	0	0.32744905	-0.004373751	false
training	oneLayer	oneLayer - rat 1	0	0.33678365	-5.0722284E-4	false
training	oneLayer	oneLayer - rat 1	0	0.34404543	0.0067545637	false
training	oneLayer	oneLayer - rat 1	0	0.34811828	0.016587308	false
training	oneLayer	oneLayer - rat 1	0	0.35526508	0.023734141	false
training	oneLayer	oneLayer - rat 1	0	0.36476603	0.027669579	false
training	oneLayer	oneLayer - rat 1	0	0.37196535	0.0348689	false
training	oneLayer	oneLayer - rat 1	0	0.3819996	0.039025243	false
training	oneLayer	oneLayer - rat 1	0	0.38950318	0.046528827	false
training	oneLayer	oneLayer - rat 1	0	0.3936049	0.056431327	false
training	oneLayer	oneLayer - rat 1	0	0.40123388	0.06406033	false
training	oneLayer	oneLayer - rat 1	0	0.4051377	0.07348496	false
training	oneLayer	oneLayer - rat 1	0	0.41270807	0.081055366	false
training	oneLayer	oneLayer - rat 1	0	0.41686124	0.091082014	false
training	oneLayer	oneLayer - rat 1	0	0.42071655	0.100389645	false
training	oneLayer	oneLayer - rat 1	0	0.4248433	0.110352546	false
training	oneLayer	oneLayer - rat 1	0	0.4248433	0.1204894	false
training	oneLayer	oneLayer - rat 1	0	0.4286968	0.12979263	false
training	oneLayer	oneLayer - rat 1	0	0.4286968	0.13999721	false
training	oneLayer	oneLayer - rat 1	0	0.4328737	0.15008119	false
training	oneLayer	oneLayer - rat 1	0	0.4328737	0.16008855	false
training	oneLayer	oneLayer - rat 1	0	0.4370694	0.17021789	false
training	oneLayer	oneLayer - rat 1	0	0.4370694	0.18038386	false
training	oneLayer	oneLayer - rat 1	0	0.4370694	0.18038386	false
training	oneLayer	oneLayer - rat 1	0	0.43706936	0.19069035	false
training	oneLayer	oneLayer - rat 1	0	0.43305108	0.20039131	false
training	oneLayer	oneLayer - rat 1	0	0.4257593	0.20768307	false
training	oneLayer	oneLayer - rat 1	0	0.42156577	0.21780714	false
training	oneLayer	oneLayer - rat 1	0	0.41415402	0.22521883	false
training	oneLayer	oneLayer - rat 1	0	0.4103053	0.23451051	false
training	oneLayer	oneLayer - rat 1	0	0.4026432	0.24217255	false
training	oneLayer	oneLayer - rat 1	0	0.3985999	0.251934	false
training	oneLayer	oneLayer - rat 1	0	0.39134306	0.25919077	false
training	oneLayer	oneLayer - rat 1	0	0.3871806	0.26923984	false
training	oneLayer	oneLayer - rat 1	0	0.3798179	0.2766025	false
training	oneLayer	oneLayer - rat 1	0	0.36992833	0.2806989	false
training	oneLayer	oneLayer - rat 1	0	0.36217374	0.28845346	false
training	oneLayer	oneLayer - rat 1	0	0.35280985	0.2923321	false
training	oneLayer	oneLayer - rat 1	0	0.34569797	0.29944396	false
training	oneLayer	oneLayer - rat 1	0	0.33563405	0.30361256	false
training	oneLayer	oneLayer - rat 1	0	0.3285285	0.3107181	false
training	oneLayer	oneLayer - rat 1	0	0.31904277	0.3146472	false
training	oneLayer	oneLayer - rat 1	0	0.31132764	0.3223623	false
training	oneLayer	oneLayer - rat 1	0	0.30140993	0.32647035	false
training	oneLayer	oneLayer - rat 1	0	0.293696	0.33418426	false
training	oneLayer	oneLayer - rat 1	0	0.28402227	0.33819124	false
training	oneLayer	oneLayer - rat 1	0	0.276405	0.34580848	false
training	oneLayer	oneLayer - rat 1	0	0.26707125	0.34967464	false
training	oneLayer	oneLayer - rat 1	0	0.25964484	0.35710102	false
training	oneLayer	oneLayer - rat 1	0	0.24954686	0.36128375	false
training	oneLayer	oneLayer - rat 1	0	0.2419164	0.36891416	false
training	oneLayer	oneLayer - rat 1	0	0.2322853	0.3729035	false
training	oneLayer	oneLayer - rat 1	0	0.22483853	0.38035023	false
training	oneLayer	oneLayer - rat 1	0	0.21481335	0.3845028	false
training	oneLayer	oneLayer - rat 1	0	0.207391	0.39192513	false
training	oneLayer	oneLayer - rat 1	0	0.19792384	0.39584655	false
training	oneLayer	oneLayer - rat 1	0	0.19050251	0.40326786	false
training	oneLayer	oneLayer - rat 1	0	0.1807094	0.40732428	false
training	oneLayer	oneLayer - rat 1	0	0.17336091	0.41467276	false
training	oneLayer	oneLayer - rat 1	0	0.16389064	0.41859546	false
training	oneLayer	oneLayer - rat 1	0	0.1562384	0.4262477	false
training	oneLayer	oneLayer - rat 1	0	0.14637274	0.43033415	false
training	oneLayer	oneLayer - rat 1	0	0.13570258	0.43033415	false
training	oneLayer	oneLayer - rat 1	0	0.12586378	0.42625877	false
training	oneLayer	oneLayer - rat 1	0	0.11845074	0.4188457	false
training	oneLayer	oneLayer - rat 1	0	0.1085607	0.4147491	false
training	oneLayer	oneLayer - rat 1	0	0.10084885	0.40703723	false
training	oneLayer	oneLayer - rat 1	0	0.091329694	0.40309426	false
training	oneLayer	oneLayer - rat 1	0	0.08358257	0.39534712	false
training	oneLayer	oneLayer - rat 1	0	0.07380809	0.39129838	false
training	oneLayer	oneLayer - rat 1	0	0.066468075	0.38395834	false
training	oneLayer	oneLayer - rat 1	0	0.05657129	0.37985894	false
training	oneLayer	oneLayer - rat 1	0	0.04928964	0.37257725	false
training	oneLayer	oneLayer - rat 1	0	0.039156094	0.3683798	false
training	oneLayer	oneLayer - rat 1	0	0.032037325	0.361261	false
training	oneLayer	oneLayer - rat 1	0	0.022440182	0.35728574	false
training	oneLayer	oneLayer - rat 1	0	0.01502518	0.3498707	false
training	oneLayer	oneLayer - rat 1	0	0.0049833674	0.34571123	false
training	oneLayer	oneLayer - rat 1	0	-0.002249387	0.33847848	false
training	oneLayer	oneLayer - rat 1	0	-0.0064170994	0.32841668	false
training	oneLayer	oneLayer - rat 1	0	-0.0064170854	0.31829527	false
training	oneLayer	oneLayer - rat 1	0	-0.0022130306	0.30814582	false
training	oneLayer	oneLayer - rat 1	0	0.004896311	0.3010365	false
training	oneLayer	oneLayer - rat 1	0	0.008905706	0.291357	false
training	oneLayer	oneLayer - rat 1	0	0.015992315	0.2842704	false
training	oneLayer	oneLayer - rat 1	0	0.019872054	0.27490392	false
training	oneLayer	oneLayer - rat 1	0	0.027348889	0.26742712	false
training	oneLayer	oneLayer - rat 1	0	0.031537436	0.2573151	false
training	oneLayer	oneLayer - rat 1	0	0.038978115	0.24987446	false
training	oneLayer	oneLayer - rat 1	0	0.0431726	0.2397481	false
training	oneLayer	oneLayer - rat 1	0	0.050926566	0.23199417	false
training	oneLayer	oneLayer - rat 1	0	0.05487262	0.22246757	false
training	oneLayer	oneLayer - rat 1	0	0.062420107	0.21492012	false
training	oneLayer	oneLayer - rat 1	0	0.066247076	0.20568101	false
training	oneLayer	oneLayer - rat 1	0	0.07356481	0.1983633	false
training	oneLayer	oneLayer - rat 1	0	0.07775876	0.18823826	false
training	oneLayer	oneLayer - rat 1	0	0.08506113	0.1809359	false
training	oneLayer	oneLayer - rat 1	0	0.08905837	0.17128576	false
training	oneLayer	oneLayer - rat 1	0	0.09620189	0.16414227	false
training	oneLayer	oneLayer - rat 1	0	0.10020165	0.15448602	false
training	oneLayer	oneLayer - rat 1	0	0.10769454	0.14699315	false
training	oneLayer	oneLayer - rat 1	0	0.11154201	0.13770457	false
training	oneLayer	oneLayer - rat 1	0	0.11916425	0.13008234	false
training	oneLayer	oneLayer - rat 1	0	0.12866582	0.12614667	false
training	oneLayer	oneLayer - rat 1	0	0.13611373	0.118698776	false
training	oneLayer	oneLayer - rat 1	0	0.14581439	0.114680655	false
training	oneLayer	oneLayer - rat 1	0	0.15319312	0.10730194	false
training	oneLayer	oneLayer - rat 1	0	0.16272546	0.10335353	false
training	oneLayer	oneLayer - rat 1	0	0.17002623	0.09605279	false
training	oneLayer	oneLayer - rat 1	0	0.17934279	0.09219376	false
training	oneLayer	oneLayer - rat 1	0	0.18699872	0.08453784	false
training	oneLayer	oneLayer - rat 1	0	0.19676192	0.08049381	false
training	oneLayer	oneLayer - rat 1	0	0.2043258	0.072929956	false
training	oneLayer	oneLayer - rat 1	0	0.21383618	0.06899065	false
training	oneLayer	oneLayer - rat 1	0	0.22114034	0.061686497	false
training	oneLayer	oneLayer - rat 1	0	0.23091123	0.057639282	false
training	oneLayer	oneLayer - rat 1	0	0.23813222	0.0504183	false
training	oneLayer	oneLayer - rat 1	0	0.24751942	0.04653001	false
training	oneLayer	oneLayer - rat 1	0	0.25465238	0.039397053	false
training	oneLayer	oneLayer - rat 1	0	0.26429588	0.03540261	false
training	oneLayer	oneLayer - rat 1	0	0.27140734	0.028291162	false
training	oneLayer	oneLayer - rat 1	0	0.28140697	0.024149196	false
training	oneLayer	oneLayer - rat 1	0	0.28855264	0.017003546	false
training	oneLayer	oneLayer - rat 1	0	0.29784787	0.013153354	false
training	oneLayer	oneLayer - rat 1	0	0.30535775	0.0056434656	false
training	oneLayer	oneLayer - rat 1	0	0.31510505	0.001606021	false
training	oneLayer	oneLayer - rat 1	0	0.32245353	-0.0057424377	false
training	oneLayer	oneLayer - rat 1	0	0.3323931	-0.009859525	false
training	oneLayer	oneLayer - rat 1	0	0.34244147	-0.009859511	false
training	oneLayer	oneLayer - rat 1	0	0.35258776	-0.0056567565	false
training	oneLayer	oneLayer - rat 1	0	0.36003762	0.0017931147	false
training	oneLayer	oneLayer - rat 1	0	0.3699834	0.0059128148	false
training	oneLayer	oneLayer - rat 1	0	0.37766895	0.013598385	false
training	oneLayer	oneLayer - rat 1	0	0.38746655	0.017656695	false
training	oneLayer	oneLayer - rat 1	0	0.39458814	0.024778323	false
training	oneLayer	oneLayer - rat 1	0	0.39850476	0.034233887	false
training	oneLayer	oneLayer - rat 1	0	0.40602514	0.041754298	false
training	oneLayer	oneLayer - rat 1	0	0.40988192	0.051065415	false
training	oneLayer	oneLayer - rat 1	0	0.40988192	0.06123418	false
training	oneLayer	oneLayer - rat 1	0	0.41370898	0.07047361	false
training	oneLayer	oneLayer - rat 1	0	0.41370898	0.08084837	false
training	oneLayer	oneLayer - rat 1	0	0.41770148	0.0904872	false
training	oneLayer	oneLayer - rat 1	0	0.42176583	0.10029941	false
training	oneLayer	oneLayer - rat 1	0	0.4217658	0.11048942	false
training	oneLayer	oneLayer - rat 1	0	0.4217658	0.12125414	false
training	oneLayer	oneLayer - rat 1	0	0.42176577	0.13140625	false
training	oneLayer	oneLayer - rat 1	0	0.42176577	0.14168367	false
training	oneLayer	oneLayer - rat 1	0	0.42176574	0.15228452	false
training	oneLayer	oneLayer - rat 1	0	0.42176574	0.16228548	false
training	oneLayer	oneLayer - rat 1	0	0.4217657	0.17291126	false
training	oneLayer	oneLayer - rat 1	0	0.4175822	0.1830111	false
training	oneLayer	oneLayer - rat 1	0	0.41005477	0.19053851	false
training	oneLayer	oneLayer - rat 1	0	0.40063903	0.19443862	false
training	oneLayer	oneLayer - rat 1	0	0.39322922	0.2018484	false
training	oneLayer	oneLayer - rat 1	0	0.3831059	0.2060416	false
training	oneLayer	oneLayer - rat 1	0	0.37584502	0.21330248	false
training	oneLayer	oneLayer - rat 1	0	0.36653164	0.2171602	false
training	oneLayer	oneLayer - rat 1	0	0.35929474	0.22439708	false
training	oneLayer	oneLayer - rat 1	0	0.3491522	0.22859822	false
training	oneLayer	oneLayer - rat 1	0	0.34196216	0.23578826	false
training	oneLayer	oneLayer - rat 1	0	0.33268705	0.23963012	false
training	oneLayer	oneLayer - rat 1	0	0.3253253	0.24699184	false
training	oneLayer	oneLayer - rat 1	0	0.31527597	0.2511544	false
training	oneLayer	oneLayer - rat 1	0	0.30790702	0.25852332	false
training	oneLayer	oneLayer - rat 1	0	0.29858598	0.2623842	false
training	oneLayer	oneLayer - rat 1	0	0.29081985	0.2701503	false
training	oneLayer	oneLayer - rat 1	0	0.28158048	0.27397737	false
training	oneLayer	oneLayer - rat 1	0	0.27419063	0.28136718	false
training	oneLayer	oneLayer - rat 1	0	0.26459956	0.28533992	false
training	oneLayer	oneLayer - rat 1	0	0.25690812	0.2930313	false
training	oneLayer	oneLayer - rat 1	0	0.24691631	0.29717004	false
training	oneLayer	oneLayer - rat 1	0	0.23944925	0.3046371	false
training	oneLayer	oneLayer - rat 1	0	0.23020986	0.30846414	false
training	oneLayer	oneLayer - rat 1	0	0.22304462	0.3156294	false
training	oneLayer	oneLayer - rat 1	0	0.21312389	0.31973866	false
training	oneLayer	oneLayer - rat 1	0	0.20605147	0.32681108	false
training	oneLayer	oneLayer - rat 1	0	0.19593495	0.33100143	false
training	oneLayer	oneLayer - rat 1	0	0.18868394	0.33825243	false
training	oneLayer	oneLayer - rat 1	0	0.17900507	0.34226152	false
training	oneLayer	oneLayer - rat 1	0	0.1718232	0.34944338	false
training	oneLayer	oneLayer - rat 1	0	0.16237487	0.353357	false
training	oneLayer	oneLayer - rat 1	0	0.15492903	0.36080283	false
training	oneLayer	oneLayer - rat 1	0	0.145313	0.36478588	false
training	oneLayer	oneLayer - rat 1	0	0.1381036	0.37199527	false
training	oneLayer	oneLayer - rat 1	0	0.1283001	0.376056	false
training	oneLayer	oneLayer - rat 1	0	0.12060209	0.383754	false
training	oneLayer	oneLayer - rat 1	0	0.11046404	0.38795328	false
training	oneLayer	oneLayer - rat 1	0	0.10308123	0.39533606	false
training	oneLayer	oneLayer - rat 1	0	0.09354034	0.39928803	false
training	oneLayer	oneLayer - rat 1	0	0.0863743	0.40645406	false
training	oneLayer	oneLayer - rat 1	0	0.07623818	0.41065255	false
training	oneLayer	oneLayer - rat 1	0	0.06886771	0.418023	false
training	oneLayer	oneLayer - rat 1	0	0.05948036	0.42191133	false
training	oneLayer	oneLayer - rat 1	0	0.051935565	0.4294561	false
training	oneLayer	oneLayer - rat 1	0	0.042499214	0.43336478	false
training	oneLayer	oneLayer - rat 1	0	0.03215895	0.43336475	false
training	oneLayer	oneLayer - rat 1	0	0.022069661	0.4291856	false
training	oneLayer	oneLayer - rat 1	0	0.014793111	0.42190903	false
training	oneLayer	oneLayer - rat 1	0	0.010857763	0.41240823	false
training	oneLayer	oneLayer - rat 1	0	0.010857779	0.40216246	false
training	oneLayer	oneLayer - rat 1	0	0.014970308	0.392234	false
training	oneLayer	oneLayer - rat 1	0	0.022568863	0.38463548	false
training	oneLayer	oneLayer - rat 1	0	0.026410544	0.37536088	false
training	oneLayer	oneLayer - rat 1	0	0.033532277	0.36823916	false
training	oneLayer	oneLayer - rat 1	0	0.037425548	0.35884002	false
training	oneLayer	oneLayer - rat 1	0	0.044920336	0.35134524	false
training	oneLayer	oneLayer - rat 1	0	0.04902751	0.3414297	false
training	oneLayer	oneLayer - rat 1	0	0.056686334	0.3337709	false
training	oneLayer	oneLayer - rat 1	0	0.060564622	0.32440794	false
training	oneLayer	oneLayer - rat 1	0	0.067917794	0.31705478	false
training	oneLayer	oneLayer - rat 1	0	0.071948	0.30732504	false
training	oneLayer	oneLayer - rat 1	0	0.07920794	0.30006513	false
training	oneLayer	oneLayer - rat 1	0	0.08326318	0.29027495	false
training	oneLayer	oneLayer - rat 1	0	0.09067528	0.28286287	false
training	oneLayer	oneLayer - rat 1	0	0.094829224	0.2728344	false
training	oneLayer	oneLayer - rat 1	0	0.102199405	0.26546425	false
training	oneLayer	oneLayer - rat 1	0	0.106201485	0.2558024	false
training	oneLayer	oneLayer - rat 1	0	0.11387019	0.24813373	false
training	oneLayer	oneLayer - rat 1	0	0.11790996	0.2383809	false
training	oneLayer	oneLayer - rat 1	0	0.12505606	0.23123482	false
training	oneLayer	oneLayer - rat 1	0	0.12896435	0.22179942	false
training	oneLayer	oneLayer - rat 1	0	0.1365653	0.2141985	false
training	oneLayer	oneLayer - rat 1	0	0.1405796	0.20450716	false
training	oneLayer	oneLayer - rat 1	0	0.14812456	0.19696222	false
training	oneLayer	oneLayer - rat 1	0	0.15195261	0.18772054	false
training	oneLayer	oneLayer - rat 1	0	0.15960807	0.1800651	false
training	oneLayer	oneLayer - rat 1	0	0.16376449	0.17003064	false
training	oneLayer	oneLayer - rat 1	0	0.1712579	0.16253725	false
training	oneLayer	oneLayer - rat 1	0	0.17530082	0.15277682	false
training	oneLayer	oneLayer - rat 1	0	0.18258238	0.14549528	false
training	oneLayer	oneLayer - rat 1	0	0.1865321	0.13595988	false
training	oneLayer	oneLayer - rat 1	0	0.19389255	0.12859945	false
training	oneLayer	oneLayer - rat 1	0	0.19799826	0.118687436	false
training	oneLayer	oneLayer - rat 1	0	0.20552766	0.11115806	false
training	oneLayer	oneLayer - rat 1	0	0.20958458	0.10136384	false
training	oneLayer	oneLayer - rat 1	0	0.21685553	0.09409291	false
training	oneLayer	oneLayer - rat 1	0	0.22664557	0.090037756	false
training	oneLayer	oneLayer - rat 1	0	0.23739068	0.09003778	false
training	oneLayer	oneLayer - rat 1	0	0.24681838	0.09394287	false
training	oneLayer	oneLayer - rat 1	0	0.2543244	0.10144894	false
training	oneLayer	oneLayer - rat 1	0	0.2583604	0.111192636	false
training	oneLayer	oneLayer - rat 1	0	0.2654763	0.11830857	false
training	oneLayer	oneLayer - rat 1	0	0.27545726	0.12244284	false
training	oneLayer	oneLayer - rat 1	0	0.28297067	0.12995628	false
training	oneLayer	oneLayer - rat 1	0	0.2924693	0.13389075	false
training	oneLayer	oneLayer - rat 1	0	0.2996497	0.14107114	false
training	oneLayer	oneLayer - rat 1	0	0.3034984	0.15036282	false
training	oneLayer	oneLayer - rat 1	0	0.3107435	0.15760797	false
training	oneLayer	oneLayer - rat 1	0	0.3199999	0.16144212	false
training	oneLayer	oneLayer - rat 1	0	0.3273728	0.168815	false
training	oneLayer	oneLayer - rat 1	0	0.3372554	0.17290853	false
training	oneLayer	oneLayer - rat 1	0	0.34450376	0.18015692	false
training	oneLayer	oneLayer - rat 1	0	0.34851265	0.1898353	false
training	oneLayer	oneLayer - rat 1	0	0.3525266	0.1995259	false
training	oneLayer	oneLayer - rat 1	0	0.35252658	0.20985872	false
training	oneLayer	oneLayer - rat 1	0	0.35671785	0.21997735	false
training	oneLayer	oneLayer - rat 1	0	0.35671782	0.23021181	false
training	oneLayer	oneLayer - rat 1	0	0.3567178	0.24027957	false
training	oneLayer	oneLayer - rat 1	0	0.3567178	0.2512129	false
training	oneLayer	oneLayer - rat 1	0	0.35269937	0.26091415	false
training	oneLayer	oneLayer - rat 1	0	0.34512827	0.26848522	false
training	oneLayer	oneLayer - rat 1	0	0.3350914	0.2726426	false
training	oneLayer	oneLayer - rat 1	0	0.32462692	0.27264258	false
training	oneLayer	oneLayer - rat 1	0	0.31484804	0.26859203	false
training	oneLayer	oneLayer - rat 1	0	0.30729425	0.2610382	false
training	oneLayer	oneLayer - rat 1	0	0.29767564	0.25705403	false
training	oneLayer	oneLayer - rat 1	0	0.2900443	0.24942265	false
training	oneLayer	oneLayer - rat 1	0	0.28616014	0.24004544	false
training	oneLayer	oneLayer - rat 1	0	0.28616017	0.22990765	false
training	oneLayer	oneLayer - rat 1	0	0.2900525	0.22051077	false
training	oneLayer	oneLayer - rat 1	0	0.2900525	0.20983826	false
training	oneLayer	oneLayer - rat 1	0	0.2942042	0.19981523	false
training	oneLayer	oneLayer - rat 1	0	0.30163592	0.19238353	false
training	oneLayer	oneLayer - rat 1	0	0.3109201	0.18853793	false
training	oneLayer	oneLayer - rat 1	0	0.3217547	0.18853794	false
training	oneLayer	oneLayer - rat 1	0	0.33112627	0.19241978	false
training	oneLayer	oneLayer - rat 1	0	0.3382078	0.19950135	false
training	oneLayer	oneLayer - rat 1	0	0.34207228	0.20883106	false
training	oneLayer	oneLayer - rat 1	0	0.34917027	0.21592908	false
training	oneLayer	oneLayer - rat 1	0	0.3533309	0.22597378	false
training	oneLayer	oneLayer - rat 1	0	0.35333088	0.23678994	false
training	oneLayer	oneLayer - rat 1	0	0.35333088	0.24768674	false
training	oneLayer	oneLayer - rat 1	0	0.35333085	0.2578386	false
training	oneLayer	oneLayer - rat 1	0	0.34920803	0.2677919	false
training	oneLayer	oneLayer - rat 1	0	0.34157118	0.27542874	false
training	oneLayer	oneLayer - rat 1	0	0.33167148	0.27952933	false
training	oneLayer	oneLayer - rat 1	0	0.32149228	0.2795293	false
training	oneLayer	oneLayer - rat 1	0	0.31188685	0.27555057	false
training	oneLayer	oneLayer - rat 1	0	0.30428126	0.26794496	false
training	oneLayer	oneLayer - rat 1	0	0.30040154	0.25857842	false
training	oneLayer	oneLayer - rat 1	0	0.30040157	0.24832499	false
training	oneLayer	oneLayer - rat 1	0	0.30439064	0.23869452	false
training	oneLayer	oneLayer - rat 1	0	0.31170046	0.23138475	false
training	oneLayer	oneLayer - rat 1	0	0.32121512	0.22744367	false
training	oneLayer	oneLayer - rat 1	0	0.3314076	0.22744368	false
training	oneLayer	oneLayer - rat 1	0	0.34083953	0.22353688	false
training	oneLayer	oneLayer - rat 1	0	0.35164416	0.2235369	false
training	oneLayer	oneLayer - rat 1	0	0.3612983	0.21953805	false
training	oneLayer	oneLayer - rat 1	0	0.3688133	0.21202306	false
training	oneLayer	oneLayer - rat 1	0	0.3788916	0.20784852	false
training	oneLayer	oneLayer - rat 1	0	0.38660824	0.2001319	false
training	oneLayer	oneLayer - rat 1	0	0.39048585	0.1907706	false
training	oneLayer	oneLayer - rat 1	0	0.39770344	0.18355303	false
training	oneLayer	oneLayer - rat 1	0	0.40164748	0.17403135	false
training	oneLayer	oneLayer - rat 1	0	0.40904117	0.16663769	false
training	oneLayer	oneLayer - rat 1	0	0.41325065	0.15647511	false
training	oneLayer	oneLayer - rat 1	0	0.42039123	0.14933455	false
training	oneLayer	oneLayer - rat 1	0	0.42422184	0.14008668	false
training	oneLayer	oneLayer - rat 1	0	0.43178242	0.13252614	false
training	oneLayer	oneLayer - rat 1	0	0.43597975	0.12239293	false
training	oneLayer	oneLayer - rat 1	0	0.43597978	0.11194381	false
training	oneLayer	oneLayer - rat 1	0	0.4399705	0.102309406	false
training	oneLayer	oneLayer - rat 1	0	0.43997052	0.09182131	false
training	oneLayer	oneLayer - rat 1	0	0.44407523	0.08191174	false
training	oneLayer	oneLayer - rat 1	0	0.44407523	0.071742676	false
training	oneLayer	oneLayer - rat 1	0	0.44803643	0.062179547	false
training	oneLayer	oneLayer - rat 1	0	0.44803646	0.051453516	false
training	oneLayer	oneLayer - rat 1	0	0.45195246	0.041999526	false
training	oneLayer	oneLayer - rat 1	0	0.45195246	0.03111016	false
training	oneLayer	oneLayer - rat 1	0	0.45610666	0.021081127	false
training	oneLayer	oneLayer - rat 1	0	0.45610666	0.011069395	false
training	oneLayer	oneLayer - rat 1	0	0.4521576	0.0015353847	false
training	oneLayer	oneLayer - rat 1	0	0.44463998	-0.005982251	false
training	oneLayer	oneLayer - rat 1	0	0.43523923	-0.009876181	false
training	oneLayer	oneLayer - rat 1	0	0.42457336	-0.009876201	false
training	oneLayer	oneLayer - rat 1	0	0.41453108	-0.0057165776	false
training	oneLayer	oneLayer - rat 1	0	0.40354607	-0.0057165977	false
training	oneLayer	oneLayer - rat 1	0	0.39388853	-0.001716342	false
training	oneLayer	oneLayer - rat 1	0	0.38336036	-0.0017163614	false
training	oneLayer	oneLayer - rat 1	0	0.37341598	0.0024027145	false
training	oneLayer	oneLayer - rat 1	0	0.36331108	0.0024026958	false
training	oneLayer	oneLayer - rat 1	0	0.35403013	0.006246975	false
training	oneLayer	oneLayer - rat 1	0	0.3432016	0.006246955	false
training	oneLayer	oneLayer - rat 1	0	0.33349693	0.010266745	false
training	oneLayer	oneLayer - rat 1	0	0.3230543	0.010266726	false
training	oneLayer	oneLayer - rat 1	0	0.31371754	0.01413412	false
training	oneLayer	oneLayer - rat 1	0	0.30295646	0.014134101	false
training	oneLayer	oneLayer - rat 1	0	0.29326373	0.018148944	false
training	oneLayer	oneLayer - rat 1	0	0.28266564	0.018148925	false
training	oneLayer	oneLayer - rat 1	0	0.27286455	0.022208652	false
training	oneLayer	oneLayer - rat 1	0	0.2619315	0.022208631	false
training	oneLayer	oneLayer - rat 1	0	0.2524193	0.026148703	false
training	oneLayer	oneLayer - rat 1	0	0.24151379	0.026148682	false
training	oneLayer	oneLayer - rat 1	0	0.23139139	0.030341504	false
training	oneLayer	oneLayer - rat 1	0	0.22061338	0.030341484	false
training	oneLayer	oneLayer - rat 1	0	0.21136224	0.034173407	false
training	oneLayer	oneLayer - rat 1	0	0.20122743	0.034173388	false
training	oneLayer	oneLayer - rat 1	0	0.19129306	0.038288318	false
training	oneLayer	oneLayer - rat 1	0	0.18089066	0.0382883	false
training	oneLayer	oneLayer - rat 1	0	0.17097367	0.04239603	false
training	oneLayer	oneLayer - rat 1	0	0.16095242	0.042396013	false
training	oneLayer	oneLayer - rat 1	0	0.15144554	0.046333868	false
training	oneLayer	oneLayer - rat 1	0	0.1409522	0.046333846	false
training	oneLayer	oneLayer - rat 1	0	0.13130702	0.050328992	false
training	oneLayer	oneLayer - rat 1	0	0.121015094	0.050328974	false
training	oneLayer	oneLayer - rat 1	0	0.111504786	0.054268252	false
training	oneLayer	oneLayer - rat 1	0	0.10079941	0.054268233	false
training	oneLayer	oneLayer - rat 1	0	0.0913071	0.058200054	false
training	oneLayer	oneLayer - rat 1	0	0.080585696	0.058200035	false
training	oneLayer	oneLayer - rat 1	0	0.070817396	0.062246177	false
training	oneLayer	oneLayer - rat 1	0	0.06010972	0.06224616	false
training	oneLayer	oneLayer - rat 1	0	0.050707743	0.06614056	false
training	oneLayer	oneLayer - rat 1	0	0.040494937	0.06614055	false
training	oneLayer	oneLayer - rat 1	0	0.031219644	0.06998248	false
training	oneLayer	oneLayer - rat 1	0	0.020340936	0.069982454	false
training	oneLayer	oneLayer - rat 1	0	0.011078699	0.07381898	false
training	oneLayer	oneLayer - rat 1	0	5.5186654E-4	0.07381896	false
training	oneLayer	oneLayer - rat 1	0	-0.008804816	0.07769461	false
training	oneLayer	oneLayer - rat 1	0	-0.01969192	0.07769459	false
training	oneLayer	oneLayer - rat 1	0	-0.029681314	0.081832305	false
training	oneLayer	oneLayer - rat 1	0	-0.04067059	0.08183229	false
training	oneLayer	oneLayer - rat 1	0	-0.050207403	0.08578254	false
training	oneLayer	oneLayer - rat 1	0	-0.060750965	0.08578253	false
training	oneLayer	oneLayer - rat 1	0	-0.070084184	0.08964845	false
training	oneLayer	oneLayer - rat 1	0	-0.08014755	0.08964843	false
training	oneLayer	oneLayer - rat 1	0	-0.08962856	0.093575574	false
training	oneLayer	oneLayer - rat 1	0	-0.09977267	0.09357556	false
training	oneLayer	oneLayer - rat 1	0	-0.109491274	0.097601116	false
training	oneLayer	oneLayer - rat 1	0	-0.1201766	0.09760109	false
training	oneLayer	oneLayer - rat 1	0	-0.13028555	0.101788335	false
training	oneLayer	oneLayer - rat 1	0	-0.1408259	0.10178831	false
training	oneLayer	oneLayer - rat 1	0	-0.15074776	0.10589807	false
training	oneLayer	oneLayer - rat 1	0	-0.16114776	0.105898045	false
training	oneLayer	oneLayer - rat 1	0	-0.17101456	0.109984994	false
training	oneLayer	oneLayer - rat 1	0	-0.18175	0.10998497	false
training	oneLayer	oneLayer - rat 1	0	-0.19107625	0.11384801	false
training	oneLayer	oneLayer - rat 1	0	-0.20145538	0.11384799	false
training	oneLayer	oneLayer - rat 1	0	-0.21144116	0.11798421	false
training	oneLayer	oneLayer - rat 1	0	-0.22156528	0.11798419	false
training	oneLayer	oneLayer - rat 1	0	-0.23162994	0.122153096	false
training	oneLayer	oneLayer - rat 1	0	-0.24252293	0.12215307	false
training	oneLayer	oneLayer - rat 1	0	-0.25243878	0.12626034	false
training	oneLayer	oneLayer - rat 1	0	-0.26270106	0.12626033	false
training	oneLayer	oneLayer - rat 1	0	-0.27259228	0.13035738	false
training	oneLayer	oneLayer - rat 1	0	-0.28348488	0.13035735	false
training	oneLayer	oneLayer - rat 1	0	-0.2934355	0.13447903	false
training	oneLayer	oneLayer - rat 1	0	-0.3038404	0.134479	false
training	oneLayer	oneLayer - rat 1	0	-0.31348515	0.13847397	false
training	oneLayer	oneLayer - rat 1	0	-0.3238146	0.13847396	false
training	oneLayer	oneLayer - rat 1	0	-0.33314374	0.14233819	false
training	oneLayer	oneLayer - rat 1	0	-0.34365717	0.14233817	false
training	oneLayer	oneLayer - rat 1	0	-0.35298502	0.1462019	false
training	oneLayer	oneLayer - rat 1	0	-0.36303946	0.14620186	false
training	oneLayer	oneLayer - rat 1	0	-0.37247002	0.15010811	false
training	oneLayer	oneLayer - rat 1	0	-0.38307396	0.1501081	false
training	oneLayer	oneLayer - rat 1	0	-0.392826	0.14606865	false
training	oneLayer	oneLayer - rat 1	0	-0.40279892	0.1419377	false
training	oneLayer	oneLayer - rat 1	0	-0.41042367	0.13431293	false
training	oneLayer	oneLayer - rat 1	0	-0.41805792	0.12667863	false
training	oneLayer	oneLayer - rat 1	0	-0.42530513	0.11943141	false
training	oneLayer	oneLayer - rat 1	0	-0.43293244	0.111804076	false
training	oneLayer	oneLayer - rat 1	0	-0.43711206	0.10171351	false
training	oneLayer	oneLayer - rat 1	0	-0.43711203	0.09169938	false
training	oneLayer	oneLayer - rat 1	0	-0.43306655	0.081932746	false
training	oneLayer	oneLayer - rat 1	0	-0.43306652	0.07114899	false
training	oneLayer	oneLayer - rat 1	0	-0.42908105	0.06152724	false
training	oneLayer	oneLayer - rat 1	0	-0.42908102	0.05110649	false
training	oneLayer	oneLayer - rat 1	0	-0.42508528	0.041459993	false
training	oneLayer	oneLayer - rat 1	0	-0.41763833	0.034013055	false
training	oneLayer	oneLayer - rat 1	0	-0.40785924	0.02996245	false
training	oneLayer	oneLayer - rat 1	0	-0.3971826	0.02996247	false
training	oneLayer	oneLayer - rat 1	0	-0.38773742	0.03387483	false
training	oneLayer	oneLayer - rat 1	0	-0.38000038	0.0416119	false
training	oneLayer	oneLayer - rat 1	0	-0.37605187	0.051144496	false
training	oneLayer	oneLayer - rat 1	0	-0.37605187	0.061903823	false
training	oneLayer	oneLayer - rat 1	0	-0.37210056	0.07144323	false
training	oneLayer	oneLayer - rat 1	0	-0.36821374	0.08082687	false
training	oneLayer	oneLayer - rat 1	0	-0.36431637	0.09023599	false
training	oneLayer	oneLayer - rat 1	0	-0.36037916	0.09974131	false
training	oneLayer	oneLayer - rat 1	0	-0.3562753	0.10964898	false
training	oneLayer	oneLayer - rat 1	0	-0.3523528	0.11911882	false
training	oneLayer	oneLayer - rat 1	0	-0.34830862	0.12888233	false
training	oneLayer	oneLayer - rat 1	0	-0.34432563	0.13849819	false
training	oneLayer	oneLayer - rat 1	0	-0.34037957	0.14802487	false
training	oneLayer	oneLayer - rat 1	0	-0.33653307	0.1573112	false
training	oneLayer	oneLayer - rat 1	0	-0.33264923	0.1666877	false
training	oneLayer	oneLayer - rat 1	0	-0.32856995	0.176536	false
training	oneLayer	oneLayer - rat 1	0	-0.3244265	0.18653923	false
training	oneLayer	oneLayer - rat 1	0	-0.32039538	0.19627124	false
training	oneLayer	oneLayer - rat 1	0	-0.31644416	0.20581041	false
training	oneLayer	oneLayer - rat 1	0	-0.3164442	0.21666868	false
training	oneLayer	oneLayer - rat 1	0	-0.32035956	0.22612114	false
training	oneLayer	oneLayer - rat 1	0	-0.32035956	0.23633397	false
training	oneLayer	oneLayer - rat 1	0	-0.3245164	0.24636936	false
training	oneLayer	oneLayer - rat 1	0	-0.32451642	0.2573007	false
training	oneLayer	oneLayer - rat 1	0	-0.32063636	0.26666802	false
training	oneLayer	oneLayer - rat 1	0	-0.31657666	0.27646908	false
training	oneLayer	oneLayer - rat 1	0	-0.31657666	0.28690836	false
training	oneLayer	oneLayer - rat 1	0	-0.31254077	0.29665193	false
training	oneLayer	oneLayer - rat 1	0	-0.30844817	0.30653244	false
training	oneLayer	oneLayer - rat 1	0	-0.30453226	0.31598634	false
training	oneLayer	oneLayer - rat 1	0	-0.3006537	0.32535002	false
training	oneLayer	oneLayer - rat 1	0	-0.29654807	0.33526197	false
training	oneLayer	oneLayer - rat 1	0	-0.2926542	0.3446627	false
training	oneLayer	oneLayer - rat 1	0	-0.2854612	0.35185573	false
training	oneLayer	oneLayer - rat 1	0	-0.27619457	0.3556941	false
training	oneLayer	oneLayer - rat 1	0	-0.26589066	0.35569412	false
training	oneLayer	oneLayer - rat 1	0	-0.25574717	0.35149255	false
training	oneLayer	oneLayer - rat 1	0	-0.24855193	0.34429735	false
training	oneLayer	oneLayer - rat 1	0	-0.244466	0.33443314	false
training	oneLayer	oneLayer - rat 1	0	-0.24446599	0.3242304	false
training	oneLayer	oneLayer - rat 1	0	-0.24846596	0.31457356	false
training	oneLayer	oneLayer - rat 1	0	-0.24846594	0.30385306	false
training	oneLayer	oneLayer - rat 1	0	-0.2523014	0.29459342	false
training	oneLayer	oneLayer - rat 1	0	-0.25230137	0.28398162	false
training	oneLayer	oneLayer - rat 1	0	-0.25624457	0.2744618	false
training	oneLayer	oneLayer - rat 1	0	-0.25624454	0.26373923	false
training	oneLayer	oneLayer - rat 1	0	-0.26039413	0.2537212	false
training	oneLayer	oneLayer - rat 1	0	-0.2603941	0.24361914	false
training	oneLayer	oneLayer - rat 1	0	-0.26438028	0.2339956	false
training	oneLayer	oneLayer - rat 1	0	-0.26438028	0.22320524	false
training	oneLayer	oneLayer - rat 1	0	-0.26848784	0.21328865	false
training	oneLayer	oneLayer - rat 1	0	-0.2684878	0.20297305	false
training	oneLayer	oneLayer - rat 1	0	-0.27251053	0.1932613	false
training	oneLayer	oneLayer - rat 1	0	-0.2725105	0.18265934	false
training	oneLayer	oneLayer - rat 1	0	-0.27652892	0.17295797	false
training	oneLayer	oneLayer - rat 1	0	-0.2840685	0.16541839	false
training	oneLayer	oneLayer - rat 1	0	-0.28796068	0.15602176	false
training	oneLayer	oneLayer - rat 1	0	-0.29572842	0.148254	false
training	oneLayer	oneLayer - rat 1	0	-0.29977646	0.13848107	false
training	oneLayer	oneLayer - rat 1	0	-0.30744532	0.13081218	false
training	oneLayer	oneLayer - rat 1	0	-0.3113881	0.121293396	false
training	oneLayer	oneLayer - rat 1	0	-0.31903043	0.11365105	false
training	oneLayer	oneLayer - rat 1	0	-0.32290658	0.10429316	false
training	oneLayer	oneLayer - rat 1	0	-0.33019862	0.09700109	false
training	oneLayer	oneLayer - rat 1	0	-0.33414698	0.08746886	false
training	oneLayer	oneLayer - rat 1	0	-0.34181678	0.07979902	false
training	oneLayer	oneLayer - rat 1	0	-0.34597534	0.06975935	false
training	oneLayer	oneLayer - rat 1	0	-0.35365087	0.06208378	false
training	oneLayer	oneLayer - rat 1	0	-0.35753703	0.052701708	false
training	oneLayer	oneLayer - rat 1	0	-0.36506018	0.04517853	false
training	oneLayer	oneLayer - rat 1	0	-0.36919108	0.035205636	false
training	oneLayer	oneLayer - rat 1	0	-0.3768381	0.027558606	false
training	oneLayer	oneLayer - rat 1	0	-0.38608694	0.02372758	false
training	oneLayer	oneLayer - rat 1	0	-0.3936538	0.016160684	false
training	oneLayer	oneLayer - rat 1	0	-0.4029153	0.0123244235	false
training	oneLayer	oneLayer - rat 1	0	-0.4103873	0.0048524137	false
training	oneLayer	oneLayer - rat 1	0	-0.4176528	-0.0024131057	false
training	oneLayer	oneLayer - rat 1	0	-0.4252702	-0.010030553	false
training	oneLayer	oneLayer - rat 1	0	-0.4291084	-0.019296851	false
training	oneLayer	oneLayer - rat 1	0	-0.42910838	-0.03016535	false
training	oneLayer	oneLayer - rat 1	0	-0.4250495	-0.03996429	false
training	oneLayer	oneLayer - rat 1	0	-0.42504948	-0.05005499	false
training	oneLayer	oneLayer - rat 1	0	-0.42088342	-0.060112733	false
training	oneLayer	oneLayer - rat 1	0	-0.41318974	-0.06780638	false
training	oneLayer	oneLayer - rat 1	0	-0.40363044	-0.07176595	false
training	oneLayer	oneLayer - rat 1	0	-0.3934817	-0.07176594	false
training	oneLayer	oneLayer - rat 1	0	-0.3841433	-0.06789782	false
training	oneLayer	oneLayer - rat 1	0	-0.3766698	-0.060424317	false
training	oneLayer	oneLayer - rat 1	0	-0.37255245	-0.050484106	false
training	oneLayer	oneLayer - rat 1	0	-0.3685125	-0.040730763	false
training	oneLayer	oneLayer - rat 1	0	-0.36453658	-0.031131921	false
training	oneLayer	oneLayer - rat 1	0	-0.36056605	-0.021546194	false
training	oneLayer	oneLayer - rat 1	0	-0.35663342	-0.01205194	false
training	oneLayer	oneLayer - rat 1	0	-0.35267514	-0.0024957738	false
training	oneLayer	oneLayer - rat 1	0	-0.3487427	0.0069980784	false
training	oneLayer	oneLayer - rat 1	0	-0.34486333	0.016363733	false
training	oneLayer	oneLayer - rat 1	0	-0.3409927	0.025708346	false
training	oneLayer	oneLayer - rat 1	0	-0.33687106	0.035658933	false
training	oneLayer	oneLayer - rat 1	0	-0.33270216	0.04572354	false
training	oneLayer	oneLayer - rat 1	0	-0.32874927	0.055266708	false
training	oneLayer	oneLayer - rat 1	0	-0.32461882	0.065238595	false
training	oneLayer	oneLayer - rat 1	0	-0.32063526	0.0748558	false
training	oneLayer	oneLayer - rat 1	0	-0.31652707	0.084773876	false
training	oneLayer	oneLayer - rat 1	0	-0.3165271	0.09506965	false
training	oneLayer	oneLayer - rat 1	0	-0.31235144	0.105150625	false
training	oneLayer	oneLayer - rat 1	0	-0.31235147	0.1153024	false
training	oneLayer	oneLayer - rat 1	0	-0.31621593	0.124631956	false
training	oneLayer	oneLayer - rat 1	0	-0.32393992	0.13235593	false
training	oneLayer	oneLayer - rat 1	0	-0.3280349	0.14224203	false
training	oneLayer	oneLayer - rat 1	0	-0.3280349	0.15234849	false
training	oneLayer	oneLayer - rat 1	0	-0.3320341	0.16200332	false
training	oneLayer	oneLayer - rat 1	0	-0.33203414	0.17257911	false
training	oneLayer	oneLayer - rat 1	0	-0.33623224	0.18271424	false
training	oneLayer	oneLayer - rat 1	0	-0.33623227	0.1934272	false
training	oneLayer	oneLayer - rat 1	0	-0.3404109	0.20351517	false
training	oneLayer	oneLayer - rat 1	0	-0.3404109	0.2143182	false
training	oneLayer	oneLayer - rat 1	0	-0.34439647	0.22394015	false
training	oneLayer	oneLayer - rat 1	0	-0.3443965	0.23403288	false
training	oneLayer	oneLayer - rat 1	0	-0.3403505	0.24380077	false
training	oneLayer	oneLayer - rat 1	0	-0.33648825	0.2531252	false
training	oneLayer	oneLayer - rat 1	0	-0.33233503	0.263152	false
training	oneLayer	oneLayer - rat 1	0	-0.32849205	0.27242982	false
training	oneLayer	oneLayer - rat 1	0	-0.32849208	0.28342012	false
training	oneLayer	oneLayer - rat 1	0	-0.32440573	0.29328543	false
training	oneLayer	oneLayer - rat 1	0	-0.32024002	0.30334246	false
training	oneLayer	oneLayer - rat 1	0	-0.31620014	0.31309566	false
training	oneLayer	oneLayer - rat 1	0	-0.31203082	0.32316133	false
training	oneLayer	oneLayer - rat 1	0	-0.30794135	0.33303422	false
training	oneLayer	oneLayer - rat 1	0	-0.30021396	0.34076163	false
training	oneLayer	oneLayer - rat 1	0	-0.29022676	0.3448985	false
training	oneLayer	oneLayer - rat 1	0	-0.27993137	0.34489852	false
training	oneLayer	oneLayer - rat 1	0	-0.27017164	0.34085593	false
training	oneLayer	oneLayer - rat 1	0	-0.26297408	0.3336584	false
training	oneLayer	oneLayer - rat 1	0	-0.258942	0.32392415	false
training	oneLayer	oneLayer - rat 1	0	-0.25894198	0.3136726	false
training	oneLayer	oneLayer - rat 1	0	-0.26304823	0.30375916	false
training	oneLayer	oneLayer - rat 1	0	-0.26304823	0.29322004	false
training	oneLayer	oneLayer - rat 1	0	-0.26706162	0.28353077	false
training	oneLayer	oneLayer - rat 1	0	-0.26706162	0.27259016	false
training	oneLayer	oneLayer - rat 1	0	-0.27111772	0.26279783	false
training	oneLayer	oneLayer - rat 1	0	-0.2711177	0.2523108	false
training	oneLayer	oneLayer - rat 1	0	-0.27520803	0.24243581	false
training	oneLayer	oneLayer - rat 1	0	-0.275208	0.23186778	false
training	oneLayer	oneLayer - rat 1	0	-0.27926102	0.22208282	false
training	oneLayer	oneLayer - rat 1	0	-0.27926102	0.21167211	false
training	oneLayer	oneLayer - rat 1	0	-0.2833487	0.2018035	false
training	oneLayer	oneLayer - rat 1	0	-0.28334868	0.19163157	false
training	oneLayer	oneLayer - rat 1	0	-0.2872849	0.1821286	false
training	oneLayer	oneLayer - rat 1	0	-0.2872849	0.17134109	false
training	oneLayer	oneLayer - rat 1	0	-0.29116485	0.16197404	false
training	oneLayer	oneLayer - rat 1	0	-0.29116482	0.15126102	false
training	oneLayer	oneLayer - rat 1	0	-0.29502633	0.14193845	false
training	oneLayer	oneLayer - rat 1	0	-0.30255693	0.13440782	false
training	oneLayer	oneLayer - rat 1	0	-0.3119038	0.1305362	false
training	oneLayer	oneLayer - rat 1	0	-0.31929967	0.12314031	false
training	oneLayer	oneLayer - rat 1	0	-0.32335612	0.113347106	false
training	oneLayer	oneLayer - rat 1	0	-0.33107042	0.10563277	false
training	oneLayer	oneLayer - rat 1	0	-0.33503035	0.0960726	false
training	oneLayer	oneLayer - rat 1	0	-0.34218833	0.08891459	false
training	oneLayer	oneLayer - rat 1	0	-0.34624407	0.07912316	false
training	oneLayer	oneLayer - rat 1	0	-0.35343164	0.071935564	false
training	oneLayer	oneLayer - rat 1	0	-0.3573338	0.06251484	false
training	oneLayer	oneLayer - rat 1	0	-0.36451098	0.055337645	false
training	oneLayer	oneLayer - rat 1	0	-0.3684975	0.045713287	false
training	oneLayer	oneLayer - rat 1	0	-0.37592384	0.038286895	false
training	oneLayer	oneLayer - rat 1	0	-0.3798992	0.02868951	false
training	oneLayer	oneLayer - rat 1	0	-0.38727418	0.021314498	false
training	oneLayer	oneLayer - rat 1	0	-0.3972148	0.017196937	false
training	oneLayer	oneLayer - rat 1	0	-0.4044896	0.009922118	false
training	oneLayer	oneLayer - rat 1	0	-0.40869573	-2.3240918E-4	false
training	oneLayer	oneLayer - rat 1	0	-0.4086957	-0.010500407	false
training	oneLayer	oneLayer - rat 1	0	-0.40452516	-0.020568946	false
training	oneLayer	oneLayer - rat 1	0	-0.3971041	-0.027989948	false
training	oneLayer	oneLayer - rat 1	0	-0.38748023	-0.031976268	false
training	oneLayer	oneLayer - rat 1	0	-0.37686267	-0.03197625	false
training	oneLayer	oneLayer - rat 1	0	-0.36723396	-0.027987875	false
training	oneLayer	oneLayer - rat 1	0	-0.3599537	-0.02070759	false
training	oneLayer	oneLayer - rat 1	0	-0.35018462	-0.016661081	false
training	oneLayer	oneLayer - rat 1	0	-0.3426919	-0.009168338	false
training	oneLayer	oneLayer - rat 1	0	-0.33852997	8.794891E-4	false
training	oneLayer	oneLayer - rat 1	0	-0.3345815	0.010412034	false
training	oneLayer	oneLayer - rat 1	0	-0.32697338	0.018020177	false
training	oneLayer	oneLayer - rat 1	0	-0.32278487	0.028132223	false
training	oneLayer	oneLayer - rat 1	0	-0.31543636	0.03548075	false
training	oneLayer	oneLayer - rat 1	0	-0.30576703	0.039485943	false
training	oneLayer	oneLayer - rat 1	0	-0.29838768	0.046865318	false
training	oneLayer	oneLayer - rat 1	0	-0.28825018	0.051064424	false
training	oneLayer	oneLayer - rat 1	0	-0.2808424	0.05847225	false
training	oneLayer	oneLayer - rat 1	0	-0.27701116	0.06772172	false
training	oneLayer	oneLayer - rat 1	0	-0.2770112	0.078675404	false
training	oneLayer	oneLayer - rat 1	0	-0.27316245	0.0879671	false
training	oneLayer	oneLayer - rat 1	0	-0.27316245	0.098018035	false
training	oneLayer	oneLayer - rat 1	0	-0.2690276	0.108000554	false
training	oneLayer	oneLayer - rat 1	0	-0.26143792	0.11559026	false
training	oneLayer	oneLayer - rat 1	0	-0.25752485	0.12503733	false
training	oneLayer	oneLayer - rat 1	0	-0.25044805	0.13211414	false
training	oneLayer	oneLayer - rat 1	0	-0.24033754	0.13630207	false
training	oneLayer	oneLayer - rat 1	0	-0.23315357	0.14348607	false
training	oneLayer	oneLayer - rat 1	0	-0.22354633	0.14746554	false
training	oneLayer	oneLayer - rat 1	0	-0.21641082	0.15460108	false
training	oneLayer	oneLayer - rat 1	0	-0.21243052	0.16421041	false
training	oneLayer	oneLayer - rat 1	0	-0.20855415	0.17356886	false
training	oneLayer	oneLayer - rat 1	0	-0.20855416	0.18417846	false
training	oneLayer	oneLayer - rat 1	0	-0.20855418	0.1943474	false
training	oneLayer	oneLayer - rat 1	0	-0.20449314	0.20415168	false
training	oneLayer	oneLayer - rat 1	0	-0.20449317	0.21442659	false
training	oneLayer	oneLayer - rat 1	0	-0.20032369	0.22449265	false
training	oneLayer	oneLayer - rat 1	0	-0.1928079	0.23200847	false
training	oneLayer	oneLayer - rat 1	0	-0.18892455	0.24138376	false
training	oneLayer	oneLayer - rat 1	0	-0.18160339	0.24870495	false
training	oneLayer	oneLayer - rat 1	0	-0.17231463	0.2525525	false
training	oneLayer	oneLayer - rat 1	0	-0.1651945	0.25967264	false
training	oneLayer	oneLayer - rat 1	0	-0.15545872	0.26370537	false
training	oneLayer	oneLayer - rat 1	0	-0.14778593	0.2713782	false
training	oneLayer	oneLayer - rat 1	0	-0.14384228	0.28089905	false
training	oneLayer	oneLayer - rat 1	0	-0.13981287	0.29062694	false
training	oneLayer	oneLayer - rat 1	0	-0.13212293	0.29831693	false
training	oneLayer	oneLayer - rat 1	0	-0.12825602	0.3076525	false
training	oneLayer	oneLayer - rat 1	0	-0.12100083	0.31490773	false
training	oneLayer	oneLayer - rat 1	0	-0.11136952	0.3188972	false
training	oneLayer	oneLayer - rat 1	0	-0.10424587	0.32602084	false
training	oneLayer	oneLayer - rat 1	0	-0.09435273	0.33011875	false
training	oneLayer	oneLayer - rat 1	0	-0.087120906	0.3373506	false
training	oneLayer	oneLayer - rat 1	0	-0.08311886	0.34701243	false
training	oneLayer	oneLayer - rat 1	0	-0.075553365	0.35457796	false
training	oneLayer	oneLayer - rat 1	0	-0.07141386	0.36457166	false
training	oneLayer	oneLayer - rat 1	0	-0.063673034	0.37231252	false
training	oneLayer	oneLayer - rat 1	0	-0.059563406	0.3822341	false
training	oneLayer	oneLayer - rat 1	0	-0.05181902	0.38997853	false
training	oneLayer	oneLayer - rat 1	0	-0.047839954	0.3995849	false
training	oneLayer	oneLayer - rat 1	0	-0.040755097	0.40666977	false
training	oneLayer	oneLayer - rat 1	0	-0.031161187	0.41064373	false
training	oneLayer	oneLayer - rat 1	0	-0.023442704	0.41836223	false
training	oneLayer	oneLayer - rat 1	0	-0.0137817385	0.42236397	false
training	oneLayer	oneLayer - rat 1	0	-0.0060864743	0.43005925	false
training	oneLayer	oneLayer - rat 1	0	0.0031553232	0.43388736	false
training	oneLayer	oneLayer - rat 1	0	0.014045325	0.43388736	false
training	oneLayer	oneLayer - rat 1	0	0.02333051	0.43773344	false
training	oneLayer	oneLayer - rat 1	0	0.033358112	0.43773347	false
training	oneLayer	oneLayer - rat 1	0	0.043115444	0.43369186	false
training	oneLayer	oneLayer - rat 1	0	0.05330524	0.4336919	false
training	oneLayer	oneLayer - rat 1	0	0.062619776	0.4298337	false
training	oneLayer	oneLayer - rat 1	0	0.0697483	0.4227052	false
training	oneLayer	oneLayer - rat 1	0	0.07990723	0.41849726	false
training	oneLayer	oneLayer - rat 1	0	0.08734865	0.41105586	false
training	oneLayer	oneLayer - rat 1	0	0.096669786	0.40719494	false
training	oneLayer	oneLayer - rat 1	0	0.10707381	0.40719497	false
training	oneLayer	oneLayer - rat 1	0	0.11670186	0.41118306	false
training	oneLayer	oneLayer - rat 1	0	0.12757976	0.4111831	false
training	oneLayer	oneLayer - rat 1	0	0.1376881	0.4069961	false
training	oneLayer	oneLayer - rat 1	0	0.14778082	0.40699613	false
training	oneLayer	oneLayer - rat 1	0	0.15714574	0.40311706	false
training	oneLayer	oneLayer - rat 1	0	0.16463542	0.3956274	false
training	oneLayer	oneLayer - rat 1	0	0.16860738	0.3860383	false
training	oneLayer	oneLayer - rat 1	0	0.1757266	0.3789191	false
training	oneLayer	oneLayer - rat 1	0	0.17972744	0.36926028	false
training	oneLayer	oneLayer - rat 1	0	0.17972745	0.3583495	false
training	oneLayer	oneLayer - rat 1	0	0.18371646	0.3487192	false
training	oneLayer	oneLayer - rat 1	0	0.1912266	0.3412091	false
training	oneLayer	oneLayer - rat 1	0	0.20104791	0.337141	false
training	oneLayer	oneLayer - rat 1	0	0.20872049	0.32946846	false
training	oneLayer	oneLayer - rat 1	0	0.21266858	0.319937	false
training	oneLayer	oneLayer - rat 1	0	0.21985464	0.31275097	false
training	oneLayer	oneLayer - rat 1	0	0.22399013	0.30276707	false
training	oneLayer	oneLayer - rat 1	0	0.22399014	0.29218596	false
training	oneLayer	oneLayer - rat 1	0	0.2280464	0.28239337	false
training	oneLayer	oneLayer - rat 1	0	0.23512442	0.27531537	false
training	oneLayer	oneLayer - rat 1	0	0.23898284	0.26600036	false
training	oneLayer	oneLayer - rat 1	0	0.24614204	0.2588412	false
training	oneLayer	oneLayer - rat 1	0	0.256045	0.25473925	false
training	oneLayer	oneLayer - rat 1	0	0.26355585	0.24722843	false
training	oneLayer	oneLayer - rat 1	0	0.27370733	0.24302359	false
training	oneLayer	oneLayer - rat 1	0	0.280881	0.23584996	false
training	oneLayer	oneLayer - rat 1	0	0.29068348	0.23178966	false
training	oneLayer	oneLayer - rat 1	0	0.29786095	0.2246122	false
training	oneLayer	oneLayer - rat 1	0	0.30793765	0.22043832	false
training	oneLayer	oneLayer - rat 1	0	0.31568998	0.21268603	false
training	oneLayer	oneLayer - rat 1	0	0.3251098	0.20878422	false
training	oneLayer	oneLayer - rat 1	0	0.3326643	0.20122977	false
training	oneLayer	oneLayer - rat 1	0	0.34261575	0.19710776	false
training	oneLayer	oneLayer - rat 1	0	0.35010633	0.1896172	false
training	oneLayer	oneLayer - rat 1	0	0.35995218	0.18553895	false
training	oneLayer	oneLayer - rat 1	0	0.3675112	0.17797995	false
training	oneLayer	oneLayer - rat 1	0	0.3768569	0.17410886	false
training	oneLayer	oneLayer - rat 1	0	0.38454205	0.16642372	false
training	oneLayer	oneLayer - rat 1	0	0.3886496	0.15650724	false
training	oneLayer	oneLayer - rat 1	0	0.39603558	0.1491213	false
training	oneLayer	oneLayer - rat 1	0	0.4001479	0.13919333	false
training	oneLayer	oneLayer - rat 1	0	0.40783277	0.13150848	false
training	oneLayer	oneLayer - rat 1	0	0.4118084	0.12191053	false
training	oneLayer	oneLayer - rat 1	0	0.41914248	0.11457647	false
training	oneLayer	oneLayer - rat 1	0	0.42311475	0.10498662	false
training	oneLayer	oneLayer - rat 1	0	0.43035588	0.09774553	false
training	oneLayer	oneLayer - rat 1	0	0.43438032	0.08802975	false
training	oneLayer	oneLayer - rat 1	0	0.43438032	0.07704913	false
training	oneLayer	oneLayer - rat 1	0	0.43824348	0.06772272	false
training	oneLayer	oneLayer - rat 1	0	0.4382435	0.057002943	false
training	oneLayer	oneLayer - rat 1	0	0.44237146	0.0470372	false
training	oneLayer	oneLayer - rat 1	0	0.4423715	0.03695271	false
training	oneLayer	oneLayer - rat 1	0	0.43835205	0.027248861	false
training	oneLayer	oneLayer - rat 1	0	0.43088722	0.019784013	false
training	oneLayer	oneLayer - rat 1	0	0.42111632	0.015736753	false
training	oneLayer	oneLayer - rat 1	0	0.4137822	0.008402612	false
training	oneLayer	oneLayer - rat 1	0	0.4041635	0.004418398	false
training	oneLayer	oneLayer - rat 1	0	0.39652142	-0.0032237256	false
training	oneLayer	oneLayer - rat 1	0	0.38675317	-0.0072698854	false
training	oneLayer	oneLayer - rat 1	0	0.3760389	-0.007269905	false
training	oneLayer	oneLayer - rat 1	0	0.36617962	-0.011353782	false
training	oneLayer	oneLayer - rat 1	0	0.3556878	-0.011353801	false
training	oneLayer	oneLayer - rat 1	0	0.3462307	-0.015271086	false
training	oneLayer	oneLayer - rat 1	0	0.33584127	-0.015271106	false
training	oneLayer	oneLayer - rat 1	0	0.32651022	-0.01913617	false
training	oneLayer	oneLayer - rat 1	0	0.31617534	-0.019136189	false
training	oneLayer	oneLayer - rat 1	0	0.30630186	-0.02322595	false
training	oneLayer	oneLayer - rat 1	0	0.29582092	-0.023225969	false
training	oneLayer	oneLayer - rat 1	0	0.28592363	-0.027325576	false
training	oneLayer	oneLayer - rat 1	0	0.27569234	-0.027325595	false
training	oneLayer	oneLayer - rat 1	0	0.2655427	-0.031529732	false
training	oneLayer	oneLayer - rat 1	0	0.2552814	-0.031529754	false
training	oneLayer	oneLayer - rat 1	0	0.24548991	-0.03558554	false
training	oneLayer	oneLayer - rat 1	0	0.23516148	-0.03558556	false
training	oneLayer	oneLayer - rat 1	0	0.22516057	-0.0397281	false
training	oneLayer	oneLayer - rat 1	0	0.21473353	-0.03972812	false
training	oneLayer	oneLayer - rat 1	0	0.20485269	-0.04382092	false
training	oneLayer	oneLayer - rat 1	0	0.19439137	-0.04382094	false
training	oneLayer	oneLayer - rat 1	0	0.18480428	-0.04779206	false
training	oneLayer	oneLayer - rat 1	0	0.1745021	-0.047792077	false
training	oneLayer	oneLayer - rat 1	0	0.16437703	-0.05198604	false
training	oneLayer	oneLayer - rat 1	0	0.15419775	-0.051986057	false
training	oneLayer	oneLayer - rat 1	0	0.14458676	-0.05596708	false
training	oneLayer	oneLayer - rat 1	0	0.13369189	-0.0559671	false
training	oneLayer	oneLayer - rat 1	0	0.124355	-0.05983459	false
training	oneLayer	oneLayer - rat 1	0	0.11403026	-0.059834607	false
training	oneLayer	oneLayer - rat 1	0	0.10432458	-0.06385485	false
training	oneLayer	oneLayer - rat 1	0	0.09427068	-0.063854866	false
training	oneLayer	oneLayer - rat 1	0	0.084246546	-0.06800702	false
training	oneLayer	oneLayer - rat 1	0	0.07371884	-0.06800704	false
training	oneLayer	oneLayer - rat 1	0	0.06440555	-0.07186475	false
training	oneLayer	oneLayer - rat 1	0	0.05419569	-0.07186477	false
training	oneLayer	oneLayer - rat 1	0	0.04434954	-0.075943194	false
training	oneLayer	oneLayer - rat 1	0	0.03417077	-0.07594322	false
training	oneLayer	oneLayer - rat 1	0	0.024761613	-0.07984064	false
training	oneLayer	oneLayer - rat 1	0	0.014256009	-0.07984065	false
training	oneLayer	oneLayer - rat 1	0	0.004978502	-0.08368354	false
training	oneLayer	oneLayer - rat 1	0	-0.0054500103	-0.083683565	false
training	oneLayer	oneLayer - rat 1	0	-0.014762265	-0.08754084	false
training	oneLayer	oneLayer - rat 1	0	-0.025169175	-0.087540865	false
training	oneLayer	oneLayer - rat 1	0	-0.03499731	-0.09161183	false
training	oneLayer	oneLayer - rat 1	0	-0.04580034	-0.091611855	false
training	oneLayer	oneLayer - rat 1	0	-0.055505104	-0.09563172	false
training	oneLayer	oneLayer - rat 1	0	-0.066221416	-0.09563174	false
training	oneLayer	oneLayer - rat 1	0	-0.07572944	-0.09957011	false
training	oneLayer	oneLayer - rat 1	0	-0.08598658	-0.099570125	false
training	oneLayer	oneLayer - rat 1	0	-0.09568014	-0.103585355	false
training	oneLayer	oneLayer - rat 1	0	-0.10581328	-0.10358537	false
training	oneLayer	oneLayer - rat 1	0	-0.115291856	-0.10751155	false
training	oneLayer	oneLayer - rat 1	0	-0.1261588	-0.107511565	false
training	oneLayer	oneLayer - rat 1	0	-0.13551712	-0.11138792	false
training	oneLayer	oneLayer - rat 1	0	-0.14579278	-0.111387946	false
training	oneLayer	oneLayer - rat 1	0	-0.15529402	-0.11532351	false
training	oneLayer	oneLayer - rat 1	0	-0.16620941	-0.11532353	false
training	oneLayer	oneLayer - rat 1	0	-0.17550546	-0.11917409	false
training	oneLayer	oneLayer - rat 1	0	-0.18628448	-0.119174115	false
training	oneLayer	oneLayer - rat 1	0	-0.1957899	-0.11523686	false
training	oneLayer	oneLayer - rat 1	0	-0.20631337	-0.11523688	false
training	oneLayer	oneLayer - rat 1	0	-0.21592064	-0.11125744	false
training	oneLayer	oneLayer - rat 1	0	-0.22613166	-0.11125746	false
training	oneLayer	oneLayer - rat 1	0	-0.23606756	-0.1071419	false
training	oneLayer	oneLayer - rat 1	0	-0.24627623	-0.10714192	false
training	oneLayer	oneLayer - rat 1	0	-0.2557107	-0.10323406	false
training	oneLayer	oneLayer - rat 1	0	-0.26659712	-0.103234075	false
training	oneLayer	oneLayer - rat 1	0	-0.27621815	-0.099248946	false
training	oneLayer	oneLayer - rat 1	0	-0.28642967	-0.09924896	false
training	oneLayer	oneLayer - rat 1	0	-0.2963641	-0.09513401	false
training	oneLayer	oneLayer - rat 1	0	-0.3067299	-0.095134035	false
training	oneLayer	oneLayer - rat 1	0	-0.31629094	-0.09117374	false
training	oneLayer	oneLayer - rat 1	0	-0.32706213	-0.09117376	false
training	oneLayer	oneLayer - rat 1	0	-0.33710626	-0.08701338	false
training	oneLayer	oneLayer - rat 1	0	-0.34805587	-0.08701339	false
training	oneLayer	oneLayer - rat 1	0	-0.3578249	-0.082966946	false
training	oneLayer	oneLayer - rat 1	0	-0.3681752	-0.08296697	false
training	oneLayer	oneLayer - rat 1	0	-0.3781637	-0.078829624	false
training	oneLayer	oneLayer - rat 1	0	-0.3852895	-0.07170384	false
training	oneLayer	oneLayer - rat 1	0	-0.39256394	-0.064429425	false
training	oneLayer	oneLayer - rat 1	0	-0.39967445	-0.05731895	false
training	oneLayer	oneLayer - rat 1	0	-0.4072474	-0.04974601	false
training	oneLayer	oneLayer - rat 1	0	-0.41492394	-0.042069513	false
training	oneLayer	oneLayer - rat 1	0	-0.4220546	-0.034938887	false
training	oneLayer	oneLayer - rat 1	0	-0.42601353	-0.02538117	false
training	oneLayer	oneLayer - rat 1	0	-0.42601356	-0.01465591	false
training	oneLayer	oneLayer - rat 1	0	-0.43000233	-0.005026176	false
training	oneLayer	oneLayer - rat 1	0	-0.43000236	0.0055013406	false
training	oneLayer	oneLayer - rat 1	0	-0.43385687	0.01480693	false
training	oneLayer	oneLayer - rat 1	0	-0.4338569	0.025153406	false
training	oneLayer	oneLayer - rat 1	0	-0.43789756	0.034908388	false
training	oneLayer	oneLayer - rat 1	0	-0.4378976	0.045801498	false
training	oneLayer	oneLayer - rat 1	0	-0.43404737	0.05509676	false
training	oneLayer	oneLayer - rat 1	0	-0.43005428	0.06473705	false
training	oneLayer	oneLayer - rat 1	0	-0.42620856	0.074021466	false
training	oneLayer	oneLayer - rat 1	0	-0.42223483	0.08361496	false
training	oneLayer	oneLayer - rat 1	0	-0.4183928	0.09289048	false
training	oneLayer	oneLayer - rat 1	0	-0.41434553	0.10266145	false
training	oneLayer	oneLayer - rat 1	0	-0.4102475	0.11255502	false
training	oneLayer	oneLayer - rat 1	0	-0.40628523	0.12212085	false
training	oneLayer	oneLayer - rat 1	0	-0.40212512	0.13216428	false
training	oneLayer	oneLayer - rat 1	0	-0.39811233	0.14185207	false
training	oneLayer	oneLayer - rat 1	0	-0.39427167	0.15112433	false
training	oneLayer	oneLayer - rat 1	0	-0.39012492	0.16113554	false
training	oneLayer	oneLayer - rat 1	0	-0.38600957	0.17107089	false
training	oneLayer	oneLayer - rat 1	0	-0.38197413	0.18081336	false
training	oneLayer	oneLayer - rat 1	0	-0.37793064	0.19057523	false
training	oneLayer	oneLayer - rat 1	0	-0.37375095	0.20066594	false
training	oneLayer	oneLayer - rat 1	0	-0.36968264	0.21048777	false
training	oneLayer	oneLayer - rat 1	0	-0.36564457	0.2202366	false
training	oneLayer	oneLayer - rat 1	0	-0.36153528	0.23015736	false
training	oneLayer	oneLayer - rat 1	0	-0.3574863	0.23993246	false
training	oneLayer	oneLayer - rat 1	0	-0.35331517	0.25000253	false
training	oneLayer	oneLayer - rat 1	0	-0.349202	0.25993267	false
training	oneLayer	oneLayer - rat 1	0	-0.3450389	0.26998338	false
training	oneLayer	oneLayer - rat 1	0	-0.34084532	0.28010762	false
training	oneLayer	oneLayer - rat 1	0	-0.33684716	0.28976002	false
training	oneLayer	oneLayer - rat 1	0	-0.3328358	0.29944435	false
training	oneLayer	oneLayer - rat 1	0	-0.32895175	0.30882135	false
training	oneLayer	oneLayer - rat 1	0	-0.32499745	0.31836793	false
training	oneLayer	oneLayer - rat 1	0	-0.3178305	0.32553488	false
training	oneLayer	oneLayer - rat 1	0	-0.30810422	0.32956368	false
training	oneLayer	oneLayer - rat 1	0	-0.2978558	0.32956368	false
training	oneLayer	oneLayer - rat 1	0	-0.28784963	0.325419	false
training	oneLayer	oneLayer - rat 1	0	-0.2802854	0.3178548	false
training	oneLayer	oneLayer - rat 1	0	-0.276458	0.30861467	false
training	oneLayer	oneLayer - rat 1	0	-0.27645797	0.298044	false
training	oneLayer	oneLayer - rat 1	0	-0.28066134	0.28789607	false
training	oneLayer	oneLayer - rat 1	0	-0.28066134	0.2774975	false
training	oneLayer	oneLayer - rat 1	0	-0.28478825	0.26753414	false
training	oneLayer	oneLayer - rat 1	0	-0.28478825	0.2570986	false
training	oneLayer	oneLayer - rat 1	0	-0.2887498	0.24753451	false
training	oneLayer	oneLayer - rat 1	0	-0.28874978	0.23702358	false
training	oneLayer	oneLayer - rat 1	0	-0.29265016	0.22760718	false
training	oneLayer	oneLayer - rat 1	0	-0.29265016	0.21758725	false
training	oneLayer	oneLayer - rat 1	0	-0.2965142	0.20825852	false
training	oneLayer	oneLayer - rat 1	0	-0.2965142	0.19768716	false
training	oneLayer	oneLayer - rat 1	0	-0.30049944	0.18806592	false
training	oneLayer	oneLayer - rat 1	0	-0.3004994	0.17793573	false
training	oneLayer	oneLayer - rat 1	0	-0.30470437	0.16778404	false
training	oneLayer	oneLayer - rat 1	0	-0.30470434	0.15740116	false
training	oneLayer	oneLayer - rat 1	0	-0.3086342	0.14791363	false
training	oneLayer	oneLayer - rat 1	0	-0.30863416	0.1372133	false
training	oneLayer	oneLayer - rat 1	0	-0.31280097	0.12715371	false
training	oneLayer	oneLayer - rat 1	0	-0.3201247	0.119829975	false
training	oneLayer	oneLayer - rat 1	0	-0.32421267	0.10996059	false
training	oneLayer	oneLayer - rat 1	0	-0.3316866	0.10248667	false
training	oneLayer	oneLayer - rat 1	0	-0.3355791	0.093089275	false
training	oneLayer	oneLayer - rat 1	0	-0.34328455	0.0853838	false
training	oneLayer	oneLayer - rat 1	0	-0.3473142	0.0756553	false
training	oneLayer	oneLayer - rat 1	0	-0.35489032	0.06807915	false
training	oneLayer	oneLayer - rat 1	0	-0.35880443	0.0586296	false
training	oneLayer	oneLayer - rat 1	0	-0.36634475	0.05108925	false
training	oneLayer	oneLayer - rat 1	0	-0.3703462	0.04142889	false
training	oneLayer	oneLayer - rat 1	0	-0.3778267	0.033948362	false
training	oneLayer	oneLayer - rat 1	0	-0.38178772	0.024385568	false
training	oneLayer	oneLayer - rat 1	0	-0.38932973	0.016843524	false
training	oneLayer	oneLayer - rat 1	0	-0.39925632	0.012731781	false
training	oneLayer	oneLayer - rat 1	0	-0.40697247	0.0050156084	false
training	oneLayer	oneLayer - rat 1	0	-0.41107067	-0.0048784018	false
training	oneLayer	oneLayer - rat 1	0	-0.41107064	-0.01496421	false
training	oneLayer	oneLayer - rat 1	0	-0.40692678	-0.024968328	false
training	oneLayer	oneLayer - rat 1	0	-0.40692678	-0.035938278	false
training	oneLayer	oneLayer - rat 1	0	-0.4030303	-0.045345157	false
training	oneLayer	oneLayer - rat 1	0	-0.39527825	-0.053097196	false
training	oneLayer	oneLayer - rat 1	0	-0.38548306	-0.057154477	false
training	oneLayer	oneLayer - rat 1	0	-0.3752211	-0.057154458	false
training	oneLayer	oneLayer - rat 1	0	-0.3656694	-0.053197995	false
training	oneLayer	oneLayer - rat 1	0	-0.35818574	-0.045714308	false
training	oneLayer	oneLayer - rat 1	0	-0.35424304	-0.03619573	false
training	oneLayer	oneLayer - rat 1	0	-0.35031217	-0.02670578	false
training	oneLayer	oneLayer - rat 1	0	-0.34635276	-0.017146816	false
training	oneLayer	oneLayer - rat 1	0	-0.3424093	-0.0076264525	false
training	oneLayer	oneLayer - rat 1	0	-0.3382419	0.002434613	false
training	oneLayer	oneLayer - rat 1	0	-0.33428285	0.011992675	false
training	oneLayer	oneLayer - rat 1	0	-0.33012378	0.022033574	false
training	oneLayer	oneLayer - rat 1	0	-0.32592082	0.032180447	false
training	oneLayer	oneLayer - rat 1	0	-0.32202557	0.041584518	false
training	oneLayer	oneLayer - rat 1	0	-0.31802985	0.05123102	false
training	oneLayer	oneLayer - rat 1	0	-0.31802988	0.061703995	false
training	oneLayer	oneLayer - rat 1	0	-0.31387952	0.07172387	false
training	oneLayer	oneLayer - rat 1	0	-0.31387955	0.08188014	false
training	oneLayer	oneLayer - rat 1	0	-0.30975455	0.091838844	false
training	oneLayer	oneLayer - rat 1	0	-0.30975455	0.102651305	false
training	oneLayer	oneLayer - rat 1	0	-0.3057929	0.11221566	false
training	oneLayer	oneLayer - rat 1	0	-0.30579293	0.12240012	false
training	oneLayer	oneLayer - rat 1	0	-0.30166632	0.13236268	false
training	oneLayer	oneLayer - rat 1	0	-0.30166632	0.1433475	false
training	oneLayer	oneLayer - rat 1	0	-0.29748073	0.15345249	false
training	oneLayer	oneLayer - rat 1	0	-0.29748076	0.16397321	false
training	oneLayer	oneLayer - rat 1	0	-0.2934553	0.17369151	false
training	oneLayer	oneLayer - rat 1	0	-0.29345533	0.18456554	false
training	oneLayer	oneLayer - rat 1	0	-0.28957012	0.1939453	false
training	oneLayer	oneLayer - rat 1	0	-0.28957015	0.20406574	false
training	oneLayer	oneLayer - rat 1	0	-0.28555283	0.21376446	false
training	oneLayer	oneLayer - rat 1	0	-0.28555286	0.22403038	false
training	oneLayer	oneLayer - rat 1	0	-0.28138268	0.23409814	false
training	oneLayer	oneLayer - rat 1	0	-0.28138268	0.24415621	false
training	oneLayer	oneLayer - rat 1	0	-0.27745038	0.25364968	false
training	oneLayer	oneLayer - rat 1	0	-0.2774504	0.26402512	false
training	oneLayer	oneLayer - rat 1	0	-0.27331632	0.27400568	false
training	oneLayer	oneLayer - rat 1	0	-0.27331635	0.284983	false
training	oneLayer	oneLayer - rat 1	0	-0.27745318	0.29497012	false
training	oneLayer	oneLayer - rat 1	0	-0.2850645	0.30258143	false
training	oneLayer	oneLayer - rat 1	0	-0.2924433	0.3099602	false
training	oneLayer	oneLayer - rat 1	0	-0.30234036	0.31405967	false
training	oneLayer	oneLayer - rat 1	0	-0.30951145	0.32123074	false
training	oneLayer	oneLayer - rat 1	0	-0.31904647	0.32518023	false
training	oneLayer	oneLayer - rat 1	0	-0.31904647	0.32518023	false
training	oneLayer	oneLayer - rat 1	0	-0.31904647	0.32518023	false
training	oneLayer	oneLayer - rat 1	0	-0.31904647	0.32518023	false
training	oneLayer	oneLayer - rat 1	0	-0.31904647	0.32518023	false
training	oneLayer	oneLayer - rat 1	0	-0.31904647	0.32518023	false
training	oneLayer	oneLayer - rat 1	0	-0.31904647	0.32518023	false
training	oneLayer	oneLayer - rat 1	0	-0.31904647	0.32518023	false
training	oneLayer	oneLayer - rat 1	0	-0.31904647	0.32518023	false
training	oneLayer	oneLayer - rat 1	0	-0.31904647	0.32518023	false
training	oneLayer	oneLayer - rat 1	0	-0.31904647	0.32518023	false
training	oneLayer	oneLayer - rat 1	0	-0.31904647	0.32518023	false
training	oneLayer	oneLayer - rat 1	0	-0.31904647	0.32518023	false
training	oneLayer	oneLayer - rat 1	0	-0.31904647	0.32518023	false
training	oneLayer	oneLayer - rat 1	0	-0.31904647	0.32518023	false
training	oneLayer	oneLayer - rat 1	0	-0.31904647	0.32518023	false
training	oneLayer	oneLayer - rat 1	0	-0.31904647	0.32518023	false
training	oneLayer	oneLayer - rat 1	0	-0.31904647	0.32518023	false
training	oneLayer	oneLayer - rat 1	0	-0.31904647	0.32518023	false
training	oneLayer	oneLayer - rat 1	0	-0.31904647	0.32518023	false
training	oneLayer	oneLayer - rat 1	0	-0.31904647	0.32518023	false
training	oneLayer	oneLayer - rat 1	0	-0.31904647	0.32518023	false
training	oneLayer	oneLayer - rat 1	0	-0.31904647	0.32518023	false
training	oneLayer	oneLayer - rat 1	0	-0.31904647	0.32518023	false
training	oneLayer	oneLayer - rat 1	0	-0.31904647	0.32518023	false
training	oneLayer	oneLayer - rat 1	0	-0.31904647	0.32518023	false
training	oneLayer	oneLayer - rat 1	0	-0.31904647	0.32518023	false
training	oneLayer	oneLayer - rat 1	0	-0.32959825	0.32518023	false
training	oneLayer	oneLayer - rat 1	0	-0.33975676	0.3209724	false
training	oneLayer	oneLayer - rat 1	0	-0.34746763	0.3132615	false
training	oneLayer	oneLayer - rat 1	0	-0.35158828	0.3033133	false
training	oneLayer	oneLayer - rat 1	0	-0.35158828	0.29324472	false
training	oneLayer	oneLayer - rat 1	0	-0.34752095	0.28342542	false
training	oneLayer	oneLayer - rat 1	0	-0.34752095	0.2729704	false
training	oneLayer	oneLayer - rat 1	0	-0.351426	0.26354268	false
training	oneLayer	oneLayer - rat 1	0	-0.351426	0.2533488	false
training	oneLayer	oneLayer - rat 1	0	-0.35536867	0.24383028	false
training	oneLayer	oneLayer - rat 1	0	-0.36250684	0.23669207	false
training	oneLayer	oneLayer - rat 1	0	-0.36642233	0.2272392	false
training	oneLayer	oneLayer - rat 1	0	-0.37350702	0.22015448	false
training	oneLayer	oneLayer - rat 1	0	-0.3775251	0.21045399	false
training	oneLayer	oneLayer - rat 1	0	-0.37752506	0.20040944	false
training	oneLayer	oneLayer - rat 1	0	-0.37344858	0.19056797	false
training	oneLayer	oneLayer - rat 1	0	-0.37344855	0.18020421	false
training	oneLayer	oneLayer - rat 1	0	-0.37731797	0.17086263	false
training	oneLayer	oneLayer - rat 1	0	-0.37731794	0.16038518	false
training	oneLayer	oneLayer - rat 1	0	-0.3811784	0.15106513	false
training	oneLayer	oneLayer - rat 1	0	-0.38858196	0.14366154	false
training	oneLayer	oneLayer - rat 1	0	-0.3984253	0.13958427	false
training	oneLayer	oneLayer - rat 1	0	-0.40559894	0.13241062	false
training	oneLayer	oneLayer - rat 1	0	-0.4097994	0.12226975	false
training	oneLayer	oneLayer - rat 1	0	-0.41722584	0.11484329	false
training	oneLayer	oneLayer - rat 1	0	-0.4211966	0.105256975	false
training	oneLayer	oneLayer - rat 1	0	-0.42865607	0.097797476	false
training	oneLayer	oneLayer - rat 1	0	-0.4325805	0.08832298	false
training	oneLayer	oneLayer - rat 1	0	-0.4325805	0.07747746	false
training	oneLayer	oneLayer - rat 1	0	-0.4287093	0.06813162	false
training	oneLayer	oneLayer - rat 1	0	-0.42870927	0.057562992	false
training	oneLayer	oneLayer - rat 1	0	-0.43263987	0.048073616	false
training	oneLayer	oneLayer - rat 1	0	-0.43263987	0.03737739	false
training	oneLayer	oneLayer - rat 1	0	-0.42849264	0.027365133	false
training	oneLayer	oneLayer - rat 1	0	-0.42121077	0.020083318	false
training	oneLayer	oneLayer - rat 1	0	-0.41188568	0.016220758	false
training	oneLayer	oneLayer - rat 1	0	-0.40092024	0.01622078	false
training	oneLayer	oneLayer - rat 1	0	-0.3910616	0.020304391	false
training	oneLayer	oneLayer - rat 1	0	-0.38025036	0.020304412	false
training	oneLayer	oneLayer - rat 1	0	-0.3706878	0.024265379	false
training	oneLayer	oneLayer - rat 1	0	-0.36047983	0.024265397	false
training	oneLayer	oneLayer - rat 1	0	-0.35057807	0.028366866	false
training	oneLayer	oneLayer - rat 1	0	-0.3395787	0.028366886	false
training	oneLayer	oneLayer - rat 1	0	-0.33020896	0.03224798	false
training	oneLayer	oneLayer - rat 1	0	-0.31927398	0.032247998	false
training	oneLayer	oneLayer - rat 1	0	-0.3095383	0.036280666	false
training	oneLayer	oneLayer - rat 1	0	-0.29932648	0.036280684	false
training	oneLayer	oneLayer - rat 1	0	-0.2900782	0.040111467	false
training	oneLayer	oneLayer - rat 1	0	-0.2791718	0.04011149	false
training	oneLayer	oneLayer - rat 1	0	-0.26979223	0.043996654	false
training	oneLayer	oneLayer - rat 1	0	-0.2620708	0.051718123	false
training	oneLayer	oneLayer - rat 1	0	-0.25819302	0.061079994	false
training	oneLayer	oneLayer - rat 1	0	-0.25819302	0.07152412	false
training	oneLayer	oneLayer - rat 1	0	-0.25414488	0.08129728	false
training	oneLayer	oneLayer - rat 1	0	-0.24645682	0.08898537	false
training	oneLayer	oneLayer - rat 1	0	-0.24248305	0.09857893	false
training	oneLayer	oneLayer - rat 1	0	-0.23489422	0.10616779	false
training	oneLayer	oneLayer - rat 1	0	-0.22544909	0.110080115	false
training	oneLayer	oneLayer - rat 1	0	-0.21781534	0.1177139	false
training	oneLayer	oneLayer - rat 1	0	-0.20792088	0.121812336	false
training	oneLayer	oneLayer - rat 1	0	-0.19745472	0.12181236	false
training	oneLayer	oneLayer - rat 1	0	-0.18815878	0.12566288	false
training	oneLayer	oneLayer - rat 1	0	-0.17766586	0.12566291	false
training	oneLayer	oneLayer - rat 1	0	-0.16836064	0.12180857	false
training	oneLayer	oneLayer - rat 1	0	-0.15807709	0.121808596	false
training	oneLayer	oneLayer - rat 1	0	-0.14835079	0.11777985	false
training	oneLayer	oneLayer - rat 1	0	-0.1377409	0.11777987	false
training	oneLayer	oneLayer - rat 1	0	-0.1281517	0.12175187	false
training	oneLayer	oneLayer - rat 1	0	-0.11765076	0.12175189	false
training	oneLayer	oneLayer - rat 1	0	-0.10753008	0.12594403	false
training	oneLayer	oneLayer - rat 1	0	-0.09694494	0.12594405	false
training	oneLayer	oneLayer - rat 1	0	-0.087645404	0.12979607	false
training	oneLayer	oneLayer - rat 1	0	-0.07736241	0.12979609	false
training	oneLayer	oneLayer - rat 1	0	-0.06797843	0.13368309	false
training	oneLayer	oneLayer - rat 1	0	-0.060304757	0.14135678	false
training	oneLayer	oneLayer - rat 1	0	-0.056398362	0.1507877	false
training	oneLayer	oneLayer - rat 1	0	-0.0524285	0.16037185	false
training	oneLayer	oneLayer - rat 1	0	-0.052428517	0.17071155	false
training	oneLayer	oneLayer - rat 1	0	-0.05242854	0.18165748	false
training	oneLayer	oneLayer - rat 1	0	-0.048578892	0.1909514	false
training	oneLayer	oneLayer - rat 1	0	-0.04082793	0.1987024	false
training	oneLayer	oneLayer - rat 1	0	-0.0367468	0.20855516	false
training	oneLayer	oneLayer - rat 1	0	-0.029312622	0.21598938	false
training	oneLayer	oneLayer - rat 1	0	-0.025275318	0.22573633	false
training	oneLayer	oneLayer - rat 1	0	-0.017766744	0.23324494	false
training	oneLayer	oneLayer - rat 1	0	-0.013619686	0.24325688	false
training	oneLayer	oneLayer - rat 1	0	-0.006453136	0.25042346	false
training	oneLayer	oneLayer - rat 1	0	-0.0023463904	0.26033807	false
training	oneLayer	oneLayer - rat 1	0	0.005428036	0.26811254	false
training	oneLayer	oneLayer - rat 1	0	0.00952791	0.27801055	false
training	oneLayer	oneLayer - rat 1	0	0.017102495	0.28558517	false
training	oneLayer	oneLayer - rat 1	0	0.020997737	0.29498917	false
training	oneLayer	oneLayer - rat 1	0	0.028310401	0.30230185	false
training	oneLayer	oneLayer - rat 1	0	0.03249298	0.31239957	false
training	oneLayer	oneLayer - rat 1	0	0.040107194	0.3200138	false
training	oneLayer	oneLayer - rat 1	0	0.04952647	0.32391542	false
training	oneLayer	oneLayer - rat 1	0	0.06032266	0.32391545	false
training	oneLayer	oneLayer - rat 1	0	0.069675595	0.32004136	false
training	oneLayer	oneLayer - rat 1	0	0.07690055	0.3128164	false
training	oneLayer	oneLayer - rat 1	0	0.08675294	0.30873543	false
training	oneLayer	oneLayer - rat 1	0	0.09400346	0.30148494	false
training	oneLayer	oneLayer - rat 1	0	0.097983375	0.29187664	false
training	oneLayer	oneLayer - rat 1	0	0.10538663	0.28447342	false
training	oneLayer	oneLayer - rat 1	0	0.11539422	0.28032815	false
training	oneLayer	oneLayer - rat 1	0	0.12631701	0.28032818	false
training	oneLayer	oneLayer - rat 1	0	0.13578746	0.27640542	false
training	oneLayer	oneLayer - rat 1	0	0.14629814	0.27640545	false
training	oneLayer	oneLayer - rat 1	0	0.1555911	0.28025472	false
training	oneLayer	oneLayer - rat 1	0	0.16617884	0.28025475	false
training	oneLayer	oneLayer - rat 1	0	0.17566715	0.28418496	false
training	oneLayer	oneLayer - rat 1	0	0.18662198	0.284185	false
training	oneLayer	oneLayer - rat 1	0	0.19675824	0.28838357	false
training	oneLayer	oneLayer - rat 1	0	0.20727026	0.2883836	false
training	oneLayer	oneLayer - rat 1	0	0.21731105	0.2842246	false
training	oneLayer	oneLayer - rat 1	0	0.22449778	0.2770379	false
training	oneLayer	oneLayer - rat 1	0	0.22838609	0.26765075	false
training	oneLayer	oneLayer - rat 1	0	0.23611613	0.25992075	false
training	oneLayer	oneLayer - rat 1	0	0.24540626	0.25607267	false
training	oneLayer	oneLayer - rat 1	0	0.2526486	0.24883035	false
training	oneLayer	oneLayer - rat 1	0	0.26196894	0.24496976	false
training	oneLayer	oneLayer - rat 1	0	0.26958188	0.23735684	false
training	oneLayer	oneLayer - rat 1	0	0.27886543	0.2335115	false
training	oneLayer	oneLayer - rat 1	0	0.286535	0.22584194	false
training	oneLayer	oneLayer - rat 1	0	0.29630366	0.22179565	false
training	oneLayer	oneLayer - rat 1	0	0.30350783	0.21459152	false
training	oneLayer	oneLayer - rat 1	0	0.3129405	0.21068439	false
training	oneLayer	oneLayer - rat 1	0	0.32026982	0.2033551	false
training	oneLayer	oneLayer - rat 1	0	0.33012843	0.19927156	false
training	oneLayer	oneLayer - rat 1	0	0.3373908	0.19200921	false
training	oneLayer	oneLayer - rat 1	0	0.3472579	0.18792215	false
training	oneLayer	oneLayer - rat 1	0	0.35432974	0.18085034	false
training	oneLayer	oneLayer - rat 1	0	0.36412597	0.17679264	false
training	oneLayer	oneLayer - rat 1	0	0.37128136	0.16963726	false
training	oneLayer	oneLayer - rat 1	0	0.38083345	0.16568069	false
training	oneLayer	oneLayer - rat 1	0	0.38804364	0.15847053	false
training	oneLayer	oneLayer - rat 1	0	0.39196226	0.14901021	false
training	oneLayer	oneLayer - rat 1	0	0.39196226	0.13810043	false
training	oneLayer	oneLayer - rat 1	0	0.39593625	0.12850645	false
training	oneLayer	oneLayer - rat 1	0	0.39593625	0.117844254	false
training	oneLayer	oneLayer - rat 1	0	0.4001169	0.10775141	false
training	oneLayer	oneLayer - rat 1	0	0.40760627	0.10026205	false
training	oneLayer	oneLayer - rat 1	0	0.41171238	0.09034909	false
training	oneLayer	oneLayer - rat 1	0	0.41925514	0.08280634	false
training	oneLayer	oneLayer - rat 1	0	0.4234361	0.072712705	false
training	oneLayer	oneLayer - rat 1	0	0.4308983	0.06525051	false
training	oneLayer	oneLayer - rat 1	0	0.43475565	0.055938136	false
training	oneLayer	oneLayer - rat 1	0	0.43475568	0.04498949	false
training	oneLayer	oneLayer - rat 1	0	0.43894833	0.034867536	false
training	oneLayer	oneLayer - rat 1	0	0.43894836	0.024796689	false
training	oneLayer	oneLayer - rat 1	0	0.44291207	0.015227457	false
training	oneLayer	oneLayer - rat 1	0	0.4429121	0.004320056	false
training	oneLayer	oneLayer - rat 1	0	0.44698873	-0.0055217436	false
training	oneLayer	oneLayer - rat 1	0	0.44698876	-0.015557203	false
training	oneLayer	oneLayer - rat 1	0	0.45084807	-0.024874358	false
training	oneLayer	oneLayer - rat 1	0	0.45084807	-0.035638954	false
training	oneLayer	oneLayer - rat 1	0	0.44699234	-0.04494762	false
training	oneLayer	oneLayer - rat 1	0	0.44699234	-0.05529881	false
training	oneLayer	oneLayer - rat 1	0	0.44287813	-0.06523149	false
training	oneLayer	oneLayer - rat 1	0	0.44287813	-0.07561819	false
training	oneLayer	oneLayer - rat 1	0	0.43882388	-0.08540607	false
training	oneLayer	oneLayer - rat 1	0	0.4388239	-0.09638219	false
training	oneLayer	oneLayer - rat 1	0	0.43470314	-0.10633066	false
training	oneLayer	oneLayer - rat 1	0	0.43470317	-0.11644868	false
training	oneLayer	oneLayer - rat 1	0	0.4308534	-0.12574285	false
training	oneLayer	oneLayer - rat 1	0	0.43085343	-0.13596626	false
training	oneLayer	oneLayer - rat 1	0	0.42680693	-0.1457354	false
training	oneLayer	oneLayer - rat 1	0	0.42680696	-0.1558208	false
training	oneLayer	oneLayer - rat 1	0	0.42263758	-0.16588658	false
training	oneLayer	oneLayer - rat 1	0	0.4226376	-0.17647685	false
training	oneLayer	oneLayer - rat 1	0	0.41865614	-0.18608904	false
training	oneLayer	oneLayer - rat 1	0	0.4109966	-0.19374862	false
training	oneLayer	oneLayer - rat 1	0	0.40715724	-0.20301767	false
training	oneLayer	oneLayer - rat 1	0	0.40001807	-0.21015687	false
training	oneLayer	oneLayer - rat 1	0	0.3961394	-0.21952084	false
training	oneLayer	oneLayer - rat 1	0	0.3887509	-0.22690937	false
training	oneLayer	oneLayer - rat 1	0	0.38482147	-0.2363959	false
training	oneLayer	oneLayer - rat 1	0	0.37736556	-0.24385184	false
training	oneLayer	oneLayer - rat 1	0	0.37336627	-0.25350702	false
training	oneLayer	oneLayer - rat 1	0	0.36584884	-0.26102448	false
training	oneLayer	oneLayer - rat 1	0	0.36190316	-0.27055022	false
training	oneLayer	oneLayer - rat 1	0	0.35459888	-0.27785456	false
training	oneLayer	oneLayer - rat 1	0	0.35062107	-0.28745785	false
training	oneLayer	oneLayer - rat 1	0	0.3428587	-0.29522026	false
training	oneLayer	oneLayer - rat 1	0	0.3386687	-0.30533582	false
training	oneLayer	oneLayer - rat 1	0	0.33100095	-0.3130036	false
training	oneLayer	oneLayer - rat 1	0	0.321641	-0.31688064	false
training	oneLayer	oneLayer - rat 1	0	0.31091878	-0.31688067	false
training	oneLayer	oneLayer - rat 1	0	0.3009286	-0.31274262	false
training	oneLayer	oneLayer - rat 1	0	0.29073143	-0.31274265	false
training	oneLayer	oneLayer - rat 1	0	0.28120625	-0.30879718	false
training	oneLayer	oneLayer - rat 1	0	0.27088237	-0.3087972	false
training	oneLayer	oneLayer - rat 1	0	0.2616352	-0.30496693	false
training	oneLayer	oneLayer - rat 1	0	0.25090823	-0.30496696	false
training	oneLayer	oneLayer - rat 1	0	0.2408714	-0.3008096	false
training	oneLayer	oneLayer - rat 1	0	0.23029888	-0.30080962	false
training	oneLayer	oneLayer - rat 1	0	0.22027893	-0.29665923	false
training	oneLayer	oneLayer - rat 1	0	0.20979838	-0.29665926	false
training	oneLayer	oneLayer - rat 1	0	0.20046516	-0.29279333	false
training	oneLayer	oneLayer - rat 1	0	0.18974416	-0.29279333	false
training	oneLayer	oneLayer - rat 1	0	0.18017115	-0.2888281	false
training	oneLayer	oneLayer - rat 1	0	0.1693838	-0.2888281	false
training	oneLayer	oneLayer - rat 1	0	0.15924804	-0.28462976	false
training	oneLayer	oneLayer - rat 1	0	0.14837438	-0.2846298	false
training	oneLayer	oneLayer - rat 1	0	0.13859539	-0.2805792	false
training	oneLayer	oneLayer - rat 1	0	0.12763683	-0.28057924	false
training	oneLayer	oneLayer - rat 1	0	0.11781416	-0.27651057	false
training	oneLayer	oneLayer - rat 1	0	0.10703595	-0.2765106	false
training	oneLayer	oneLayer - rat 1	0	0.09765241	-0.2726238	false
training	oneLayer	oneLayer - rat 1	0	0.08700812	-0.27262384	false
training	oneLayer	oneLayer - rat 1	0	0.07715562	-0.26854283	false
training	oneLayer	oneLayer - rat 1	0	0.0666958	-0.26854283	false
training	oneLayer	oneLayer - rat 1	0	0.05712698	-0.26457933	false
training	oneLayer	oneLayer - rat 1	0	0.046464335	-0.26457933	false
training	oneLayer	oneLayer - rat 1	0	0.03644467	-0.26042908	false
training	oneLayer	oneLayer - rat 1	0	0.026022803	-0.26042908	false
training	oneLayer	oneLayer - rat 1	0	0.016771706	-0.2565972	false
training	oneLayer	oneLayer - rat 1	0	0.0058622803	-0.25659722	false
training	oneLayer	oneLayer - rat 1	0	-0.0035921372	-0.25268108	false
training	oneLayer	oneLayer - rat 1	0	-0.014440563	-0.2526811	false
training	oneLayer	oneLayer - rat 1	0	-0.02432619	-0.24858636	false
training	oneLayer	oneLayer - rat 1	0	-0.03515617	-0.24858639	false
training	oneLayer	oneLayer - rat 1	0	-0.044749875	-0.24461256	false
training	oneLayer	oneLayer - rat 1	0	-0.054805588	-0.24461257	false
training	oneLayer	oneLayer - rat 1	0	-0.06421033	-0.24071702	false
training	oneLayer	oneLayer - rat 1	0	-0.07470076	-0.24071705	false
training	oneLayer	oneLayer - rat 1	0	-0.08404361	-0.23684713	false
training	oneLayer	oneLayer - rat 1	0	-0.094622254	-0.23684715	false
training	oneLayer	oneLayer - rat 1	0	-0.10408749	-0.23292655	false
training	oneLayer	oneLayer - rat 1	0	-0.11480755	-0.23292656	false
training	oneLayer	oneLayer - rat 1	0	-0.12420755	-0.22903298	false
training	oneLayer	oneLayer - rat 1	0	-0.13425516	-0.229033	false
training	oneLayer	oneLayer - rat 1	0	-0.14413644	-0.22494006	false
training	oneLayer	oneLayer - rat 1	0	-0.15417303	-0.22494008	false
training	oneLayer	oneLayer - rat 1	0	-0.16347833	-0.22108571	false
training	oneLayer	oneLayer - rat 1	0	-0.1739727	-0.22108573	false
training	oneLayer	oneLayer - rat 1	0	-0.18343076	-0.2171681	false
training	oneLayer	oneLayer - rat 1	0	-0.19397978	-0.21716811	false
training	oneLayer	oneLayer - rat 1	0	-0.20321919	-0.21334104	false
training	oneLayer	oneLayer - rat 1	0	-0.21388483	-0.21334106	false
training	oneLayer	oneLayer - rat 1	0	-0.22359729	-0.20931806	false
training	oneLayer	oneLayer - rat 1	0	-0.23395924	-0.20931807	false
training	oneLayer	oneLayer - rat 1	0	-0.24400184	-0.20515832	false
training	oneLayer	oneLayer - rat 1	0	-0.2548384	-0.20515834	false
training	oneLayer	oneLayer - rat 1	0	-0.2647985	-0.20103276	false
training	oneLayer	oneLayer - rat 1	0	-0.2751418	-0.20103277	false
training	oneLayer	oneLayer - rat 1	0	-0.2846624	-0.19708924	false
training	oneLayer	oneLayer - rat 1	0	-0.2951864	-0.19708925	false
training	oneLayer	oneLayer - rat 1	0	-0.30443954	-0.1932565	false
training	oneLayer	oneLayer - rat 1	0	-0.31472263	-0.19325651	false
training	oneLayer	oneLayer - rat 1	0	-0.32441303	-0.18924265	false
training	oneLayer	oneLayer - rat 1	0	-0.33517438	-0.18924266	false
training	oneLayer	oneLayer - rat 1	0	-0.34532517	-0.18503807	false
training	oneLayer	oneLayer - rat 1	0	-0.3555634	-0.1850381	false
training	oneLayer	oneLayer - rat 1	0	-0.3655504	-0.18090138	false
training	oneLayer	oneLayer - rat 1	0	-0.3761829	-0.1809014	false
training	oneLayer	oneLayer - rat 1	0	-0.38543594	-0.17706868	false
training	oneLayer	oneLayer - rat 1	0	-0.39264664	-0.169858	false
training	oneLayer	oneLayer - rat 1	0	-0.39654514	-0.16044627	false
training	oneLayer	oneLayer - rat 1	0	-0.39654514	-0.1500759	false
training	oneLayer	oneLayer - rat 1	0	-0.4005713	-0.14035602	false
training	oneLayer	oneLayer - rat 1	0	-0.4005713	-0.12993734	false
training	oneLayer	oneLayer - rat 1	0	-0.40467253	-0.12003615	false
training	oneLayer	oneLayer - rat 1	0	-0.40467253	-0.10983801	false
training	oneLayer	oneLayer - rat 1	0	-0.40055057	-0.09988667	false
training	oneLayer	oneLayer - rat 1	0	-0.3965179	-0.09015087	false
training	oneLayer	oneLayer - rat 1	0	-0.39232615	-0.080031045	false
training	oneLayer	oneLayer - rat 1	0	-0.38839749	-0.07054634	false
training	oneLayer	oneLayer - rat 1	0	-0.38440633	-0.060910817	false
training	oneLayer	oneLayer - rat 1	0	-0.38054928	-0.051599022	false
training	oneLayer	oneLayer - rat 1	0	-0.3765808	-0.042018194	false
training	oneLayer	oneLayer - rat 1	0	-0.37263104	-0.032482598	false
training	oneLayer	oneLayer - rat 1	0	-0.36862308	-0.022806464	false
training	oneLayer	oneLayer - rat 1	0	-0.3645214	-0.012904098	false
training	oneLayer	oneLayer - rat 1	0	-0.36048463	-0.003158442	false
training	oneLayer	oneLayer - rat 1	0	-0.35663304	0.006140158	false
training	oneLayer	oneLayer - rat 1	0	-0.35254848	0.016001254	false
training	oneLayer	oneLayer - rat 1	0	-0.34842032	0.025967514	false
training	oneLayer	oneLayer - rat 1	0	-0.3445757	0.035249315	false
training	oneLayer	oneLayer - rat 1	0	-0.34064642	0.044735525	false
training	oneLayer	oneLayer - rat 1	0	-0.3365025	0.0547399	false
training	oneLayer	oneLayer - rat 1	0	-0.33255032	0.0642813	false
training	oneLayer	oneLayer - rat 1	0	-0.32843608	0.074214004	false
training	oneLayer	oneLayer - rat 1	0	-0.32424322	0.0843365	false
training	oneLayer	oneLayer - rat 1	0	-0.32036397	0.093701914	false
training	oneLayer	oneLayer - rat 1	0	-0.31615764	0.10385694	false
training	oneLayer	oneLayer - rat 1	0	-0.31615767	0.11403208	false
training	oneLayer	oneLayer - rat 1	0	-0.320048	0.123424195	false
training	oneLayer	oneLayer - rat 1	0	-0.32004803	0.13417149	false
training	oneLayer	oneLayer - rat 1	0	-0.32402956	0.1437837	false
training	oneLayer	oneLayer - rat 1	0	-0.3240296	0.15405947	false
training	oneLayer	oneLayer - rat 1	0	-0.32806078	0.16379158	false
training	oneLayer	oneLayer - rat 1	0	-0.3280608	0.17436647	false
training	oneLayer	oneLayer - rat 1	0	-0.3320359	0.18396313	false
training	oneLayer	oneLayer - rat 1	0	-0.3320359	0.19437198	false
training	oneLayer	oneLayer - rat 1	0	-0.3359062	0.20371567	false
training	oneLayer	oneLayer - rat 1	0	-0.33590624	0.21454555	false
training	oneLayer	oneLayer - rat 1	0	-0.33987603	0.22412947	false
training	oneLayer	oneLayer - rat 1	0	-0.33987606	0.2349359	false
training	oneLayer	oneLayer - rat 1	0	-0.33588105	0.24458073	false
training	oneLayer	oneLayer - rat 1	0	-0.33200356	0.2539419	false
training	oneLayer	oneLayer - rat 1	0	-0.3280248	0.2635475	false
training	oneLayer	oneLayer - rat 1	0	-0.3238229	0.27369186	false
training	oneLayer	oneLayer - rat 1	0	-0.32382292	0.2839408	false
training	oneLayer	oneLayer - rat 1	0	-0.3197098	0.29387072	false
training	oneLayer	oneLayer - rat 1	0	-0.31578115	0.30335543	false
training	oneLayer	oneLayer - rat 1	0	-0.31159565	0.3134601	false
training	oneLayer	oneLayer - rat 1	0	-0.30752513	0.32328728	false
training	oneLayer	oneLayer - rat 1	0	-0.3036159	0.33272505	false
training	oneLayer	oneLayer - rat 1	0	-0.29647613	0.33986485	false
training	oneLayer	oneLayer - rat 1	0	-0.2864387	0.3440225	false
training	oneLayer	oneLayer - rat 1	0	-0.27619803	0.34402254	false
training	oneLayer	oneLayer - rat 1	0	-0.26661095	0.34005144	false
training	oneLayer	oneLayer - rat 1	0	-0.25892818	0.33236873	false
training	oneLayer	oneLayer - rat 1	0	-0.25473726	0.32225102	false
training	oneLayer	oneLayer - rat 1	0	-0.25473726	0.31172267	false
training	oneLayer	oneLayer - rat 1	0	-0.2587442	0.302049	false
training	oneLayer	oneLayer - rat 1	0	-0.25874418	0.2917162	false
training	oneLayer	oneLayer - rat 1	0	-0.26279974	0.28192514	false
training	oneLayer	oneLayer - rat 1	0	-0.26279974	0.27132022	false
training	oneLayer	oneLayer - rat 1	0	-0.26678038	0.26171002	false
training	oneLayer	oneLayer - rat 1	0	-0.2744628	0.2540276	false
training	oneLayer	oneLayer - rat 1	0	-0.2839896	0.25008145	false
training	oneLayer	oneLayer - rat 1	0	-0.29108885	0.24298216	false
training	oneLayer	oneLayer - rat 1	0	-0.30048734	0.23908918	false
training	oneLayer	oneLayer - rat 1	0	-0.30775154	0.23182495	false
training	oneLayer	oneLayer - rat 1	0	-0.3173976	0.2278294	false
training	oneLayer	oneLayer - rat 1	0	-0.32508913	0.22013785	false
training	oneLayer	oneLayer - rat 1	0	-0.33458802	0.21620327	false
training	oneLayer	oneLayer - rat 1	0	-0.34197393	0.20881733	false
training	oneLayer	oneLayer - rat 1	0	-0.35172743	0.20477727	false
training	oneLayer	oneLayer - rat 1	0	-0.35894075	0.19756393	false
training	oneLayer	oneLayer - rat 1	0	-0.368295	0.19368926	false
training	oneLayer	oneLayer - rat 1	0	-0.37562656	0.18635768	false
training	oneLayer	oneLayer - rat 1	0	-0.37947142	0.17707533	false
training	oneLayer	oneLayer - rat 1	0	-0.3867715	0.16977523	false
training	oneLayer	oneLayer - rat 1	0	-0.39065143	0.16040814	false
training	oneLayer	oneLayer - rat 1	0	-0.39065143	0.14966662	false
training	oneLayer	oneLayer - rat 1	0	-0.3867711	0.14029872	false
training	oneLayer	oneLayer - rat 1	0	-0.38677108	0.12950073	false
training	oneLayer	oneLayer - rat 1	0	-0.39086226	0.11962372	false
training	oneLayer	oneLayer - rat 1	0	-0.39845347	0.112032466	false
training	oneLayer	oneLayer - rat 1	0	-0.40854782	0.10785124	false
training	oneLayer	oneLayer - rat 1	0	-0.4156763	0.10072274	false
training	oneLayer	oneLayer - rat 1	0	-0.4196449	0.09114164	false
training	oneLayer	oneLayer - rat 1	0	-0.42729613	0.08349039	false
training	oneLayer	oneLayer - rat 1	0	-0.43123978	0.07396946	false
training	oneLayer	oneLayer - rat 1	0	-0.43123978	0.06377869	false
training	oneLayer	oneLayer - rat 1	0	-0.42719778	0.05402052	false
training	oneLayer	oneLayer - rat 1	0	-0.42719778	0.04336655	false
training	oneLayer	oneLayer - rat 1	0	-0.42311087	0.033499923	false
training	oneLayer	oneLayer - rat 1	0	-0.41564438	0.026033452	false
training	oneLayer	oneLayer - rat 1	0	-0.40592736	0.022008559	false
training	oneLayer	oneLayer - rat 1	0	-0.3950149	0.022008577	false
training	oneLayer	oneLayer - rat 1	0	-0.38544244	0.025973644	false
training	oneLayer	oneLayer - rat 1	0	-0.37835968	0.033056453	false
training	oneLayer	oneLayer - rat 1	0	-0.37451407	0.042340547	false
training	oneLayer	oneLayer - rat 1	0	-0.37067547	0.051607806	false
training	oneLayer	oneLayer - rat 1	0	-0.36679488	0.06097644	false
training	oneLayer	oneLayer - rat 1	0	-0.36271724	0.07082078	false
training	oneLayer	oneLayer - rat 1	0	-0.3585426	0.080899335	false
training	oneLayer	oneLayer - rat 1	0	-0.3543931	0.090917125	false
training	oneLayer	oneLayer - rat 1	0	-0.35046658	0.10039667	false
training	oneLayer	oneLayer - rat 1	0	-0.34661216	0.10970211	false
training	oneLayer	oneLayer - rat 1	0	-0.3424163	0.11983189	false
training	oneLayer	oneLayer - rat 1	0	-0.33841178	0.12949966	false
training	oneLayer	oneLayer - rat 1	0	-0.33448964	0.13896856	false
training	oneLayer	oneLayer - rat 1	0	-0.3304666	0.14868112	false
training	oneLayer	oneLayer - rat 1	0	-0.326422	0.15844566	false
training	oneLayer	oneLayer - rat 1	0	-0.32242468	0.16809611	false
training	oneLayer	oneLayer - rat 1	0	-0.318285	0.17809024	false
training	oneLayer	oneLayer - rat 1	0	-0.31828502	0.18880723	false
training	oneLayer	oneLayer - rat 1	0	-0.32216093	0.19816448	false
training	oneLayer	oneLayer - rat 1	0	-0.32216096	0.20889297	false
training	oneLayer	oneLayer - rat 1	0	-0.32613167	0.21847905	false
training	oneLayer	oneLayer - rat 1	0	-0.32613167	0.22852746	false
training	oneLayer	oneLayer - rat 1	0	-0.33002844	0.23793507	false
training	oneLayer	oneLayer - rat 1	0	-0.33002847	0.24810782	false
training	oneLayer	oneLayer - rat 1	0	-0.32607853	0.25764382	false
training	oneLayer	oneLayer - rat 1	0	-0.32202917	0.26741993	false
training	oneLayer	oneLayer - rat 1	0	-0.31790194	0.27738404	false
training	oneLayer	oneLayer - rat 1	0	-0.31019065	0.28509533	false
training	oneLayer	oneLayer - rat 1	0	-0.30043578	0.28913596	false
training	oneLayer	oneLayer - rat 1	0	-0.29020998	0.289136	false
training	oneLayer	oneLayer - rat 1	0	-0.28085086	0.29301268	false
training	oneLayer	oneLayer - rat 1	0	-0.27023137	0.29301268	false
training	oneLayer	oneLayer - rat 1	0	-0.2608508	0.29689828	false
training	oneLayer	oneLayer - rat 1	0	-0.25072274	0.29689828	false
training	oneLayer	oneLayer - rat 1	0	-0.24100877	0.29287466	false
training	oneLayer	oneLayer - rat 1	0	-0.23055446	0.29287466	false
training	oneLayer	oneLayer - rat 1	0	-0.22057477	0.28874096	false
training	oneLayer	oneLayer - rat 1	0	-0.21053398	0.288741	false
training	oneLayer	oneLayer - rat 1	0	-0.20115383	0.28485563	false
training	oneLayer	oneLayer - rat 1	0	-0.19053483	0.28485563	false
training	oneLayer	oneLayer - rat 1	0	-0.18126121	0.2810144	false
training	oneLayer	oneLayer - rat 1	0	-0.17059952	0.2810144	false
training	oneLayer	oneLayer - rat 1	0	-0.16093011	0.27700925	false
training	oneLayer	oneLayer - rat 1	0	-0.15035781	0.27700925	false
training	oneLayer	oneLayer - rat 1	0	-0.14021534	0.28121042	false
training	oneLayer	oneLayer - rat 1	0	-0.12938228	0.28121045	false
training	oneLayer	oneLayer - rat 1	0	-0.11951171	0.285299	false
training	oneLayer	oneLayer - rat 1	0	-0.10947372	0.285299	false
training	oneLayer	oneLayer - rat 1	0	-0.09948811	0.2894352	false
training	oneLayer	oneLayer - rat 1	0	-0.088858806	0.28943524	false
training	oneLayer	oneLayer - rat 1	0	-0.07961526	0.29326406	false
training	oneLayer	oneLayer - rat 1	0	-0.06871617	0.29326406	false
training	oneLayer	oneLayer - rat 1	0	-0.05912397	0.2972373	false
training	oneLayer	oneLayer - rat 1	0	-0.048973728	0.29723734	false
training	oneLayer	oneLayer - rat 1	0	-0.039453495	0.30118075	false
training	oneLayer	oneLayer - rat 1	0	-0.028841749	0.30118078	false
training	oneLayer	oneLayer - rat 1	0	-0.019508278	0.30504686	false
training	oneLayer	oneLayer - rat 1	0	-0.008672148	0.30504686	false
training	oneLayer	oneLayer - rat 1	0	0.0011096837	0.30909866	false
training	oneLayer	oneLayer - rat 1	0	0.011514453	0.30909866	false
training	oneLayer	oneLayer - rat 1	0	0.020910136	0.31299052	false
training	oneLayer	oneLayer - rat 1	0	0.031670835	0.31299052	false
training	oneLayer	oneLayer - rat 1	0	0.04123444	0.31695193	false
training	oneLayer	oneLayer - rat 1	0	0.05131495	0.31695193	false
training	oneLayer	oneLayer - rat 1	0	0.060617816	0.32080534	false
training	oneLayer	oneLayer - rat 1	0	0.07125801	0.32080534	false
training	oneLayer	oneLayer - rat 1	0	0.08071454	0.3247224	false
training	oneLayer	oneLayer - rat 1	0	0.091412775	0.3247224	false
training	oneLayer	oneLayer - rat 1	0	0.101127915	0.3287466	false
training	oneLayer	oneLayer - rat 1	0	0.11156126	0.3287466	false
training	oneLayer	oneLayer - rat 1	0	0.12114674	0.33271706	false
training	oneLayer	oneLayer - rat 1	0	0.13115099	0.33271706	false
training	oneLayer	oneLayer - rat 1	0	0.14083253	0.33672732	false
training	oneLayer	oneLayer - rat 1	0	0.15146777	0.33672732	false
training	oneLayer	oneLayer - rat 1	0	0.16084212	0.33284438	false
training	oneLayer	oneLayer - rat 1	0	0.16812775	0.32555875	false
training	oneLayer	oneLayer - rat 1	0	0.17806728	0.32144168	false
training	oneLayer	oneLayer - rat 1	0	0.18559137	0.31391764	false
training	oneLayer	oneLayer - rat 1	0	0.1949512	0.31004068	false
training	oneLayer	oneLayer - rat 1	0	0.20202556	0.30296636	false
training	oneLayer	oneLayer - rat 1	0	0.21131082	0.29912028	false
training	oneLayer	oneLayer - rat 1	0	0.21855313	0.291878	false
training	oneLayer	oneLayer - rat 1	0	0.22785205	0.2880263	false
training	oneLayer	oneLayer - rat 1	0	0.235358	0.28052035	false
training	oneLayer	oneLayer - rat 1	0	0.24495907	0.2765435	false
training	oneLayer	oneLayer - rat 1	0	0.25227842	0.26922417	false
training	oneLayer	oneLayer - rat 1	0	0.26223868	0.2650985	false
training	oneLayer	oneLayer - rat 1	0	0.26949543	0.2578418	false
training	oneLayer	oneLayer - rat 1	0	0.27895164	0.2539249	false
training	oneLayer	oneLayer - rat 1	0	0.28608802	0.24678856	false
training	oneLayer	oneLayer - rat 1	0	0.2960307	0.2426702	false
training	oneLayer	oneLayer - rat 1	0	0.30370563	0.2349953	false
training	oneLayer	oneLayer - rat 1	0	0.31357387	0.23090777	false
training	oneLayer	oneLayer - rat 1	0	0.32108077	0.22340089	false
training	oneLayer	oneLayer - rat 1	0	0.3307205	0.21940799	false
training	oneLayer	oneLayer - rat 1	0	0.3381698	0.21195874	false
training	oneLayer	oneLayer - rat 1	0	0.3479163	0.20792162	false
training	oneLayer	oneLayer - rat 1	0	0.35546568	0.20037228	false
training	oneLayer	oneLayer - rat 1	0	0.36556852	0.19618756	false
training	oneLayer	oneLayer - rat 1	0	0.37301713	0.18873897	false
training	oneLayer	oneLayer - rat 1	0	0.37695834	0.1792241	false
training	oneLayer	oneLayer - rat 1	0	0.37695837	0.16904189	false
training	oneLayer	oneLayer - rat 1	0	0.38099083	0.1593067	false
training	oneLayer	oneLayer - rat 1	0	0.38810986	0.15218769	false
training	oneLayer	oneLayer - rat 1	0	0.39202422	0.14273761	false
training	oneLayer	oneLayer - rat 1	0	0.39965725	0.13510461	false
training	oneLayer	oneLayer - rat 1	0	0.40382323	0.1250471	false
training	oneLayer	oneLayer - rat 1	0	0.41154766	0.1173227	false
training	oneLayer	oneLayer - rat 1	0	0.4155345	0.107697666	false
training	oneLayer	oneLayer - rat 1	0	0.4228575	0.100374706	false
training	oneLayer	oneLayer - rat 1	0	0.42680192	0.09085208	false
training	oneLayer	oneLayer - rat 1	0	0.43452224	0.08313177	false
training	oneLayer	oneLayer - rat 1	0	0.43872145	0.07299407	false
training	oneLayer	oneLayer - rat 1	0	0.43872145	0.062449183	false
training	oneLayer	oneLayer - rat 1	0	0.44284838	0.05248592	false
training	oneLayer	oneLayer - rat 1	0	0.4428484	0.042368893	false
training	oneLayer	oneLayer - rat 1	0	0.44673783	0.032979038	false
training	oneLayer	oneLayer - rat 1	0	0.44673786	0.022939825	false
training	oneLayer	oneLayer - rat 1	0	0.44256213	0.012858704	false
training	oneLayer	oneLayer - rat 1	0	0.44256216	0.0019547436	false
training	oneLayer	oneLayer - rat 1	0	0.43854788	-0.0077366084	false
training	oneLayer	oneLayer - rat 1	0	0.43126214	-0.015022384	false
training	oneLayer	oneLayer - rat 1	0	0.4271451	-0.02496182	false
training	oneLayer	oneLayer - rat 1	0	0.41976887	-0.032338068	false
training	oneLayer	oneLayer - rat 1	0	0.415756	-0.042026103	false
training	oneLayer	oneLayer - rat 1	0	0.41575602	-0.052461818	false
training	oneLayer	oneLayer - rat 1	0	0.4197457	-0.062093806	false
training	oneLayer	oneLayer - rat 1	0	0.41974574	-0.07243502	false
training	oneLayer	oneLayer - rat 1	0	0.41555592	-0.082550146	false
training	oneLayer	oneLayer - rat 1	0	0.41555595	-0.09257216	false
training	oneLayer	oneLayer - rat 1	0	0.41170526	-0.101868585	false
training	oneLayer	oneLayer - rat 1	0	0.40430543	-0.10926845	false
training	oneLayer	oneLayer - rat 1	0	0.40021884	-0.11913441	false
training	oneLayer	oneLayer - rat 1	0	0.39255583	-0.12679744	false
training	oneLayer	oneLayer - rat 1	0	0.3885313	-0.13651358	false
training	oneLayer	oneLayer - rat 1	0	0.3885313	-0.14677814	false
training	oneLayer	oneLayer - rat 1	0	0.39237082	-0.15604751	false
training	oneLayer	oneLayer - rat 1	0	0.39237085	-0.16680701	false
training	oneLayer	oneLayer - rat 1	0	0.38835052	-0.17651297	false
training	oneLayer	oneLayer - rat 1	0	0.38835055	-0.18722513	false
training	oneLayer	oneLayer - rat 1	0	0.38444132	-0.19666284	false
training	oneLayer	oneLayer - rat 1	0	0.3768336	-0.20427063	false
training	oneLayer	oneLayer - rat 1	0	0.37291342	-0.21373478	false
training	oneLayer	oneLayer - rat 1	0	0.36527458	-0.22137365	false
training	oneLayer	oneLayer - rat 1	0	0.36115125	-0.23132831	false
training	oneLayer	oneLayer - rat 1	0	0.36115125	-0.24189304	false
training	oneLayer	oneLayer - rat 1	0	0.35731894	-0.25114515	false
training	oneLayer	oneLayer - rat 1	0	0.34987888	-0.2585852	false
training	oneLayer	oneLayer - rat 1	0	0.3457339	-0.26859212	false
training	oneLayer	oneLayer - rat 1	0	0.33802745	-0.2762986	false
training	oneLayer	oneLayer - rat 1	0	0.33385223	-0.28637853	false
training	oneLayer	oneLayer - rat 1	0	0.32640117	-0.29382962	false
training	oneLayer	oneLayer - rat 1	0	0.32254067	-0.30314973	false
training	oneLayer	oneLayer - rat 1	0	0.31511572	-0.3105747	false
training	oneLayer	oneLayer - rat 1	0	0.31117216	-0.32009533	false
training	oneLayer	oneLayer - rat 1	0	0.30404347	-0.32722405	false
training	oneLayer	oneLayer - rat 1	0	0.3001452	-0.33663535	false
training	oneLayer	oneLayer - rat 1	0	0.2925452	-0.34423536	false
training	oneLayer	oneLayer - rat 1	0	0.2828482	-0.34825203	false
training	oneLayer	oneLayer - rat 1	0	0.27200556	-0.34825203	false
training	oneLayer	oneLayer - rat 1	0	0.26265243	-0.34437788	false
training	oneLayer	oneLayer - rat 1	0	0.25503677	-0.33676225	false
training	oneLayer	oneLayer - rat 1	0	0.25092268	-0.32683	false
training	oneLayer	oneLayer - rat 1	0	0.2436854	-0.31959274	false
training	oneLayer	oneLayer - rat 1	0	0.23949137	-0.3094675	false
training	oneLayer	oneLayer - rat 1	0	0.23235328	-0.30232945	false
training	oneLayer	oneLayer - rat 1	0	0.22817007	-0.2922303	false
training	oneLayer	oneLayer - rat 1	0	0.22817005	-0.28149688	false
training	oneLayer	oneLayer - rat 1	0	0.22426806	-0.2720767	false
training	oneLayer	oneLayer - rat 1	0	0.22426805	-0.26129836	false
training	oneLayer	oneLayer - rat 1	0	0.2204218	-0.25201273	false
training	oneLayer	oneLayer - rat 1	0	0.21284135	-0.24443232	false
training	oneLayer	oneLayer - rat 1	0	0.20888293	-0.2348759	false
training	oneLayer	oneLayer - rat 1	0	0.20180298	-0.22779597	false
training	oneLayer	oneLayer - rat 1	0	0.1976703	-0.21781883	false
training	oneLayer	oneLayer - rat 1	0	0.19767028	-0.20695594	false
training	oneLayer	oneLayer - rat 1	0	0.19364285	-0.19723293	false
training	oneLayer	oneLayer - rat 1	0	0.19364284	-0.18669657	false
training	oneLayer	oneLayer - rat 1	0	0.1895041	-0.1767048	false
training	oneLayer	oneLayer - rat 1	0	0.18179609	-0.16899683	false
training	oneLayer	oneLayer - rat 1	0	0.17762624	-0.15892994	false
training	oneLayer	oneLayer - rat 1	0	0.16989635	-0.15120009	false
training	oneLayer	oneLayer - rat 1	0	0.16597064	-0.14172262	false
training	oneLayer	oneLayer - rat 1	0	0.15862896	-0.13438097	false
training	oneLayer	oneLayer - rat 1	0	0.15451808	-0.12445648	false
training	oneLayer	oneLayer - rat 1	0	0.14683975	-0.11677818	false
training	oneLayer	oneLayer - rat 1	0	0.14271925	-0.10683045	false
training	oneLayer	oneLayer - rat 1	0	0.13530217	-0.09941339	false
training	oneLayer	oneLayer - rat 1	0	0.13120408	-0.08951979	false
training	oneLayer	oneLayer - rat 1	0	0.12357076	-0.08188649	false
training	oneLayer	oneLayer - rat 1	0	0.119734325	-0.07262455	false
training	oneLayer	oneLayer - rat 1	0	0.1124052	-0.06529546	false
training	oneLayer	oneLayer - rat 1	0	0.10826894	-0.05530967	false
training	oneLayer	oneLayer - rat 1	0	0.10118701	-0.04822777	false
training	oneLayer	oneLayer - rat 1	0	0.09707688	-0.03830507	false
training	oneLayer	oneLayer - rat 1	0	0.08999373	-0.031221943	false
training	oneLayer	oneLayer - rat 1	0	0.085886635	-0.0213066	false
training	oneLayer	oneLayer - rat 1	0	0.07879785	-0.01421783	false
training	oneLayer	oneLayer - rat 1	0	0.07484461	-0.0046739285	false
training	oneLayer	oneLayer - rat 1	0	0.06742175	0.002748908	false
training	oneLayer	oneLayer - rat 1	0	0.063559815	0.012072411	false
training	oneLayer	oneLayer - rat 1	0	0.056289047	0.019343155	false
training	oneLayer	oneLayer - rat 1	0	0.052195977	0.02922465	false
training	oneLayer	oneLayer - rat 1	0	0.04486277	0.03655783	false
training	oneLayer	oneLayer - rat 1	0	0.041010275	0.045858536	false
training	oneLayer	oneLayer - rat 1	0	0.03335778	0.053511005	false
training	oneLayer	oneLayer - rat 1	0	0.029280523	0.06335433	false
training	oneLayer	oneLayer - rat 1	0	0.021666747	0.07096808	false
training	oneLayer	oneLayer - rat 1	0	0.01761222	0.08075653	false
training	oneLayer	oneLayer - rat 1	0	0.010397799	0.08797093	false
training	oneLayer	oneLayer - rat 1	0	0.00636553	0.09770564	false
training	oneLayer	oneLayer - rat 1	0	-7.217486E-4	0.10479289	false
training	oneLayer	oneLayer - rat 1	0	-0.004893635	0.11486467	false
training	oneLayer	oneLayer - rat 1	0	-0.011980676	0.12195169	false
training	oneLayer	oneLayer - rat 1	0	-0.016041083	0.13175434	false
training	oneLayer	oneLayer - rat 1	0	-0.023552176	0.1392654	false
training	oneLayer	oneLayer - rat 1	0	-0.027546616	0.1489088	false
training	oneLayer	oneLayer - rat 1	0	-0.035276387	0.15663853	false
training	oneLayer	oneLayer - rat 1	0	-0.039286293	0.16631927	false
training	oneLayer	oneLayer - rat 1	0	-0.046987154	0.1740201	false
training	oneLayer	oneLayer - rat 1	0	-0.05118788	0.1841615	false
training	oneLayer	oneLayer - rat 1	0	-0.058627486	0.19160108	false
training	oneLayer	oneLayer - rat 1	0	-0.0625792	0.20114133	false
training	oneLayer	oneLayer - rat 1	0	-0.06977974	0.20834184	false
training	oneLayer	oneLayer - rat 1	0	-0.073767625	0.2179694	false
training	oneLayer	oneLayer - rat 1	0	-0.08101371	0.22521546	false
training	oneLayer	oneLayer - rat 1	0	-0.08521966	0.23536949	false
training	oneLayer	oneLayer - rat 1	0	-0.092778064	0.24292786	false
training	oneLayer	oneLayer - rat 1	0	-0.09670347	0.2524046	false
training	oneLayer	oneLayer - rat 1	0	-0.10394228	0.25964338	false
training	oneLayer	oneLayer - rat 1	0	-0.107788265	0.26892838	false
training	oneLayer	oneLayer - rat 1	0	-0.11551105	0.2766511	false
training	oneLayer	oneLayer - rat 1	0	-0.11949986	0.28628093	false
training	oneLayer	oneLayer - rat 1	0	-0.12694983	0.29373088	false
training	oneLayer	oneLayer - rat 1	0	-0.13098776	0.30347928	false
training	oneLayer	oneLayer - rat 1	0	-0.1383888	0.31088027	false
training	oneLayer	oneLayer - rat 1	0	-0.14257656	0.32099038	false
training	oneLayer	oneLayer - rat 1	0	-0.15009664	0.32851043	false
training	oneLayer	oneLayer - rat 1	0	-0.15423875	0.33851033	false
training	oneLayer	oneLayer - rat 1	0	-0.161807	0.34607857	false
training	oneLayer	oneLayer - rat 1	0	-0.16596356	0.3561133	false
training	oneLayer	oneLayer - rat 1	0	-0.17350082	0.36365056	false
training	oneLayer	oneLayer - rat 1	0	-0.18339266	0.36774787	false
training	oneLayer	oneLayer - rat 1	0	-0.19369985	0.36774787	false
training	oneLayer	oneLayer - rat 1	0	-0.2031046	0.37164342	false
training	oneLayer	oneLayer - rat 1	0	-0.2132236	0.3716434	false
training	oneLayer	oneLayer - rat 1	0	-0.22269341	0.36772084	false
training	oneLayer	oneLayer - rat 1	0	-0.23028885	0.3601254	false
training	oneLayer	oneLayer - rat 1	0	-0.23428866	0.35046893	false
training	oneLayer	oneLayer - rat 1	0	-0.23428865	0.34016418	false
training	oneLayer	oneLayer - rat 1	0	-0.23008943	0.3300264	false
training	oneLayer	oneLayer - rat 1	0	-0.2300894	0.31931055	false
training	oneLayer	oneLayer - rat 1	0	-0.2342788	0.3091964	false
training	oneLayer	oneLayer - rat 1	0	-0.23427878	0.29911852	false
training	oneLayer	oneLayer - rat 1	0	-0.23843823	0.28907663	false
training	oneLayer	oneLayer - rat 1	0	-0.24587458	0.28164026	false
training	oneLayer	oneLayer - rat 1	0	-0.24999723	0.27168727	false
training	oneLayer	oneLayer - rat 1	0	-0.25765038	0.2640341	false
training	oneLayer	oneLayer - rat 1	0	-0.2615014	0.25473687	false
training	oneLayer	oneLayer - rat 1	0	-0.26150137	0.24470708	false
training	oneLayer	oneLayer - rat 1	0	-0.25767443	0.23546807	false
training	oneLayer	oneLayer - rat 1	0	-0.25767443	0.22454442	false
training	oneLayer	oneLayer - rat 1	0	-0.26162726	0.21500139	false
training	oneLayer	oneLayer - rat 1	0	-0.26162723	0.20498626	false
training	oneLayer	oneLayer - rat 1	0	-0.26560554	0.19538175	false
training	oneLayer	oneLayer - rat 1	0	-0.27277625	0.18821102	false
training	oneLayer	oneLayer - rat 1	0	-0.27668962	0.17876326	false
training	oneLayer	oneLayer - rat 1	0	-0.2840011	0.17145173	false
training	oneLayer	oneLayer - rat 1	0	-0.28808653	0.16158858	false
training	oneLayer	oneLayer - rat 1	0	-0.28808653	0.15077384	false
training	oneLayer	oneLayer - rat 1	0	-0.2839684	0.14083184	false
training	oneLayer	oneLayer - rat 1	0	-0.27645653	0.13332002	false
training	oneLayer	oneLayer - rat 1	0	-0.26634684	0.12913245	false
training	oneLayer	oneLayer - rat 1	0	-0.255601	0.12913248	false
training	oneLayer	oneLayer - rat 1	0	-0.24599522	0.13311133	false
training	oneLayer	oneLayer - rat 1	0	-0.23862888	0.1404777	false
training	oneLayer	oneLayer - rat 1	0	-0.23469846	0.14996661	false
training	oneLayer	oneLayer - rat 1	0	-0.2306861	0.15965337	false
training	oneLayer	oneLayer - rat 1	0	-0.23068613	0.16996181	false
training	oneLayer	oneLayer - rat 1	0	-0.23455386	0.1792993	false
training	oneLayer	oneLayer - rat 1	0	-0.23455387	0.19003184	false
training	oneLayer	oneLayer - rat 1	0	-0.23869422	0.20002748	false
training	oneLayer	oneLayer - rat 1	0	-0.23869424	0.21024683	false
training	oneLayer	oneLayer - rat 1	0	-0.24272367	0.21997468	false
training	oneLayer	oneLayer - rat 1	0	-0.24272369	0.23083337	false
training	oneLayer	oneLayer - rat 1	0	-0.24680206	0.24067938	false
training	oneLayer	oneLayer - rat 1	0	-0.24680209	0.25115445	false
training	oneLayer	oneLayer - rat 1	0	-0.25088885	0.26102075	false
training	oneLayer	oneLayer - rat 1	0	-0.25859648	0.26872835	false
training	oneLayer	oneLayer - rat 1	0	-0.26797816	0.27261436	false
training	oneLayer	oneLayer - rat 1	0	-0.27525282	0.279889	false
training	oneLayer	oneLayer - rat 1	0	-0.2847746	0.28383303	false
training	oneLayer	oneLayer - rat 1	0	-0.29510087	0.283833	false
training	oneLayer	oneLayer - rat 1	0	-0.30456886	0.27991122	false
training	oneLayer	oneLayer - rat 1	0	-0.31208706	0.272393	false
training	oneLayer	oneLayer - rat 1	0	-0.32155782	0.26847005	false
training	oneLayer	oneLayer - rat 1	0	-0.32895055	0.26107726	false
training	oneLayer	oneLayer - rat 1	0	-0.3382083	0.25724256	false
training	oneLayer	oneLayer - rat 1	0	-0.34530476	0.25014606	false
training	oneLayer	oneLayer - rat 1	0	-0.35494164	0.24615434	false
training	oneLayer	oneLayer - rat 1	0	-0.36264285	0.23845306	false
training	oneLayer	oneLayer - rat 1	0	-0.36675796	0.22851832	false
training	oneLayer	oneLayer - rat 1	0	-0.37417725	0.221099	false
training	oneLayer	oneLayer - rat 1	0	-0.37808257	0.21167067	false
training	oneLayer	oneLayer - rat 1	0	-0.38536265	0.20439057	false
training	oneLayer	oneLayer - rat 1	0	-0.38944244	0.194541	false
training	oneLayer	oneLayer - rat 1	0	-0.39719015	0.18679328	false
training	oneLayer	oneLayer - rat 1	0	-0.40103108	0.1775204	false
training	oneLayer	oneLayer - rat 1	0	-0.40825224	0.1702992	false
training	oneLayer	oneLayer - rat 1	0	-0.4124113	0.16025828	false
training	oneLayer	oneLayer - rat 1	0	-0.41969177	0.1529778	false
training	oneLayer	oneLayer - rat 1	0	-0.42357436	0.14360434	false
training	oneLayer	oneLayer - rat 1	0	-0.43091807	0.1362606	false
training	oneLayer	oneLayer - rat 1	0	-0.43502662	0.12634166	false
training	oneLayer	oneLayer - rat 1	0	-0.4350266	0.11559816	false
training	oneLayer	oneLayer - rat 1	0	-0.43897915	0.106055796	false
training	oneLayer	oneLayer - rat 1	0	-0.43897912	0.09535394	false
training	oneLayer	oneLayer - rat 1	0	-0.44301724	0.085604995	false
training	oneLayer	oneLayer - rat 1	0	-0.4430172	0.07534068	false
training	oneLayer	oneLayer - rat 1	0	-0.4469973	0.06573188	false
training	oneLayer	oneLayer - rat 1	0	-0.44699728	0.054769844	false
training	oneLayer	oneLayer - rat 1	0	-0.4511192	0.044818535	false
training	oneLayer	oneLayer - rat 1	0	-0.4511192	0.034316055	false
training	oneLayer	oneLayer - rat 1	0	-0.44697058	0.024300458	false
training	oneLayer	oneLayer - rat 1	0	-0.44697055	0.01408575	false
training	oneLayer	oneLayer - rat 1	0	-0.4431184	0.0047858455	false
training	oneLayer	oneLayer - rat 1	0	-0.43583927	-0.0024932593	false
training	oneLayer	oneLayer - rat 1	0	-0.42579937	-0.0066518947	false
training	oneLayer	oneLayer - rat 1	0	-0.4149673	-0.006651874	false
training	oneLayer	oneLayer - rat 1	0	-0.40513265	-0.0025782008	false
training	oneLayer	oneLayer - rat 1	0	-0.39748216	0.0050723245	false
training	oneLayer	oneLayer - rat 1	0	-0.39355147	0.014561895	false
training	oneLayer	oneLayer - rat 1	0	-0.38946414	0.024429617	false
training	oneLayer	oneLayer - rat 1	0	-0.3855532	0.033871453	false
training	oneLayer	oneLayer - rat 1	0	-0.38151586	0.043618545	false
training	oneLayer	oneLayer - rat 1	0	-0.37735906	0.053654045	false
training	oneLayer	oneLayer - rat 1	0	-0.37346283	0.06306045	false
training	oneLayer	oneLayer - rat 1	0	-0.36955976	0.07248327	false
training	oneLayer	oneLayer - rat 1	0	-0.3654242	0.08246754	false
training	oneLayer	oneLayer - rat 1	0	-0.36126807	0.09250132	false
training	oneLayer	oneLayer - rat 1	0	-0.3572928	0.10209855	false
training	oneLayer	oneLayer - rat 1	0	-0.3533734	0.11156081	false
training	oneLayer	oneLayer - rat 1	0	-0.34950733	0.12089443	false
training	oneLayer	oneLayer - rat 1	0	-0.34553015	0.13049623	false
training	oneLayer	oneLayer - rat 1	0	-0.34158525	0.14002013	false
training	oneLayer	oneLayer - rat 1	0	-0.3375188	0.14983743	false
training	oneLayer	oneLayer - rat 1	0	-0.33352822	0.15947163	false
training	oneLayer	oneLayer - rat 1	0	-0.32963702	0.16886586	false
training	oneLayer	oneLayer - rat 1	0	-0.32555225	0.17872743	false
training	oneLayer	oneLayer - rat 1	0	-0.3213734	0.18881609	false
training	oneLayer	oneLayer - rat 1	0	-0.31730154	0.19864649	false
training	oneLayer	oneLayer - rat 1	0	-0.31730157	0.20925798	false
training	oneLayer	oneLayer - rat 1	0	-0.31326175	0.21901101	false
training	oneLayer	oneLayer - rat 1	0	-0.31326178	0.22984307	false
training	oneLayer	oneLayer - rat 1	0	-0.30929622	0.2394168	false
training	oneLayer	oneLayer - rat 1	0	-0.30929625	0.24979268	false
training	oneLayer	oneLayer - rat 1	0	-0.31322366	0.25927424	false
training	oneLayer	oneLayer - rat 1	0	-0.31322366	0.26935908	false
training	oneLayer	oneLayer - rat 1	0	-0.30925784	0.2789335	false
training	oneLayer	oneLayer - rat 1	0	-0.30925786	0.28915197	false
training	oneLayer	oneLayer - rat 1	0	-0.30533913	0.29861265	false
training	oneLayer	oneLayer - rat 1	0	-0.30116257	0.30869585	false
training	oneLayer	oneLayer - rat 1	0	-0.2970563	0.3186093	false
training	oneLayer	oneLayer - rat 1	0	-0.29300886	0.3283807	false
training	oneLayer	oneLayer - rat 1	0	-0.28915897	0.3376752	false
training	oneLayer	oneLayer - rat 1	0	-0.2851952	0.34724468	false
training	oneLayer	oneLayer - rat 1	0	-0.27774987	0.35469005	false
training	oneLayer	oneLayer - rat 1	0	-0.2680992	0.3586875	false
training	oneLayer	oneLayer - rat 1	0	-0.2571549	0.35868752	false
training	oneLayer	oneLayer - rat 1	0	-0.24702775	0.35449275	false
training	oneLayer	oneLayer - rat 1	0	-0.23926885	0.34673387	false
training	oneLayer	oneLayer - rat 1	0	-0.2352658	0.33706972	false
training	oneLayer	oneLayer - rat 1	0	-0.23526579	0.3262037	false
training	oneLayer	oneLayer - rat 1	0	-0.23916915	0.3167801	false
training	oneLayer	oneLayer - rat 1	0	-0.24683493	0.30911428	false
training	oneLayer	oneLayer - rat 1	0	-0.2567628	0.305002	false
training	oneLayer	oneLayer - rat 1	0	-0.26404858	0.2977162	false
training	oneLayer	oneLayer - rat 1	0	-0.2737016	0.29371777	false
training	oneLayer	oneLayer - rat 1	0	-0.28087708	0.28654227	false
training	oneLayer	oneLayer - rat 1	0	-0.29014957	0.28270146	false
training	oneLayer	oneLayer - rat 1	0	-0.29746163	0.27538937	false
training	oneLayer	oneLayer - rat 1	0	-0.30684277	0.27150357	false
training	oneLayer	oneLayer - rat 1	0	-0.3145166	0.2638297	false
training	oneLayer	oneLayer - rat 1	0	-0.32377785	0.25999355	false
training	oneLayer	oneLayer - rat 1	0	-0.3311698	0.25260156	false
training	oneLayer	oneLayer - rat 1	0	-0.34067276	0.2486653	false
training	oneLayer	oneLayer - rat 1	0	-0.3483838	0.2409542	false
training	oneLayer	oneLayer - rat 1	0	-0.35769716	0.23709647	false
training	oneLayer	oneLayer - rat 1	0	-0.36485606	0.22993754	false
training	oneLayer	oneLayer - rat 1	0	-0.36881384	0.2203826	false
training	oneLayer	oneLayer - rat 1	0	-0.37646613	0.21273029	false
training	oneLayer	oneLayer - rat 1	0	-0.38064218	0.20264833	false
training	oneLayer	oneLayer - rat 1	0	-0.38782302	0.19546744	false
training	oneLayer	oneLayer - rat 1	0	-0.39191505	0.1855884	false
training	oneLayer	oneLayer - rat 1	0	-0.39899954	0.17850387	false
training	oneLayer	oneLayer - rat 1	0	-0.40286914	0.1691618	false
training	oneLayer	oneLayer - rat 1	0	-0.40996048	0.16207045	false
training	oneLayer	oneLayer - rat 1	0	-0.4140966	0.15208489	false
training	oneLayer	oneLayer - rat 1	0	-0.42141703	0.14476442	false
training	oneLayer	oneLayer - rat 1	0	-0.4254963	0.13491616	false
training	oneLayer	oneLayer - rat 1	0	-0.42549628	0.12454924	false
training	oneLayer	oneLayer - rat 1	0	-0.42939538	0.11513595	false
training	oneLayer	oneLayer - rat 1	0	-0.42939535	0.10465878	false
training	oneLayer	oneLayer - rat 1	0	-0.43358874	0.094534986	false
training	oneLayer	oneLayer - rat 1	0	-0.4335887	0.08387435	false
training	oneLayer	oneLayer - rat 1	0	-0.43767753	0.07400303	false
training	oneLayer	oneLayer - rat 1	0	-0.4376775	0.063881926	false
training	oneLayer	oneLayer - rat 1	0	-0.4417348	0.05408676	false
training	oneLayer	oneLayer - rat 1	0	-0.44173476	0.04318949	false
training	oneLayer	oneLayer - rat 1	0	-0.4379015	0.033935186	false
training	oneLayer	oneLayer - rat 1	0	-0.43037134	0.026405059	false
training	oneLayer	oneLayer - rat 1	0	-0.4205477	0.022335991	false
training	oneLayer	oneLayer - rat 1	0	-0.40955544	0.022336012	false
training	oneLayer	oneLayer - rat 1	0	-0.40008745	0.026257796	false
training	oneLayer	oneLayer - rat 1	0	-0.3890887	0.026257817	false
training	oneLayer	oneLayer - rat 1	0	-0.37924397	0.030335657	false
training	oneLayer	oneLayer - rat 1	0	-0.36912438	0.030335678	false
training	oneLayer	oneLayer - rat 1	0	-0.35947642	0.034332015	false
training	oneLayer	oneLayer - rat 1	0	-0.34893355	0.034332033	false
training	oneLayer	oneLayer - rat 1	0	-0.33947742	0.03824892	false
training	oneLayer	oneLayer - rat 1	0	-0.3290042	0.03824894	false
training	oneLayer	oneLayer - rat 1	0	-0.3194611	0.042201843	false
training	oneLayer	oneLayer - rat 1	0	-0.30851054	0.042201865	false
training	oneLayer	oneLayer - rat 1	0	-0.29899916	0.046141624	false
training	oneLayer	oneLayer - rat 1	0	-0.2882826	0.046141647	false
training	oneLayer	oneLayer - rat 1	0	-0.27887756	0.05003736	false
training	oneLayer	oneLayer - rat 1	0	-0.26860723	0.050037384	false
training	oneLayer	oneLayer - rat 1	0	-0.25907335	0.05398646	false
training	oneLayer	oneLayer - rat 1	0	-0.24832086	0.053986482	false
training	oneLayer	oneLayer - rat 1	0	-0.23907995	0.057814207	false
training	oneLayer	oneLayer - rat 1	0	-0.2285905	0.05781423	false
training	oneLayer	oneLayer - rat 1	0	-0.21845853	0.06201105	false
training	oneLayer	oneLayer - rat 1	0	-0.20777251	0.06201107	false
training	oneLayer	oneLayer - rat 1	0	-0.19818552	0.065982156	false
training	oneLayer	oneLayer - rat 1	0	-0.18817665	0.06598217	false
training	oneLayer	oneLayer - rat 1	0	-0.17816903	0.07012748	false
training	oneLayer	oneLayer - rat 1	0	-0.16791244	0.0701275	false
training	oneLayer	oneLayer - rat 1	0	-0.15866625	0.07395741	false
training	oneLayer	oneLayer - rat 1	0	-0.14784642	0.073957436	false
training	oneLayer	oneLayer - rat 1	0	-0.13831893	0.077903874	false
training	oneLayer	oneLayer - rat 1	0	-0.12822235	0.0779039	false
training	oneLayer	oneLayer - rat 1	0	-0.11842326	0.08196283	false
training	oneLayer	oneLayer - rat 1	0	-0.111217104	0.08916902	false
training	oneLayer	oneLayer - rat 1	0	-0.107193075	0.098883934	false
training	oneLayer	oneLayer - rat 1	0	-0.1071931	0.10940021	false
training	oneLayer	oneLayer - rat 1	0	-0.10312395	0.11922407	false
training	oneLayer	oneLayer - rat 1	0	-0.095655724	0.12669232	false
training	oneLayer	oneLayer - rat 1	0	-0.09176682	0.13608101	false
training	oneLayer	oneLayer - rat 1	0	-0.08441225	0.14343561	false
training	oneLayer	oneLayer - rat 1	0	-0.07454533	0.14752264	false
training	oneLayer	oneLayer - rat 1	0	-0.0637693	0.14752267	false
training	oneLayer	oneLayer - rat 1	0	-0.054530095	0.1513497	false
training	oneLayer	oneLayer - rat 1	0	-0.04430926	0.15134972	false
training	oneLayer	oneLayer - rat 1	0	-0.03495652	0.15522377	false
training	oneLayer	oneLayer - rat 1	0	-0.02406927	0.15522379	false
training	oneLayer	oneLayer - rat 1	0	-0.014761215	0.15907933	false
training	oneLayer	oneLayer - rat 1	0	-0.004460152	0.15907936	false
training	oneLayer	oneLayer - rat 1	0	0.004983818	0.1629912	false
training	oneLayer	oneLayer - rat 1	0	0.015458397	0.16299121	false
training	oneLayer	oneLayer - rat 1	0	0.025561536	0.1671761	false
training	oneLayer	oneLayer - rat 1	0	0.03602582	0.16717611	false
training	oneLayer	oneLayer - rat 1	0	0.046181593	0.1713828	false
training	oneLayer	oneLayer - rat 1	0	0.056895945	0.17138281	false
training	oneLayer	oneLayer - rat 1	0	0.06629974	0.17527802	false
training	oneLayer	oneLayer - rat 1	0	0.07644035	0.17527804	false
training	oneLayer	oneLayer - rat 1	0	0.085734	0.17912762	false
training	oneLayer	oneLayer - rat 1	0	0.09629835	0.17912763	false
training	oneLayer	oneLayer - rat 1	0	0.10582476	0.18307362	false
training	oneLayer	oneLayer - rat 1	0	0.11682414	0.18307365	false
training	oneLayer	oneLayer - rat 1	0	0.12682901	0.18721783	false
training	oneLayer	oneLayer - rat 1	0	0.1370039	0.18721785	false
training	oneLayer	oneLayer - rat 1	0	0.14679167	0.1912721	false
training	oneLayer	oneLayer - rat 1	0	0.15684722	0.19127211	false
training	oneLayer	oneLayer - rat 1	0	0.16643968	0.19524546	false
training	oneLayer	oneLayer - rat 1	0	0.1769285	0.19524547	false
training	oneLayer	oneLayer - rat 1	0	0.18687181	0.19936416	false
training	oneLayer	oneLayer - rat 1	0	0.19739644	0.19936417	false
training	oneLayer	oneLayer - rat 1	0	0.20696256	0.2033266	false
training	oneLayer	oneLayer - rat 1	0	0.21714169	0.20332663	false
training	oneLayer	oneLayer - rat 1	0	0.22693563	0.20738342	false
training	oneLayer	oneLayer - rat 1	0	0.23790036	0.20738345	false
training	oneLayer	oneLayer - rat 1	0	0.24776453	0.21146934	false
training	oneLayer	oneLayer - rat 1	0	0.25798157	0.21146937	false
training	oneLayer	oneLayer - rat 1	0	0.26735374	0.21535146	false
training	oneLayer	oneLayer - rat 1	0	0.27779984	0.21535149	false
training	oneLayer	oneLayer - rat 1	0	0.2870925	0.21920066	false
training	oneLayer	oneLayer - rat 1	0	0.29765016	0.21920067	false
training	oneLayer	oneLayer - rat 1	0	0.30781254	0.2234101	false
training	oneLayer	oneLayer - rat 1	0	0.31850255	0.22341011	false
training	oneLayer	oneLayer - rat 1	0	0.3283988	0.2275093	false
training	oneLayer	oneLayer - rat 1	0	0.3388156	0.22750932	false
training	oneLayer	oneLayer - rat 1	0	0.34842747	0.22352797	false
training	oneLayer	oneLayer - rat 1	0	0.35617864	0.21577683	false
training	oneLayer	oneLayer - rat 1	0	0.36592406	0.21174017	false
training	oneLayer	oneLayer - rat 1	0	0.3732512	0.20441306	false
training	oneLayer	oneLayer - rat 1	0	0.3773593	0.19449528	false
training	oneLayer	oneLayer - rat 1	0	0.37735933	0.18381655	false
training	oneLayer	oneLayer - rat 1	0	0.3815299	0.17374791	false
training	oneLayer	oneLayer - rat 1	0	0.3887455	0.16653237	false
training	oneLayer	oneLayer - rat 1	0	0.392844	0.15663771	false
training	oneLayer	oneLayer - rat 1	0	0.40047202	0.14900973	false
training	oneLayer	oneLayer - rat 1	0	0.40446737	0.13936414	false
training	oneLayer	oneLayer - rat 1	0	0.4118968	0.13193473	false
training	oneLayer	oneLayer - rat 1	0	0.4157897	0.12253651	false
training	oneLayer	oneLayer - rat 1	0	0.42334858	0.114977665	false
training	oneLayer	oneLayer - rat 1	0	0.4275114	0.104927786	false
training	oneLayer	oneLayer - rat 1	0	0.43465683	0.09778238	false
training	oneLayer	oneLayer - rat 1	0	0.4388094	0.087757245	false
training	oneLayer	oneLayer - rat 1	0	0.4388094	0.07749548	false
training	oneLayer	oneLayer - rat 1	0	0.44283307	0.06778155	false
training	oneLayer	oneLayer - rat 1	0	0.4428331	0.057340473	false
training	oneLayer	oneLayer - rat 1	0	0.4468424	0.047661167	false
training	oneLayer	oneLayer - rat 1	0	0.44684243	0.037057873	false
training	oneLayer	oneLayer - rat 1	0	0.44265968	0.026959741	false
training	oneLayer	oneLayer - rat 1	0	0.43511122	0.01941126	false
training	oneLayer	oneLayer - rat 1	0	0.43122566	0.010030682	false
training	oneLayer	oneLayer - rat 1	0	0.42387038	0.0026753687	false
training	oneLayer	oneLayer - rat 1	0	0.41968274	-0.0074345763	false
training	oneLayer	oneLayer - rat 1	0	0.41968274	-0.018006418	false
training	oneLayer	oneLayer - rat 1	0	0.41563535	-0.027777756	false
training	oneLayer	oneLayer - rat 1	0	0.4082764	-0.035136722	false
training	oneLayer	oneLayer - rat 1	0	0.40441784	-0.044452168	false
training	oneLayer	oneLayer - rat 1	0	0.39727747	-0.05159257	false
training	oneLayer	oneLayer - rat 1	0	0.39321	-0.06141238	false
training	oneLayer	oneLayer - rat 1	0	0.38612485	-0.06849756	false
training	oneLayer	oneLayer - rat 1	0	0.38206565	-0.078297324	false
training	oneLayer	oneLayer - rat 1	0	0.37451106	-0.08585195	false
training	oneLayer	oneLayer - rat 1	0	0.37053767	-0.09544463	false
training	oneLayer	oneLayer - rat 1	0	0.3634389	-0.10254343	false
training	oneLayer	oneLayer - rat 1	0	0.35953134	-0.11197715	false
training	oneLayer	oneLayer - rat 1	0	0.3517544	-0.119754136	false
training	oneLayer	oneLayer - rat 1	0	0.34767383	-0.12960549	false
training	oneLayer	oneLayer - rat 1	0	0.340518	-0.13676137	false
training	oneLayer	oneLayer - rat 1	0	0.33641124	-0.146676	false
training	oneLayer	oneLayer - rat 1	0	0.3292842	-0.15380307	false
training	oneLayer	oneLayer - rat 1	0	0.32515627	-0.1637688	false
training	oneLayer	oneLayer - rat 1	0	0.3178968	-0.1710283	false
training	oneLayer	oneLayer - rat 1	0	0.31370297	-0.18115316	false
training	oneLayer	oneLayer - rat 1	0	0.30609393	-0.18876223	false
training	oneLayer	oneLayer - rat 1	0	0.3019858	-0.1986802	false
training	oneLayer	oneLayer - rat 1	0	0.29431415	-0.20635188	false
training	oneLayer	oneLayer - rat 1	0	0.29031685	-0.2160023	false
training	oneLayer	oneLayer - rat 1	0	0.28260255	-0.22371663	false
training	oneLayer	oneLayer - rat 1	0	0.278507	-0.23360422	false
training	oneLayer	oneLayer - rat 1	0	0.2709152	-0.241196	false
training	oneLayer	oneLayer - rat 1	0	0.26690638	-0.25087428	false
training	oneLayer	oneLayer - rat 1	0	0.259631	-0.25814968	false
training	oneLayer	oneLayer - rat 1	0	0.25545213	-0.26823846	false
training	oneLayer	oneLayer - rat 1	0	0.2480205	-0.27567008	false
training	oneLayer	oneLayer - rat 1	0	0.24387226	-0.2856849	false
training	oneLayer	oneLayer - rat 1	0	0.23644404	-0.29311314	false
training	oneLayer	oneLayer - rat 1	0	0.23241195	-0.30284756	false
training	oneLayer	oneLayer - rat 1	0	0.22513588	-0.31012365	false
training	oneLayer	oneLayer - rat 1	0	0.22125947	-0.31948218	false
training	oneLayer	oneLayer - rat 1	0	0.21368288	-0.32705882	false
training	oneLayer	oneLayer - rat 1	0	0.20982236	-0.33637896	false
training	oneLayer	oneLayer - rat 1	0	0.20259869	-0.34360266	false
training	oneLayer	oneLayer - rat 1	0	0.19866325	-0.3531037	false
training	oneLayer	oneLayer - rat 1	0	0.19144237	-0.36032462	false
training	oneLayer	oneLayer - rat 1	0	0.18732606	-0.37026232	false
training	oneLayer	oneLayer - rat 1	0	0.1800796	-0.37750882	false
training	oneLayer	oneLayer - rat 1	0	0.17607895	-0.38716727	false
training	oneLayer	oneLayer - rat 1	0	0.16842395	-0.3948223	false
training	oneLayer	oneLayer - rat 1	0	0.15832613	-0.39900497	false
training	oneLayer	oneLayer - rat 1	0	0.1508825	-0.40644863	false
training	oneLayer	oneLayer - rat 1	0	0.1407604	-0.41064137	false
training	oneLayer	oneLayer - rat 1	0	0.13351046	-0.41789132	false
training	oneLayer	oneLayer - rat 1	0	0.12358223	-0.42200375	false
training	oneLayer	oneLayer - rat 1	0	0.115969226	-0.42961678	false
training	oneLayer	oneLayer - rat 1	0	0.10638774	-0.43358558	false
training	oneLayer	oneLayer - rat 1	0	0.09634232	-0.4335856	false
training	oneLayer	oneLayer - rat 1	0	0.08701841	-0.42972353	false
training	oneLayer	oneLayer - rat 1	0	0.07661795	-0.42972356	false
training	oneLayer	oneLayer - rat 1	0	0.06709004	-0.425777	false
training	oneLayer	oneLayer - rat 1	0	0.059611514	-0.41829848	false
training	oneLayer	oneLayer - rat 1	0	0.05541969	-0.40817857	false
training	oneLayer	oneLayer - rat 1	0	0.047892302	-0.40065122	false
training	oneLayer	oneLayer - rat 1	0	0.044042397	-0.39135677	false
training	oneLayer	oneLayer - rat 1	0	0.036623538	-0.38393795	false
training	oneLayer	oneLayer - rat 1	0	0.027033616	-0.3799657	false
training	oneLayer	oneLayer - rat 1	0	0.01635849	-0.3799657	false
training	oneLayer	oneLayer - rat 1	0	0.0066927774	-0.37596205	false
training	oneLayer	oneLayer - rat 1	0	-9.6184615E-4	-0.36830747	false
training	oneLayer	oneLayer - rat 1	0	-0.010557783	-0.3643327	false
training	oneLayer	oneLayer - rat 1	0	-0.01810046	-0.35679007	false
training	oneLayer	oneLayer - rat 1	0	-0.027715607	-0.35280737	false
training	oneLayer	oneLayer - rat 1	0	-0.034986008	-0.34553698	false
training	oneLayer	oneLayer - rat 1	0	-0.04477173	-0.34148362	false
training	oneLayer	oneLayer - rat 1	0	-0.05249045	-0.33376494	false
training	oneLayer	oneLayer - rat 1	0	-0.056418333	-0.32428223	false
training	oneLayer	oneLayer - rat 1	0	-0.06416535	-0.31653523	false
training	oneLayer	oneLayer - rat 1	0	-0.06819674	-0.30680266	false
training	oneLayer	oneLayer - rat 1	0	-0.06819676	-0.29636952	false
training	oneLayer	oneLayer - rat 1	0	-0.06405528	-0.28637105	false
training	oneLayer	oneLayer - rat 1	0	-0.064055294	-0.27577946	false
training	oneLayer	oneLayer - rat 1	0	-0.06795345	-0.26636854	false
training	oneLayer	oneLayer - rat 1	0	-0.067953475	-0.25574535	false
training	oneLayer	oneLayer - rat 1	0	-0.07209123	-0.24575597	false
training	oneLayer	oneLayer - rat 1	0	-0.07209125	-0.23491563	false
training	oneLayer	oneLayer - rat 1	0	-0.07618012	-0.22504427	false
training	oneLayer	oneLayer - rat 1	0	-0.08328802	-0.2179364	false
training	oneLayer	oneLayer - rat 1	0	-0.093213655	-0.21382508	false
training	oneLayer	oneLayer - rat 1	0	-0.10031456	-0.20672421	false
training	oneLayer	oneLayer - rat 1	0	-0.10968792	-0.20284165	false
training	oneLayer	oneLayer - rat 1	0	-0.11719528	-0.19533432	false
training	oneLayer	oneLayer - rat 1	0	-0.121302865	-0.18541777	false
training	oneLayer	oneLayer - rat 1	0	-0.12875009	-0.17797057	false
training	oneLayer	oneLayer - rat 1	0	-0.13279015	-0.16821706	false
training	oneLayer	oneLayer - rat 1	0	-0.1400795	-0.16092774	false
training	oneLayer	oneLayer - rat 1	0	-0.14393015	-0.15163149	false
training	oneLayer	oneLayer - rat 1	0	-0.1512955	-0.14426616	false
training	oneLayer	oneLayer - rat 1	0	-0.15530631	-0.13458326	false
training	oneLayer	oneLayer - rat 1	0	-0.16282424	-0.12706535	false
training	oneLayer	oneLayer - rat 1	0	-0.16685456	-0.11733537	false
training	oneLayer	oneLayer - rat 1	0	-0.17435178	-0.10983818	false
training	oneLayer	oneLayer - rat 1	0	-0.17821355	-0.10051507	false
training	oneLayer	oneLayer - rat 1	0	-0.18595193	-0.09277672	false
training	oneLayer	oneLayer - rat 1	0	-0.19011898	-0.0827166	false
training	oneLayer	oneLayer - rat 1	0	-0.19772232	-0.07511331	false
training	oneLayer	oneLayer - rat 1	0	-0.20165347	-0.06562271	false
training	oneLayer	oneLayer - rat 1	0	-0.20926853	-0.058007684	false
training	oneLayer	oneLayer - rat 1	0	-0.21323122	-0.048440915	false
training	oneLayer	oneLayer - rat 1	0	-0.22037533	-0.041296836	false
training	oneLayer	oneLayer - rat 1	0	-0.22441432	-0.03154588	false
training	oneLayer	oneLayer - rat 1	0	-0.23199815	-0.02396209	false
training	oneLayer	oneLayer - rat 1	0	-0.23618653	-0.013850467	false
training	oneLayer	oneLayer - rat 1	0	-0.24345817	-0.0065788706	false
training	oneLayer	oneLayer - rat 1	0	-0.24758159	0.003375905	false
training	oneLayer	oneLayer - rat 1	0	-0.2552089	0.011003201	false
training	oneLayer	oneLayer - rat 1	0	-0.25909546	0.020386115	false
training	oneLayer	oneLayer - rat 1	0	-0.2667363	0.028026912	false
training	oneLayer	oneLayer - rat 1	0	-0.27093866	0.03817227	false
training	oneLayer	oneLayer - rat 1	0	-0.2783389	0.045572497	false
training	oneLayer	oneLayer - rat 1	0	-0.2824732	0.05555351	false
training	oneLayer	oneLayer - rat 1	0	-0.2899673	0.063047595	false
training	oneLayer	oneLayer - rat 1	0	-0.29384476	0.07240851	false
training	oneLayer	oneLayer - rat 1	0	-0.30136216	0.07992589	false
training	oneLayer	oneLayer - rat 1	0	-0.3054712	0.089846015	false
training	oneLayer	oneLayer - rat 1	0	-0.3129005	0.09727527	false
training	oneLayer	oneLayer - rat 1	0	-0.31708452	0.10737633	false
training	oneLayer	oneLayer - rat 1	0	-0.32449582	0.1147876	false
training	oneLayer	oneLayer - rat 1	0	-0.32832277	0.124026656	false
training	oneLayer	oneLayer - rat 1	0	-0.3283228	0.13451813	false
training	oneLayer	oneLayer - rat 1	0	-0.3244061	0.14397399	false
training	oneLayer	oneLayer - rat 1	0	-0.32022312	0.1540726	false
training	oneLayer	oneLayer - rat 1	0	-0.31639123	0.16332367	false
training	oneLayer	oneLayer - rat 1	0	-0.31639123	0.17356764	false
training	oneLayer	oneLayer - rat 1	0	-0.31253397	0.18287994	false
training	oneLayer	oneLayer - rat 1	0	-0.312534	0.19382447	false
training	oneLayer	oneLayer - rat 1	0	-0.31668255	0.20383991	false
training	oneLayer	oneLayer - rat 1	0	-0.32434234	0.21149968	false
training	oneLayer	oneLayer - rat 1	0	-0.3284804	0.22148976	false
training	oneLayer	oneLayer - rat 1	0	-0.3284804	0.23160729	false
training	oneLayer	oneLayer - rat 1	0	-0.3323379	0.24092005	false
training	oneLayer	oneLayer - rat 1	0	-0.33233792	0.2509634	false
training	oneLayer	oneLayer - rat 1	0	-0.32839474	0.26048312	false
training	oneLayer	oneLayer - rat 1	0	-0.3242206	0.2705604	false
training	oneLayer	oneLayer - rat 1	0	-0.32422063	0.28083786	false
training	oneLayer	oneLayer - rat 1	0	-0.3200278	0.29096025	false
training	oneLayer	oneLayer - rat 1	0	-0.31617054	0.30027258	false
training	oneLayer	oneLayer - rat 1	0	-0.31196666	0.31042168	false
training	oneLayer	oneLayer - rat 1	0	-0.30809635	0.3197655	false
training	oneLayer	oneLayer - rat 1	0	-0.30415803	0.3292735	false
training	oneLayer	oneLayer - rat 1	0	-0.29996863	0.33938763	false
training	oneLayer	oneLayer - rat 1	0	-0.29261926	0.34673703	false
training	oneLayer	oneLayer - rat 1	0	-0.28309175	0.35068348	false
training	oneLayer	oneLayer - rat 1	0	-0.27246156	0.35068348	false
training	oneLayer	oneLayer - rat 1	0	-0.26311517	0.3468121	false
training	oneLayer	oneLayer - rat 1	0	-0.2555314	0.33922836	false
training	oneLayer	oneLayer - rat 1	0	-0.25160143	0.32974058	false
training	oneLayer	oneLayer - rat 1	0	-0.2516014	0.31893128	false
training	oneLayer	oneLayer - rat 1	0	-0.25567317	0.3091011	false
training	oneLayer	oneLayer - rat 1	0	-0.25567317	0.29813102	false
training	oneLayer	oneLayer - rat 1	0	-0.25972134	0.2883578	false
training	oneLayer	oneLayer - rat 1	0	-0.2597213	0.27808386	false
training	oneLayer	oneLayer - rat 1	0	-0.26374847	0.26836148	false
training	oneLayer	oneLayer - rat 1	0	-0.270954	0.2611559	false
training	oneLayer	oneLayer - rat 1	0	-0.28050986	0.2571977	false
training	oneLayer	oneLayer - rat 1	0	-0.28762	0.25008756	false
training	oneLayer	oneLayer - rat 1	0	-0.29689977	0.24624373	false
training	oneLayer	oneLayer - rat 1	0	-0.3045397	0.23860376	false
training	oneLayer	oneLayer - rat 1	0	-0.31415603	0.23462053	false
training	oneLayer	oneLayer - rat 1	0	-0.32146522	0.22731131	false
training	oneLayer	oneLayer - rat 1	0	-0.3307181	0.22347863	false
training	oneLayer	oneLayer - rat 1	0	-0.33780536	0.21639135	false
training	oneLayer	oneLayer - rat 1	0	-0.34737828	0.2124261	false
training	oneLayer	oneLayer - rat 1	0	-0.35492378	0.20488057	false
training	oneLayer	oneLayer - rat 1	0	-0.3643648	0.20096995	false
training	oneLayer	oneLayer - rat 1	0	-0.3718077	0.19352703	false
training	oneLayer	oneLayer - rat 1	0	-0.37573385	0.18404841	false
training	oneLayer	oneLayer - rat 1	0	-0.38321757	0.17656466	false
training	oneLayer	oneLayer - rat 1	0	-0.38737178	0.16653548	false
training	oneLayer	oneLayer - rat 1	0	-0.39487714	0.1590301	false
training	oneLayer	oneLayer - rat 1	0	-0.39902928	0.14900587	false
training	oneLayer	oneLayer - rat 1	0	-0.4066264	0.14140874	false
training	oneLayer	oneLayer - rat 1	0	-0.41070133	0.1315709	false
training	oneLayer	oneLayer - rat 1	0	-0.4182667	0.1240055	false
training	oneLayer	oneLayer - rat 1	0	-0.42239124	0.11404797	false
training	oneLayer	oneLayer - rat 1	0	-0.42981645	0.106622726	false
training	oneLayer	oneLayer - rat 1	0	-0.43368095	0.09729296	false
training	oneLayer	oneLayer - rat 1	0	-0.43368092	0.086293936	false
training	oneLayer	oneLayer - rat 1	0	-0.42973036	0.07675648	false
training	oneLayer	oneLayer - rat 1	0	-0.42973036	0.06651261	false
training	oneLayer	oneLayer - rat 1	0	-0.433745	0.056820355	false
training	oneLayer	oneLayer - rat 1	0	-0.43374497	0.046400942	false
training	oneLayer	oneLayer - rat 1	0	-0.42989412	0.03710421	false
training	oneLayer	oneLayer - rat 1	0	-0.42989412	0.026975235	false
training	oneLayer	oneLayer - rat 1	0	-0.42598313	0.017533354	false
training	oneLayer	oneLayer - rat 1	0	-0.42598313	0.0066462355	false
training	oneLayer	oneLayer - rat 1	0	-0.42177796	-0.0035058642	false
training	oneLayer	oneLayer - rat 1	0	-0.414295	-0.010988817	false
training	oneLayer	oneLayer - rat 1	0	-0.40456435	-0.015019355	false
training	oneLayer	oneLayer - rat 1	0	-0.39392722	-0.015019337	false
training	oneLayer	oneLayer - rat 1	0	-0.38422742	-0.01100153	false
training	oneLayer	oneLayer - rat 1	0	-0.37659112	-0.0033651888	false
training	oneLayer	oneLayer - rat 1	0	-0.3727133	0.005996726	false
training	oneLayer	oneLayer - rat 1	0	-0.3685304	0.01609523	false
training	oneLayer	oneLayer - rat 1	0	-0.3644947	0.025838226	false
training	oneLayer	oneLayer - rat 1	0	-0.36030737	0.03594747	false
training	oneLayer	oneLayer - rat 1	0	-0.35636163	0.045473363	false
training	oneLayer	oneLayer - rat 1	0	-0.35235533	0.055145465	false
training	oneLayer	oneLayer - rat 1	0	-0.34819826	0.06518151	false
training	oneLayer	oneLayer - rat 1	0	-0.3443514	0.07446869	false
training	oneLayer	oneLayer - rat 1	0	-0.34036645	0.08408934	false
training	oneLayer	oneLayer - rat 1	0	-0.3361593	0.09424633	false
training	oneLayer	oneLayer - rat 1	0	-0.33200875	0.10426671	false
training	oneLayer	oneLayer - rat 1	0	-0.32810384	0.11369404	false
training	oneLayer	oneLayer - rat 1	0	-0.3242741	0.122939855	false
training	oneLayer	oneLayer - rat 1	0	-0.32032764	0.13246752	false
training	oneLayer	oneLayer - rat 1	0	-0.31648532	0.14174378	false
training	oneLayer	oneLayer - rat 1	0	-0.31648532	0.1525365	false
training	oneLayer	oneLayer - rat 1	0	-0.32048264	0.16218683	false
training	oneLayer	oneLayer - rat 1	0	-0.32048267	0.17253093	false
training	oneLayer	oneLayer - rat 1	0	-0.32453397	0.1823116	false
training	oneLayer	oneLayer - rat 1	0	-0.324534	0.19244103	false
training	oneLayer	oneLayer - rat 1	0	-0.32870543	0.20251173	false
training	oneLayer	oneLayer - rat 1	0	-0.32870546	0.21315145	false
training	oneLayer	oneLayer - rat 1	0	-0.33269334	0.22277904	false
training	oneLayer	oneLayer - rat 1	0	-0.33269337	0.23335953	false
training	oneLayer	oneLayer - rat 1	0	-0.33668128	0.24298714	false
training	oneLayer	oneLayer - rat 1	0	-0.33668128	0.25382078	false
training	oneLayer	oneLayer - rat 1	0	-0.3327312	0.2633572	false
training	oneLayer	oneLayer - rat 1	0	-0.3285653	0.27341458	false
training	oneLayer	oneLayer - rat 1	0	-0.3210078	0.28097212	false
training	oneLayer	oneLayer - rat 1	0	-0.3114635	0.28492552	false
training	oneLayer	oneLayer - rat 1	0	-0.30086488	0.28492555	false
training	oneLayer	oneLayer - rat 1	0	-0.2908887	0.28905782	false
training	oneLayer	oneLayer - rat 1	0	-0.27989665	0.28905785	false
training	oneLayer	oneLayer - rat 1	0	-0.26994875	0.2931784	false
training	oneLayer	oneLayer - rat 1	0	-0.25934905	0.29317844	false
training	oneLayer	oneLayer - rat 1	0	-0.24951072	0.2972536	false
training	oneLayer	oneLayer - rat 1	0	-0.23884541	0.29725364	false
training	oneLayer	oneLayer - rat 1	0	-0.22910936	0.29322085	false
training	oneLayer	oneLayer - rat 1	0	-0.21880133	0.29322088	false
training	oneLayer	oneLayer - rat 1	0	-0.20877583	0.2890682	false
training	oneLayer	oneLayer - rat 1	0	-0.19861668	0.28906822	false
training	oneLayer	oneLayer - rat 1	0	-0.18881837	0.29312682	false
training	oneLayer	oneLayer - rat 1	0	-0.17870553	0.29312685	false
training	oneLayer	oneLayer - rat 1	0	-0.16857047	0.29732496	false
training	oneLayer	oneLayer - rat 1	0	-0.15831438	0.29732496	false
training	oneLayer	oneLayer - rat 1	0	-0.14855753	0.30136642	false
training	oneLayer	oneLayer - rat 1	0	-0.13843131	0.30136642	false
training	oneLayer	oneLayer - rat 1	0	-0.12843761	0.30550596	false
training	oneLayer	oneLayer - rat 1	0	-0.1175636	0.305506	false
training	oneLayer	oneLayer - rat 1	0	-0.10783724	0.30953482	false
training	oneLayer	oneLayer - rat 1	0	-0.09748215	0.30953482	false
training	oneLayer	oneLayer - rat 1	0	-0.08765823	0.31360406	false
training	oneLayer	oneLayer - rat 1	0	-0.07753903	0.31360406	false
training	oneLayer	oneLayer - rat 1	0	-0.067962006	0.317571	false
training	oneLayer	oneLayer - rat 1	0	-0.05697339	0.31757104	false
training	oneLayer	oneLayer - rat 1	0	-0.047213953	0.32161355	false
training	oneLayer	oneLayer - rat 1	0	-0.036671422	0.32161358	false
training	oneLayer	oneLayer - rat 1	0	-0.026660098	0.32576042	false
training	oneLayer	oneLayer - rat 1	0	-0.016622046	0.32576042	false
training	oneLayer	oneLayer - rat 1	0	-0.007317321	0.32961458	false
training	oneLayer	oneLayer - rat 1	0	0.0034358243	0.3296146	false
training	oneLayer	oneLayer - rat 1	0	0.012900131	0.33353487	false
training	oneLayer	oneLayer - rat 1	0	0.023876965	0.3335349	false
training	oneLayer	oneLayer - rat 1	0	0.03346316	0.33750564	false
training	oneLayer	oneLayer - rat 1	0	0.04357587	0.33750567	false
training	oneLayer	oneLayer - rat 1	0	0.05336894	0.34156212	false
training	oneLayer	oneLayer - rat 1	0	0.06419564	0.34156212	false
training	oneLayer	oneLayer - rat 1	0	0.07350261	0.34541723	false
training	oneLayer	oneLayer - rat 1	0	0.08449909	0.34541723	false
training	oneLayer	oneLayer - rat 1	0	0.09419993	0.34943548	false
training	oneLayer	oneLayer - rat 1	0	0.10440166	0.3494355	false
training	oneLayer	oneLayer - rat 1	0	0.114543624	0.35363647	false
training	oneLayer	oneLayer - rat 1	0	0.124596566	0.35363647	false
training	oneLayer	oneLayer - rat 1	0	0.13390978	0.34977883	false
training	oneLayer	oneLayer - rat 1	0	0.14143166	0.34225696	false
training	oneLayer	oneLayer - rat 1	0	0.15098296	0.33830073	false
training	oneLayer	oneLayer - rat 1	0	0.15861508	0.33066863	false
training	oneLayer	oneLayer - rat 1	0	0.16872689	0.3264802	false
training	oneLayer	oneLayer - rat 1	0	0.17634858	0.31885853	false
training	oneLayer	oneLayer - rat 1	0	0.18566377	0.3150001	false
training	oneLayer	oneLayer - rat 1	0	0.19314678	0.3075171	false
training	oneLayer	oneLayer - rat 1	0	0.20264897	0.30358118	false
training	oneLayer	oneLayer - rat 1	0	0.20995341	0.29627678	false
training	oneLayer	oneLayer - rat 1	0	0.21979536	0.29220012	false
training	oneLayer	oneLayer - rat 1	0	0.22748826	0.28450724	false
training	oneLayer	oneLayer - rat 1	0	0.2375368	0.28034502	false
training	oneLayer	oneLayer - rat 1	0	0.24505386	0.27282798	false
training	oneLayer	oneLayer - rat 1	0	0.2543573	0.2689744	false
training	oneLayer	oneLayer - rat 1	0	0.26154307	0.26178867	false
training	oneLayer	oneLayer - rat 1	0	0.27144143	0.25768864	false
training	oneLayer	oneLayer - rat 1	0	0.27880228	0.25032783	false
training	oneLayer	oneLayer - rat 1	0	0.28823498	0.2464207	false
training	oneLayer	oneLayer - rat 1	0	0.2958002	0.23885547	false
training	oneLayer	oneLayer - rat 1	0	0.30575898	0.23473044	false
training	oneLayer	oneLayer - rat 1	0	0.31320232	0.22728713	false
training	oneLayer	oneLayer - rat 1	0	0.32265747	0.2233707	false
training	oneLayer	oneLayer - rat 1	0	0.33020845	0.21581975	false
training	oneLayer	oneLayer - rat 1	0	0.34010112	0.21172209	false
training	oneLayer	oneLayer - rat 1	0	0.34756204	0.20426118	false
training	oneLayer	oneLayer - rat 1	0	0.3576614	0.20007792	false
training	oneLayer	oneLayer - rat 1	0	0.36516747	0.19257185	false
training	oneLayer	oneLayer - rat 1	0	0.3747461	0.18860428	false
training	oneLayer	oneLayer - rat 1	0	0.38206014	0.18129027	false
training	oneLayer	oneLayer - rat 1	0	0.38620448	0.17128499	false
training	oneLayer	oneLayer - rat 1	0	0.3935009	0.1639886	false
training	oneLayer	oneLayer - rat 1	0	0.3974705	0.15440512	false
training	oneLayer	oneLayer - rat 1	0	0.40497518	0.14690049	false
training	oneLayer	oneLayer - rat 1	0	0.4088163	0.1376272	false
training	oneLayer	oneLayer - rat 1	0	0.4165712	0.12987235	false
training	oneLayer	oneLayer - rat 1	0	0.42070776	0.11988583	false
training	oneLayer	oneLayer - rat 1	0	0.4283675	0.112226136	false
training	oneLayer	oneLayer - rat 1	0	0.4323659	0.10257316	false
training	oneLayer	oneLayer - rat 1	0	0.43236592	0.09196328	false
training	oneLayer	oneLayer - rat 1	0	0.4364772	0.08203778	false
training	oneLayer	oneLayer - rat 1	0	0.43647724	0.07191137	false
training	oneLayer	oneLayer - rat 1	0	0.44068196	0.06176029	false
training	oneLayer	oneLayer - rat 1	0	0.440682	0.051716547	false
training	oneLayer	oneLayer - rat 1	0	0.44461522	0.042220935	false
training	oneLayer	oneLayer - rat 1	0	0.44461524	0.0315811	false
training	oneLayer	oneLayer - rat 1	0	0.44053298	0.021725602	false
training	oneLayer	oneLayer - rat 1	0	0.43290904	0.014101635	false
training	oneLayer	oneLayer - rat 1	0	0.42295808	0.009979798	false
training	oneLayer	oneLayer - rat 1	0	0.41560218	0.0026238798	false
training	oneLayer	oneLayer - rat 1	0	0.40562525	-0.0015087231	false
training	oneLayer	oneLayer - rat 1	0	0.39847094	-0.008663047	false
training	oneLayer	oneLayer - rat 1	0	0.38875124	-0.0126891	false
training	oneLayer	oneLayer - rat 1	0	0.38153818	-0.019902201	false
training	oneLayer	oneLayer - rat 1	0	0.37216514	-0.023784654	false
training	oneLayer	oneLayer - rat 1	0	0.3648545	-0.031095307	false
training	oneLayer	oneLayer - rat 1	0	0.35511002	-0.035131626	false
training	oneLayer	oneLayer - rat 1	0	0.3478865	-0.042355165	false
training	oneLayer	oneLayer - rat 1	0	0.338541	-0.04622622	false
training	oneLayer	oneLayer - rat 1	0	0.33126506	-0.053502176	false
training	oneLayer	oneLayer - rat 1	0	0.32200766	-0.057336744	false
training	oneLayer	oneLayer - rat 1	0	0.31488463	-0.064459786	false
training	oneLayer	oneLayer - rat 1	0	0.30532452	-0.068419725	false
training	oneLayer	oneLayer - rat 1	0	0.2980049	-0.0757394	false
training	oneLayer	oneLayer - rat 1	0	0.28797156	-0.079895355	false
training	oneLayer	oneLayer - rat 1	0	0.28030738	-0.08755958	false
training	oneLayer	oneLayer - rat 1	0	0.27047732	-0.09163133	false
training	oneLayer	oneLayer - rat 1	0	0.2633737	-0.09873498	false
training	oneLayer	oneLayer - rat 1	0	0.25326663	-0.102921486	false
training	oneLayer	oneLayer - rat 1	0	0.24595495	-0.11023321	false
training	oneLayer	oneLayer - rat 1	0	0.23611091	-0.11431076	false
training	oneLayer	oneLayer - rat 1	0	0.22887452	-0.12154716	false
training	oneLayer	oneLayer - rat 1	0	0.21945709	-0.12544802	false
training	oneLayer	oneLayer - rat 1	0	0.21186371	-0.13304143	false
training	oneLayer	oneLayer - rat 1	0	0.20195669	-0.13714506	false
training	oneLayer	oneLayer - rat 1	0	0.19474217	-0.14435962	false
training	oneLayer	oneLayer - rat 1	0	0.18506223	-0.1483692	false
training	oneLayer	oneLayer - rat 1	0	0.1775519	-0.15587956	false
training	oneLayer	oneLayer - rat 1	0	0.16750334	-0.16004182	false
training	oneLayer	oneLayer - rat 1	0	0.1598334	-0.16771178	false
training	oneLayer	oneLayer - rat 1	0	0.14973724	-0.17189378	false
training	oneLayer	oneLayer - rat 1	0	0.14207512	-0.17955591	false
training	oneLayer	oneLayer - rat 1	0	0.13212776	-0.18367626	false
training	oneLayer	oneLayer - rat 1	0	0.12438358	-0.19142047	false
training	oneLayer	oneLayer - rat 1	0	0.11470592	-0.1954291	false
training	oneLayer	oneLayer - rat 1	0	0.10758021	-0.20255484	false
training	oneLayer	oneLayer - rat 1	0	0.09828161	-0.20640646	false
training	oneLayer	oneLayer - rat 1	0	0.09053589	-0.2141522	false
training	oneLayer	oneLayer - rat 1	0	0.080550104	-0.21828847	false
training	oneLayer	oneLayer - rat 1	0	0.07281512	-0.22602348	false
training	oneLayer	oneLayer - rat 1	0	0.06295203	-0.23010893	false
training	oneLayer	oneLayer - rat 1	0	0.055726945	-0.23733403	false
training	oneLayer	oneLayer - rat 1	0	0.04595043	-0.24138361	false
training	oneLayer	oneLayer - rat 1	0	0.038334116	-0.24899995	false
training	oneLayer	oneLayer - rat 1	0	0.02862103	-0.25302327	false
training	oneLayer	oneLayer - rat 1	0	0.02086972	-0.2607746	false
training	oneLayer	oneLayer - rat 1	0	0.011035762	-0.264848	false
training	oneLayer	oneLayer - rat 1	0	0.0039424608	-0.2719413	false
training	oneLayer	oneLayer - rat 1	0	-0.0061039585	-0.2761027	false
training	oneLayer	oneLayer - rat 1	0	-0.013716751	-0.28371552	false
training	oneLayer	oneLayer - rat 1	0	-0.023058586	-0.28758505	false
training	oneLayer	oneLayer - rat 1	0	-0.030174758	-0.29470125	false
training	oneLayer	oneLayer - rat 1	0	-0.039807044	-0.2986911	false
training	oneLayer	oneLayer - rat 1	0	-0.047347277	-0.30623135	false
training	oneLayer	oneLayer - rat 1	0	-0.05746167	-0.31042087	false
training	oneLayer	oneLayer - rat 1	0	-0.06466215	-0.31762138	false
training	oneLayer	oneLayer - rat 1	0	-0.07471805	-0.3217867	false
training	oneLayer	oneLayer - rat 1	0	-0.08236573	-0.3294344	false
training	oneLayer	oneLayer - rat 1	0	-0.09219743	-0.33350685	false
training	oneLayer	oneLayer - rat 1	0	-0.09987414	-0.34118357	false
training	oneLayer	oneLayer - rat 1	0	-0.109135404	-0.34501973	false
training	oneLayer	oneLayer - rat 1	0	-0.116841234	-0.3527256	false
training	oneLayer	oneLayer - rat 1	0	-0.12622583	-0.35661283	false
training	oneLayer	oneLayer - rat 1	0	-0.1338562	-0.36424324	false
training	oneLayer	oneLayer - rat 1	0	-0.14345358	-0.36821863	false
training	oneLayer	oneLayer - rat 1	0	-0.15079162	-0.37555668	false
training	oneLayer	oneLayer - rat 1	0	-0.16028813	-0.3794903	false
training	oneLayer	oneLayer - rat 1	0	-0.17059544	-0.3794903	false
training	oneLayer	oneLayer - rat 1	0	-0.18023632	-0.37549692	false
training	oneLayer	oneLayer - rat 1	0	-0.18764625	-0.36808702	false
training	oneLayer	oneLayer - rat 1	0	-0.19147456	-0.35884473	false
training	oneLayer	oneLayer - rat 1	0	-0.19897884	-0.35134047	false
training	oneLayer	oneLayer - rat 1	0	-0.20290715	-0.34185675	false
training	oneLayer	oneLayer - rat 1	0	-0.21028288	-0.33448103	false
training	oneLayer	oneLayer - rat 1	0	-0.2144681	-0.32437706	false
training	oneLayer	oneLayer - rat 1	0	-0.22183894	-0.31700626	false
training	oneLayer	oneLayer - rat 1	0	-0.2260453	-0.30685124	false
training	oneLayer	oneLayer - rat 1	0	-0.2334647	-0.29943186	false
training	oneLayer	oneLayer - rat 1	0	-0.23747502	-0.28975016	false
training	oneLayer	oneLayer - rat 1	0	-0.24465242	-0.28257278	false
training	oneLayer	oneLayer - rat 1	0	-0.24871308	-0.27276954	false
training	oneLayer	oneLayer - rat 1	0	-0.25605735	-0.2654253	false
training	oneLayer	oneLayer - rat 1	0	-0.25998205	-0.25595024	false
training	oneLayer	oneLayer - rat 1	0	-0.2676247	-0.24830762	false
training	oneLayer	oneLayer - rat 1	0	-0.27179432	-0.23824134	false
training	oneLayer	oneLayer - rat 1	0	-0.27891552	-0.23112017	false
training	oneLayer	oneLayer - rat 1	0	-0.28290263	-0.22149447	false
training	oneLayer	oneLayer - rat 1	0	-0.29028928	-0.21410786	false
training	oneLayer	oneLayer - rat 1	0	-0.29438987	-0.20420817	false
training	oneLayer	oneLayer - rat 1	0	-0.3016963	-0.19690175	false
training	oneLayer	oneLayer - rat 1	0	-0.30559918	-0.18747942	false
training	oneLayer	oneLayer - rat 1	0	-0.31298482	-0.1800938	false
training	oneLayer	oneLayer - rat 1	0	-0.31681475	-0.17084761	false
training	oneLayer	oneLayer - rat 1	0	-0.32449144	-0.16317093	false
training	oneLayer	oneLayer - rat 1	0	-0.32849425	-0.1535073	false
training	oneLayer	oneLayer - rat 1	0	-0.32849428	-0.14329623	false
training	oneLayer	oneLayer - rat 1	0	-0.33246598	-0.13370775	false
training	oneLayer	oneLayer - rat 1	0	-0.332466	-0.12315455	false
training	oneLayer	oneLayer - rat 1	0	-0.33646807	-0.11349275	false
training	oneLayer	oneLayer - rat 1	0	-0.33646807	-0.10335296	false
training	oneLayer	oneLayer - rat 1	0	-0.34035578	-0.09396728	false
training	oneLayer	oneLayer - rat 1	0	-0.34035578	-0.08344891	false
training	oneLayer	oneLayer - rat 1	0	-0.3442928	-0.07394418	false
training	oneLayer	oneLayer - rat 1	0	-0.34429282	-0.063572384	false
training	oneLayer	oneLayer - rat 1	0	-0.34836763	-0.0537349	false
training	oneLayer	oneLayer - rat 1	0	-0.34836766	-0.043028243	false
training	oneLayer	oneLayer - rat 1	0	-0.3522521	-0.03365047	false
training	oneLayer	oneLayer - rat 1	0	-0.3522521	-0.022776458	false
training	oneLayer	oneLayer - rat 1	0	-0.35642174	-0.012710109	false
training	oneLayer	oneLayer - rat 1	0	-0.35642177	-0.0017608003	false
training	oneLayer	oneLayer - rat 1	0	-0.36056155	0.0082335295	false
training	oneLayer	oneLayer - rat 1	0	-0.36056158	0.018481866	false
training	oneLayer	oneLayer - rat 1	0	-0.3647583	0.028613629	false
training	oneLayer	oneLayer - rat 1	0	-0.36475834	0.039079327	false
training	oneLayer	oneLayer - rat 1	0	-0.36886925	0.049003936	false
training	oneLayer	oneLayer - rat 1	0	-0.36886927	0.05914968	false
training	oneLayer	oneLayer - rat 1	0	-0.37271145	0.06842548	false
training	oneLayer	oneLayer - rat 1	0	-0.37271148	0.07924508	false
training	oneLayer	oneLayer - rat 1	0	-0.3768855	0.08932208	false
training	oneLayer	oneLayer - rat 1	0	-0.37688553	0.10025473	false
training	oneLayer	oneLayer - rat 1	0	-0.38074535	0.10957309	false
training	oneLayer	oneLayer - rat 1	0	-0.38074535	0.120128565	false
training	oneLayer	oneLayer - rat 1	0	-0.38475022	0.12979709	false
training	oneLayer	oneLayer - rat 1	0	-0.38475022	0.13980097	false
training	oneLayer	oneLayer - rat 1	0	-0.38870317	0.14934415	false
training	oneLayer	oneLayer - rat 1	0	-0.38870317	0.15947674	false
training	oneLayer	oneLayer - rat 1	0	-0.3848152	0.16886319	false
training	oneLayer	oneLayer - rat 1	0	-0.38086477	0.17840038	false
training	oneLayer	oneLayer - rat 1	0	-0.37685016	0.18809257	false
training	oneLayer	oneLayer - rat 1	0	-0.37270582	0.19809793	false
training	oneLayer	oneLayer - rat 1	0	-0.3687608	0.20762216	false
training	oneLayer	oneLayer - rat 1	0	-0.36481056	0.21715888	false
training	oneLayer	oneLayer - rat 1	0	-0.3609183	0.22655563	false
training	oneLayer	oneLayer - rat 1	0	-0.35686082	0.23635131	false
training	oneLayer	oneLayer - rat 1	0	-0.3528127	0.24612436	false
training	oneLayer	oneLayer - rat 1	0	-0.34883115	0.25573677	false
training	oneLayer	oneLayer - rat 1	0	-0.34492016	0.26517874	false
training	oneLayer	oneLayer - rat 1	0	-0.34109145	0.27442214	false
training	oneLayer	oneLayer - rat 1	0	-0.33704725	0.28418574	false
training	oneLayer	oneLayer - rat 1	0	-0.32962686	0.29160613	false
training	oneLayer	oneLayer - rat 1	0	-0.32018265	0.29551807	false
training	oneLayer	oneLayer - rat 1	0	-0.3101584	0.2955181	false
training	oneLayer	oneLayer - rat 1	0	-0.30013096	0.29967162	false
training	oneLayer	oneLayer - rat 1	0	-0.2897489	0.29967165	false
training	oneLayer	oneLayer - rat 1	0	-0.2804787	0.3035115	false
training	oneLayer	oneLayer - rat 1	0	-0.26996073	0.30351153	false
training	oneLayer	oneLayer - rat 1	0	-0.26005504	0.29940847	false
training	oneLayer	oneLayer - rat 1	0	-0.24991956	0.2994085	false
training	oneLayer	oneLayer - rat 1	0	-0.24015462	0.29536372	false
training	oneLayer	oneLayer - rat 1	0	-0.22954002	0.29536375	false
training	oneLayer	oneLayer - rat 1	0	-0.22023107	0.29150787	false
training	oneLayer	oneLayer - rat 1	0	-0.20969915	0.2915079	false
training	oneLayer	oneLayer - rat 1	0	-0.2003347	0.28762904	false
training	oneLayer	oneLayer - rat 1	0	-0.18994719	0.28762904	false
training	oneLayer	oneLayer - rat 1	0	-0.17989469	0.29179296	false
training	oneLayer	oneLayer - rat 1	0	-0.16899271	0.29179296	false
training	oneLayer	oneLayer - rat 1	0	-0.15960518	0.29568142	false
training	oneLayer	oneLayer - rat 1	0	-0.14867264	0.29568145	false
training	oneLayer	oneLayer - rat 1	0	-0.13885918	0.29974633	false
training	oneLayer	oneLayer - rat 1	0	-0.12872204	0.29974633	false
training	oneLayer	oneLayer - rat 1	0	-0.11875301	0.30387568	false
training	oneLayer	oneLayer - rat 1	0	-0.108482115	0.30387568	false
training	oneLayer	oneLayer - rat 1	0	-0.09836766	0.30806527	false
training	oneLayer	oneLayer - rat 1	0	-0.087937266	0.30806527	false
training	oneLayer	oneLayer - rat 1	0	-0.078457095	0.3119921	false
training	oneLayer	oneLayer - rat 1	0	-0.06792392	0.3119921	false
training	oneLayer	oneLayer - rat 1	0	-0.058111817	0.31605646	false
training	oneLayer	oneLayer - rat 1	0	-0.047655087	0.31605646	false
training	oneLayer	oneLayer - rat 1	0	-0.03829002	0.31993562	false
training	oneLayer	oneLayer - rat 1	0	-0.02778991	0.31993562	false
training	oneLayer	oneLayer - rat 1	0	-0.018250275	0.3238871	false
training	oneLayer	oneLayer - rat 1	0	-0.0074352566	0.3238871	false
training	oneLayer	oneLayer - rat 1	0	0.0018735782	0.32774296	false
training	oneLayer	oneLayer - rat 1	0	0.011947053	0.327743	false
training	oneLayer	oneLayer - rat 1	0	0.021215102	0.33158195	false
training	oneLayer	oneLayer - rat 1	0	0.031702273	0.33158198	false
training	oneLayer	oneLayer - rat 1	0	0.04118663	0.33551055	false
training	oneLayer	oneLayer - rat 1	0	0.051867716	0.33551055	false
training	oneLayer	oneLayer - rat 1	0	0.06163269	0.33955535	false
training	oneLayer	oneLayer - rat 1	0	0.07191526	0.33955538	false
training	oneLayer	oneLayer - rat 1	0	0.08125789	0.34342524	false
training	oneLayer	oneLayer - rat 1	0	0.09176043	0.34342524	false
training	oneLayer	oneLayer - rat 1	0	0.10177603	0.34757388	false
training	oneLayer	oneLayer - rat 1	0	0.11274405	0.3475739	false
training	oneLayer	oneLayer - rat 1	0	0.12268719	0.34345534	false
training	oneLayer	oneLayer - rat 1	0	0.12982461	0.33631793	false
training	oneLayer	oneLayer - rat 1	0	0.1397477	0.33220768	false
training	oneLayer	oneLayer - rat 1	0	0.14720395	0.32475144	false
training	oneLayer	oneLayer - rat 1	0	0.15736566	0.32054234	false
training	oneLayer	oneLayer - rat 1	0	0.16495472	0.31295332	false
training	oneLayer	oneLayer - rat 1	0	0.17483546	0.3088606	false
training	oneLayer	oneLayer - rat 1	0	0.18220474	0.30149135	false
training	oneLayer	oneLayer - rat 1	0	0.19157338	0.29761073	false
training	oneLayer	oneLayer - rat 1	0	0.19898681	0.29019734	false
training	oneLayer	oneLayer - rat 1	0	0.2087969	0.2861339	false
training	oneLayer	oneLayer - rat 1	0	0.2164517	0.2784791	false
training	oneLayer	oneLayer - rat 1	0	0.2263092	0.274396	false
training	oneLayer	oneLayer - rat 1	0	0.23365338	0.26705185	false
training	oneLayer	oneLayer - rat 1	0	0.24350129	0.26297274	false
training	oneLayer	oneLayer - rat 1	0	0.25079337	0.25568068	false
training	oneLayer	oneLayer - rat 1	0	0.26081926	0.25152785	false
training	oneLayer	oneLayer - rat 1	0	0.26793283	0.2444143	false
training	oneLayer	oneLayer - rat 1	0	0.27789935	0.24028604	false
training	oneLayer	oneLayer - rat 1	0	0.28532338	0.23286203	false
training	oneLayer	oneLayer - rat 1	0	0.2950699	0.22882491	false
training	oneLayer	oneLayer - rat 1	0	0.30244532	0.22144951	false
training	oneLayer	oneLayer - rat 1	0	0.31194285	0.21751553	false
training	oneLayer	oneLayer - rat 1	0	0.31928197	0.21017642	false
training	oneLayer	oneLayer - rat 1	0	0.32927468	0.20603731	false
training	oneLayer	oneLayer - rat 1	0	0.3366082	0.19870381	false
training	oneLayer	oneLayer - rat 1	0	0.3467694	0.19449493	false
training	oneLayer	oneLayer - rat 1	0	0.35410848	0.18715586	false
training	oneLayer	oneLayer - rat 1	0	0.36389276	0.1831031	false
training	oneLayer	oneLayer - rat 1	0	0.37127724	0.17571864	false
training	oneLayer	oneLayer - rat 1	0	0.3811901	0.17161264	false
training	oneLayer	oneLayer - rat 1	0	0.3889199	0.16388284	false
training	oneLayer	oneLayer - rat 1	0	0.3930498	0.15391241	false
training	oneLayer	oneLayer - rat 1	0	0.40022254	0.14673969	false
training	oneLayer	oneLayer - rat 1	0	0.40433437	0.13681291	false
training	oneLayer	oneLayer - rat 1	0	0.4115568	0.1295905	false
training	oneLayer	oneLayer - rat 1	0	0.41562295	0.11977399	false
training	oneLayer	oneLayer - rat 1	0	0.4232964	0.11210056	false
training	oneLayer	oneLayer - rat 1	0	0.42746046	0.102047674	false
training	oneLayer	oneLayer - rat 1	0	0.43510872	0.094399445	false
training	oneLayer	oneLayer - rat 1	0	0.43911234	0.08473389	false
training	oneLayer	oneLayer - rat 1	0	0.43911234	0.074017234	false
training	oneLayer	oneLayer - rat 1	0	0.4430549	0.06449909	false
training	oneLayer	oneLayer - rat 1	0	0.44305494	0.053910602	false
training	oneLayer	oneLayer - rat 1	0	0.44711003	0.04412076	false
