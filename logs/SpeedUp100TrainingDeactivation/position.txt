trial	group	subject	repetition	x	y	random
training	oneLayer	oneLayer - rat 1	0	0.009715462	-0.34597573	false
training	oneLayer	oneLayer - rat 1	0	0.019748868	-0.34181973	false
training	oneLayer	oneLayer - rat 1	0	0.02983187	-0.33764324	false
training	oneLayer	oneLayer - rat 1	0	0.039598353	-0.3335978	false
training	oneLayer	oneLayer - rat 1	0	0.049567085	-0.32946864	false
training	oneLayer	oneLayer - rat 1	0	0.059221655	-0.32546958	false
training	oneLayer	oneLayer - rat 1	0	0.06912471	-0.3213676	false
training	oneLayer	oneLayer - rat 1	0	0.078748085	-0.31738147	false
training	oneLayer	oneLayer - rat 1	0	0.08862294	-0.31329116	false
training	oneLayer	oneLayer - rat 1	0	0.098491654	-0.30920342	false
training	oneLayer	oneLayer - rat 1	0	0.10828356	-0.30514747	false
training	oneLayer	oneLayer - rat 1	0	0.117908694	-0.3011606	false
training	oneLayer	oneLayer - rat 1	0	0.12750645	-0.2971851	false
training	oneLayer	oneLayer - rat 1	0	0.13719508	-0.29317194	false
training	oneLayer	oneLayer - rat 1	0	0.14694488	-0.28913343	false
training	oneLayer	oneLayer - rat 1	0	0.15699854	-0.28496906	false
training	oneLayer	oneLayer - rat 1	0	0.16656163	-0.28100792	false
training	oneLayer	oneLayer - rat 1	0	0.17637655	-0.27694243	false
training	oneLayer	oneLayer - rat 1	0	0.1840042	-0.2693148	false
training	oneLayer	oneLayer - rat 1	0	0.1912124	-0.2621066	false
training	oneLayer	oneLayer - rat 1	0	0.19869871	-0.25462025	false
training	oneLayer	oneLayer - rat 1	0	0.20589161	-0.24742737	false
training	oneLayer	oneLayer - rat 1	0	0.21356633	-0.23975265	false
training	oneLayer	oneLayer - rat 1	0	0.2209371	-0.23238188	false
training	oneLayer	oneLayer - rat 1	0	0.22826083	-0.22505815	false
training	oneLayer	oneLayer - rat 1	0	0.23564184	-0.21767715	false
training	oneLayer	oneLayer - rat 1	0	0.24320015	-0.21011883	false
training	oneLayer	oneLayer - rat 1	0	0.25072533	-0.20259364	false
training	oneLayer	oneLayer - rat 1	0	0.25784686	-0.19547212	false
training	oneLayer	oneLayer - rat 1	0	0.26516008	-0.1881589	false
training	oneLayer	oneLayer - rat 1	0	0.2729331	-0.18038587	false
training	oneLayer	oneLayer - rat 1	0	0.28029776	-0.17302121	false
training	oneLayer	oneLayer - rat 1	0	0.28740963	-0.16590934	false
training	oneLayer	oneLayer - rat 1	0	0.29518145	-0.15813752	false
training	oneLayer	oneLayer - rat 1	0	0.30249485	-0.15082413	false
training	oneLayer	oneLayer - rat 1	0	0.30992478	-0.14339419	false
training	oneLayer	oneLayer - rat 1	0	0.31721303	-0.13610597	false
training	oneLayer	oneLayer - rat 1	0	0.3245668	-0.12875217	false
training	oneLayer	oneLayer - rat 1	0	0.3319057	-0.12141328	false
training	oneLayer	oneLayer - rat 1	0	0.33900136	-0.11431761	false
training	oneLayer	oneLayer - rat 1	0	0.3460881	-0.107230864	false
training	oneLayer	oneLayer - rat 1	0	0.35321224	-0.10010674	false
training	oneLayer	oneLayer - rat 1	0	0.3605738	-0.09274517	false
training	oneLayer	oneLayer - rat 1	0	0.36764696	-0.085672006	false
training	oneLayer	oneLayer - rat 1	0	0.37475857	-0.07856041	false
training	oneLayer	oneLayer - rat 1	0	0.38227654	-0.07104244	false
training	oneLayer	oneLayer - rat 1	0	0.38948295	-0.06383604	false
training	oneLayer	oneLayer - rat 1	0	0.39678	-0.056538958	false
training	oneLayer	oneLayer - rat 1	0	0.40404448	-0.049274486	false
training	oneLayer	oneLayer - rat 1	0	0.4111271	-0.04219187	false
training	oneLayer	oneLayer - rat 1	0	0.41833022	-0.034988753	false
training	oneLayer	oneLayer - rat 1	0	0.42235777	-0.025265366	false
training	oneLayer	oneLayer - rat 1	0	0.42235777	-0.014746248	false
training	oneLayer	oneLayer - rat 1	0	0.41837856	-0.005139555	false
training	oneLayer	oneLayer - rat 1	0	0.41122264	0.0020163676	false
training	oneLayer	oneLayer - rat 1	0	0.40124717	0.0061483392	false
training	oneLayer	oneLayer - rat 1	0	0.39096168	0.0061483383	false
training	oneLayer	oneLayer - rat 1	0	0.38039395	0.0061483374	false
training	oneLayer	oneLayer - rat 1	0	0.369593	0.0061483365	false
training	oneLayer	oneLayer - rat 1	0	0.3587703	0.0061483355	false
training	oneLayer	oneLayer - rat 1	0	0.34839186	0.0061483346	false
training	oneLayer	oneLayer - rat 1	0	0.33778217	0.0061483337	false
training	oneLayer	oneLayer - rat 1	0	0.32721505	0.0061483327	false
training	oneLayer	oneLayer - rat 1	0	0.31704918	0.0061483323	false
training	oneLayer	oneLayer - rat 1	0	0.30681586	0.0061483313	false
training	oneLayer	oneLayer - rat 1	0	0.29603866	0.0061483304	false
training	oneLayer	oneLayer - rat 1	0	0.28574035	0.0061483295	false
training	oneLayer	oneLayer - rat 1	0	0.27546284	0.0061483285	false
training	oneLayer	oneLayer - rat 1	0	0.26501396	0.0061483276	false
training	oneLayer	oneLayer - rat 1	0	0.25457737	0.0061483267	false
training	oneLayer	oneLayer - rat 1	0	0.2436643	0.0061483257	false
training	oneLayer	oneLayer - rat 1	0	0.23289113	0.006148325	false
training	oneLayer	oneLayer - rat 1	0	0.22245736	0.006148324	false
training	oneLayer	oneLayer - rat 1	0	0.21178706	0.006148323	false
training	oneLayer	oneLayer - rat 1	0	0.20101382	0.006148322	false
training	oneLayer	oneLayer - rat 1	0	0.19022742	0.006148321	false
training	oneLayer	oneLayer - rat 1	0	0.17975152	0.00614832	false
training	oneLayer	oneLayer - rat 1	0	0.16961384	0.006148319	false
training	oneLayer	oneLayer - rat 1	0	0.15887897	0.0061483183	false
training	oneLayer	oneLayer - rat 1	0	0.14866209	0.0061483174	false
training	oneLayer	oneLayer - rat 1	0	0.1382115	0.0061483164	false
training	oneLayer	oneLayer - rat 1	0	0.12787607	0.0061483155	false
training	oneLayer	oneLayer - rat 1	0	0.117014684	0.0061483146	false
training	oneLayer	oneLayer - rat 1	0	0.106616974	0.0061483136	false
training	oneLayer	oneLayer - rat 1	0	0.09630148	0.0061483127	false
training	oneLayer	oneLayer - rat 1	0	0.085693106	0.006148312	false
training	oneLayer	oneLayer - rat 1	0	0.074926734	0.006148311	false
training	oneLayer	oneLayer - rat 1	0	0.06461804	0.00614831	false
training	oneLayer	oneLayer - rat 1	0	0.053884443	0.006148309	false
training	oneLayer	oneLayer - rat 1	0	0.043338742	0.006148308	false
training	oneLayer	oneLayer - rat 1	0	0.033219427	0.006148307	false
training	oneLayer	oneLayer - rat 1	0	0.02320309	0.006148306	false
training	oneLayer	oneLayer - rat 1	0	0.0128581645	0.0061483053	false
training	oneLayer	oneLayer - rat 1	0	0.002729652	0.006148305	false
training	oneLayer	oneLayer - rat 1	0	-0.007789018	0.006148304	false
training	oneLayer	oneLayer - rat 1	0	-0.01827849	0.006148303	false
training	oneLayer	oneLayer - rat 1	0	-0.029088894	0.006148302	false
training	oneLayer	oneLayer - rat 1	0	-0.039903603	0.006148301	false
training	oneLayer	oneLayer - rat 1	0	-0.050443165	0.0061483	false
training	oneLayer	oneLayer - rat 1	0	-0.06127762	0.006148299	false
training	oneLayer	oneLayer - rat 1	0	-0.07196448	0.0061482983	false
training	oneLayer	oneLayer - rat 1	0	-0.08210257	0.0061482973	false
training	oneLayer	oneLayer - rat 1	0	-0.092377715	0.0061482964	false
training	oneLayer	oneLayer - rat 1	0	-0.102973245	0.0061482955	false
training	oneLayer	oneLayer - rat 1	0	-0.11354533	0.0061482945	false
training	oneLayer	oneLayer - rat 1	0	-0.1243511	0.0061482936	false
training	oneLayer	oneLayer - rat 1	0	-0.13532537	0.0061482927	false
training	oneLayer	oneLayer - rat 1	0	-0.14584938	0.0061482918	false
training	oneLayer	oneLayer - rat 1	0	-0.15594664	0.006148291	false
training	oneLayer	oneLayer - rat 1	0	-0.16650477	0.00614829	false
training	oneLayer	oneLayer - rat 1	0	-0.17688252	0.006148289	false
training	oneLayer	oneLayer - rat 1	0	-0.18693183	0.006148288	false
training	oneLayer	oneLayer - rat 1	0	-0.19747503	0.006148287	false
training	oneLayer	oneLayer - rat 1	0	-0.20792194	0.006148286	false
training	oneLayer	oneLayer - rat 1	0	-0.21848536	0.006148285	false
training	oneLayer	oneLayer - rat 1	0	-0.22946042	0.0061482843	false
training	oneLayer	oneLayer - rat 1	0	-0.2403574	0.0061482834	false
training	oneLayer	oneLayer - rat 1	0	-0.2506402	0.0061482824	false
training	oneLayer	oneLayer - rat 1	0	-0.2614981	0.0061482815	false
training	oneLayer	oneLayer - rat 1	0	-0.27178118	0.0061482806	false
training	oneLayer	oneLayer - rat 1	0	-0.28207937	0.0061482796	false
training	oneLayer	oneLayer - rat 1	0	-0.29293793	0.0061482787	false
training	oneLayer	oneLayer - rat 1	0	-0.303691	0.006148278	false
training	oneLayer	oneLayer - rat 1	0	-0.3140463	0.006148277	false
training	oneLayer	oneLayer - rat 1	0	-0.3245423	0.006148276	false
training	oneLayer	oneLayer - rat 1	0	-0.33487853	0.006148275	false
training	oneLayer	oneLayer - rat 1	0	-0.34546503	0.006148274	false
training	oneLayer	oneLayer - rat 1	0	-0.35638493	0.006148273	false
training	oneLayer	oneLayer - rat 1	0	-0.36667696	0.006148272	false
training	oneLayer	oneLayer - rat 1	0	-0.3774189	0.0061482713	false
training	oneLayer	oneLayer - rat 1	0	-0.38803685	0.0061482703	false
training	oneLayer	oneLayer - rat 1	0	-0.3984966	0.0061482694	false
training	oneLayer	oneLayer - rat 1	0	-0.40890393	0.0061482685	false
training	oneLayer	oneLayer - rat 1	0	-0.4184116	0.0022100622	false
training	oneLayer	oneLayer - rat 1	0	-0.4257671	-0.0051454417	false
training	oneLayer	oneLayer - rat 1	0	-0.4297673	-0.014802813	false
training	oneLayer	oneLayer - rat 1	0	-0.4297673	-0.025486136	false
training	oneLayer	oneLayer - rat 1	0	-0.42583048	-0.034990463	false
training	oneLayer	oneLayer - rat 1	0	-0.41842306	-0.042397898	false
training	oneLayer	oneLayer - rat 1	0	-0.40851358	-0.046502534	false
training	oneLayer	oneLayer - rat 1	0	-0.39758372	-0.04650253	false
training	oneLayer	oneLayer - rat 1	0	-0.3878166	-0.042456854	false
training	oneLayer	oneLayer - rat 1	0	-0.38067633	-0.035316583	false
training	oneLayer	oneLayer - rat 1	0	-0.37677795	-0.025905063	false
training	oneLayer	oneLayer - rat 1	0	-0.3725724	-0.01575198	false
training	oneLayer	oneLayer - rat 1	0	-0.36842287	-0.00573413	false
training	oneLayer	oneLayer - rat 1	0	-0.36445606	0.0038426532	false
training	oneLayer	oneLayer - rat 1	0	-0.36028257	0.0139183495	false
training	oneLayer	oneLayer - rat 1	0	-0.35616046	0.023869963	false
training	oneLayer	oneLayer - rat 1	0	-0.35210195	0.033668093	false
training	oneLayer	oneLayer - rat 1	0	-0.34815663	0.04319298	false
training	oneLayer	oneLayer - rat 1	0	-0.34395516	0.053336207	false
training	oneLayer	oneLayer - rat 1	0	-0.33999234	0.06290327	false
training	oneLayer	oneLayer - rat 1	0	-0.33595213	0.07265726	false
training	oneLayer	oneLayer - rat 1	0	-0.33198398	0.08223718	false
training	oneLayer	oneLayer - rat 1	0	-0.32785198	0.092212744	false
training	oneLayer	oneLayer - rat 1	0	-0.32381624	0.10195587	false
training	oneLayer	oneLayer - rat 1	0	-0.31970355	0.111884795	false
training	oneLayer	oneLayer - rat 1	0	-0.31970355	0.12233372	false
training	oneLayer	oneLayer - rat 1	0	-0.31970355	0.13322024	false
training	oneLayer	oneLayer - rat 1	0	-0.31970355	0.14338633	false
training	oneLayer	oneLayer - rat 1	0	-0.31970355	0.15348412	false
training	oneLayer	oneLayer - rat 1	0	-0.31970358	0.16376346	false
training	oneLayer	oneLayer - rat 1	0	-0.31970358	0.17415026	false
training	oneLayer	oneLayer - rat 1	0	-0.31970358	0.18483369	false
training	oneLayer	oneLayer - rat 1	0	-0.31970358	0.19526058	false
training	oneLayer	oneLayer - rat 1	0	-0.31970358	0.20607796	false
training	oneLayer	oneLayer - rat 1	0	-0.31970358	0.21692047	false
training	oneLayer	oneLayer - rat 1	0	-0.31970358	0.22765799	false
training	oneLayer	oneLayer - rat 1	0	-0.31970358	0.23835826	false
training	oneLayer	oneLayer - rat 1	0	-0.31970358	0.24927525	false
training	oneLayer	oneLayer - rat 1	0	-0.31970358	0.25977883	false
training	oneLayer	oneLayer - rat 1	0	-0.31970358	0.2698644	false
training	oneLayer	oneLayer - rat 1	0	-0.31970358	0.28073972	false
training	oneLayer	oneLayer - rat 1	0	-0.3155412	0.2907886	false
training	oneLayer	oneLayer - rat 1	0	-0.30826628	0.29806352	false
training	oneLayer	oneLayer - rat 1	0	-0.29892617	0.30193233	false
training	oneLayer	oneLayer - rat 1	0	-0.28837052	0.30193233	false
training	oneLayer	oneLayer - rat 1	0	-0.27742052	0.30193233	false
training	oneLayer	oneLayer - rat 1	0	-0.26766083	0.29788974	false
training	oneLayer	oneLayer - rat 1	0	-0.25784278	0.29382297	false
training	oneLayer	oneLayer - rat 1	0	-0.24857342	0.28998348	false
training	oneLayer	oneLayer - rat 1	0	-0.23883216	0.28594851	false
training	oneLayer	oneLayer - rat 1	0	-0.22884823	0.28181303	false
training	oneLayer	oneLayer - rat 1	0	-0.21872434	0.27761957	false
training	oneLayer	oneLayer - rat 1	0	-0.20862354	0.2734357	false
training	oneLayer	oneLayer - rat 1	0	-0.1991957	0.26953056	false
training	oneLayer	oneLayer - rat 1	0	-0.18989827	0.26567945	false
training	oneLayer	oneLayer - rat 1	0	-0.18006812	0.26160768	false
training	oneLayer	oneLayer - rat 1	0	-0.17044108	0.25762	false
training	oneLayer	oneLayer - rat 1	0	-0.1603925	0.25345775	false
training	oneLayer	oneLayer - rat 1	0	-0.15079293	0.24948148	false
training	oneLayer	oneLayer - rat 1	0	-0.14098729	0.24541986	false
training	oneLayer	oneLayer - rat 1	0	-0.13089556	0.24123973	false
training	oneLayer	oneLayer - rat 1	0	-0.1212452	0.23724242	false
training	oneLayer	oneLayer - rat 1	0	-0.11157788	0.23323809	false
training	oneLayer	oneLayer - rat 1	0	-0.102024265	0.22928086	false
training	oneLayer	oneLayer - rat 1	0	-0.09201723	0.2251358	false
training	oneLayer	oneLayer - rat 1	0	-0.0826483	0.22125508	false
training	oneLayer	oneLayer - rat 1	0	-0.07264634	0.21711212	false
training	oneLayer	oneLayer - rat 1	0	-0.06315793	0.2131819	false
training	oneLayer	oneLayer - rat 1	0	-0.053129595	0.20902804	false
training	oneLayer	oneLayer - rat 1	0	-0.043632172	0.20509407	false
training	oneLayer	oneLayer - rat 1	0	-0.034098405	0.20114505	false
training	oneLayer	oneLayer - rat 1	0	-0.024776494	0.19728379	false
training	oneLayer	oneLayer - rat 1	0	-0.015139958	0.19329222	false
training	oneLayer	oneLayer - rat 1	0	-0.0054152934	0.18926413	false
training	oneLayer	oneLayer - rat 1	0	0.004215414	0.18527496	false
training	oneLayer	oneLayer - rat 1	0	0.013986196	0.18122777	false
training	oneLayer	oneLayer - rat 1	0	0.023364155	0.1773433	false
training	oneLayer	oneLayer - rat 1	0	0.033479203	0.1731535	false
training	oneLayer	oneLayer - rat 1	0	0.043630224	0.16894881	false
training	oneLayer	oneLayer - rat 1	0	0.0537875	0.16474155	false
training	oneLayer	oneLayer - rat 1	0	0.06390301	0.16055156	false
training	oneLayer	oneLayer - rat 1	0	0.073923044	0.15640113	false
training	oneLayer	oneLayer - rat 1	0	0.0834692	0.15244699	false
training	oneLayer	oneLayer - rat 1	0	0.093407296	0.1483305	false
training	oneLayer	oneLayer - rat 1	0	0.10301897	0.1443492	false
training	oneLayer	oneLayer - rat 1	0	0.11232722	0.1404936	false
training	oneLayer	oneLayer - rat 1	0	0.12243604	0.13630639	false
training	oneLayer	oneLayer - rat 1	0	0.13209991	0.13230349	false
training	oneLayer	oneLayer - rat 1	0	0.14163318	0.12835468	false
training	oneLayer	oneLayer - rat 1	0	0.15090795	0.12451295	false
training	oneLayer	oneLayer - rat 1	0	0.1605666	0.12051221	false
training	oneLayer	oneLayer - rat 1	0	0.16984513	0.11666892	false
training	oneLayer	oneLayer - rat 1	0	0.17927296	0.112763785	false
training	oneLayer	oneLayer - rat 1	0	0.1890534	0.10871259	false
training	oneLayer	oneLayer - rat 1	0	0.19877535	0.104685634	false
training	oneLayer	oneLayer - rat 1	0	0.20882621	0.100522436	false
training	oneLayer	oneLayer - rat 1	0	0.21882407	0.09638119	false
training	oneLayer	oneLayer - rat 1	0	0.22896126	0.09218223	false
training	oneLayer	oneLayer - rat 1	0	0.23877084	0.08811896	false
training	oneLayer	oneLayer - rat 1	0	0.24855395	0.084066674	false
training	oneLayer	oneLayer - rat 1	0	0.25869828	0.079864755	false
training	oneLayer	oneLayer - rat 1	0	0.2685224	0.075795464	false
training	oneLayer	oneLayer - rat 1	0	0.27805448	0.071847156	false
training	oneLayer	oneLayer - rat 1	0	0.2881364	0.0676711	false
training	oneLayer	oneLayer - rat 1	0	0.29791683	0.063619904	false
training	oneLayer	oneLayer - rat 1	0	0.308047	0.059423864	false
training	oneLayer	oneLayer - rat 1	0	0.31773034	0.05541289	false
training	oneLayer	oneLayer - rat 1	0	0.32774082	0.051266413	false
training	oneLayer	oneLayer - rat 1	0	0.33698902	0.04743568	false
training	oneLayer	oneLayer - rat 1	0	0.34702715	0.043277748	false
training	oneLayer	oneLayer - rat 1	0	0.35647866	0.039362818	false
training	oneLayer	oneLayer - rat 1	0	0.366413	0.035247877	false
training	oneLayer	oneLayer - rat 1	0	0.37567735	0.03141046	false
training	oneLayer	oneLayer - rat 1	0	0.38563767	0.027284762	false
training	oneLayer	oneLayer - rat 1	0	0.39531374	0.023276802	false
training	oneLayer	oneLayer - rat 1	0	0.40538806	0.019103894	false
training	oneLayer	oneLayer - rat 1	0	0.41292855	0.011563395	false
training	oneLayer	oneLayer - rat 1	0	0.4171045	0.0014817314	false
training	oneLayer	oneLayer - rat 1	0	0.4171045	-0.008537156	false
training	oneLayer	oneLayer - rat 1	0	0.41300124	-0.018443333	false
training	oneLayer	oneLayer - rat 1	0	0.40546685	-0.025977718	false
training	oneLayer	oneLayer - rat 1	0	0.39535648	-0.030165574	false
training	oneLayer	oneLayer - rat 1	0	0.38469437	-0.030165575	false
training	oneLayer	oneLayer - rat 1	0	0.3740593	-0.030165575	false
training	oneLayer	oneLayer - rat 1	0	0.36344612	-0.030165577	false
training	oneLayer	oneLayer - rat 1	0	0.35275114	-0.030165577	false
training	oneLayer	oneLayer - rat 1	0	0.34270498	-0.03016558	false
training	oneLayer	oneLayer - rat 1	0	0.33216727	-0.03016558	false
training	oneLayer	oneLayer - rat 1	0	0.3220919	-0.030165581	false
training	oneLayer	oneLayer - rat 1	0	0.31175837	-0.030165581	false
training	oneLayer	oneLayer - rat 1	0	0.30119124	-0.030165583	false
training	oneLayer	oneLayer - rat 1	0	0.29023713	-0.030165583	false
training	oneLayer	oneLayer - rat 1	0	0.2792461	-0.030165585	false
training	oneLayer	oneLayer - rat 1	0	0.2682604	-0.030165585	false
training	oneLayer	oneLayer - rat 1	0	0.25785452	-0.030165587	false
training	oneLayer	oneLayer - rat 1	0	0.24752586	-0.030165587	false
training	oneLayer	oneLayer - rat 1	0	0.23685694	-0.030165588	false
training	oneLayer	oneLayer - rat 1	0	0.22632967	-0.030165588	false
training	oneLayer	oneLayer - rat 1	0	0.21560837	-0.03016559	false
training	oneLayer	oneLayer - rat 1	0	0.20500585	-0.03016559	false
training	oneLayer	oneLayer - rat 1	0	0.19419992	-0.030165592	false
training	oneLayer	oneLayer - rat 1	0	0.18346651	-0.030165592	false
training	oneLayer	oneLayer - rat 1	0	0.17306876	-0.030165594	false
training	oneLayer	oneLayer - rat 1	0	0.16274734	-0.030165594	false
training	oneLayer	oneLayer - rat 1	0	0.15242726	-0.030165596	false
training	oneLayer	oneLayer - rat 1	0	0.14177361	-0.030165596	false
training	oneLayer	oneLayer - rat 1	0	0.13082615	-0.030165598	false
training	oneLayer	oneLayer - rat 1	0	0.120640025	-0.030165598	false
training	oneLayer	oneLayer - rat 1	0	0.10994039	-0.0301656	false
training	oneLayer	oneLayer - rat 1	0	0.09897396	-0.0301656	false
training	oneLayer	oneLayer - rat 1	0	0.08826923	-0.030165602	false
training	oneLayer	oneLayer - rat 1	0	0.07761209	-0.030165602	false
training	oneLayer	oneLayer - rat 1	0	0.06751136	-0.030165603	false
training	oneLayer	oneLayer - rat 1	0	0.057100613	-0.030165603	false
training	oneLayer	oneLayer - rat 1	0	0.04644591	-0.030165605	false
training	oneLayer	oneLayer - rat 1	0	0.036417097	-0.030165605	false
training	oneLayer	oneLayer - rat 1	0	0.026408719	-0.030165607	false
training	oneLayer	oneLayer - rat 1	0	0.015758386	-0.030165607	false
training	oneLayer	oneLayer - rat 1	0	0.004790679	-0.030165609	false
training	oneLayer	oneLayer - rat 1	0	-0.0060673445	-0.030165609	false
training	oneLayer	oneLayer - rat 1	0	-0.01688072	-0.03016561	false
training	oneLayer	oneLayer - rat 1	0	-0.027352422	-0.03016561	false
training	oneLayer	oneLayer - rat 1	0	-0.03789128	-0.030165613	false
training	oneLayer	oneLayer - rat 1	0	-0.04814511	-0.030165613	false
training	oneLayer	oneLayer - rat 1	0	-0.05838875	-0.030165615	false
training	oneLayer	oneLayer - rat 1	0	-0.069296606	-0.030165615	false
training	oneLayer	oneLayer - rat 1	0	-0.079768464	-0.030165616	false
training	oneLayer	oneLayer - rat 1	0	-0.09062952	-0.030165616	false
training	oneLayer	oneLayer - rat 1	0	-0.10065259	-0.030165618	false
training	oneLayer	oneLayer - rat 1	0	-0.11153228	-0.030165618	false
training	oneLayer	oneLayer - rat 1	0	-0.12246041	-0.03016562	false
training	oneLayer	oneLayer - rat 1	0	-0.13333106	-0.03016562	false
training	oneLayer	oneLayer - rat 1	0	-0.14425476	-0.030165622	false
training	oneLayer	oneLayer - rat 1	0	-0.1547441	-0.030165622	false
training	oneLayer	oneLayer - rat 1	0	-0.16548713	-0.030165624	false
training	oneLayer	oneLayer - rat 1	0	-0.17629936	-0.030165624	false
training	oneLayer	oneLayer - rat 1	0	-0.18663639	-0.030165626	false
training	oneLayer	oneLayer - rat 1	0	-0.19740948	-0.030165626	false
training	oneLayer	oneLayer - rat 1	0	-0.2081025	-0.030165628	false
training	oneLayer	oneLayer - rat 1	0	-0.21834287	-0.030165628	false
training	oneLayer	oneLayer - rat 1	0	-0.22874106	-0.03016563	false
training	oneLayer	oneLayer - rat 1	0	-0.23925078	-0.03016563	false
training	oneLayer	oneLayer - rat 1	0	-0.24995631	-0.030165631	false
training	oneLayer	oneLayer - rat 1	0	-0.26035696	-0.030165631	false
training	oneLayer	oneLayer - rat 1	0	-0.27125168	-0.030165633	false
training	oneLayer	oneLayer - rat 1	0	-0.28152287	-0.030165633	false
training	oneLayer	oneLayer - rat 1	0	-0.2920321	-0.030165635	false
training	oneLayer	oneLayer - rat 1	0	-0.30204302	-0.030165635	false
training	oneLayer	oneLayer - rat 1	0	-0.31273368	-0.030165637	false
training	oneLayer	oneLayer - rat 1	0	-0.32278726	-0.030165637	false
training	oneLayer	oneLayer - rat 1	0	-0.3335561	-0.030165639	false
training	oneLayer	oneLayer - rat 1	0	-0.34421209	-0.030165639	false
training	oneLayer	oneLayer - rat 1	0	-0.35496354	-0.03016564	false
training	oneLayer	oneLayer - rat 1	0	-0.365199	-0.03016564	false
training	oneLayer	oneLayer - rat 1	0	-0.37590486	-0.030165642	false
training	oneLayer	oneLayer - rat 1	0	-0.38608277	-0.030165642	false
training	oneLayer	oneLayer - rat 1	0	-0.39608604	-0.026022151	false
training	oneLayer	oneLayer - rat 1	0	-0.40602693	-0.021904504	false
training	oneLayer	oneLayer - rat 1	0	-0.41321054	-0.014720897	false
training	oneLayer	oneLayer - rat 1	0	-0.41727754	-0.0049022427	false
training	oneLayer	oneLayer - rat 1	0	-0.41727754	0.0056193257	false
training	oneLayer	oneLayer - rat 1	0	-0.41322663	0.015399149	false
training	oneLayer	oneLayer - rat 1	0	-0.40557107	0.023054693	false
training	oneLayer	oneLayer - rat 1	0	-0.39603227	0.0270058	false
training	oneLayer	oneLayer - rat 1	0	-0.38599637	0.0270058	false
training	oneLayer	oneLayer - rat 1	0	-0.37530753	0.0270058	false
training	oneLayer	oneLayer - rat 1	0	-0.36495718	0.0270058	false
training	oneLayer	oneLayer - rat 1	0	-0.35479423	0.0270058	false
training	oneLayer	oneLayer - rat 1	0	-0.34398538	0.0270058	false
training	oneLayer	oneLayer - rat 1	0	-0.3338083	0.0270058	false
training	oneLayer	oneLayer - rat 1	0	-0.3230845	0.0270058	false
training	oneLayer	oneLayer - rat 1	0	-0.31306443	0.0270058	false
training	oneLayer	oneLayer - rat 1	0	-0.30271325	0.0270058	false
training	oneLayer	oneLayer - rat 1	0	-0.29185233	0.0270058	false
training	oneLayer	oneLayer - rat 1	0	-0.28109676	0.0270058	false
training	oneLayer	oneLayer - rat 1	0	-0.27055854	0.0270058	false
training	oneLayer	oneLayer - rat 1	0	-0.25991046	0.0270058	false
training	oneLayer	oneLayer - rat 1	0	-0.2491059	0.0270058	false
training	oneLayer	oneLayer - rat 1	0	-0.2384764	0.0270058	false
training	oneLayer	oneLayer - rat 1	0	-0.22833855	0.0270058	false
training	oneLayer	oneLayer - rat 1	0	-0.21832867	0.0270058	false
training	oneLayer	oneLayer - rat 1	0	-0.20751838	0.0270058	false
training	oneLayer	oneLayer - rat 1	0	-0.1972846	0.0270058	false
training	oneLayer	oneLayer - rat 1	0	-0.18683289	0.0270058	false
training	oneLayer	oneLayer - rat 1	0	-0.17596835	0.0270058	false
training	oneLayer	oneLayer - rat 1	0	-0.16565526	0.0270058	false
training	oneLayer	oneLayer - rat 1	0	-0.1555702	0.0270058	false
training	oneLayer	oneLayer - rat 1	0	-0.14550436	0.0270058	false
training	oneLayer	oneLayer - rat 1	0	-0.1345948	0.0270058	false
training	oneLayer	oneLayer - rat 1	0	-0.1236799	0.0270058	false
training	oneLayer	oneLayer - rat 1	0	-0.11275505	0.0270058	false
training	oneLayer	oneLayer - rat 1	0	-0.10227696	0.0270058	false
training	oneLayer	oneLayer - rat 1	0	-0.091411404	0.0270058	false
training	oneLayer	oneLayer - rat 1	0	-0.0808697	0.0270058	false
training	oneLayer	oneLayer - rat 1	0	-0.070634864	0.0270058	false
training	oneLayer	oneLayer - rat 1	0	-0.060301818	0.0270058	false
training	oneLayer	oneLayer - rat 1	0	-0.049421083	0.0270058	false
training	oneLayer	oneLayer - rat 1	0	-0.038958997	0.0270058	false
training	oneLayer	oneLayer - rat 1	0	-0.028267961	0.0270058	false
training	oneLayer	oneLayer - rat 1	0	-0.017527783	0.0270058	false
training	oneLayer	oneLayer - rat 1	0	-0.0075210906	0.0270058	false
training	oneLayer	oneLayer - rat 1	0	0.0027609835	0.0270058	false
training	oneLayer	oneLayer - rat 1	0	0.013084577	0.0270058	false
training	oneLayer	oneLayer - rat 1	0	0.023472099	0.0270058	false
training	oneLayer	oneLayer - rat 1	0	0.033999383	0.0270058	false
training	oneLayer	oneLayer - rat 1	0	0.04481182	0.0270058	false
training	oneLayer	oneLayer - rat 1	0	0.05499771	0.0270058	false
training	oneLayer	oneLayer - rat 1	0	0.06500065	0.0270058	false
training	oneLayer	oneLayer - rat 1	0	0.07572079	0.0270058	false
training	oneLayer	oneLayer - rat 1	0	0.08582273	0.0270058	false
training	oneLayer	oneLayer - rat 1	0	0.096671425	0.0270058	false
training	oneLayer	oneLayer - rat 1	0	0.10671446	0.0270058	false
training	oneLayer	oneLayer - rat 1	0	0.117113605	0.0270058	false
training	oneLayer	oneLayer - rat 1	0	0.12774378	0.0270058	false
training	oneLayer	oneLayer - rat 1	0	0.13833304	0.0270058	false
training	oneLayer	oneLayer - rat 1	0	0.14898473	0.0270058	false
training	oneLayer	oneLayer - rat 1	0	0.15954979	0.0270058	false
training	oneLayer	oneLayer - rat 1	0	0.16984563	0.0270058	false
training	oneLayer	oneLayer - rat 1	0	0.18068278	0.0270058	false
training	oneLayer	oneLayer - rat 1	0	0.19148277	0.0270058	false
training	oneLayer	oneLayer - rat 1	0	0.20213039	0.0270058	false
training	oneLayer	oneLayer - rat 1	0	0.2128557	0.0270058	false
training	oneLayer	oneLayer - rat 1	0	0.22286741	0.0270058	false
training	oneLayer	oneLayer - rat 1	0	0.2328831	0.0270058	false
training	oneLayer	oneLayer - rat 1	0	0.24304591	0.0270058	false
training	oneLayer	oneLayer - rat 1	0	0.25328946	0.0270058	false
training	oneLayer	oneLayer - rat 1	0	0.26333696	0.0270058	false
training	oneLayer	oneLayer - rat 1	0	0.27390268	0.0270058	false
training	oneLayer	oneLayer - rat 1	0	0.284562	0.0270058	false
training	oneLayer	oneLayer - rat 1	0	0.29496992	0.0270058	false
training	oneLayer	oneLayer - rat 1	0	0.3057272	0.0270058	false
training	oneLayer	oneLayer - rat 1	0	0.31628752	0.0270058	false
training	oneLayer	oneLayer - rat 1	0	0.32633144	0.0270058	false
training	oneLayer	oneLayer - rat 1	0	0.33717608	0.0270058	false
training	oneLayer	oneLayer - rat 1	0	0.34745333	0.0270058	false
training	oneLayer	oneLayer - rat 1	0	0.3582737	0.0270058	false
training	oneLayer	oneLayer - rat 1	0	0.36926723	0.0270058	false
training	oneLayer	oneLayer - rat 1	0	0.3801938	0.0270058	false
training	oneLayer	oneLayer - rat 1	0	0.3902533	0.0270058	false
training	oneLayer	oneLayer - rat 1	0	0.4000123	0.022963487	false
training	oneLayer	oneLayer - rat 1	0	0.40937513	0.019085282	false
training	oneLayer	oneLayer - rat 1	0	0.41686687	0.011593547	false
training	oneLayer	oneLayer - rat 1	0	0.42097232	0.0016820867	false
training	oneLayer	oneLayer - rat 1	0	0.42097232	-0.008889608	false
training	oneLayer	oneLayer - rat 1	0	0.41696897	-0.018554555	false
training	oneLayer	oneLayer - rat 1	0	0.40977213	-0.02575139	false
training	oneLayer	oneLayer - rat 1	0	0.40001428	-0.029793229	false
training	oneLayer	oneLayer - rat 1	0	0.389138	-0.029793227	false
training	oneLayer	oneLayer - rat 1	0	0.37952763	-0.025812475	false
training	oneLayer	oneLayer - rat 1	0	0.3700248	-0.021876276	false
training	oneLayer	oneLayer - rat 1	0	0.36070368	-0.01801534	false
training	oneLayer	oneLayer - rat 1	0	0.3508465	-0.013932365	false
training	oneLayer	oneLayer - rat 1	0	0.34114707	-0.009914718	false
training	oneLayer	oneLayer - rat 1	0	0.3313348	-0.0058503454	false
training	oneLayer	oneLayer - rat 1	0	0.32151806	-0.001784118	false
training	oneLayer	oneLayer - rat 1	0	0.31219587	0.0020772617	false
training	oneLayer	oneLayer - rat 1	0	0.30270934	0.0060067065	false
training	oneLayer	oneLayer - rat 1	0	0.2929036	0.010068382	false
training	oneLayer	oneLayer - rat 1	0	0.2829624	0.014186149	false
training	oneLayer	oneLayer - rat 1	0	0.27328178	0.01819601	false
training	oneLayer	oneLayer - rat 1	0	0.26334447	0.022312181	false
training	oneLayer	oneLayer - rat 1	0	0.25405064	0.02616181	false
training	oneLayer	oneLayer - rat 1	0	0.2442017	0.030241372	false
training	oneLayer	oneLayer - rat 1	0	0.23428018	0.034351002	false
training	oneLayer	oneLayer - rat 1	0	0.22433923	0.03846868	false
training	oneLayer	oneLayer - rat 1	0	0.21451779	0.04253686	false
training	oneLayer	oneLayer - rat 1	0	0.20509541	0.04643973	false
training	oneLayer	oneLayer - rat 1	0	0.1952203	0.05053014	false
training	oneLayer	oneLayer - rat 1	0	0.18580489	0.05443013	false
training	oneLayer	oneLayer - rat 1	0	0.17565817	0.058633044	false
training	oneLayer	oneLayer - rat 1	0	0.16552095	0.06283202	false
training	oneLayer	oneLayer - rat 1	0	0.15542503	0.06701388	false
training	oneLayer	oneLayer - rat 1	0	0.14530094	0.07120742	false
training	oneLayer	oneLayer - rat 1	0	0.13585234	0.07512116	false
training	oneLayer	oneLayer - rat 1	0	0.12636165	0.07905233	false
training	oneLayer	oneLayer - rat 1	0	0.11659253	0.083098836	false
training	oneLayer	oneLayer - rat 1	0	0.10699703	0.08707342	false
training	oneLayer	oneLayer - rat 1	0	0.09721344	0.09112592	false
training	oneLayer	oneLayer - rat 1	0	0.08726769	0.095245585	false
training	oneLayer	oneLayer - rat 1	0	0.077584565	0.09925647	false
training	oneLayer	oneLayer - rat 1	0	0.06830488	0.10310024	false
training	oneLayer	oneLayer - rat 1	0	0.058898173	0.106996626	false
training	oneLayer	oneLayer - rat 1	0	0.049221452	0.11100486	false
training	oneLayer	oneLayer - rat 1	0	0.0397376	0.1149332	false
training	oneLayer	oneLayer - rat 1	0	0.03018672	0.1188893	false
training	oneLayer	oneLayer - rat 1	0	0.020164799	0.12304052	false
training	oneLayer	oneLayer - rat 1	0	0.01087517	0.12688841	false
training	oneLayer	oneLayer - rat 1	0	0.0011298147	0.13092507	false
training	oneLayer	oneLayer - rat 1	0	-0.00839917	0.13487211	false
training	oneLayer	oneLayer - rat 1	0	-0.01777298	0.13875487	false
training	oneLayer	oneLayer - rat 1	0	-0.027342865	0.14271885	false
training	oneLayer	oneLayer - rat 1	0	-0.03696711	0.14670534	false
training	oneLayer	oneLayer - rat 1	0	-0.04675217	0.15075845	false
training	oneLayer	oneLayer - rat 1	0	-0.05630484	0.15471528	false
training	oneLayer	oneLayer - rat 1	0	-0.06590608	0.15869226	false
training	oneLayer	oneLayer - rat 1	0	-0.07596109	0.16285717	false
training	oneLayer	oneLayer - rat 1	0	-0.08611082	0.16706134	false
training	oneLayer	oneLayer - rat 1	0	-0.09536815	0.17089584	false
training	oneLayer	oneLayer - rat 1	0	-0.10505054	0.17490643	false
training	oneLayer	oneLayer - rat 1	0	-0.114919685	0.17899436	false
training	oneLayer	oneLayer - rat 1	0	-0.124947205	0.18314789	false
training	oneLayer	oneLayer - rat 1	0	-0.13433602	0.18703687	false
training	oneLayer	oneLayer - rat 1	0	-0.14393297	0.19101205	false
training	oneLayer	oneLayer - rat 1	0	-0.1533033	0.19489338	false
training	oneLayer	oneLayer - rat 1	0	-0.16327436	0.19902353	false
training	oneLayer	oneLayer - rat 1	0	-0.17315146	0.20311476	false
training	oneLayer	oneLayer - rat 1	0	-0.18326186	0.20730263	false
training	oneLayer	oneLayer - rat 1	0	-0.19267668	0.21120237	false
training	oneLayer	oneLayer - rat 1	0	-0.2024226	0.21523927	false
training	oneLayer	oneLayer - rat 1	0	-0.2124845	0.21940704	false
training	oneLayer	oneLayer - rat 1	0	-0.22261955	0.22360511	false
training	oneLayer	oneLayer - rat 1	0	-0.23264416	0.22775745	false
training	oneLayer	oneLayer - rat 1	0	-0.24002536	0.23513865	false
training	oneLayer	oneLayer - rat 1	0	-0.24756435	0.24267763	false
training	oneLayer	oneLayer - rat 1	0	-0.2550424	0.2501557	false
training	oneLayer	oneLayer - rat 1	0	-0.26253688	0.25765017	false
training	oneLayer	oneLayer - rat 1	0	-0.26989546	0.26500875	false
training	oneLayer	oneLayer - rat 1	0	-0.27760932	0.2727226	false
training	oneLayer	oneLayer - rat 1	0	-0.28514355	0.28025684	false
training	oneLayer	oneLayer - rat 1	0	-0.29266202	0.28777534	false
training	oneLayer	oneLayer - rat 1	0	-0.30197197	0.29163164	false
training	oneLayer	oneLayer - rat 1	0	-0.31268454	0.29163164	false
training	oneLayer	oneLayer - rat 1	0	-0.3227987	0.2874422	false
training	oneLayer	oneLayer - rat 1	0	-0.32988545	0.28035545	false
training	oneLayer	oneLayer - rat 1	0	-0.3337365	0.2710582	false
training	oneLayer	oneLayer - rat 1	0	-0.3337365	0.26017794	false
training	oneLayer	oneLayer - rat 1	0	-0.32963002	0.25026393	false
training	oneLayer	oneLayer - rat 1	0	-0.3221151	0.24274902	false
training	oneLayer	oneLayer - rat 1	0	-0.31265983	0.23883252	false
training	oneLayer	oneLayer - rat 1	0	-0.30298832	0.23482645	false
training	oneLayer	oneLayer - rat 1	0	-0.29295677	0.23067124	false
training	oneLayer	oneLayer - rat 1	0	-0.2828062	0.22646673	false
training	oneLayer	oneLayer - rat 1	0	-0.27267224	0.22226912	false
training	oneLayer	oneLayer - rat 1	0	-0.26292098	0.21823001	false
training	oneLayer	oneLayer - rat 1	0	-0.25316396	0.21418852	false
training	oneLayer	oneLayer - rat 1	0	-0.24338472	0.21013783	false
training	oneLayer	oneLayer - rat 1	0	-0.23323901	0.20593533	false
training	oneLayer	oneLayer - rat 1	0	-0.22345567	0.20188294	false
training	oneLayer	oneLayer - rat 1	0	-0.21343009	0.19773021	false
training	oneLayer	oneLayer - rat 1	0	-0.2036067	0.19366123	false
training	oneLayer	oneLayer - rat 1	0	-0.19392805	0.1896522	false
training	oneLayer	oneLayer - rat 1	0	-0.18386771	0.18548506	false
training	oneLayer	oneLayer - rat 1	0	-0.17382072	0.18132347	false
training	oneLayer	oneLayer - rat 1	0	-0.164505	0.17746478	false
training	oneLayer	oneLayer - rat 1	0	-0.15492448	0.1734964	false
training	oneLayer	oneLayer - rat 1	0	-0.14544527	0.16956998	false
training	oneLayer	oneLayer - rat 1	0	-0.13572681	0.16554447	false
training	oneLayer	oneLayer - rat 1	0	-0.12559828	0.16134909	false
training	oneLayer	oneLayer - rat 1	0	-0.116138145	0.15743057	false
training	oneLayer	oneLayer - rat 1	0	-0.10674198	0.15353855	false
training	oneLayer	oneLayer - rat 1	0	-0.09708262	0.14953752	false
training	oneLayer	oneLayer - rat 1	0	-0.08752672	0.14557932	false
training	oneLayer	oneLayer - rat 1	0	-0.07784058	0.1415672	false
training	oneLayer	oneLayer - rat 1	0	-0.06811815	0.13754003	false
training	oneLayer	oneLayer - rat 1	0	-0.058365107	0.13350019	false
training	oneLayer	oneLayer - rat 1	0	-0.04869429	0.12949441	false
training	oneLayer	oneLayer - rat 1	0	-0.038694724	0.12535246	false
training	oneLayer	oneLayer - rat 1	0	-0.029144239	0.12139651	false
training	oneLayer	oneLayer - rat 1	0	-0.0196947	0.11748239	false
training	oneLayer	oneLayer - rat 1	0	-0.009768911	0.113370985	false
training	oneLayer	oneLayer - rat 1	0	-1.3705745E-4	0.10938134	false
training	oneLayer	oneLayer - rat 1	0	0.009270943	0.10548442	false
training	oneLayer	oneLayer - rat 1	0	0.019357331	0.101306506	false
training	oneLayer	oneLayer - rat 1	0	0.029044915	0.09729377	false
training	oneLayer	oneLayer - rat 1	0	0.038521875	0.093368284	false
training	oneLayer	oneLayer - rat 1	0	0.048356935	0.08929447	false
training	oneLayer	oneLayer - rat 1	0	0.058266126	0.08518995	false
training	oneLayer	oneLayer - rat 1	0	0.06760445	0.08132189	false
training	oneLayer	oneLayer - rat 1	0	0.077757716	0.07711627	false
training	oneLayer	oneLayer - rat 1	0	0.087178916	0.07321388	false
training	oneLayer	oneLayer - rat 1	0	0.09697884	0.06915462	false
training	oneLayer	oneLayer - rat 1	0	0.106928654	0.06503327	false
training	oneLayer	oneLayer - rat 1	0	0.116305456	0.061149273	false
training	oneLayer	oneLayer - rat 1	0	0.12602144	0.057124775	false
training	oneLayer	oneLayer - rat 1	0	0.13593484	0.053018514	false
training	oneLayer	oneLayer - rat 1	0	0.1457695	0.04894486	false
training	oneLayer	oneLayer - rat 1	0	0.15561166	0.044868108	false
training	oneLayer	oneLayer - rat 1	0	0.16531047	0.040850732	false
training	oneLayer	oneLayer - rat 1	0	0.17500311	0.03683591	false
training	oneLayer	oneLayer - rat 1	0	0.18500975	0.032691024	false
training	oneLayer	oneLayer - rat 1	0	0.1943119	0.028837945	false
training	oneLayer	oneLayer - rat 1	0	0.20441669	0.024652401	false
training	oneLayer	oneLayer - rat 1	0	0.21405162	0.020661484	false
training	oneLayer	oneLayer - rat 1	0	0.22396949	0.016553365	false
training	oneLayer	oneLayer - rat 1	0	0.2339476	0.012420296	false
training	oneLayer	oneLayer - rat 1	0	0.24406222	0.008230687	false
training	oneLayer	oneLayer - rat 1	0	0.25398698	0.004119714	false
training	oneLayer	oneLayer - rat 1	0	0.2634262	2.0985684E-4	false
training	oneLayer	oneLayer - rat 1	0	0.27324462	-0.0038570582	false
training	oneLayer	oneLayer - rat 1	0	0.28356892	-0.0038570582	false
training	oneLayer	oneLayer - rat 1	0	0.2941955	-0.0038570582	false
training	oneLayer	oneLayer - rat 1	0	0.3050438	-0.0038570582	false
training	oneLayer	oneLayer - rat 1	0	0.31571588	-0.0038570582	false
training	oneLayer	oneLayer - rat 1	0	0.325826	-0.0038570582	false
training	oneLayer	oneLayer - rat 1	0	0.33636808	-0.0038570582	false
training	oneLayer	oneLayer - rat 1	0	0.34733188	-0.0038570582	false
training	oneLayer	oneLayer - rat 1	0	0.35749054	-0.0038570582	false
training	oneLayer	oneLayer - rat 1	0	0.36765337	-0.0038570582	false
training	oneLayer	oneLayer - rat 1	0	0.37848255	-0.0038570582	false
training	oneLayer	oneLayer - rat 1	0	0.38909936	-0.0038570582	false
training	oneLayer	oneLayer - rat 1	0	0.39978328	-0.0038570582	false
training	oneLayer	oneLayer - rat 1	0	0.40982115	-0.0038570582	false
training	oneLayer	oneLayer - rat 1	0	0.4194968	1.5072481E-4	false
training	oneLayer	oneLayer - rat 1	0	0.427048	0.007701917	false
training	oneLayer	oneLayer - rat 1	0	0.43093398	0.017083514	false
training	oneLayer	oneLayer - rat 1	0	0.43093398	0.027935598	false
training	oneLayer	oneLayer - rat 1	0	0.4270019	0.03742852	false
training	oneLayer	oneLayer - rat 1	0	0.41930512	0.0451253	false
training	oneLayer	oneLayer - rat 1	0	0.40958998	0.04914944	false
training	oneLayer	oneLayer - rat 1	0	0.398761	0.04914944	false
training	oneLayer	oneLayer - rat 1	0	0.38857958	0.04914944	false
training	oneLayer	oneLayer - rat 1	0	0.37793797	0.049149435	false
training	oneLayer	oneLayer - rat 1	0	0.3673375	0.049149435	false
training	oneLayer	oneLayer - rat 1	0	0.35639256	0.049149435	false
training	oneLayer	oneLayer - rat 1	0	0.34563643	0.049149435	false
training	oneLayer	oneLayer - rat 1	0	0.3354359	0.04914943	false
training	oneLayer	oneLayer - rat 1	0	0.32509595	0.04914943	false
training	oneLayer	oneLayer - rat 1	0	0.31414342	0.04914943	false
training	oneLayer	oneLayer - rat 1	0	0.30371904	0.04914943	false
training	oneLayer	oneLayer - rat 1	0	0.29355565	0.049149428	false
training	oneLayer	oneLayer - rat 1	0	0.28332314	0.049149428	false
training	oneLayer	oneLayer - rat 1	0	0.27317417	0.049149428	false
training	oneLayer	oneLayer - rat 1	0	0.26282686	0.049149428	false
training	oneLayer	oneLayer - rat 1	0	0.25238052	0.049149424	false
training	oneLayer	oneLayer - rat 1	0	0.24191599	0.049149424	false
training	oneLayer	oneLayer - rat 1	0	0.2315781	0.049149424	false
training	oneLayer	oneLayer - rat 1	0	0.22126831	0.049149424	false
training	oneLayer	oneLayer - rat 1	0	0.21057521	0.04914942	false
training	oneLayer	oneLayer - rat 1	0	0.20036232	0.04914942	false
training	oneLayer	oneLayer - rat 1	0	0.18982747	0.04914942	false
training	oneLayer	oneLayer - rat 1	0	0.1796765	0.04914942	false
training	oneLayer	oneLayer - rat 1	0	0.16905211	0.049149416	false
training	oneLayer	oneLayer - rat 1	0	0.15900047	0.049149416	false
training	oneLayer	oneLayer - rat 1	0	0.14866365	0.049149416	false
training	oneLayer	oneLayer - rat 1	0	0.1386122	0.049149416	false
training	oneLayer	oneLayer - rat 1	0	0.12791838	0.049149413	false
training	oneLayer	oneLayer - rat 1	0	0.11790921	0.049149413	false
training	oneLayer	oneLayer - rat 1	0	0.10782253	0.049149413	false
training	oneLayer	oneLayer - rat 1	0	0.09770294	0.049149413	false
training	oneLayer	oneLayer - rat 1	0	0.08694121	0.04914941	false
training	oneLayer	oneLayer - rat 1	0	0.075966395	0.04914941	false
training	oneLayer	oneLayer - rat 1	0	0.06525006	0.04914941	false
training	oneLayer	oneLayer - rat 1	0	0.054441877	0.04914941	false
training	oneLayer	oneLayer - rat 1	0	0.044026095	0.049149405	false
training	oneLayer	oneLayer - rat 1	0	0.033936635	0.049149405	false
training	oneLayer	oneLayer - rat 1	0	0.022998562	0.049149405	false
training	oneLayer	oneLayer - rat 1	0	0.012893195	0.049149405	false
training	oneLayer	oneLayer - rat 1	0	0.0019883306	0.0491494	false
training	oneLayer	oneLayer - rat 1	0	-0.008162965	0.0491494	false
training	oneLayer	oneLayer - rat 1	0	-0.018331654	0.0491494	false
training	oneLayer	oneLayer - rat 1	0	-0.028918488	0.0491494	false
training	oneLayer	oneLayer - rat 1	0	-0.039719388	0.0491494	false
training	oneLayer	oneLayer - rat 1	0	-0.05022943	0.049149398	false
training	oneLayer	oneLayer - rat 1	0	-0.060290948	0.049149398	false
training	oneLayer	oneLayer - rat 1	0	-0.07104058	0.049149398	false
training	oneLayer	oneLayer - rat 1	0	-0.08132953	0.049149398	false
training	oneLayer	oneLayer - rat 1	0	-0.092030816	0.049149394	false
training	oneLayer	oneLayer - rat 1	0	-0.10222257	0.049149394	false
training	oneLayer	oneLayer - rat 1	0	-0.112837404	0.049149394	false
training	oneLayer	oneLayer - rat 1	0	-0.12341909	0.049149394	false
training	oneLayer	oneLayer - rat 1	0	-0.1336605	0.04914939	false
training	oneLayer	oneLayer - rat 1	0	-0.1438077	0.04914939	false
training	oneLayer	oneLayer - rat 1	0	-0.15391298	0.04914939	false
training	oneLayer	oneLayer - rat 1	0	-0.16467498	0.04914939	false
training	oneLayer	oneLayer - rat 1	0	-0.17487475	0.049149387	false
training	oneLayer	oneLayer - rat 1	0	-0.18585859	0.049149387	false
training	oneLayer	oneLayer - rat 1	0	-0.19658925	0.049149387	false
training	oneLayer	oneLayer - rat 1	0	-0.20721129	0.049149387	false
training	oneLayer	oneLayer - rat 1	0	-0.21727763	0.049149383	false
training	oneLayer	oneLayer - rat 1	0	-0.22792827	0.049149383	false
training	oneLayer	oneLayer - rat 1	0	-0.23868516	0.049149383	false
training	oneLayer	oneLayer - rat 1	0	-0.24872123	0.049149383	false
training	oneLayer	oneLayer - rat 1	0	-0.25968042	0.04914938	false
training	oneLayer	oneLayer - rat 1	0	-0.27012947	0.04914938	false
training	oneLayer	oneLayer - rat 1	0	-0.28074846	0.04914938	false
training	oneLayer	oneLayer - rat 1	0	-0.2912623	0.04914938	false
training	oneLayer	oneLayer - rat 1	0	-0.30142626	0.049149375	false
training	oneLayer	oneLayer - rat 1	0	-0.3118444	0.049149375	false
training	oneLayer	oneLayer - rat 1	0	-0.32269657	0.049149375	false
training	oneLayer	oneLayer - rat 1	0	-0.33307496	0.049149375	false
training	oneLayer	oneLayer - rat 1	0	-0.3432261	0.04494463	false
training	oneLayer	oneLayer - rat 1	0	-0.35326368	0.040786922	false
training	oneLayer	oneLayer - rat 1	0	-0.36261857	0.03691201	false
training	oneLayer	oneLayer - rat 1	0	-0.37258545	0.032783587	false
training	oneLayer	oneLayer - rat 1	0	-0.38254005	0.028660253	false
training	oneLayer	oneLayer - rat 1	0	-0.39195156	0.024761874	false
training	oneLayer	oneLayer - rat 1	0	-0.40153235	0.020793376	false
training	oneLayer	oneLayer - rat 1	0	-0.41134652	0.016728213	false
training	oneLayer	oneLayer - rat 1	0	-0.41875786	0.009316893	false
training	oneLayer	oneLayer - rat 1	0	-0.42647728	0.0015974545	false
training	oneLayer	oneLayer - rat 1	0	-0.4306854	-0.008561795	false
training	oneLayer	oneLayer - rat 1	0	-0.43453747	-0.017861528	false
training	oneLayer	oneLayer - rat 1	0	-0.43837655	-0.027129922	false
training	oneLayer	oneLayer - rat 1	0	-0.44231328	-0.036634013	false
training	oneLayer	oneLayer - rat 1	0	-0.44650918	-0.04676385	false
training	oneLayer	oneLayer - rat 1	0	-0.44650918	-0.057164952	false
training	oneLayer	oneLayer - rat 1	0	-0.44244283	-0.06698198	false
training	oneLayer	oneLayer - rat 1	0	-0.43501157	-0.07441324	false
training	oneLayer	oneLayer - rat 1	0	-0.42544734	-0.07837487	false
training	oneLayer	oneLayer - rat 1	0	-0.41521618	-0.07837487	false
training	oneLayer	oneLayer - rat 1	0	-0.40521684	-0.074232996	false
training	oneLayer	oneLayer - rat 1	0	-0.39751628	-0.066532455	false
training	oneLayer	oneLayer - rat 1	0	-0.3935515	-0.056960624	false
training	oneLayer	oneLayer - rat 1	0	-0.38962573	-0.047482952	false
training	oneLayer	oneLayer - rat 1	0	-0.38563305	-0.037843753	false
training	oneLayer	oneLayer - rat 1	0	-0.38176998	-0.028517472	false
training	oneLayer	oneLayer - rat 1	0	-0.37768215	-0.018648582	false
training	oneLayer	oneLayer - rat 1	0	-0.37368914	-0.009008644	false
training	oneLayer	oneLayer - rat 1	0	-0.36961094	8.37062E-4	false
training	oneLayer	oneLayer - rat 1	0	-0.36549783	0.010767008	false
training	oneLayer	oneLayer - rat 1	0	-0.36136284	0.020749759	false
training	oneLayer	oneLayer - rat 1	0	-0.35727972	0.030607294	false
training	oneLayer	oneLayer - rat 1	0	-0.3531429	0.040594485	false
training	oneLayer	oneLayer - rat 1	0	-0.34907243	0.050421458	false
training	oneLayer	oneLayer - rat 1	0	-0.3448975	0.060500614	false
training	oneLayer	oneLayer - rat 1	0	-0.34105062	0.069787815	false
training	oneLayer	oneLayer - rat 1	0	-0.33701885	0.07952138	false
training	oneLayer	oneLayer - rat 1	0	-0.33292565	0.08940323	false
training	oneLayer	oneLayer - rat 1	0	-0.3290042	0.09887049	false
training	oneLayer	oneLayer - rat 1	0	-0.32480827	0.109000325	false
training	oneLayer	oneLayer - rat 1	0	-0.32074213	0.11881688	false
training	oneLayer	oneLayer - rat 1	0	-0.31680146	0.12833047	false
training	oneLayer	oneLayer - rat 1	0	-0.31680146	0.13925804	false
training	oneLayer	oneLayer - rat 1	0	-0.3168015	0.14943495	false
training	oneLayer	oneLayer - rat 1	0	-0.3168015	0.1595785	false
training	oneLayer	oneLayer - rat 1	0	-0.3168015	0.17043833	false
training	oneLayer	oneLayer - rat 1	0	-0.3168015	0.181304	false
training	oneLayer	oneLayer - rat 1	0	-0.3168015	0.19149865	false
training	oneLayer	oneLayer - rat 1	0	-0.3168015	0.20204791	false
training	oneLayer	oneLayer - rat 1	0	-0.3168015	0.2128991	false
training	oneLayer	oneLayer - rat 1	0	-0.3168015	0.22344963	false
training	oneLayer	oneLayer - rat 1	0	-0.3168015	0.23392288	false
training	oneLayer	oneLayer - rat 1	0	-0.3168015	0.2444664	false
training	oneLayer	oneLayer - rat 1	0	-0.3168015	0.25496042	false
training	oneLayer	oneLayer - rat 1	0	-0.3168015	0.26555404	false
training	oneLayer	oneLayer - rat 1	0	-0.3168015	0.275696	false
training	oneLayer	oneLayer - rat 1	0	-0.31680152	0.28661668	false
training	oneLayer	oneLayer - rat 1	0	-0.31680152	0.29707134	false
training	oneLayer	oneLayer - rat 1	0	-0.3129578	0.30635092	false
training	oneLayer	oneLayer - rat 1	0	-0.30882165	0.3163364	false
training	oneLayer	oneLayer - rat 1	0	-0.30494547	0.32569435	false
training	oneLayer	oneLayer - rat 1	0	-0.30102333	0.33516324	false
training	oneLayer	oneLayer - rat 1	0	-0.29390556	0.342281	false
training	oneLayer	oneLayer - rat 1	0	-0.28382096	0.3464582	false
training	oneLayer	oneLayer - rat 1	0	-0.27381998	0.3464582	false
training	oneLayer	oneLayer - rat 1	0	-0.26445872	0.34258062	false
training	oneLayer	oneLayer - rat 1	0	-0.25707665	0.33519855	false
training	oneLayer	oneLayer - rat 1	0	-0.25311634	0.32563755	false
training	oneLayer	oneLayer - rat 1	0	-0.25311634	0.31501225	false
training	oneLayer	oneLayer - rat 1	0	-0.2569657	0.30571905	false
training	oneLayer	oneLayer - rat 1	0	-0.26094428	0.29611394	false
training	oneLayer	oneLayer - rat 1	0	-0.26514557	0.2859711	false
training	oneLayer	oneLayer - rat 1	0	-0.26908857	0.27645186	false
training	oneLayer	oneLayer - rat 1	0	-0.27299568	0.26701924	false
training	oneLayer	oneLayer - rat 1	0	-0.27711007	0.25708628	false
training	oneLayer	oneLayer - rat 1	0	-0.281018	0.24765167	false
training	oneLayer	oneLayer - rat 1	0	-0.2848892	0.23830578	false
training	oneLayer	oneLayer - rat 1	0	-0.28901288	0.2283503	false
training	oneLayer	oneLayer - rat 1	0	-0.29296568	0.21880737	false
training	oneLayer	oneLayer - rat 1	0	-0.29709738	0.20883258	false
training	oneLayer	oneLayer - rat 1	0	-0.3011072	0.19915202	false
training	oneLayer	oneLayer - rat 1	0	-0.3051638	0.18935849	false
training	oneLayer	oneLayer - rat 1	0	-0.30929354	0.17938846	false
training	oneLayer	oneLayer - rat 1	0	-0.31338406	0.16951303	false
training	oneLayer	oneLayer - rat 1	0	-0.3174839	0.15961513	false
training	oneLayer	oneLayer - rat 1	0	-0.32140532	0.15014797	false
training	oneLayer	oneLayer - rat 1	0	-0.32533655	0.14065716	false
training	oneLayer	oneLayer - rat 1	0	-0.3292961	0.13109796	false
training	oneLayer	oneLayer - rat 1	0	-0.3332153	0.121636234	false
training	oneLayer	oneLayer - rat 1	0	-0.3371863	0.112049356	false
training	oneLayer	oneLayer - rat 1	0	-0.34474707	0.1044886	false
training	oneLayer	oneLayer - rat 1	0	-0.35207778	0.097157866	false
training	oneLayer	oneLayer - rat 1	0	-0.3592809	0.089954734	false
training	oneLayer	oneLayer - rat 1	0	-0.36689043	0.0823452	false
training	oneLayer	oneLayer - rat 1	0	-0.37416127	0.07507436	false
training	oneLayer	oneLayer - rat 1	0	-0.38133678	0.06789888	false
training	oneLayer	oneLayer - rat 1	0	-0.3886698	0.06056585	false
training	oneLayer	oneLayer - rat 1	0	-0.3957878	0.053447817	false
training	oneLayer	oneLayer - rat 1	0	-0.40286967	0.046365958	false
training	oneLayer	oneLayer - rat 1	0	-0.4104937	0.038741928	false
training	oneLayer	oneLayer - rat 1	0	-0.41810292	0.031132724	false
training	oneLayer	oneLayer - rat 1	0	-0.42532697	0.02390865	false
training	oneLayer	oneLayer - rat 1	0	-0.4327994	0.016436223	false
training	oneLayer	oneLayer - rat 1	0	-0.4369786	0.0063466965	false
training	oneLayer	oneLayer - rat 1	0	-0.44109663	-0.003595053	false
training	oneLayer	oneLayer - rat 1	0	-0.44500938	-0.013041266	false
training	oneLayer	oneLayer - rat 1	0	-0.4491324	-0.022995174	false
training	oneLayer	oneLayer - rat 1	0	-0.4491324	-0.03378307	false
training	oneLayer	oneLayer - rat 1	0	-0.44521305	-0.04324524	false
training	oneLayer	oneLayer - rat 1	0	-0.43791154	-0.05054676	false
training	oneLayer	oneLayer - rat 1	0	-0.42825183	-0.054547936	false
training	oneLayer	oneLayer - rat 1	0	-0.41807505	-0.054547932	false
training	oneLayer	oneLayer - rat 1	0	-0.40862554	-0.050633825	false
training	oneLayer	oneLayer - rat 1	0	-0.40145203	-0.043460302	false
training	oneLayer	oneLayer - rat 1	0	-0.3972444	-0.03330218	false
training	oneLayer	oneLayer - rat 1	0	-0.39325568	-0.023672536	false
training	oneLayer	oneLayer - rat 1	0	-0.3893623	-0.014273068	false
training	oneLayer	oneLayer - rat 1	0	-0.38539898	-0.004704787	false
training	oneLayer	oneLayer - rat 1	0	-0.38135552	0.005057024	false
training	oneLayer	oneLayer - rat 1	0	-0.37733993	0.01475152	false
training	oneLayer	oneLayer - rat 1	0	-0.3731382	0.024895402	false
training	oneLayer	oneLayer - rat 1	0	-0.36930552	0.034148313	false
training	oneLayer	oneLayer - rat 1	0	-0.3654638	0.04342303	false
training	oneLayer	oneLayer - rat 1	0	-0.3613117	0.053447083	false
training	oneLayer	oneLayer - rat 1	0	-0.3574032	0.06288305	false
training	oneLayer	oneLayer - rat 1	0	-0.35326922	0.07286334	false
training	oneLayer	oneLayer - rat 1	0	-0.34934425	0.082339056	false
training	oneLayer	oneLayer - rat 1	0	-0.34518614	0.09237768	false
training	oneLayer	oneLayer - rat 1	0	-0.34135526	0.10162621	false
training	oneLayer	oneLayer - rat 1	0	-0.33734912	0.11129789	false
training	oneLayer	oneLayer - rat 1	0	-0.33338553	0.120866865	false
training	oneLayer	oneLayer - rat 1	0	-0.32947943	0.13029708	false
training	oneLayer	oneLayer - rat 1	0	-0.32563055	0.13958904	false
training	oneLayer	oneLayer - rat 1	0	-0.3217535	0.1489491	false
training	oneLayer	oneLayer - rat 1	0	-0.31785914	0.15835093	false
training	oneLayer	oneLayer - rat 1	0	-0.31785914	0.16912018	false
training	oneLayer	oneLayer - rat 1	0	-0.31785914	0.17991453	false
training	oneLayer	oneLayer - rat 1	0	-0.31785914	0.19003323	false
training	oneLayer	oneLayer - rat 1	0	-0.31785914	0.20005782	false
training	oneLayer	oneLayer - rat 1	0	-0.31785914	0.21091242	false
training	oneLayer	oneLayer - rat 1	0	-0.31785914	0.22136055	false
training	oneLayer	oneLayer - rat 1	0	-0.31785914	0.23170094	false
training	oneLayer	oneLayer - rat 1	0	-0.31785914	0.2424942	false
training	oneLayer	oneLayer - rat 1	0	-0.31785914	0.25306258	false
training	oneLayer	oneLayer - rat 1	0	-0.31785917	0.26406068	false
training	oneLayer	oneLayer - rat 1	0	-0.31785917	0.27426878	false
training	oneLayer	oneLayer - rat 1	0	-0.31373355	0.28422886	false
training	oneLayer	oneLayer - rat 1	0	-0.30602428	0.29193816	false
training	oneLayer	oneLayer - rat 1	0	-0.29595357	0.2961096	false
training	oneLayer	oneLayer - rat 1	0	-0.28538832	0.2961096	false
training	oneLayer	oneLayer - rat 1	0	-0.2744469	0.2961096	false
training	oneLayer	oneLayer - rat 1	0	-0.26413864	0.2961096	false
training	oneLayer	oneLayer - rat 1	0	-0.2539986	0.29190946	false
training	oneLayer	oneLayer - rat 1	0	-0.24466825	0.2880447	false
training	oneLayer	oneLayer - rat 1	0	-0.23476726	0.28394356	false
training	oneLayer	oneLayer - rat 1	0	-0.22507593	0.27992928	false
training	oneLayer	oneLayer - rat 1	0	-0.21567343	0.27603465	false
training	oneLayer	oneLayer - rat 1	0	-0.20580404	0.2719466	false
training	oneLayer	oneLayer - rat 1	0	-0.19601533	0.267892	false
training	oneLayer	oneLayer - rat 1	0	-0.1866265	0.264003	false
training	oneLayer	oneLayer - rat 1	0	-0.17704263	0.26003325	false
training	oneLayer	oneLayer - rat 1	0	-0.16734037	0.25601444	false
training	oneLayer	oneLayer - rat 1	0	-0.15754473	0.25195697	false
training	oneLayer	oneLayer - rat 1	0	-0.14772478	0.24788941	false
training	oneLayer	oneLayer - rat 1	0	-0.13784753	0.24379812	false
training	oneLayer	oneLayer - rat 1	0	-0.12776199	0.23962055	false
training	oneLayer	oneLayer - rat 1	0	-0.117820516	0.23550266	false
training	oneLayer	oneLayer - rat 1	0	-0.10802331	0.23144452	false
training	oneLayer	oneLayer - rat 1	0	-0.098714046	0.2275885	false
training	oneLayer	oneLayer - rat 1	0	-0.0885835	0.2233923	false
training	oneLayer	oneLayer - rat 1	0	-0.07858448	0.21925057	false
training	oneLayer	oneLayer - rat 1	0	-0.06842538	0.21504253	false
training	oneLayer	oneLayer - rat 1	0	-0.0586359	0.2109876	false
training	oneLayer	oneLayer - rat 1	0	-0.049374234	0.2071513	false
training	oneLayer	oneLayer - rat 1	0	-0.039836917	0.20320082	false
training	oneLayer	oneLayer - rat 1	0	-0.03036612	0.19927788	false
training	oneLayer	oneLayer - rat 1	0	-0.020881986	0.19534943	false
training	oneLayer	oneLayer - rat 1	0	-0.010962778	0.19124076	false
training	oneLayer	oneLayer - rat 1	0	-0.0014397202	0.18729618	false
training	oneLayer	oneLayer - rat 1	0	0.008377871	0.18322961	false
training	oneLayer	oneLayer - rat 1	0	0.018449577	0.17905776	false
training	oneLayer	oneLayer - rat 1	0	0.027881365	0.17515099	false
training	oneLayer	oneLayer - rat 1	0	0.037191246	0.17129472	false
training	oneLayer	oneLayer - rat 1	0	0.04686997	0.16728567	false
training	oneLayer	oneLayer - rat 1	0	0.056758665	0.16318963	false
training	oneLayer	oneLayer - rat 1	0	0.06682624	0.1590195	false
training	oneLayer	oneLayer - rat 1	0	0.07682602	0.15487747	false
training	oneLayer	oneLayer - rat 1	0	0.08659148	0.15083247	false
training	oneLayer	oneLayer - rat 1	0	0.09661236	0.1466817	false
training	oneLayer	oneLayer - rat 1	0	0.10600388	0.1427916	false
training	oneLayer	oneLayer - rat 1	0	0.115334146	0.13892688	false
training	oneLayer	oneLayer - rat 1	0	0.12484176	0.13498871	false
training	oneLayer	oneLayer - rat 1	0	0.13482334	0.1308542	false
training	oneLayer	oneLayer - rat 1	0	0.1441644	0.12698501	false
training	oneLayer	oneLayer - rat 1	0	0.15348057	0.12312612	false
training	oneLayer	oneLayer - rat 1	0	0.16346258	0.11899145	false
training	oneLayer	oneLayer - rat 1	0	0.17273368	0.11515123	false
training	oneLayer	oneLayer - rat 1	0	0.18215908	0.1112471	false
training	oneLayer	oneLayer - rat 1	0	0.19209622	0.107131004	false
training	oneLayer	oneLayer - rat 1	0	0.20202963	0.10301645	false
training	oneLayer	oneLayer - rat 1	0	0.21137741	0.09914447	false
training	oneLayer	oneLayer - rat 1	0	0.22122416	0.095065825	false
training	oneLayer	oneLayer - rat 1	0	0.23126431	0.09090706	false
training	oneLayer	oneLayer - rat 1	0	0.24142319	0.08669912	false
training	oneLayer	oneLayer - rat 1	0	0.2508543	0.082792625	false
training	oneLayer	oneLayer - rat 1	0	0.26050645	0.078794576	false
training	oneLayer	oneLayer - rat 1	0	0.2698532	0.07492302	false
training	oneLayer	oneLayer - rat 1	0	0.27982283	0.07079348	false
training	oneLayer	oneLayer - rat 1	0	0.2892493	0.0668889	false
training	oneLayer	oneLayer - rat 1	0	0.29934442	0.06270737	false
training	oneLayer	oneLayer - rat 1	0	0.30911022	0.05866224	false
training	oneLayer	oneLayer - rat 1	0	0.3183641	0.054829158	false
training	oneLayer	oneLayer - rat 1	0	0.32786816	0.050892446	false
training	oneLayer	oneLayer - rat 1	0	0.33758333	0.046868294	false
training	oneLayer	oneLayer - rat 1	0	0.3469903	0.04297181	false
training	oneLayer	oneLayer - rat 1	0	0.3562792	0.039124224	false
training	oneLayer	oneLayer - rat 1	0	0.36632505	0.034963094	false
training	oneLayer	oneLayer - rat 1	0	0.37605256	0.030933833	false
training	oneLayer	oneLayer - rat 1	0	0.3856965	0.026939187	false
training	oneLayer	oneLayer - rat 1	0	0.39521772	0.022995364	false
training	oneLayer	oneLayer - rat 1	0	0.40522778	0.018849066	false
training	oneLayer	oneLayer - rat 1	0	0.41262257	0.011454264	false
training	oneLayer	oneLayer - rat 1	0	0.41664803	0.0017359785	false
training	oneLayer	oneLayer - rat 1	0	0.41664803	-0.008701145	false
training	oneLayer	oneLayer - rat 1	0	0.4127745	-0.018052641	false
training	oneLayer	oneLayer - rat 1	0	0.40505803	-0.025769144	false
training	oneLayer	oneLayer - rat 1	0	0.39541644	-0.029762821	false
training	oneLayer	oneLayer - rat 1	0	0.38528845	-0.029762821	false
training	oneLayer	oneLayer - rat 1	0	0.3751715	-0.029762823	false
training	oneLayer	oneLayer - rat 1	0	0.36453336	-0.029762823	false
training	oneLayer	oneLayer - rat 1	0	0.3540847	-0.029762825	false
training	oneLayer	oneLayer - rat 1	0	0.3434199	-0.029762825	false
training	oneLayer	oneLayer - rat 1	0	0.33337656	-0.029762827	false
training	oneLayer	oneLayer - rat 1	0	0.32255074	-0.029762827	false
training	oneLayer	oneLayer - rat 1	0	0.31183714	-0.029762829	false
training	oneLayer	oneLayer - rat 1	0	0.30179438	-0.029762829	false
training	oneLayer	oneLayer - rat 1	0	0.29163763	-0.02976283	false
training	oneLayer	oneLayer - rat 1	0	0.2809947	-0.02976283	false
training	oneLayer	oneLayer - rat 1	0	0.27074984	-0.029762832	false
training	oneLayer	oneLayer - rat 1	0	0.26072806	-0.029762832	false
training	oneLayer	oneLayer - rat 1	0	0.24991202	-0.029762834	false
training	oneLayer	oneLayer - rat 1	0	0.23905684	-0.029762834	false
training	oneLayer	oneLayer - rat 1	0	0.22864944	-0.029762836	false
training	oneLayer	oneLayer - rat 1	0	0.21821164	-0.029762836	false
training	oneLayer	oneLayer - rat 1	0	0.20819382	-0.029762838	false
training	oneLayer	oneLayer - rat 1	0	0.19810207	-0.029762838	false
training	oneLayer	oneLayer - rat 1	0	0.1878451	-0.02976284	false
training	oneLayer	oneLayer - rat 1	0	0.17715696	-0.02976284	false
training	oneLayer	oneLayer - rat 1	0	0.16696091	-0.029762842	false
training	oneLayer	oneLayer - rat 1	0	0.1561204	-0.029762842	false
training	oneLayer	oneLayer - rat 1	0	0.14567779	-0.029762844	false
training	oneLayer	oneLayer - rat 1	0	0.13515408	-0.029762844	false
training	oneLayer	oneLayer - rat 1	0	0.12424782	-0.029762845	false
training	oneLayer	oneLayer - rat 1	0	0.113667354	-0.029762845	false
training	oneLayer	oneLayer - rat 1	0	0.10309686	-0.029762847	false
training	oneLayer	oneLayer - rat 1	0	0.09217206	-0.029762847	false
training	oneLayer	oneLayer - rat 1	0	0.081682034	-0.02976285	false
training	oneLayer	oneLayer - rat 1	0	0.07071318	-0.02976285	false
training	oneLayer	oneLayer - rat 1	0	0.060359884	-0.029762851	false
training	oneLayer	oneLayer - rat 1	0	0.049660817	-0.029762851	false
training	oneLayer	oneLayer - rat 1	0	0.03886393	-0.029762853	false
training	oneLayer	oneLayer - rat 1	0	0.027879324	-0.029762853	false
training	oneLayer	oneLayer - rat 1	0	0.017656963	-0.029762855	false
training	oneLayer	oneLayer - rat 1	0	0.0068989038	-0.029762855	false
training	oneLayer	oneLayer - rat 1	0	-0.0039312528	-0.029762857	false
training	oneLayer	oneLayer - rat 1	0	-0.014707829	-0.029762857	false
training	oneLayer	oneLayer - rat 1	0	-0.025616905	-0.029762859	false
training	oneLayer	oneLayer - rat 1	0	-0.03589846	-0.029762859	false
training	oneLayer	oneLayer - rat 1	0	-0.046834737	-0.02976286	false
training	oneLayer	oneLayer - rat 1	0	-0.057376016	-0.02976286	false
training	oneLayer	oneLayer - rat 1	0	-0.06825875	-0.029762862	false
training	oneLayer	oneLayer - rat 1	0	-0.07836004	-0.029762862	false
training	oneLayer	oneLayer - rat 1	0	-0.08879492	-0.029762864	false
training	oneLayer	oneLayer - rat 1	0	-0.09974244	-0.029762864	false
training	oneLayer	oneLayer - rat 1	0	-0.11023665	-0.029762866	false
training	oneLayer	oneLayer - rat 1	0	-0.12085039	-0.029762866	false
training	oneLayer	oneLayer - rat 1	0	-0.13101013	-0.029762868	false
training	oneLayer	oneLayer - rat 1	0	-0.14114241	-0.029762868	false
training	oneLayer	oneLayer - rat 1	0	-0.15192416	-0.02976287	false
training	oneLayer	oneLayer - rat 1	0	-0.16265796	-0.02976287	false
training	oneLayer	oneLayer - rat 1	0	-0.17364246	-0.029762872	false
training	oneLayer	oneLayer - rat 1	0	-0.18421751	-0.029762872	false
training	oneLayer	oneLayer - rat 1	0	-0.1945526	-0.029762873	false
training	oneLayer	oneLayer - rat 1	0	-0.20498359	-0.029762873	false
training	oneLayer	oneLayer - rat 1	0	-0.21590512	-0.029762875	false
training	oneLayer	oneLayer - rat 1	0	-0.22651695	-0.029762875	false
training	oneLayer	oneLayer - rat 1	0	-0.23749076	-0.029762877	false
training	oneLayer	oneLayer - rat 1	0	-0.24808331	-0.029762877	false
training	oneLayer	oneLayer - rat 1	0	-0.25828347	-0.029762879	false
training	oneLayer	oneLayer - rat 1	0	-0.26878366	-0.029762879	false
training	oneLayer	oneLayer - rat 1	0	-0.27960864	-0.02976288	false
training	oneLayer	oneLayer - rat 1	0	-0.29002467	-0.02976288	false
training	oneLayer	oneLayer - rat 1	0	-0.30060774	-0.029762883	false
training	oneLayer	oneLayer - rat 1	0	-0.3106731	-0.029762883	false
training	oneLayer	oneLayer - rat 1	0	-0.32090482	-0.029762885	false
training	oneLayer	oneLayer - rat 1	0	-0.3310976	-0.029762885	false
training	oneLayer	oneLayer - rat 1	0	-0.3419554	-0.029762886	false
training	oneLayer	oneLayer - rat 1	0	-0.35262477	-0.029762886	false
training	oneLayer	oneLayer - rat 1	0	-0.36296657	-0.029762886	false
training	oneLayer	oneLayer - rat 1	0	-0.37388295	-0.029762888	false
training	oneLayer	oneLayer - rat 1	0	-0.38395903	-0.029762888	false
training	oneLayer	oneLayer - rat 1	0	-0.39373764	-0.025712447	false
training	oneLayer	oneLayer - rat 1	0	-0.40381643	-0.021537686	false
training	oneLayer	oneLayer - rat 1	0	-0.41340032	-0.017567908	false
training	oneLayer	oneLayer - rat 1	0	-0.42101434	-0.009953897	false
training	oneLayer	oneLayer - rat 1	0	-0.42519188	1.3160528E-4	false
training	oneLayer	oneLayer - rat 1	0	-0.42519188	0.010866896	false
training	oneLayer	oneLayer - rat 1	0	-0.42519188	0.021766428	false
training	oneLayer	oneLayer - rat 1	0	-0.42519188	0.03246425	false
training	oneLayer	oneLayer - rat 1	0	-0.42519188	0.043016866	false
training	oneLayer	oneLayer - rat 1	0	-0.42519188	0.053641815	false
training	oneLayer	oneLayer - rat 1	0	-0.42519188	0.06447755	false
training	oneLayer	oneLayer - rat 1	0	-0.42519188	0.07503083	false
training	oneLayer	oneLayer - rat 1	0	-0.4209857	0.08518549	false
training	oneLayer	oneLayer - rat 1	0	-0.4168429	0.09518703	false
training	oneLayer	oneLayer - rat 1	0	-0.41269803	0.10519364	false
training	oneLayer	oneLayer - rat 1	0	-0.40873227	0.11476787	false
training	oneLayer	oneLayer - rat 1	0	-0.40468684	0.12453438	false
training	oneLayer	oneLayer - rat 1	0	-0.40078464	0.13395517	false
training	oneLayer	oneLayer - rat 1	0	-0.39687476	0.14339446	false
training	oneLayer	oneLayer - rat 1	0	-0.39267084	0.1535436	false
training	oneLayer	oneLayer - rat 1	0	-0.38860893	0.16334988	false
training	oneLayer	oneLayer - rat 1	0	-0.38457087	0.17309867	false
training	oneLayer	oneLayer - rat 1	0	-0.3804603	0.18302245	false
training	oneLayer	oneLayer - rat 1	0	-0.37625638	0.1931716	false
training	oneLayer	oneLayer - rat 1	0	-0.37218884	0.2029915	false
training	oneLayer	oneLayer - rat 1	0	-0.36803785	0.2130129	false
training	oneLayer	oneLayer - rat 1	0	-0.36416736	0.22235705	false
training	oneLayer	oneLayer - rat 1	0	-0.3602744	0.23175552	false
training	oneLayer	oneLayer - rat 1	0	-0.35611764	0.24179085	false
training	oneLayer	oneLayer - rat 1	0	-0.35200682	0.25171524	false
training	oneLayer	oneLayer - rat 1	0	-0.34802994	0.26131624	false
training	oneLayer	oneLayer - rat 1	0	-0.34406424	0.27089036	false
training	oneLayer	oneLayer - rat 1	0	-0.340181	0.2802653	false
training	oneLayer	oneLayer - rat 1	0	-0.33251587	0.28793043	false
training	oneLayer	oneLayer - rat 1	0	-0.32245058	0.29209962	false
training	oneLayer	oneLayer - rat 1	0	-0.31181058	0.29209962	false
training	oneLayer	oneLayer - rat 1	0	-0.30224863	0.28813893	false
training	oneLayer	oneLayer - rat 1	0	-0.29473948	0.28062978	false
training	oneLayer	oneLayer - rat 1	0	-0.29063162	0.27071252	false
training	oneLayer	oneLayer - rat 1	0	-0.29063162	0.26050037	false
training	oneLayer	oneLayer - rat 1	0	-0.29482824	0.2503689	false
training	oneLayer	oneLayer - rat 1	0	-0.29875922	0.24087866	false
training	oneLayer	oneLayer - rat 1	0	-0.30260348	0.2315978	false
training	oneLayer	oneLayer - rat 1	0	-0.30664223	0.22184734	false
training	oneLayer	oneLayer - rat 1	0	-0.31080058	0.21180822	false
training	oneLayer	oneLayer - rat 1	0	-0.31495938	0.20176798	false
training	oneLayer	oneLayer - rat 1	0	-0.318867	0.1923342	false
training	oneLayer	oneLayer - rat 1	0	-0.32287842	0.18264975	false
training	oneLayer	oneLayer - rat 1	0	-0.327008	0.17268007	false
training	oneLayer	oneLayer - rat 1	0	-0.33107427	0.16286322	false
training	oneLayer	oneLayer - rat 1	0	-0.33491567	0.15358925	false
training	oneLayer	oneLayer - rat 1	0	-0.33893692	0.14388107	false
training	oneLayer	oneLayer - rat 1	0	-0.34304953	0.13395242	false
training	oneLayer	oneLayer - rat 1	0	-0.34687805	0.1247095	false
training	oneLayer	oneLayer - rat 1	0	-0.3510849	0.11455335	false
training	oneLayer	oneLayer - rat 1	0	-0.35492393	0.105285056	false
training	oneLayer	oneLayer - rat 1	0	-0.3588646	0.09577145	false
training	oneLayer	oneLayer - rat 1	0	-0.36271694	0.086471066	false
training	oneLayer	oneLayer - rat 1	0	-0.37020943	0.0789786	false
training	oneLayer	oneLayer - rat 1	0	-0.37740517	0.07178284	false
training	oneLayer	oneLayer - rat 1	0	-0.38473147	0.06445655	false
training	oneLayer	oneLayer - rat 1	0	-0.39197215	0.057215862	false
training	oneLayer	oneLayer - rat 1	0	-0.3996987	0.04948931	false
training	oneLayer	oneLayer - rat 1	0	-0.40698966	0.042198345	false
training	oneLayer	oneLayer - rat 1	0	-0.41427395	0.03491406	false
training	oneLayer	oneLayer - rat 1	0	-0.42172185	0.027466167	false
training	oneLayer	oneLayer - rat 1	0	-0.4288092	0.020378835	false
training	oneLayer	oneLayer - rat 1	0	-0.43267763	0.011039577	false
training	oneLayer	oneLayer - rat 1	0	-0.43662813	0.0015022266	false
training	oneLayer	oneLayer - rat 1	0	-0.4407976	-0.008563766	false
training	oneLayer	oneLayer - rat 1	0	-0.4447288	-0.018054528	false
training	oneLayer	oneLayer - rat 1	0	-0.4485731	-0.027335495	false
training	oneLayer	oneLayer - rat 1	0	-0.4485731	-0.03798849	false
training	oneLayer	oneLayer - rat 1	0	-0.44455227	-0.047695644	false
training	oneLayer	oneLayer - rat 1	0	-0.43706495	-0.055182975	false
training	oneLayer	oneLayer - rat 1	0	-0.4274113	-0.059181646	false
training	oneLayer	oneLayer - rat 1	0	-0.41728702	-0.059181646	false
training	oneLayer	oneLayer - rat 1	0	-0.4074304	-0.055098895	false
training	oneLayer	oneLayer - rat 1	0	-0.40018332	-0.04785183	false
training	oneLayer	oneLayer - rat 1	0	-0.39609775	-0.037988387	false
training	oneLayer	oneLayer - rat 1	0	-0.3919251	-0.027914705	false
training	oneLayer	oneLayer - rat 1	0	-0.3880016	-0.018442526	false
training	oneLayer	oneLayer - rat 1	0	-0.38380206	-0.008303953	false
training	oneLayer	oneLayer - rat 1	0	-0.37971476	0.001563708	false
training	oneLayer	oneLayer - rat 1	0	-0.3758731	0.010838278	false
training	oneLayer	oneLayer - rat 1	0	-0.37199587	0.020198744	false
training	oneLayer	oneLayer - rat 1	0	-0.36780506	0.030316243	false
training	oneLayer	oneLayer - rat 1	0	-0.3636038	0.04045895	false
training	oneLayer	oneLayer - rat 1	0	-0.3595504	0.050244756	false
training	oneLayer	oneLayer - rat 1	0	-0.35564852	0.059664756	false
training	oneLayer	oneLayer - rat 1	0	-0.3516095	0.069415815	false
training	oneLayer	oneLayer - rat 1	0	-0.34749684	0.07934465	false
training	oneLayer	oneLayer - rat 1	0	-0.34361044	0.088727206	false
training	oneLayer	oneLayer - rat 1	0	-0.3396755	0.09822707	false
training	oneLayer	oneLayer - rat 1	0	-0.3356566	0.10792946	false
training	oneLayer	oneLayer - rat 1	0	-0.33181345	0.1172077	false
training	oneLayer	oneLayer - rat 1	0	-0.3279452	0.12654643	false
training	oneLayer	oneLayer - rat 1	0	-0.3239335	0.13623153	false
training	oneLayer	oneLayer - rat 1	0	-0.32001173	0.14569952	false
training	oneLayer	oneLayer - rat 1	0	-0.31594482	0.15551795	false
training	oneLayer	oneLayer - rat 1	0	-0.31594482	0.1655986	false
training	oneLayer	oneLayer - rat 1	0	-0.31594482	0.17599137	false
training	oneLayer	oneLayer - rat 1	0	-0.31594482	0.18688636	false
training	oneLayer	oneLayer - rat 1	0	-0.31594482	0.19772789	false
training	oneLayer	oneLayer - rat 1	0	-0.31594482	0.20805724	false
training	oneLayer	oneLayer - rat 1	0	-0.31594482	0.21890748	false
training	oneLayer	oneLayer - rat 1	0	-0.31594482	0.22941792	false
training	oneLayer	oneLayer - rat 1	0	-0.31594482	0.23982382	false
training	oneLayer	oneLayer - rat 1	0	-0.31594482	0.25073355	false
training	oneLayer	oneLayer - rat 1	0	-0.31594482	0.2612381	false
training	oneLayer	oneLayer - rat 1	0	-0.31594482	0.27138206	false
training	oneLayer	oneLayer - rat 1	0	-0.31594482	0.28232732	false
training	oneLayer	oneLayer - rat 1	0	-0.31594482	0.29277965	false
training	oneLayer	oneLayer - rat 1	0	-0.31201524	0.3022665	false
training	oneLayer	oneLayer - rat 1	0	-0.30817392	0.3115403	false
training	oneLayer	oneLayer - rat 1	0	-0.30401677	0.32157654	false
training	oneLayer	oneLayer - rat 1	0	-0.29984492	0.33164823	false
training	oneLayer	oneLayer - rat 1	0	-0.29570177	0.34165066	false
training	oneLayer	oneLayer - rat 1	0	-0.2885227	0.34882975	false
training	oneLayer	oneLayer - rat 1	0	-0.27896386	0.35278913	false
training	oneLayer	oneLayer - rat 1	0	-0.26804164	0.35278913	false
training	oneLayer	oneLayer - rat 1	0	-0.2582145	0.3487186	false
training	oneLayer	oneLayer - rat 1	0	-0.25097054	0.34147465	false
training	oneLayer	oneLayer - rat 1	0	-0.247077	0.3320748	false
training	oneLayer	oneLayer - rat 1	0	-0.247077	0.3219774	false
training	oneLayer	oneLayer - rat 1	0	-0.2511887	0.31205088	false
training	oneLayer	oneLayer - rat 1	0	-0.255365	0.30196837	false
training	oneLayer	oneLayer - rat 1	0	-0.2592619	0.29256043	false
training	oneLayer	oneLayer - rat 1	0	-0.26314333	0.28318986	false
training	oneLayer	oneLayer - rat 1	0	-0.2671242	0.2735792	false
training	oneLayer	oneLayer - rat 1	0	-0.27117455	0.2638008	false
training	oneLayer	oneLayer - rat 1	0	-0.2750874	0.2543544	false
training	oneLayer	oneLayer - rat 1	0	-0.27924618	0.24431416	false
training	oneLayer	oneLayer - rat 1	0	-0.2833424	0.234425	false
training	oneLayer	oneLayer - rat 1	0	-0.28752142	0.22433595	false
training	oneLayer	oneLayer - rat 1	0	-0.29155883	0.2145888	false
training	oneLayer	oneLayer - rat 1	0	-0.29554376	0.20496829	false
training	oneLayer	oneLayer - rat 1	0	-0.29938886	0.19568543	false
training	oneLayer	oneLayer - rat 1	0	-0.30335733	0.18610469	false
training	oneLayer	oneLayer - rat 1	0	-0.3075629	0.17595154	false
training	oneLayer	oneLayer - rat 1	0	-0.31144807	0.16657193	false
training	oneLayer	oneLayer - rat 1	0	-0.31543508	0.15694639	false
training	oneLayer	oneLayer - rat 1	0	-0.31962502	0.14683104	false
training	oneLayer	oneLayer - rat 1	0	-0.3235743	0.13729663	false
training	oneLayer	oneLayer - rat 1	0	-0.3275601	0.12767403	false
training	oneLayer	oneLayer - rat 1	0	-0.33165097	0.11779782	false
training	oneLayer	oneLayer - rat 1	0	-0.33933622	0.110112585	false
training	oneLayer	oneLayer - rat 1	0	-0.34643307	0.10301571	false
training	oneLayer	oneLayer - rat 1	0	-0.3539303	0.09551849	false
training	oneLayer	oneLayer - rat 1	0	-0.36110893	0.08833986	false
training	oneLayer	oneLayer - rat 1	0	-0.36887676	0.08057204	false
training	oneLayer	oneLayer - rat 1	0	-0.37620926	0.07323955	false
training	oneLayer	oneLayer - rat 1	0	-0.38355607	0.06589273	false
training	oneLayer	oneLayer - rat 1	0	-0.39078686	0.058661923	false
training	oneLayer	oneLayer - rat 1	0	-0.39845753	0.050991282	false
training	oneLayer	oneLayer - rat 1	0	-0.406152	0.0432968	false
training	oneLayer	oneLayer - rat 1	0	-0.41365775	0.035791032	false
training	oneLayer	oneLayer - rat 1	0	-0.42096522	0.028483575	false
training	oneLayer	oneLayer - rat 1	0	-0.4250513	0.01861888	false
training	oneLayer	oneLayer - rat 1	0	-0.4250513	0.00808949	false
training	oneLayer	oneLayer - rat 1	0	-0.4209411	-0.001833407	false
training	oneLayer	oneLayer - rat 1	0	-0.41386175	-0.008912764	false
training	oneLayer	oneLayer - rat 1	0	-0.4039419	-0.013021704	false
training	oneLayer	oneLayer - rat 1	0	-0.39343858	-0.013021704	false
training	oneLayer	oneLayer - rat 1	0	-0.38328132	-0.013021704	false
training	oneLayer	oneLayer - rat 1	0	-0.37320012	-0.013021704	false
training	oneLayer	oneLayer - rat 1	0	-0.36271927	-0.013021704	false
training	oneLayer	oneLayer - rat 1	0	-0.35263386	-0.013021704	false
training	oneLayer	oneLayer - rat 1	0	-0.34226176	-0.013021704	false
training	oneLayer	oneLayer - rat 1	0	-0.33179924	-0.013021704	false
training	oneLayer	oneLayer - rat 1	0	-0.32153383	-0.013021704	false
training	oneLayer	oneLayer - rat 1	0	-0.31059554	-0.013021704	false
training	oneLayer	oneLayer - rat 1	0	-0.30026785	-0.013021704	false
training	oneLayer	oneLayer - rat 1	0	-0.28989205	-0.013021704	false
training	oneLayer	oneLayer - rat 1	0	-0.279287	-0.013021704	false
training	oneLayer	oneLayer - rat 1	0	-0.26892596	-0.013021704	false
training	oneLayer	oneLayer - rat 1	0	-0.25827777	-0.013021704	false
training	oneLayer	oneLayer - rat 1	0	-0.24774086	-0.013021704	false
training	oneLayer	oneLayer - rat 1	0	-0.23690902	-0.013021704	false
training	oneLayer	oneLayer - rat 1	0	-0.22611521	-0.013021704	false
training	oneLayer	oneLayer - rat 1	0	-0.21569464	-0.013021704	false
training	oneLayer	oneLayer - rat 1	0	-0.20565364	-0.013021704	false
training	oneLayer	oneLayer - rat 1	0	-0.1947775	-0.013021704	false
training	oneLayer	oneLayer - rat 1	0	-0.1844742	-0.013021704	false
training	oneLayer	oneLayer - rat 1	0	-0.17383519	-0.013021704	false
training	oneLayer	oneLayer - rat 1	0	-0.16363342	-0.013021704	false
training	oneLayer	oneLayer - rat 1	0	-0.15363275	-0.013021704	false
training	oneLayer	oneLayer - rat 1	0	-0.143494	-0.013021704	false
training	oneLayer	oneLayer - rat 1	0	-0.13308828	-0.013021704	false
training	oneLayer	oneLayer - rat 1	0	-0.1224979	-0.013021704	false
training	oneLayer	oneLayer - rat 1	0	-0.11232212	-0.013021704	false
training	oneLayer	oneLayer - rat 1	0	-0.10179762	-0.013021704	false
training	oneLayer	oneLayer - rat 1	0	-0.091095775	-0.013021704	false
training	oneLayer	oneLayer - rat 1	0	-0.08090644	-0.013021704	false
training	oneLayer	oneLayer - rat 1	0	-0.070362955	-0.013021704	false
training	oneLayer	oneLayer - rat 1	0	-0.059651792	-0.013021704	false
training	oneLayer	oneLayer - rat 1	0	-0.04917735	-0.013021704	false
training	oneLayer	oneLayer - rat 1	0	-0.0386923	-0.013021704	false
training	oneLayer	oneLayer - rat 1	0	-0.028355274	-0.013021704	false
training	oneLayer	oneLayer - rat 1	0	-0.017999865	-0.013021704	false
training	oneLayer	oneLayer - rat 1	0	-0.007824173	-0.013021704	false
training	oneLayer	oneLayer - rat 1	0	0.0028942027	-0.013021704	false
training	oneLayer	oneLayer - rat 1	0	0.013494525	-0.013021704	false
training	oneLayer	oneLayer - rat 1	0	0.024400752	-0.013021704	false
training	oneLayer	oneLayer - rat 1	0	0.03503266	-0.013021704	false
training	oneLayer	oneLayer - rat 1	0	0.045652848	-0.013021704	false
training	oneLayer	oneLayer - rat 1	0	0.056067094	-0.013021704	false
training	oneLayer	oneLayer - rat 1	0	0.06683043	-0.013021704	false
training	oneLayer	oneLayer - rat 1	0	0.07727585	-0.013021704	false
training	oneLayer	oneLayer - rat 1	0	0.0879501	-0.013021704	false
training	oneLayer	oneLayer - rat 1	0	0.09891173	-0.013021704	false
training	oneLayer	oneLayer - rat 1	0	0.10972976	-0.013021704	false
training	oneLayer	oneLayer - rat 1	0	0.11989668	-0.013021704	false
training	oneLayer	oneLayer - rat 1	0	0.12997662	-0.013021704	false
training	oneLayer	oneLayer - rat 1	0	0.14026275	-0.013021704	false
training	oneLayer	oneLayer - rat 1	0	0.15111478	-0.013021704	false
training	oneLayer	oneLayer - rat 1	0	0.16186939	-0.013021704	false
training	oneLayer	oneLayer - rat 1	0	0.17223734	-0.013021704	false
training	oneLayer	oneLayer - rat 1	0	0.18224373	-0.013021704	false
training	oneLayer	oneLayer - rat 1	0	0.19267495	-0.013021704	false
training	oneLayer	oneLayer - rat 1	0	0.20323457	-0.013021704	false
training	oneLayer	oneLayer - rat 1	0	0.21353504	-0.013021704	false
training	oneLayer	oneLayer - rat 1	0	0.22426678	-0.013021704	false
training	oneLayer	oneLayer - rat 1	0	0.2345765	-0.013021704	false
training	oneLayer	oneLayer - rat 1	0	0.24496269	-0.013021704	false
training	oneLayer	oneLayer - rat 1	0	0.25545207	-0.013021704	false
training	oneLayer	oneLayer - rat 1	0	0.26588327	-0.013021704	false
training	oneLayer	oneLayer - rat 1	0	0.27666894	-0.013021704	false
training	oneLayer	oneLayer - rat 1	0	0.2868714	-0.013021704	false
training	oneLayer	oneLayer - rat 1	0	0.29747704	-0.013021704	false
training	oneLayer	oneLayer - rat 1	0	0.3083463	-0.013021704	false
training	oneLayer	oneLayer - rat 1	0	0.31839973	-0.013021704	false
training	oneLayer	oneLayer - rat 1	0	0.3289565	-0.013021704	false
training	oneLayer	oneLayer - rat 1	0	0.33908057	-0.013021704	false
training	oneLayer	oneLayer - rat 1	0	0.34974593	-0.013021704	false
training	oneLayer	oneLayer - rat 1	0	0.35976774	-0.013021704	false
training	oneLayer	oneLayer - rat 1	0	0.3702359	-0.013021704	false
training	oneLayer	oneLayer - rat 1	0	0.38069472	-0.013021704	false
training	oneLayer	oneLayer - rat 1	0	0.39087373	-0.013021704	false
training	oneLayer	oneLayer - rat 1	0	0.40136302	-0.013021704	false
training	oneLayer	oneLayer - rat 1	0	0.4111009	-0.017055267	false
training	oneLayer	oneLayer - rat 1	0	0.4184635	-0.024417872	false
training	oneLayer	oneLayer - rat 1	0	0.4223528	-0.033807434	false
training	oneLayer	oneLayer - rat 1	0	0.4223528	-0.0446527	false
training	oneLayer	oneLayer - rat 1	0	0.41829044	-0.05446005	false
training	oneLayer	oneLayer - rat 1	0	0.41069928	-0.062051214	false
training	oneLayer	oneLayer - rat 1	0	0.4013332	-0.06593076	false
training	oneLayer	oneLayer - rat 1	0	0.39094073	-0.06593076	false
training	oneLayer	oneLayer - rat 1	0	0.3814119	-0.061983794	false
training	oneLayer	oneLayer - rat 1	0	0.3720613	-0.05811065	false
training	oneLayer	oneLayer - rat 1	0	0.36193997	-0.053918254	false
training	oneLayer	oneLayer - rat 1	0	0.35180756	-0.049721267	false
training	oneLayer	oneLayer - rat 1	0	0.3417635	-0.045560878	false
training	oneLayer	oneLayer - rat 1	0	0.33215952	-0.041582778	false
training	oneLayer	oneLayer - rat 1	0	0.3226097	-0.03762712	false
training	oneLayer	oneLayer - rat 1	0	0.313054	-0.03366901	false
training	oneLayer	oneLayer - rat 1	0	0.30353945	-0.029727956	false
training	oneLayer	oneLayer - rat 1	0	0.29428256	-0.02589362	false
training	oneLayer	oneLayer - rat 1	0	0.28452274	-0.021850977	false
training	oneLayer	oneLayer - rat 1	0	0.2747098	-0.017786315	false
training	oneLayer	oneLayer - rat 1	0	0.2648578	-0.013705484	false
training	oneLayer	oneLayer - rat 1	0	0.25530186	-0.009747287	false
training	oneLayer	oneLayer - rat 1	0	0.24603297	-0.0059079877	false
training	oneLayer	oneLayer - rat 1	0	0.2365672	-0.001987135	false
training	oneLayer	oneLayer - rat 1	0	0.22671843	0.002092364	false
training	oneLayer	oneLayer - rat 1	0	0.21712439	0.0060663447	false
training	oneLayer	oneLayer - rat 1	0	0.20751433	0.01004696	false
training	oneLayer	oneLayer - rat 1	0	0.19750153	0.014194398	false
training	oneLayer	oneLayer - rat 1	0	0.18762757	0.018284328	false
training	oneLayer	oneLayer - rat 1	0	0.17787161	0.022325382	false
training	oneLayer	oneLayer - rat 1	0	0.16782327	0.026487539	false
training	oneLayer	oneLayer - rat 1	0	0.15852228	0.03034014	false
training	oneLayer	oneLayer - rat 1	0	0.14905135	0.034263127	false
training	oneLayer	oneLayer - rat 1	0	0.1396689	0.038149465	false
training	oneLayer	oneLayer - rat 1	0	0.13024908	0.04205128	false
training	oneLayer	oneLayer - rat 1	0	0.120572336	0.046059523	false
training	oneLayer	oneLayer - rat 1	0	0.110520616	0.050223082	false
training	oneLayer	oneLayer - rat 1	0	0.1010769	0.0541348	false
training	oneLayer	oneLayer - rat 1	0	0.091251336	0.058204684	false
training	oneLayer	oneLayer - rat 1	0	0.081448525	0.062265143	false
training	oneLayer	oneLayer - rat 1	0	0.071842365	0.06624414	false
training	oneLayer	oneLayer - rat 1	0	0.06208746	0.07028476	false
training	oneLayer	oneLayer - rat 1	0	0.052239165	0.07436406	false
training	oneLayer	oneLayer - rat 1	0	0.042889148	0.07823696	false
training	oneLayer	oneLayer - rat 1	0	0.033057407	0.0823094	false
training	oneLayer	oneLayer - rat 1	0	0.023053344	0.08645322	false
training	oneLayer	oneLayer - rat 1	0	0.013065588	0.09059029	false
training	oneLayer	oneLayer - rat 1	0	0.0036968593	0.09447095	false
training	oneLayer	oneLayer - rat 1	0	-0.0061636665	0.09855531	false
training	oneLayer	oneLayer - rat 1	0	-0.016287558	0.10274877	false
training	oneLayer	oneLayer - rat 1	0	-0.026376568	0.10692777	false
training	oneLayer	oneLayer - rat 1	0	-0.036261115	0.111022085	false
training	oneLayer	oneLayer - rat 1	0	-0.04558477	0.11488407	false
training	oneLayer	oneLayer - rat 1	0	-0.055600382	0.11903267	false
training	oneLayer	oneLayer - rat 1	0	-0.06536147	0.12307585	false
training	oneLayer	oneLayer - rat 1	0	-0.07470318	0.12694532	false
training	oneLayer	oneLayer - rat 1	0	-0.08417885	0.13087027	false
training	oneLayer	oneLayer - rat 1	0	-0.09343982	0.13470629	false
training	oneLayer	oneLayer - rat 1	0	-0.102738924	0.1385581	false
training	oneLayer	oneLayer - rat 1	0	-0.11203685	0.14240943	false
training	oneLayer	oneLayer - rat 1	0	-0.12168145	0.14640436	false
training	oneLayer	oneLayer - rat 1	0	-0.1313163	0.15039524	false
training	oneLayer	oneLayer - rat 1	0	-0.14064258	0.15425833	false
training	oneLayer	oneLayer - rat 1	0	-0.14993186	0.15810606	false
training	oneLayer	oneLayer - rat 1	0	-0.15930627	0.16198908	false
training	oneLayer	oneLayer - rat 1	0	-0.16868581	0.1658742	false
training	oneLayer	oneLayer - rat 1	0	-0.17605475	0.17324315	false
training	oneLayer	oneLayer - rat 1	0	-0.18382952	0.18101792	false
training	oneLayer	oneLayer - rat 1	0	-0.1909373	0.18812568	false
training	oneLayer	oneLayer - rat 1	0	-0.19816162	0.19535002	false
training	oneLayer	oneLayer - rat 1	0	-0.20551395	0.20270236	false
training	oneLayer	oneLayer - rat 1	0	-0.21325867	0.21044707	false
training	oneLayer	oneLayer - rat 1	0	-0.22079057	0.21797897	false
training	oneLayer	oneLayer - rat 1	0	-0.2284308	0.22561921	false
training	oneLayer	oneLayer - rat 1	0	-0.23562966	0.23281807	false
training	oneLayer	oneLayer - rat 1	0	-0.24329522	0.24048364	false
training	oneLayer	oneLayer - rat 1	0	-0.2506176	0.24780603	false
training	oneLayer	oneLayer - rat 1	0	-0.2579096	0.25509802	false
training	oneLayer	oneLayer - rat 1	0	-0.26498398	0.2621724	false
training	oneLayer	oneLayer - rat 1	0	-0.2725074	0.26969582	false
training	oneLayer	oneLayer - rat 1	0	-0.28010654	0.27729496	false
training	oneLayer	oneLayer - rat 1	0	-0.2876016	0.28479004	false
training	oneLayer	oneLayer - rat 1	0	-0.2914929	0.2941845	false
training	oneLayer	oneLayer - rat 1	0	-0.2914929	0.3045693	false
training	oneLayer	oneLayer - rat 1	0	-0.28736663	0.314531	false
training	oneLayer	oneLayer - rat 1	0	-0.27962452	0.3222731	false
training	oneLayer	oneLayer - rat 1	0	-0.26955968	0.32644212	false
training	oneLayer	oneLayer - rat 1	0	-0.25899708	0.32644212	false
training	oneLayer	oneLayer - rat 1	0	-0.24971096	0.3225957	false
training	oneLayer	oneLayer - rat 1	0	-0.24033128	0.31871048	false
training	oneLayer	oneLayer - rat 1	0	-0.23085864	0.3147868	false
training	oneLayer	oneLayer - rat 1	0	-0.22111696	0.31075165	false
training	oneLayer	oneLayer - rat 1	0	-0.21180363	0.30689394	false
training	oneLayer	oneLayer - rat 1	0	-0.20216975	0.30290344	false
training	oneLayer	oneLayer - rat 1	0	-0.19275853	0.2990052	false
training	oneLayer	oneLayer - rat 1	0	-0.18277045	0.294868	false
training	oneLayer	oneLayer - rat 1	0	-0.1734158	0.29099318	false
training	oneLayer	oneLayer - rat 1	0	-0.163967	0.28707933	false
training	oneLayer	oneLayer - rat 1	0	-0.1544576	0.28314042	false
training	oneLayer	oneLayer - rat 1	0	-0.14467588	0.2790887	false
training	oneLayer	oneLayer - rat 1	0	-0.13537358	0.27523556	false
training	oneLayer	oneLayer - rat 1	0	-0.12586881	0.27129856	false
training	oneLayer	oneLayer - rat 1	0	-0.11635863	0.26735932	false
training	oneLayer	oneLayer - rat 1	0	-0.10701366	0.2634885	false
training	oneLayer	oneLayer - rat 1	0	-0.097351015	0.25948608	false
training	oneLayer	oneLayer - rat 1	0	-0.087717436	0.25549573	false
training	oneLayer	oneLayer - rat 1	0	-0.07785578	0.2514109	false
training	oneLayer	oneLayer - rat 1	0	-0.067954965	0.24730985	false
training	oneLayer	oneLayer - rat 1	0	-0.058516864	0.24340045	false
training	oneLayer	oneLayer - rat 1	0	-0.048362825	0.23919451	false
training	oneLayer	oneLayer - rat 1	0	-0.038354218	0.2350488	false
training	oneLayer	oneLayer - rat 1	0	-0.02894132	0.23114985	false
training	oneLayer	oneLayer - rat 1	0	-0.018807605	0.22695233	false
training	oneLayer	oneLayer - rat 1	0	-0.009286991	0.22300875	false
training	oneLayer	oneLayer - rat 1	0	6.725724E-5	0.21913409	false
training	oneLayer	oneLayer - rat 1	0	0.009935469	0.21504655	false
training	oneLayer	oneLayer - rat 1	0	0.020087717	0.21084134	false
training	oneLayer	oneLayer - rat 1	0	0.02940928	0.20698023	false
training	oneLayer	oneLayer - rat 1	0	0.0388264	0.20307952	false
training	oneLayer	oneLayer - rat 1	0	0.048541605	0.19905536	false
training	oneLayer	oneLayer - rat 1	0	0.057834	0.19520631	false
training	oneLayer	oneLayer - rat 1	0	0.067956686	0.19101337	false
training	oneLayer	oneLayer - rat 1	0	0.07780069	0.18693584	false
training	oneLayer	oneLayer - rat 1	0	0.087634414	0.18286258	false
training	oneLayer	oneLayer - rat 1	0	0.09725935	0.17887579	false
training	oneLayer	oneLayer - rat 1	0	0.10727398	0.1747276	false
training	oneLayer	oneLayer - rat 1	0	0.11682883	0.17076986	false
training	oneLayer	oneLayer - rat 1	0	0.1264432	0.16678743	false
training	oneLayer	oneLayer - rat 1	0	0.13642564	0.16265258	false
training	oneLayer	oneLayer - rat 1	0	0.14586192	0.15874393	false
training	oneLayer	oneLayer - rat 1	0	0.15534915	0.1548142	false
training	oneLayer	oneLayer - rat 1	0	0.16491765	0.15085079	false
training	oneLayer	oneLayer - rat 1	0	0.1743149	0.14695832	false
training	oneLayer	oneLayer - rat 1	0	0.18415523	0.14288232	false
training	oneLayer	oneLayer - rat 1	0	0.19424462	0.13870315	false
training	oneLayer	oneLayer - rat 1	0	0.20430797	0.13453478	false
training	oneLayer	oneLayer - rat 1	0	0.21436365	0.13036957	false
training	oneLayer	oneLayer - rat 1	0	0.22384883	0.12644069	false
training	oneLayer	oneLayer - rat 1	0	0.23344372	0.122466356	false
training	oneLayer	oneLayer - rat 1	0	0.24331433	0.11837781	false
training	oneLayer	oneLayer - rat 1	0	0.25297016	0.11437823	false
training	oneLayer	oneLayer - rat 1	0	0.26225904	0.11053065	false
training	oneLayer	oneLayer - rat 1	0	0.2717478	0.10660028	false
training	oneLayer	oneLayer - rat 1	0	0.2811508	0.10270543	false
training	oneLayer	oneLayer - rat 1	0	0.29113874	0.098568276	false
training	oneLayer	oneLayer - rat 1	0	0.30095273	0.094503194	false
training	oneLayer	oneLayer - rat 1	0	0.31109315	0.090302885	false
training	oneLayer	oneLayer - rat 1	0	0.32112113	0.08614916	false
training	oneLayer	oneLayer - rat 1	0	0.33089662	0.08210002	false
training	oneLayer	oneLayer - rat 1	0	0.3405796	0.0780892	false
training	oneLayer	oneLayer - rat 1	0	0.35045937	0.07399686	false
training	oneLayer	oneLayer - rat 1	0	0.36052695	0.06982673	false
training	oneLayer	oneLayer - rat 1	0	0.36993128	0.06593132	false
training	oneLayer	oneLayer - rat 1	0	0.37986493	0.061816666	false
training	oneLayer	oneLayer - rat 1	0	0.38949835	0.057826377	false
training	oneLayer	oneLayer - rat 1	0	0.39922035	0.053799387	false
training	oneLayer	oneLayer - rat 1	0	0.4063682	0.046651535	false
training	oneLayer	oneLayer - rat 1	0	0.4136349	0.039384842	false
training	oneLayer	oneLayer - rat 1	0	0.42083701	0.032182716	false
training	oneLayer	oneLayer - rat 1	0	0.42500257	0.022126144	false
training	oneLayer	oneLayer - rat 1	0	0.42500257	0.011430537	false
training	oneLayer	oneLayer - rat 1	0	0.4208543	0.0014157319	false
training	oneLayer	oneLayer - rat 1	0	0.41322768	-0.0062108887	false
training	oneLayer	oneLayer - rat 1	0	0.40375462	-0.010134756	false
training	oneLayer	oneLayer - rat 1	0	0.39329803	-0.010134753	false
training	oneLayer	oneLayer - rat 1	0	0.38322988	-0.0059643905	false
training	oneLayer	oneLayer - rat 1	0	0.37351108	-0.0019387214	false
training	oneLayer	oneLayer - rat 1	0	0.36411718	0.0019523596	false
training	oneLayer	oneLayer - rat 1	0	0.35415915	0.0060771094	false
training	oneLayer	oneLayer - rat 1	0	0.34489936	0.009912648	false
training	oneLayer	oneLayer - rat 1	0	0.33546734	0.013819521	false
training	oneLayer	oneLayer - rat 1	0	0.32615387	0.017677283	false
training	oneLayer	oneLayer - rat 1	0	0.31637675	0.021727104	false
training	oneLayer	oneLayer - rat 1	0	0.30677384	0.02570476	false
training	oneLayer	oneLayer - rat 1	0	0.29753035	0.02953355	false
training	oneLayer	oneLayer - rat 1	0	0.28738573	0.033735592	false
training	oneLayer	oneLayer - rat 1	0	0.27769384	0.03775011	false
training	oneLayer	oneLayer - rat 1	0	0.26786977	0.041819375	false
training	oneLayer	oneLayer - rat 1	0	0.25846648	0.04571435	false
training	oneLayer	oneLayer - rat 1	0	0.24916464	0.049567297	false
training	oneLayer	oneLayer - rat 1	0	0.23963249	0.053515647	false
training	oneLayer	oneLayer - rat 1	0	0.22958142	0.057678938	false
training	oneLayer	oneLayer - rat 1	0	0.21988377	0.06169584	false
training	oneLayer	oneLayer - rat 1	0	0.2103301	0.0656531	false
training	oneLayer	oneLayer - rat 1	0	0.20099624	0.06951932	false
training	oneLayer	oneLayer - rat 1	0	0.19129196	0.07353897	false
training	oneLayer	oneLayer - rat 1	0	0.18168403	0.0775187	false
training	oneLayer	oneLayer - rat 1	0	0.1722542	0.08142467	false
training	oneLayer	oneLayer - rat 1	0	0.16274667	0.08536282	false
training	oneLayer	oneLayer - rat 1	0	0.15259597	0.08956738	false
training	oneLayer	oneLayer - rat 1	0	0.14251126	0.093744606	false
training	oneLayer	oneLayer - rat 1	0	0.13254766	0.09787166	false
training	oneLayer	oneLayer - rat 1	0	0.12295084	0.10184681	false
training	oneLayer	oneLayer - rat 1	0	0.113587335	0.105725296	false
training	oneLayer	oneLayer - rat 1	0	0.103854336	0.10975684	false
training	oneLayer	oneLayer - rat 1	0	0.093950145	0.113859296	false
training	oneLayer	oneLayer - rat 1	0	0.084526	0.1177629	false
training	oneLayer	oneLayer - rat 1	0	0.075042315	0.12169118	false
training	oneLayer	oneLayer - rat 1	0	0.065139495	0.12579307	false
training	oneLayer	oneLayer - rat 1	0	0.05542141	0.12981842	false
training	oneLayer	oneLayer - rat 1	0	0.045926902	0.13375118	false
training	oneLayer	oneLayer - rat 1	0	0.03603059	0.13785037	false
training	oneLayer	oneLayer - rat 1	0	0.02626532	0.1418953	false
training	oneLayer	oneLayer - rat 1	0	0.016282314	0.14603038	false
training	oneLayer	oneLayer - rat 1	0	0.00638126	0.15013154	false
training	oneLayer	oneLayer - rat 1	0	-0.0035157925	0.15423104	false
training	oneLayer	oneLayer - rat 1	0	-0.013113346	0.15820648	false
training	oneLayer	oneLayer - rat 1	0	-0.023091396	0.16233952	false
training	oneLayer	oneLayer - rat 1	0	-0.032898407	0.16640173	false
training	oneLayer	oneLayer - rat 1	0	-0.042718783	0.17046946	false
training	oneLayer	oneLayer - rat 1	0	-0.05253549	0.17453568	false
training	oneLayer	oneLayer - rat 1	0	-0.062143438	0.17851542	false
training	oneLayer	oneLayer - rat 1	0	-0.07139198	0.1823463	false
training	oneLayer	oneLayer - rat 1	0	-0.08069534	0.18619987	false
training	oneLayer	oneLayer - rat 1	0	-0.090488575	0.19025637	false
training	oneLayer	oneLayer - rat 1	0	-0.10010675	0.19424036	false
training	oneLayer	oneLayer - rat 1	0	-0.10967131	0.19820213	false
training	oneLayer	oneLayer - rat 1	0	-0.119674824	0.20234573	false
training	oneLayer	oneLayer - rat 1	0	-0.12982726	0.206551	false
training	oneLayer	oneLayer - rat 1	0	-0.13966711	0.21062681	false
training	oneLayer	oneLayer - rat 1	0	-0.14910297	0.21453527	false
training	oneLayer	oneLayer - rat 1	0	-0.1591428	0.21869391	false
training	oneLayer	oneLayer - rat 1	0	-0.16859765	0.22261024	false
training	oneLayer	oneLayer - rat 1	0	-0.1782408	0.22660457	false
training	oneLayer	oneLayer - rat 1	0	-0.18838668	0.23080713	false
training	oneLayer	oneLayer - rat 1	0	-0.19792376	0.23475753	false
training	oneLayer	oneLayer - rat 1	0	-0.20778185	0.23884088	false
training	oneLayer	oneLayer - rat 1	0	-0.21762674	0.24291876	false
training	oneLayer	oneLayer - rat 1	0	-0.22695182	0.24678135	false
training	oneLayer	oneLayer - rat 1	0	-0.23649792	0.25073546	false
training	oneLayer	oneLayer - rat 1	0	-0.24663928	0.25493616	false
training	oneLayer	oneLayer - rat 1	0	-0.2562378	0.258912	false
training	oneLayer	oneLayer - rat 1	0	-0.26583093	0.2628856	false
training	oneLayer	oneLayer - rat 1	0	-0.2734056	0.27046028	false
training	oneLayer	oneLayer - rat 1	0	-0.28053156	0.27758625	false
training	oneLayer	oneLayer - rat 1	0	-0.28817195	0.28522664	false
training	oneLayer	oneLayer - rat 1	0	-0.29759526	0.2891299	false
training	oneLayer	oneLayer - rat 1	0	-0.30770013	0.2891299	false
training	oneLayer	oneLayer - rat 1	0	-0.317044	0.28525954	false
training	oneLayer	oneLayer - rat 1	0	-0.3241804	0.27812314	false
training	oneLayer	oneLayer - rat 1	0	-0.33150685	0.2707967	false
training	oneLayer	oneLayer - rat 1	0	-0.33910027	0.26320326	false
training	oneLayer	oneLayer - rat 1	0	-0.34660044	0.25570312	false
training	oneLayer	oneLayer - rat 1	0	-0.35058483	0.24608393	false
training	oneLayer	oneLayer - rat 1	0	-0.35464585	0.2362798	false
training	oneLayer	oneLayer - rat 1	0	-0.3587407	0.22639397	false
training	oneLayer	oneLayer - rat 1	0	-0.3626194	0.21702991	false
training	oneLayer	oneLayer - rat 1	0	-0.36648268	0.20770319	false
training	oneLayer	oneLayer - rat 1	0	-0.3705923	0.19778168	false
training	oneLayer	oneLayer - rat 1	0	-0.37446436	0.18843368	false
training	oneLayer	oneLayer - rat 1	0	-0.37841803	0.17888871	false
training	oneLayer	oneLayer - rat 1	0	-0.3825393	0.16893904	false
training	oneLayer	oneLayer - rat 1	0	-0.38642457	0.1595592	false
training	oneLayer	oneLayer - rat 1	0	-0.39026147	0.15029609	false
training	oneLayer	oneLayer - rat 1	0	-0.39414993	0.14090857	false
training	oneLayer	oneLayer - rat 1	0	-0.39808995	0.13139655	false
training	oneLayer	oneLayer - rat 1	0	-0.40209395	0.12173	false
training	oneLayer	oneLayer - rat 1	0	-0.4060619	0.11215053	false
training	oneLayer	oneLayer - rat 1	0	-0.4102309	0.10208568	false
training	oneLayer	oneLayer - rat 1	0	-0.41443497	0.09193614	false
training	oneLayer	oneLayer - rat 1	0	-0.41826653	0.082685955	false
training	oneLayer	oneLayer - rat 1	0	-0.42214614	0.07331973	false
training	oneLayer	oneLayer - rat 1	0	-0.42628086	0.06333766	false
training	oneLayer	oneLayer - rat 1	0	-0.4304417	0.053292476	false
training	oneLayer	oneLayer - rat 1	0	-0.4342865	0.044010323	false
training	oneLayer	oneLayer - rat 1	0	-0.43820238	0.03455657	false
training	oneLayer	oneLayer - rat 1	0	-0.4421808	0.024951816	false
training	oneLayer	oneLayer - rat 1	0	-0.4462869	0.01503889	false
training	oneLayer	oneLayer - rat 1	0	-0.45020467	0.005580529	false
training	oneLayer	oneLayer - rat 1	0	-0.4541706	-0.0039941133	false
training	oneLayer	oneLayer - rat 1	0	-0.4541706	-0.014847596	false
training	oneLayer	oneLayer - rat 1	0	-0.45032853	-0.024123244	false
training	oneLayer	oneLayer - rat 1	0	-0.44264346	-0.031808294	false
training	oneLayer	oneLayer - rat 1	0	-0.43335995	-0.03565366	false
training	oneLayer	oneLayer - rat 1	0	-0.42251924	-0.035653662	false
training	oneLayer	oneLayer - rat 1	0	-0.41247803	-0.031494465	false
training	oneLayer	oneLayer - rat 1	0	-0.40477473	-0.023791157	false
training	oneLayer	oneLayer - rat 1	0	-0.4007987	-0.014192203	false
training	oneLayer	oneLayer - rat 1	0	-0.39678147	-0.00449373	false
training	oneLayer	oneLayer - rat 1	0	-0.39260074	0.005599428	false
training	oneLayer	oneLayer - rat 1	0	-0.38857162	0.015326611	false
training	oneLayer	oneLayer - rat 1	0	-0.38468227	0.024716316	false
training	oneLayer	oneLayer - rat 1	0	-0.38050056	0.034811877	false
training	oneLayer	oneLayer - rat 1	0	-0.3764838	0.0445092	false
training	oneLayer	oneLayer - rat 1	0	-0.37239778	0.0543737	false
training	oneLayer	oneLayer - rat 1	0	-0.3683	0.06426662	false
training	oneLayer	oneLayer - rat 1	0	-0.36437568	0.07374074	false
training	oneLayer	oneLayer - rat 1	0	-0.36022776	0.08375465	false
training	oneLayer	oneLayer - rat 1	0	-0.3562004	0.09347758	false
training	oneLayer	oneLayer - rat 1	0	-0.35207397	0.10343969	false
training	oneLayer	oneLayer - rat 1	0	-0.34804672	0.113162324	false
training	oneLayer	oneLayer - rat 1	0	-0.3441007	0.12268878	false
training	oneLayer	oneLayer - rat 1	0	-0.34025192	0.13198064	false
training	oneLayer	oneLayer - rat 1	0	-0.33634487	0.1414131	false
training	oneLayer	oneLayer - rat 1	0	-0.3324664	0.15077657	false
training	oneLayer	oneLayer - rat 1	0	-0.32858825	0.16013919	false
training	oneLayer	oneLayer - rat 1	0	-0.324381	0.17029639	false
training	oneLayer	oneLayer - rat 1	0	-0.32029828	0.18015295	false
training	oneLayer	oneLayer - rat 1	0	-0.3162365	0.18995894	false
training	oneLayer	oneLayer - rat 1	0	-0.3162365	0.20070164	false
training	oneLayer	oneLayer - rat 1	0	-0.3162365	0.21169558	false
training	oneLayer	oneLayer - rat 1	0	-0.3162365	0.22212765	false
training	oneLayer	oneLayer - rat 1	0	-0.3162365	0.23289628	false
training	oneLayer	oneLayer - rat 1	0	-0.3162365	0.24367115	false
training	oneLayer	oneLayer - rat 1	0	-0.3162365	0.2539262	false
training	oneLayer	oneLayer - rat 1	0	-0.3162365	0.2640148	false
training	oneLayer	oneLayer - rat 1	0	-0.3162365	0.27437347	false
training	oneLayer	oneLayer - rat 1	0	-0.3162365	0.28476927	false
training	oneLayer	oneLayer - rat 1	0	-0.3162365	0.2956002	false
training	oneLayer	oneLayer - rat 1	0	-0.3123442	0.30499706	false
training	oneLayer	oneLayer - rat 1	0	-0.30827448	0.3148222	false
training	oneLayer	oneLayer - rat 1	0	-0.30422693	0.32459384	false
training	oneLayer	oneLayer - rat 1	0	-0.30034804	0.33395833	false
training	oneLayer	oneLayer - rat 1	0	-0.29319233	0.341114	false
training	oneLayer	oneLayer - rat 1	0	-0.2831627	0.34526843	false
training	oneLayer	oneLayer - rat 1	0	-0.2730287	0.34526843	false
training	oneLayer	oneLayer - rat 1	0	-0.2632781	0.34122962	false
training	oneLayer	oneLayer - rat 1	0	-0.25564396	0.33359545	false
training	oneLayer	oneLayer - rat 1	0	-0.25153378	0.3236726	false
training	oneLayer	oneLayer - rat 1	0	-0.25153378	0.31329402	false
training	oneLayer	oneLayer - rat 1	0	-0.2556634	0.30332428	false
training	oneLayer	oneLayer - rat 1	0	-0.25979298	0.2933546	false
training	oneLayer	oneLayer - rat 1	0	-0.26372933	0.28385136	false
training	oneLayer	oneLayer - rat 1	0	-0.26779768	0.27402955	false
training	oneLayer	oneLayer - rat 1	0	-0.27178568	0.26440167	false
training	oneLayer	oneLayer - rat 1	0	-0.2758639	0.25455597	false
training	oneLayer	oneLayer - rat 1	0	-0.27992576	0.24474974	false
training	oneLayer	oneLayer - rat 1	0	-0.2840324	0.23483546	false
training	oneLayer	oneLayer - rat 1	0	-0.2881999	0.22477421	false
training	oneLayer	oneLayer - rat 1	0	-0.2922199	0.2150691	false
training	oneLayer	oneLayer - rat 1	0	-0.29608044	0.20574893	false
training	oneLayer	oneLayer - rat 1	0	-0.30019534	0.19581471	false
training	oneLayer	oneLayer - rat 1	0	-0.30417243	0.1862132	false
training	oneLayer	oneLayer - rat 1	0	-0.30801862	0.17692763	false
training	oneLayer	oneLayer - rat 1	0	-0.31196544	0.16739918	false
training	oneLayer	oneLayer - rat 1	0	-0.31604964	0.1575391	false
training	oneLayer	oneLayer - rat 1	0	-0.31991833	0.14819923	false
training	oneLayer	oneLayer - rat 1	0	-0.3238292	0.13875754	false
training	oneLayer	oneLayer - rat 1	0	-0.32799488	0.1287007	false
training	oneLayer	oneLayer - rat 1	0	-0.33187813	0.11932576	false
training	oneLayer	oneLayer - rat 1	0	-0.33589694	0.1096235	false
training	oneLayer	oneLayer - rat 1	0	-0.3434614	0.10205904	false
training	oneLayer	oneLayer - rat 1	0	-0.35061103	0.094909415	false
training	oneLayer	oneLayer - rat 1	0	-0.3581783	0.08734215	false
training	oneLayer	oneLayer - rat 1	0	-0.3655258	0.07999464	false
training	oneLayer	oneLayer - rat 1	0	-0.37297907	0.07254138	false
training	oneLayer	oneLayer - rat 1	0	-0.3803825	0.06513793	false
training	oneLayer	oneLayer - rat 1	0	-0.3880462	0.057474263	false
training	oneLayer	oneLayer - rat 1	0	-0.39576232	0.04975813	false
training	oneLayer	oneLayer - rat 1	0	-0.40296084	0.042559624	false
training	oneLayer	oneLayer - rat 1	0	-0.4105332	0.034987263	false
training	oneLayer	oneLayer - rat 1	0	-0.41819444	0.027326018	false
training	oneLayer	oneLayer - rat 1	0	-0.422368	0.01725018	false
training	oneLayer	oneLayer - rat 1	0	-0.42236802	0.0066208257	false
training	oneLayer	oneLayer - rat 1	0	-0.41829818	-0.003204631	false
training	oneLayer	oneLayer - rat 1	0	-0.41098943	-0.010513372	false
training	oneLayer	oneLayer - rat 1	0	-0.4010406	-0.014634304	false
training	oneLayer	oneLayer - rat 1	0	-0.39043683	-0.014634306	false
training	oneLayer	oneLayer - rat 1	0	-0.37949774	-0.0146343075	false
training	oneLayer	oneLayer - rat 1	0	-0.36876273	-0.014634309	false
training	oneLayer	oneLayer - rat 1	0	-0.35860142	-0.014634311	false
training	oneLayer	oneLayer - rat 1	0	-0.34845418	-0.014634313	false
training	oneLayer	oneLayer - rat 1	0	-0.33746544	-0.014634315	false
training	oneLayer	oneLayer - rat 1	0	-0.32652017	-0.014634317	false
training	oneLayer	oneLayer - rat 1	0	-0.3158824	-0.014634319	false
training	oneLayer	oneLayer - rat 1	0	-0.30511785	-0.0146343205	false
training	oneLayer	oneLayer - rat 1	0	-0.2949455	-0.014634322	false
training	oneLayer	oneLayer - rat 1	0	-0.28434753	-0.014634324	false
training	oneLayer	oneLayer - rat 1	0	-0.27417204	-0.014634326	false
training	oneLayer	oneLayer - rat 1	0	-0.26390588	-0.014634328	false
training	oneLayer	oneLayer - rat 1	0	-0.25307927	-0.01463433	false
training	oneLayer	oneLayer - rat 1	0	-0.24275011	-0.014634332	false
training	oneLayer	oneLayer - rat 1	0	-0.23216055	-0.014634334	false
training	oneLayer	oneLayer - rat 1	0	-0.22156666	-0.014634335	false
training	oneLayer	oneLayer - rat 1	0	-0.21079499	-0.014634337	false
training	oneLayer	oneLayer - rat 1	0	-0.20023388	-0.014634339	false
training	oneLayer	oneLayer - rat 1	0	-0.18989421	-0.014634341	false
training	oneLayer	oneLayer - rat 1	0	-0.17942448	-0.014634343	false
training	oneLayer	oneLayer - rat 1	0	-0.16886656	-0.014634345	false
training	oneLayer	oneLayer - rat 1	0	-0.15865567	-0.014634347	false
training	oneLayer	oneLayer - rat 1	0	-0.14781226	-0.014634348	false
training	oneLayer	oneLayer - rat 1	0	-0.1377905	-0.01463435	false
training	oneLayer	oneLayer - rat 1	0	-0.12757777	-0.014634352	false
training	oneLayer	oneLayer - rat 1	0	-0.116805784	-0.014634354	false
training	oneLayer	oneLayer - rat 1	0	-0.105861336	-0.014634356	false
training	oneLayer	oneLayer - rat 1	0	-0.09528615	-0.014634358	false
training	oneLayer	oneLayer - rat 1	0	-0.08436454	-0.01463436	false
training	oneLayer	oneLayer - rat 1	0	-0.07376276	-0.0146343615	false
training	oneLayer	oneLayer - rat 1	0	-0.06341181	-0.014634363	false
training	oneLayer	oneLayer - rat 1	0	-0.053047556	-0.014634365	false
training	oneLayer	oneLayer - rat 1	0	-0.042666752	-0.014634367	false
training	oneLayer	oneLayer - rat 1	0	-0.03198022	-0.014634369	false
training	oneLayer	oneLayer - rat 1	0	-0.021131134	-0.014634371	false
training	oneLayer	oneLayer - rat 1	0	-0.010164524	-0.014634373	false
training	oneLayer	oneLayer - rat 1	0	7.899836E-4	-0.0146343745	false
training	oneLayer	oneLayer - rat 1	0	0.011763838	-0.014634376	false
training	oneLayer	oneLayer - rat 1	0	0.022171669	-0.014634378	false
training	oneLayer	oneLayer - rat 1	0	0.032293305	-0.01463438	false
training	oneLayer	oneLayer - rat 1	0	0.04235283	-0.014634382	false
training	oneLayer	oneLayer - rat 1	0	0.053028494	-0.014634384	false
training	oneLayer	oneLayer - rat 1	0	0.063347615	-0.014634385	false
training	oneLayer	oneLayer - rat 1	0	0.07361955	-0.014634387	false
training	oneLayer	oneLayer - rat 1	0	0.08419154	-0.0146343885	false
training	oneLayer	oneLayer - rat 1	0	0.094200015	-0.01463439	false
training	oneLayer	oneLayer - rat 1	0	0.10455555	-0.014634392	false
training	oneLayer	oneLayer - rat 1	0	0.11490671	-0.014634394	false
training	oneLayer	oneLayer - rat 1	0	0.12560908	-0.014634396	false
training	oneLayer	oneLayer - rat 1	0	0.13610178	-0.014634398	false
training	oneLayer	oneLayer - rat 1	0	0.14672488	-0.0146344	false
training	oneLayer	oneLayer - rat 1	0	0.15754639	-0.014634402	false
training	oneLayer	oneLayer - rat 1	0	0.16815123	-0.014634403	false
training	oneLayer	oneLayer - rat 1	0	0.17846718	-0.014634405	false
training	oneLayer	oneLayer - rat 1	0	0.18939054	-0.014634407	false
training	oneLayer	oneLayer - rat 1	0	0.19992863	-0.014634409	false
training	oneLayer	oneLayer - rat 1	0	0.21061116	-0.014634411	false
training	oneLayer	oneLayer - rat 1	0	0.22126712	-0.014634413	false
training	oneLayer	oneLayer - rat 1	0	0.23183863	-0.014634415	false
training	oneLayer	oneLayer - rat 1	0	0.2426007	-0.014634416	false
training	oneLayer	oneLayer - rat 1	0	0.25264436	-0.014634418	false
training	oneLayer	oneLayer - rat 1	0	0.2628508	-0.01463442	false
training	oneLayer	oneLayer - rat 1	0	0.27299887	-0.014634422	false
training	oneLayer	oneLayer - rat 1	0	0.28392035	-0.014634424	false
training	oneLayer	oneLayer - rat 1	0	0.294814	-0.014634426	false
training	oneLayer	oneLayer - rat 1	0	0.3053799	-0.014634428	false
training	oneLayer	oneLayer - rat 1	0	0.3158086	-0.0146344295	false
training	oneLayer	oneLayer - rat 1	0	0.32679558	-0.014634431	false
training	oneLayer	oneLayer - rat 1	0	0.3371902	-0.014634433	false
training	oneLayer	oneLayer - rat 1	0	0.3478013	-0.014634435	false
training	oneLayer	oneLayer - rat 1	0	0.35785216	-0.014634437	false
training	oneLayer	oneLayer - rat 1	0	0.36788148	-0.014634439	false
training	oneLayer	oneLayer - rat 1	0	0.378531	-0.014634441	false
training	oneLayer	oneLayer - rat 1	0	0.38932633	-0.0146344425	false
training	oneLayer	oneLayer - rat 1	0	0.39988604	-0.014634444	false
training	oneLayer	oneLayer - rat 1	0	0.40924835	-0.018512437	false
training	oneLayer	oneLayer - rat 1	0	0.41665864	-0.025922736	false
training	oneLayer	oneLayer - rat 1	0	0.42054337	-0.035301324	false
training	oneLayer	oneLayer - rat 1	0	0.42054337	-0.04609857	false
training	oneLayer	oneLayer - rat 1	0	0.41645065	-0.05597925	false
training	oneLayer	oneLayer - rat 1	0	0.4087706	-0.063659325	false
training	oneLayer	oneLayer - rat 1	0	0.398832	-0.06777602	false
training	oneLayer	oneLayer - rat 1	0	0.38797107	-0.06777602	false
training	oneLayer	oneLayer - rat 1	0	0.37786618	-0.06359043	false
training	oneLayer	oneLayer - rat 1	0	0.36786422	-0.05944748	false
training	oneLayer	oneLayer - rat 1	0	0.35828885	-0.055481225	false
training	oneLayer	oneLayer - rat 1	0	0.34850225	-0.051427476	false
training	oneLayer	oneLayer - rat 1	0	0.33845395	-0.047265336	false
training	oneLayer	oneLayer - rat 1	0	0.32910794	-0.04339409	false
training	oneLayer	oneLayer - rat 1	0	0.31972235	-0.03950645	false
training	oneLayer	oneLayer - rat 1	0	0.30999035	-0.035475317	false
training	oneLayer	oneLayer - rat 1	0	0.30011073	-0.031383038	false
training	oneLayer	oneLayer - rat 1	0	0.2907594	-0.027509598	false
training	oneLayer	oneLayer - rat 1	0	0.2812897	-0.023587111	false
training	oneLayer	oneLayer - rat 1	0	0.27138364	-0.019483881	false
training	oneLayer	oneLayer - rat 1	0	0.26159835	-0.015430679	false
training	oneLayer	oneLayer - rat 1	0	0.25198698	-0.011449509	false
training	oneLayer	oneLayer - rat 1	0	0.24231511	-0.0074432953	false
training	oneLayer	oneLayer - rat 1	0	0.23227297	-0.003283698	false
training	oneLayer	oneLayer - rat 1	0	0.2222637	8.622859E-4	false
training	oneLayer	oneLayer - rat 1	0	0.2124835	0.004913375	false
training	oneLayer	oneLayer - rat 1	0	0.20293401	0.008868908	false
training	oneLayer	oneLayer - rat 1	0	0.19298501	0.012989919	false
training	oneLayer	oneLayer - rat 1	0	0.18284926	0.017188288	false
training	oneLayer	oneLayer - rat 1	0	0.17348824	0.02106575	false
training	oneLayer	oneLayer - rat 1	0	0.16374943	0.025099706	false
training	oneLayer	oneLayer - rat 1	0	0.15398334	0.029144956	false
training	oneLayer	oneLayer - rat 1	0	0.1442232	0.03318774	false
training	oneLayer	oneLayer - rat 1	0	0.13459231	0.03717699	false
training	oneLayer	oneLayer - rat 1	0	0.12529662	0.041027393	false
training	oneLayer	oneLayer - rat 1	0	0.11549858	0.045085877	false
training	oneLayer	oneLayer - rat 1	0	0.106258154	0.04891339	false
training	oneLayer	oneLayer - rat 1	0	0.096109904	0.053116933	false
training	oneLayer	oneLayer - rat 1	0	0.08650474	0.057095524	false
training	oneLayer	oneLayer - rat 1	0	0.07675001	0.06113607	false
training	oneLayer	oneLayer - rat 1	0	0.06698235	0.06518197	false
training	oneLayer	oneLayer - rat 1	0	0.05695711	0.06933457	false
training	oneLayer	oneLayer - rat 1	0	0.047217395	0.07336889	false
training	oneLayer	oneLayer - rat 1	0	0.03716693	0.077531934	false
training	oneLayer	oneLayer - rat 1	0	0.02764352	0.08147666	false
training	oneLayer	oneLayer - rat 1	0	0.017512215	0.08567319	false
training	oneLayer	oneLayer - rat 1	0	0.007964847	0.08962784	false
training	oneLayer	oneLayer - rat 1	0	-0.0012922871	0.09346227	false
training	oneLayer	oneLayer - rat 1	0	-0.010788303	0.09739566	false
training	oneLayer	oneLayer - rat 1	0	-0.020797307	0.10154153	false
training	oneLayer	oneLayer - rat 1	0	-0.030058911	0.10537781	false
training	oneLayer	oneLayer - rat 1	0	-0.040173873	0.10956757	false
training	oneLayer	oneLayer - rat 1	0	-0.04965296	0.113493934	false
training	oneLayer	oneLayer - rat 1	0	-0.05904038	0.11738233	false
training	oneLayer	oneLayer - rat 1	0	-0.068294145	0.12121537	false
training	oneLayer	oneLayer - rat 1	0	-0.078067824	0.12526377	false
training	oneLayer	oneLayer - rat 1	0	-0.08810281	0.1294204	false
training	oneLayer	oneLayer - rat 1	0	-0.097544745	0.13333137	false
training	oneLayer	oneLayer - rat 1	0	-0.106922455	0.13721576	false
training	oneLayer	oneLayer - rat 1	0	-0.116834104	0.1413213	false
training	oneLayer	oneLayer - rat 1	0	-0.12658407	0.14535987	false
training	oneLayer	oneLayer - rat 1	0	-0.13612439	0.1493116	false
training	oneLayer	oneLayer - rat 1	0	-0.14624974	0.15350567	false
training	oneLayer	oneLayer - rat 1	0	-0.15618226	0.15761985	false
training	oneLayer	oneLayer - rat 1	0	-0.1657332	0.16157599	false
training	oneLayer	oneLayer - rat 1	0	-0.17341202	0.16925481	false
training	oneLayer	oneLayer - rat 1	0	-0.18108246	0.17692526	false
training	oneLayer	oneLayer - rat 1	0	-0.1887168	0.1845596	false
training	oneLayer	oneLayer - rat 1	0	-0.19612141	0.19196421	false
training	oneLayer	oneLayer - rat 1	0	-0.2036976	0.19954042	false
training	oneLayer	oneLayer - rat 1	0	-0.2110106	0.2068534	false
training	oneLayer	oneLayer - rat 1	0	-0.2181238	0.2139666	false
training	oneLayer	oneLayer - rat 1	0	-0.22527646	0.22111927	false
training	oneLayer	oneLayer - rat 1	0	-0.232777	0.22861983	false
training	oneLayer	oneLayer - rat 1	0	-0.24039815	0.23624098	false
training	oneLayer	oneLayer - rat 1	0	-0.24814509	0.24398792	false
training	oneLayer	oneLayer - rat 1	0	-0.25543544	0.25127825	false
training	oneLayer	oneLayer - rat 1	0	-0.26263985	0.2584827	false
training	oneLayer	oneLayer - rat 1	0	-0.26998106	0.2658239	false
training	oneLayer	oneLayer - rat 1	0	-0.2776411	0.27348393	false
training	oneLayer	oneLayer - rat 1	0	-0.28486136	0.2807042	false
training	oneLayer	oneLayer - rat 1	0	-0.2925736	0.28841648	false
training	oneLayer	oneLayer - rat 1	0	-0.30197996	0.2923127	false
training	oneLayer	oneLayer - rat 1	0	-0.3120965	0.2923127	false
training	oneLayer	oneLayer - rat 1	0	-0.32138848	0.28846383	false
training	oneLayer	oneLayer - rat 1	0	-0.32892302	0.2809293	false
training	oneLayer	oneLayer - rat 1	0	-0.33280855	0.27154878	false
training	oneLayer	oneLayer - rat 1	0	-0.33280855	0.2606658	false
training	oneLayer	oneLayer - rat 1	0	-0.3288449	0.25109667	false
training	oneLayer	oneLayer - rat 1	0	-0.321314	0.24356575	false
training	oneLayer	oneLayer - rat 1	0	-0.31145167	0.23948064	false
training	oneLayer	oneLayer - rat 1	0	-0.30187893	0.23551548	false
training	oneLayer	oneLayer - rat 1	0	-0.29181552	0.23134708	false
training	oneLayer	oneLayer - rat 1	0	-0.28197113	0.2272694	false
training	oneLayer	oneLayer - rat 1	0	-0.27259263	0.2233847	false
training	oneLayer	oneLayer - rat 1	0	-0.26319584	0.2194924	false
training	oneLayer	oneLayer - rat 1	0	-0.2537793	0.21559195	false
training	oneLayer	oneLayer - rat 1	0	-0.24404858	0.21156135	false
training	oneLayer	oneLayer - rat 1	0	-0.23422182	0.20749098	false
training	oneLayer	oneLayer - rat 1	0	-0.22466537	0.20353256	false
training	oneLayer	oneLayer - rat 1	0	-0.21454607	0.19934101	false
training	oneLayer	oneLayer - rat 1	0	-0.20449658	0.19517837	false
training	oneLayer	oneLayer - rat 1	0	-0.19487044	0.19119109	false
training	oneLayer	oneLayer - rat 1	0	-0.185471	0.18729772	false
training	oneLayer	oneLayer - rat 1	0	-0.17618255	0.18345031	false
training	oneLayer	oneLayer - rat 1	0	-0.16683218	0.17957726	false
training	oneLayer	oneLayer - rat 1	0	-0.15711987	0.17555429	false
training	oneLayer	oneLayer - rat 1	0	-0.14711179	0.1714088	false
training	oneLayer	oneLayer - rat 1	0	-0.13705172	0.16724178	false
training	oneLayer	oneLayer - rat 1	0	-0.12755586	0.16330847	false
training	oneLayer	oneLayer - rat 1	0	-0.11826052	0.1594582	false
training	oneLayer	oneLayer - rat 1	0	-0.10853945	0.15543161	false
training	oneLayer	oneLayer - rat 1	0	-0.09846288	0.15125775	false
training	oneLayer	oneLayer - rat 1	0	-0.08896344	0.14732295	false
training	oneLayer	oneLayer - rat 1	0	-0.07927517	0.14330994	false
training	oneLayer	oneLayer - rat 1	0	-0.07002249	0.13947736	false
training	oneLayer	oneLayer - rat 1	0	-0.060020827	0.13533452	false
training	oneLayer	oneLayer - rat 1	0	-0.049861003	0.13112618	false
training	oneLayer	oneLayer - rat 1	0	-0.039975334	0.1270314	false
training	oneLayer	oneLayer - rat 1	0	-0.030130971	0.122953735	false
training	oneLayer	oneLayer - rat 1	0	-0.020217711	0.11884753	false
training	oneLayer	oneLayer - rat 1	0	-0.0107690105	0.114933744	false
training	oneLayer	oneLayer - rat 1	0	-0.0012791363	0.11100291	false
training	oneLayer	oneLayer - rat 1	0	0.008822763	0.106818564	false
training	oneLayer	oneLayer - rat 1	0	0.01812355	0.10296605	false
training	oneLayer	oneLayer - rat 1	0	0.0279598	0.098891735	false
training	oneLayer	oneLayer - rat 1	0	0.037929043	0.09476234	false
training	oneLayer	oneLayer - rat 1	0	0.047772903	0.090684876	false
training	oneLayer	oneLayer - rat 1	0	0.05749404	0.08665825	false
training	oneLayer	oneLayer - rat 1	0	0.06714831	0.08265932	false
training	oneLayer	oneLayer - rat 1	0	0.07650811	0.07878236	false
training	oneLayer	oneLayer - rat 1	0	0.08602963	0.074838415	false
training	oneLayer	oneLayer - rat 1	0	0.09528889	0.0710031	false
training	oneLayer	oneLayer - rat 1	0	0.104615934	0.06713971	false
training	oneLayer	oneLayer - rat 1	0	0.11474435	0.06294438	false
training	oneLayer	oneLayer - rat 1	0	0.124523714	0.058893632	false
training	oneLayer	oneLayer - rat 1	0	0.1337822	0.055058647	false
training	oneLayer	oneLayer - rat 1	0	0.14378774	0.05091421	false
training	oneLayer	oneLayer - rat 1	0	0.15360805	0.046846498	false
training	oneLayer	oneLayer - rat 1	0	0.16328071	0.042839948	false
training	oneLayer	oneLayer - rat 1	0	0.17254588	0.03900219	false
training	oneLayer	oneLayer - rat 1	0	0.18194571	0.035108652	false
training	oneLayer	oneLayer - rat 1	0	0.19182645	0.031015912	false
training	oneLayer	oneLayer - rat 1	0	0.2016432	0.026949678	false
training	oneLayer	oneLayer - rat 1	0	0.21123995	0.022974575	false
training	oneLayer	oneLayer - rat 1	0	0.22052956	0.019126693	false
training	oneLayer	oneLayer - rat 1	0	0.23043105	0.015025357	false
training	oneLayer	oneLayer - rat 1	0	0.24015646	0.01099696	false
training	oneLayer	oneLayer - rat 1	0	0.2496674	0.00705739	false
training	oneLayer	oneLayer - rat 1	0	0.25945878	0.0030016636	false
training	oneLayer	oneLayer - rat 1	0	0.26949587	-0.0011558374	false
training	oneLayer	oneLayer - rat 1	0	0.279591	-0.0011558393	false
training	oneLayer	oneLayer - rat 1	0	0.2900643	-0.001155841	false
training	oneLayer	oneLayer - rat 1	0	0.30069274	-0.0011558429	false
training	oneLayer	oneLayer - rat 1	0	0.31120345	-0.0011558448	false
training	oneLayer	oneLayer - rat 1	0	0.32137457	-0.0011558465	false
training	oneLayer	oneLayer - rat 1	0	0.33179864	-0.0011558484	false
training	oneLayer	oneLayer - rat 1	0	0.341818	-0.0011558501	false
training	oneLayer	oneLayer - rat 1	0	0.35242426	-0.001155852	false
training	oneLayer	oneLayer - rat 1	0	0.3629004	-0.0011558539	false
training	oneLayer	oneLayer - rat 1	0	0.37339455	-0.0011558556	false
training	oneLayer	oneLayer - rat 1	0	0.38433108	-0.0011558576	false
training	oneLayer	oneLayer - rat 1	0	0.39502412	-0.0011558594	false
training	oneLayer	oneLayer - rat 1	0	0.40566245	-0.0011558613	false
training	oneLayer	oneLayer - rat 1	0	0.41525942	0.0028193297	false
training	oneLayer	oneLayer - rat 1	0	0.42277613	0.010336024	false
training	oneLayer	oneLayer - rat 1	0	0.426974	0.02047063	false
training	oneLayer	oneLayer - rat 1	0	0.426974	0.03080885	false
training	oneLayer	oneLayer - rat 1	0	0.42305753	0.04026405	false
training	oneLayer	oneLayer - rat 1	0	0.4158308	0.047490805	false
training	oneLayer	oneLayer - rat 1	0	0.40586004	0.051620822	false
training	oneLayer	oneLayer - rat 1	0	0.39518383	0.051620822	false
training	oneLayer	oneLayer - rat 1	0	0.38464475	0.051620826	false
training	oneLayer	oneLayer - rat 1	0	0.3738722	0.051620826	false
training	oneLayer	oneLayer - rat 1	0	0.36293793	0.051620826	false
training	oneLayer	oneLayer - rat 1	0	0.35265768	0.051620826	false
training	oneLayer	oneLayer - rat 1	0	0.34187335	0.05162083	false
training	oneLayer	oneLayer - rat 1	0	0.33120295	0.05162083	false
training	oneLayer	oneLayer - rat 1	0	0.32030725	0.05162083	false
training	oneLayer	oneLayer - rat 1	0	0.30935436	0.05162083	false
training	oneLayer	oneLayer - rat 1	0	0.2986653	0.051620834	false
training	oneLayer	oneLayer - rat 1	0	0.28771713	0.051620834	false
training	oneLayer	oneLayer - rat 1	0	0.27687743	0.051620834	false
training	oneLayer	oneLayer - rat 1	0	0.26660043	0.051620834	false
training	oneLayer	oneLayer - rat 1	0	0.2560887	0.051620837	false
training	oneLayer	oneLayer - rat 1	0	0.24588741	0.051620837	false
training	oneLayer	oneLayer - rat 1	0	0.23551758	0.051620837	false
training	oneLayer	oneLayer - rat 1	0	0.22520867	0.051620837	false
training	oneLayer	oneLayer - rat 1	0	0.21463202	0.05162084	false
training	oneLayer	oneLayer - rat 1	0	0.20403762	0.05162084	false
training	oneLayer	oneLayer - rat 1	0	0.19307286	0.05162084	false
training	oneLayer	oneLayer - rat 1	0	0.18226393	0.05162084	false
training	oneLayer	oneLayer - rat 1	0	0.17134136	0.051620845	false
training	oneLayer	oneLayer - rat 1	0	0.16089755	0.051620845	false
training	oneLayer	oneLayer - rat 1	0	0.15070964	0.051620845	false
training	oneLayer	oneLayer - rat 1	0	0.14039189	0.051620845	false
training	oneLayer	oneLayer - rat 1	0	0.1301094	0.05162085	false
training	oneLayer	oneLayer - rat 1	0	0.119501755	0.05162085	false
training	oneLayer	oneLayer - rat 1	0	0.10861941	0.05162085	false
training	oneLayer	oneLayer - rat 1	0	0.09841784	0.05162085	false
training	oneLayer	oneLayer - rat 1	0	0.088110305	0.051620852	false
training	oneLayer	oneLayer - rat 1	0	0.078002155	0.051620852	false
training	oneLayer	oneLayer - rat 1	0	0.06741918	0.051620852	false
training	oneLayer	oneLayer - rat 1	0	0.056468893	0.051620852	false
training	oneLayer	oneLayer - rat 1	0	0.045531694	0.051620856	false
training	oneLayer	oneLayer - rat 1	0	0.035359874	0.051620856	false
training	oneLayer	oneLayer - rat 1	0	0.02455407	0.051620856	false
training	oneLayer	oneLayer - rat 1	0	0.014513686	0.051620856	false
training	oneLayer	oneLayer - rat 1	0	0.0039777025	0.05162086	false
training	oneLayer	oneLayer - rat 1	0	-0.006433818	0.05162086	false
training	oneLayer	oneLayer - rat 1	0	-0.017426077	0.05162086	false
training	oneLayer	oneLayer - rat 1	0	-0.02778923	0.05162086	false
training	oneLayer	oneLayer - rat 1	0	-0.03839433	0.051620863	false
training	oneLayer	oneLayer - rat 1	0	-0.048988167	0.051620863	false
training	oneLayer	oneLayer - rat 1	0	-0.05991471	0.051620863	false
training	oneLayer	oneLayer - rat 1	0	-0.07063528	0.051620863	false
training	oneLayer	oneLayer - rat 1	0	-0.08111828	0.051620867	false
training	oneLayer	oneLayer - rat 1	0	-0.091920555	0.051620867	false
training	oneLayer	oneLayer - rat 1	0	-0.10248037	0.051620867	false
training	oneLayer	oneLayer - rat 1	0	-0.11328055	0.051620867	false
training	oneLayer	oneLayer - rat 1	0	-0.1234232	0.05162087	false
training	oneLayer	oneLayer - rat 1	0	-0.1342724	0.05162087	false
training	oneLayer	oneLayer - rat 1	0	-0.14455992	0.05162087	false
training	oneLayer	oneLayer - rat 1	0	-0.15502812	0.05162087	false
training	oneLayer	oneLayer - rat 1	0	-0.16522962	0.051620875	false
training	oneLayer	oneLayer - rat 1	0	-0.17610626	0.051620875	false
training	oneLayer	oneLayer - rat 1	0	-0.18685791	0.051620875	false
training	oneLayer	oneLayer - rat 1	0	-0.19737543	0.051620875	false
training	oneLayer	oneLayer - rat 1	0	-0.20801191	0.05162088	false
training	oneLayer	oneLayer - rat 1	0	-0.21901071	0.05162088	false
training	oneLayer	oneLayer - rat 1	0	-0.22981791	0.05162088	false
training	oneLayer	oneLayer - rat 1	0	-0.23987798	0.05162088	false
training	oneLayer	oneLayer - rat 1	0	-0.2507621	0.051620882	false
training	oneLayer	oneLayer - rat 1	0	-0.26092893	0.051620882	false
training	oneLayer	oneLayer - rat 1	0	-0.27158546	0.051620882	false
training	oneLayer	oneLayer - rat 1	0	-0.2818776	0.051620882	false
training	oneLayer	oneLayer - rat 1	0	-0.29249087	0.051620882	false
training	oneLayer	oneLayer - rat 1	0	-0.302794	0.051620886	false
training	oneLayer	oneLayer - rat 1	0	-0.3129091	0.051620886	false
training	oneLayer	oneLayer - rat 1	0	-0.32298198	0.051620886	false
training	oneLayer	oneLayer - rat 1	0	-0.33351701	0.051620886	false
training	oneLayer	oneLayer - rat 1	0	-0.3429228	0.047724888	false
training	oneLayer	oneLayer - rat 1	0	-0.3526348	0.04370205	false
training	oneLayer	oneLayer - rat 1	0	-0.36261344	0.039568756	false
training	oneLayer	oneLayer - rat 1	0	-0.37235156	0.0355351	false
training	oneLayer	oneLayer - rat 1	0	-0.38196233	0.031554192	false
training	oneLayer	oneLayer - rat 1	0	-0.3919391	0.027421677	false
training	oneLayer	oneLayer - rat 1	0	-0.40187728	0.023305139	false
training	oneLayer	oneLayer - rat 1	0	-0.41139552	0.019362563	false
training	oneLayer	oneLayer - rat 1	0	-0.41894537	0.011812722	false
training	oneLayer	oneLayer - rat 1	0	-0.4228765	0.0023221266	false
training	oneLayer	oneLayer - rat 1	0	-0.4228765	-0.007895544	false
training	oneLayer	oneLayer - rat 1	0	-0.41888973	-0.017520417	false
training	oneLayer	oneLayer - rat 1	0	-0.4111454	-0.025264781	false
training	oneLayer	oneLayer - rat 1	0	-0.4013041	-0.029341169	false
training	oneLayer	oneLayer - rat 1	0	-0.3909661	-0.029341169	false
training	oneLayer	oneLayer - rat 1	0	-0.380606	-0.029341169	false
training	oneLayer	oneLayer - rat 1	0	-0.37055087	-0.029341169	false
training	oneLayer	oneLayer - rat 1	0	-0.35965377	-0.029341169	false
training	oneLayer	oneLayer - rat 1	0	-0.34869638	-0.029341169	false
training	oneLayer	oneLayer - rat 1	0	-0.33785814	-0.029341169	false
training	oneLayer	oneLayer - rat 1	0	-0.32747528	-0.029341169	false
training	oneLayer	oneLayer - rat 1	0	-0.3165057	-0.029341169	false
training	oneLayer	oneLayer - rat 1	0	-0.30627552	-0.029341169	false
training	oneLayer	oneLayer - rat 1	0	-0.2960351	-0.029341169	false
training	oneLayer	oneLayer - rat 1	0	-0.28582323	-0.029341169	false
training	oneLayer	oneLayer - rat 1	0	-0.2749702	-0.029341169	false
training	oneLayer	oneLayer - rat 1	0	-0.26489723	-0.029341169	false
training	oneLayer	oneLayer - rat 1	0	-0.25489432	-0.029341169	false
training	oneLayer	oneLayer - rat 1	0	-0.24476294	-0.029341169	false
training	oneLayer	oneLayer - rat 1	0	-0.23454353	-0.029341169	false
training	oneLayer	oneLayer - rat 1	0	-0.22375081	-0.029341169	false
training	oneLayer	oneLayer - rat 1	0	-0.21360295	-0.029341169	false
training	oneLayer	oneLayer - rat 1	0	-0.20293863	-0.029341169	false
training	oneLayer	oneLayer - rat 1	0	-0.19210042	-0.029341169	false
training	oneLayer	oneLayer - rat 1	0	-0.18135267	-0.029341169	false
training	oneLayer	oneLayer - rat 1	0	-0.17113455	-0.029341169	false
training	oneLayer	oneLayer - rat 1	0	-0.16112982	-0.029341169	false
training	oneLayer	oneLayer - rat 1	0	-0.15026508	-0.029341169	false
training	oneLayer	oneLayer - rat 1	0	-0.13983403	-0.029341169	false
training	oneLayer	oneLayer - rat 1	0	-0.1291783	-0.029341169	false
training	oneLayer	oneLayer - rat 1	0	-0.11855738	-0.029341169	false
training	oneLayer	oneLayer - rat 1	0	-0.10791618	-0.029341169	false
training	oneLayer	oneLayer - rat 1	0	-0.09716416	-0.029341169	false
training	oneLayer	oneLayer - rat 1	0	-0.086726144	-0.029341169	false
training	oneLayer	oneLayer - rat 1	0	-0.07627275	-0.029341169	false
training	oneLayer	oneLayer - rat 1	0	-0.06595444	-0.029341169	false
training	oneLayer	oneLayer - rat 1	0	-0.0553435	-0.029341169	false
training	oneLayer	oneLayer - rat 1	0	-0.045005884	-0.029341169	false
training	oneLayer	oneLayer - rat 1	0	-0.03476896	-0.029341169	false
training	oneLayer	oneLayer - rat 1	0	-0.02410307	-0.029341169	false
training	oneLayer	oneLayer - rat 1	0	-0.014005873	-0.029341169	false
training	oneLayer	oneLayer - rat 1	0	-0.003137399	-0.029341169	false
training	oneLayer	oneLayer - rat 1	0	0.0074914764	-0.029341169	false
training	oneLayer	oneLayer - rat 1	0	0.018174624	-0.029341169	false
training	oneLayer	oneLayer - rat 1	0	0.028645938	-0.029341169	false
training	oneLayer	oneLayer - rat 1	0	0.03957448	-0.029341169	false
training	oneLayer	oneLayer - rat 1	0	0.05003177	-0.029341169	false
training	oneLayer	oneLayer - rat 1	0	0.06094436	-0.029341169	false
training	oneLayer	oneLayer - rat 1	0	0.07113234	-0.029341169	false
training	oneLayer	oneLayer - rat 1	0	0.0813689	-0.029341169	false
training	oneLayer	oneLayer - rat 1	0	0.09183776	-0.029341169	false
training	oneLayer	oneLayer - rat 1	0	0.10263384	-0.029341169	false
training	oneLayer	oneLayer - rat 1	0	0.11346933	-0.029341169	false
training	oneLayer	oneLayer - rat 1	0	0.12439698	-0.029341169	false
training	oneLayer	oneLayer - rat 1	0	0.13471216	-0.029341169	false
training	oneLayer	oneLayer - rat 1	0	0.14559595	-0.029341169	false
training	oneLayer	oneLayer - rat 1	0	0.15560721	-0.029341169	false
training	oneLayer	oneLayer - rat 1	0	0.16566186	-0.029341169	false
training	oneLayer	oneLayer - rat 1	0	0.17635603	-0.029341169	false
training	oneLayer	oneLayer - rat 1	0	0.18733081	-0.029341169	false
training	oneLayer	oneLayer - rat 1	0	0.19754004	-0.029341169	false
training	oneLayer	oneLayer - rat 1	0	0.20755708	-0.029341169	false
training	oneLayer	oneLayer - rat 1	0	0.21845897	-0.029341169	false
training	oneLayer	oneLayer - rat 1	0	0.22943102	-0.029341169	false
training	oneLayer	oneLayer - rat 1	0	0.23979893	-0.029341169	false
training	oneLayer	oneLayer - rat 1	0	0.25017762	-0.029341169	false
training	oneLayer	oneLayer - rat 1	0	0.2610038	-0.029341169	false
training	oneLayer	oneLayer - rat 1	0	0.27111006	-0.029341169	false
training	oneLayer	oneLayer - rat 1	0	0.28136626	-0.029341169	false
training	oneLayer	oneLayer - rat 1	0	0.29161248	-0.029341169	false
training	oneLayer	oneLayer - rat 1	0	0.3016567	-0.029341169	false
training	oneLayer	oneLayer - rat 1	0	0.31250063	-0.029341169	false
training	oneLayer	oneLayer - rat 1	0	0.32255158	-0.029341169	false
training	oneLayer	oneLayer - rat 1	0	0.3329981	-0.029341169	false
training	oneLayer	oneLayer - rat 1	0	0.34377143	-0.029341169	false
training	oneLayer	oneLayer - rat 1	0	0.35457698	-0.029341169	false
training	oneLayer	oneLayer - rat 1	0	0.36549467	-0.029341169	false
training	oneLayer	oneLayer - rat 1	0	0.37569228	-0.029341169	false
training	oneLayer	oneLayer - rat 1	0	0.3860791	-0.029341169	false
training	oneLayer	oneLayer - rat 1	0	0.3957059	-0.025353612	false
training	oneLayer	oneLayer - rat 1	0	0.40580988	-0.02116842	false
training	oneLayer	oneLayer - rat 1	0	0.41292074	-0.01405754	false
training	oneLayer	oneLayer - rat 1	0	0.41676968	-0.0047653816	false
training	oneLayer	oneLayer - rat 1	0	0.41676968	0.00592961	false
training	oneLayer	oneLayer - rat 1	0	0.41291913	0.015225644	false
training	oneLayer	oneLayer - rat 1	0	0.4058157	0.022329101	false
training	oneLayer	oneLayer - rat 1	0	0.39595982	0.026411528	false
training	oneLayer	oneLayer - rat 1	0	0.3850476	0.026411528	false
training	oneLayer	oneLayer - rat 1	0	0.3749424	0.026411526	false
training	oneLayer	oneLayer - rat 1	0	0.364723	0.026411526	false
training	oneLayer	oneLayer - rat 1	0	0.3538224	0.026411524	false
training	oneLayer	oneLayer - rat 1	0	0.3434079	0.026411524	false
training	oneLayer	oneLayer - rat 1	0	0.33257085	0.026411522	false
training	oneLayer	oneLayer - rat 1	0	0.32210553	0.026411522	false
training	oneLayer	oneLayer - rat 1	0	0.31151664	0.02641152	false
training	oneLayer	oneLayer - rat 1	0	0.3005737	0.02641152	false
training	oneLayer	oneLayer - rat 1	0	0.29048416	0.026411518	false
training	oneLayer	oneLayer - rat 1	0	0.28028938	0.026411518	false
training	oneLayer	oneLayer - rat 1	0	0.2701296	0.026411517	false
training	oneLayer	oneLayer - rat 1	0	0.25921464	0.026411517	false
training	oneLayer	oneLayer - rat 1	0	0.24914424	0.026411515	false
training	oneLayer	oneLayer - rat 1	0	0.23890118	0.026411515	false
training	oneLayer	oneLayer - rat 1	0	0.22800054	0.026411513	false
training	oneLayer	oneLayer - rat 1	0	0.21735163	0.026411513	false
training	oneLayer	oneLayer - rat 1	0	0.20677668	0.026411511	false
training	oneLayer	oneLayer - rat 1	0	0.19639689	0.026411511	false
training	oneLayer	oneLayer - rat 1	0	0.18624286	0.02641151	false
training	oneLayer	oneLayer - rat 1	0	0.17599072	0.02641151	false
training	oneLayer	oneLayer - rat 1	0	0.16546494	0.026411507	false
training	oneLayer	oneLayer - rat 1	0	0.15453199	0.026411507	false
training	oneLayer	oneLayer - rat 1	0	0.14397126	0.026411505	false
training	oneLayer	oneLayer - rat 1	0	0.1332827	0.026411505	false
training	oneLayer	oneLayer - rat 1	0	0.12298065	0.026411504	false
training	oneLayer	oneLayer - rat 1	0	0.11260051	0.026411504	false
training	oneLayer	oneLayer - rat 1	0	0.10243454	0.026411502	false
training	oneLayer	oneLayer - rat 1	0	0.092003465	0.026411502	false
training	oneLayer	oneLayer - rat 1	0	0.08189426	0.0264115	false
training	oneLayer	oneLayer - rat 1	0	0.07106633	0.0264115	false
training	oneLayer	oneLayer - rat 1	0	0.060465034	0.026411498	false
training	oneLayer	oneLayer - rat 1	0	0.05022296	0.026411498	false
training	oneLayer	oneLayer - rat 1	0	0.040184036	0.026411496	false
training	oneLayer	oneLayer - rat 1	0	0.029761713	0.026411496	false
training	oneLayer	oneLayer - rat 1	0	0.019318439	0.026411494	false
training	oneLayer	oneLayer - rat 1	0	0.008579067	0.026411494	false
training	oneLayer	oneLayer - rat 1	0	-0.0016254487	0.026411492	false
training	oneLayer	oneLayer - rat 1	0	-0.011885494	0.026411492	false
training	oneLayer	oneLayer - rat 1	0	-0.022542594	0.02641149	false
training	oneLayer	oneLayer - rat 1	0	-0.033223983	0.02641149	false
training	oneLayer	oneLayer - rat 1	0	-0.04394501	0.026411489	false
training	oneLayer	oneLayer - rat 1	0	-0.05453219	0.026411489	false
training	oneLayer	oneLayer - rat 1	0	-0.065333046	0.026411487	false
training	oneLayer	oneLayer - rat 1	0	-0.076095834	0.026411487	false
training	oneLayer	oneLayer - rat 1	0	-0.08686471	0.026411485	false
training	oneLayer	oneLayer - rat 1	0	-0.09690273	0.026411485	false
training	oneLayer	oneLayer - rat 1	0	-0.107742496	0.026411483	false
training	oneLayer	oneLayer - rat 1	0	-0.1183361	0.026411483	false
training	oneLayer	oneLayer - rat 1	0	-0.12851827	0.026411481	false
training	oneLayer	oneLayer - rat 1	0	-0.13880858	0.026411481	false
training	oneLayer	oneLayer - rat 1	0	-0.14962281	0.02641148	false
training	oneLayer	oneLayer - rat 1	0	-0.16040342	0.02641148	false
training	oneLayer	oneLayer - rat 1	0	-0.17088893	0.026411477	false
training	oneLayer	oneLayer - rat 1	0	-0.18165343	0.026411477	false
training	oneLayer	oneLayer - rat 1	0	-0.19214691	0.026411476	false
training	oneLayer	oneLayer - rat 1	0	-0.2028336	0.026411476	false
training	oneLayer	oneLayer - rat 1	0	-0.21291459	0.026411476	false
training	oneLayer	oneLayer - rat 1	0	-0.22346029	0.026411474	false
training	oneLayer	oneLayer - rat 1	0	-0.23414442	0.026411474	false
training	oneLayer	oneLayer - rat 1	0	-0.24432766	0.026411472	false
training	oneLayer	oneLayer - rat 1	0	-0.25479317	0.026411472	false
training	oneLayer	oneLayer - rat 1	0	-0.26572275	0.02641147	false
training	oneLayer	oneLayer - rat 1	0	-0.27647135	0.02641147	false
training	oneLayer	oneLayer - rat 1	0	-0.28745347	0.026411468	false
training	oneLayer	oneLayer - rat 1	0	-0.29750898	0.026411468	false
training	oneLayer	oneLayer - rat 1	0	-0.30815274	0.026411466	false
training	oneLayer	oneLayer - rat 1	0	-0.3190737	0.026411466	false
training	oneLayer	oneLayer - rat 1	0	-0.3297561	0.026411464	false
training	oneLayer	oneLayer - rat 1	0	-0.3406079	0.026411464	false
training	oneLayer	oneLayer - rat 1	0	-0.3511586	0.026411463	false
training	oneLayer	oneLayer - rat 1	0	-0.3612902	0.026411463	false
training	oneLayer	oneLayer - rat 1	0	-0.37216726	0.02641146	false
training	oneLayer	oneLayer - rat 1	0	-0.38289645	0.02641146	false
training	oneLayer	oneLayer - rat 1	0	-0.39326727	0.026411459	false
training	oneLayer	oneLayer - rat 1	0	-0.40297163	0.022391792	false
training	oneLayer	oneLayer - rat 1	0	-0.41309685	0.018197779	false
training	oneLayer	oneLayer - rat 1	0	-0.4202311	0.011063529	false
training	oneLayer	oneLayer - rat 1	0	-0.4279746	0.003320018	false
training	oneLayer	oneLayer - rat 1	0	-0.43192086	-0.006207083	false
training	oneLayer	oneLayer - rat 1	0	-0.43606484	-0.016211478	false
training	oneLayer	oneLayer - rat 1	0	-0.44012892	-0.02602307	false
training	oneLayer	oneLayer - rat 1	0	-0.4440844	-0.035572488	false
training	oneLayer	oneLayer - rat 1	0	-0.44816998	-0.04543588	false
training	oneLayer	oneLayer - rat 1	0	-0.44816998	-0.056223553	false
training	oneLayer	oneLayer - rat 1	0	-0.4440931	-0.06606596	false
training	oneLayer	oneLayer - rat 1	0	-0.4366432	-0.07351584	false
training	oneLayer	oneLayer - rat 1	0	-0.42686296	-0.07756696	false
training	oneLayer	oneLayer - rat 1	0	-0.41668883	-0.07756696	false
training	oneLayer	oneLayer - rat 1	0	-0.40718117	-0.073628746	false
training	oneLayer	oneLayer - rat 1	0	-0.39940548	-0.065853074	false
training	oneLayer	oneLayer - rat 1	0	-0.39555	-0.056545112	false
training	oneLayer	oneLayer - rat 1	0	-0.39142746	-0.046592373	false
training	oneLayer	oneLayer - rat 1	0	-0.387293	-0.036610927	false
training	oneLayer	oneLayer - rat 1	0	-0.3831183	-0.026532335	false
training	oneLayer	oneLayer - rat 1	0	-0.37913337	-0.016911836	false
training	oneLayer	oneLayer - rat 1	0	-0.37497497	-0.0068725566	false
training	oneLayer	oneLayer - rat 1	0	-0.37102026	0.0026749591	false
training	oneLayer	oneLayer - rat 1	0	-0.3670421	0.012279115	false
training	oneLayer	oneLayer - rat 1	0	-0.3629273	0.02221315	false
training	oneLayer	oneLayer - rat 1	0	-0.35882208	0.03212399	false
training	oneLayer	oneLayer - rat 1	0	-0.35479933	0.04183576	false
training	oneLayer	oneLayer - rat 1	0	-0.3505931	0.051990528	false
training	oneLayer	oneLayer - rat 1	0	-0.34655458	0.061740372	false
training	oneLayer	oneLayer - rat 1	0	-0.3423932	0.07178688	false
training	oneLayer	oneLayer - rat 1	0	-0.3385655	0.08102772	false
training	oneLayer	oneLayer - rat 1	0	-0.33451486	0.090806834	false
training	oneLayer	oneLayer - rat 1	0	-0.3304866	0.100531936	false
training	oneLayer	oneLayer - rat 1	0	-0.32643992	0.11030149	false
training	oneLayer	oneLayer - rat 1	0	-0.32237765	0.12010868	false
training	oneLayer	oneLayer - rat 1	0	-0.31849533	0.12948142	false
training	oneLayer	oneLayer - rat 1	0	-0.31849533	0.13962884	false
training	oneLayer	oneLayer - rat 1	0	-0.31849533	0.14970067	false
training	oneLayer	oneLayer - rat 1	0	-0.31849533	0.16051693	false
training	oneLayer	oneLayer - rat 1	0	-0.31849536	0.17123075	false
training	oneLayer	oneLayer - rat 1	0	-0.31849536	0.18141685	false
training	oneLayer	oneLayer - rat 1	0	-0.31849536	0.19191279	false
training	oneLayer	oneLayer - rat 1	0	-0.31849536	0.20210263	false
training	oneLayer	oneLayer - rat 1	0	-0.31849536	0.21239367	false
training	oneLayer	oneLayer - rat 1	0	-0.31849536	0.22265087	false
training	oneLayer	oneLayer - rat 1	0	-0.31849536	0.23343873	false
training	oneLayer	oneLayer - rat 1	0	-0.31849536	0.24426013	false
training	oneLayer	oneLayer - rat 1	0	-0.31849536	0.25449413	false
training	oneLayer	oneLayer - rat 1	0	-0.31849536	0.26524606	false
training	oneLayer	oneLayer - rat 1	0	-0.31849536	0.2758769	false
training	oneLayer	oneLayer - rat 1	0	-0.31448698	0.285554	false
training	oneLayer	oneLayer - rat 1	0	-0.30708286	0.29295814	false
training	oneLayer	oneLayer - rat 1	0	-0.29725873	0.2970274	false
training	oneLayer	oneLayer - rat 1	0	-0.28687933	0.29702744	false
training	oneLayer	oneLayer - rat 1	0	-0.27604908	0.29702744	false
training	oneLayer	oneLayer - rat 1	0	-0.26579154	0.29702744	false
training	oneLayer	oneLayer - rat 1	0	-0.25589386	0.29292768	false
training	oneLayer	oneLayer - rat 1	0	-0.24628001	0.2889455	false
training	oneLayer	oneLayer - rat 1	0	-0.2363789	0.2848443	false
training	oneLayer	oneLayer - rat 1	0	-0.22705868	0.28098378	false
training	oneLayer	oneLayer - rat 1	0	-0.21703954	0.2768337	false
training	oneLayer	oneLayer - rat 1	0	-0.20720118	0.2727585	false
training	oneLayer	oneLayer - rat 1	0	-0.19773935	0.2688393	false
training	oneLayer	oneLayer - rat 1	0	-0.188492	0.26500893	false
training	oneLayer	oneLayer - rat 1	0	-0.17898722	0.26107192	false
training	oneLayer	oneLayer - rat 1	0	-0.16965203	0.25720516	false
training	oneLayer	oneLayer - rat 1	0	-0.16027771	0.25332218	false
training	oneLayer	oneLayer - rat 1	0	-0.15093304	0.24945152	false
training	oneLayer	oneLayer - rat 1	0	-0.14098409	0.24533051	false
training	oneLayer	oneLayer - rat 1	0	-0.13086495	0.24113904	false
training	oneLayer	oneLayer - rat 1	0	-0.12160657	0.23730409	false
training	oneLayer	oneLayer - rat 1	0	-0.112049446	0.2333454	false
training	oneLayer	oneLayer - rat 1	0	-0.10195434	0.22916387	false
training	oneLayer	oneLayer - rat 1	0	-0.092174515	0.22511294	false
training	oneLayer	oneLayer - rat 1	0	-0.08202976	0.22091085	false
training	oneLayer	oneLayer - rat 1	0	-0.07252362	0.21697327	false
training	oneLayer	oneLayer - rat 1	0	-0.06303453	0.21304277	false
training	oneLayer	oneLayer - rat 1	0	-0.05367895	0.20916757	false
training	oneLayer	oneLayer - rat 1	0	-0.04401843	0.20516604	false
training	oneLayer	oneLayer - rat 1	0	-0.034216486	0.20110595	false
training	oneLayer	oneLayer - rat 1	0	-0.024599874	0.19712262	false
training	oneLayer	oneLayer - rat 1	0	-0.014988551	0.19314149	false
training	oneLayer	oneLayer - rat 1	0	-0.0048486544	0.1889414	false
training	oneLayer	oneLayer - rat 1	0	0.004844687	0.18492629	false
training	oneLayer	oneLayer - rat 1	0	0.014112479	0.18108745	false
training	oneLayer	oneLayer - rat 1	0	0.023821697	0.17706576	false
training	oneLayer	oneLayer - rat 1	0	0.03314067	0.17320572	false
training	oneLayer	oneLayer - rat 1	0	0.043219805	0.1690308	false
training	oneLayer	oneLayer - rat 1	0	0.052701402	0.1651034	false
training	oneLayer	oneLayer - rat 1	0	0.062224638	0.16115876	false
training	oneLayer	oneLayer - rat 1	0	0.071591765	0.15727876	false
training	oneLayer	oneLayer - rat 1	0	0.08126682	0.15327123	false
training	oneLayer	oneLayer - rat 1	0	0.09084459	0.14930399	false
training	oneLayer	oneLayer - rat 1	0	0.10036609	0.14536005	false
training	oneLayer	oneLayer - rat 1	0	0.11049188	0.14116581	false
training	oneLayer	oneLayer - rat 1	0	0.120239116	0.13712837	false
training	oneLayer	oneLayer - rat 1	0	0.13014106	0.13302685	false
training	oneLayer	oneLayer - rat 1	0	0.14025244	0.12883858	false
training	oneLayer	oneLayer - rat 1	0	0.15018469	0.12472452	false
training	oneLayer	oneLayer - rat 1	0	0.15985163	0.12072035	false
training	oneLayer	oneLayer - rat 1	0	0.16996218	0.116532415	false
training	oneLayer	oneLayer - rat 1	0	0.1800371	0.112359256	false
training	oneLayer	oneLayer - rat 1	0	0.18946879	0.10845252	false
training	oneLayer	oneLayer - rat 1	0	0.19878729	0.10459267	false
training	oneLayer	oneLayer - rat 1	0	0.20856373	0.100543134	false
training	oneLayer	oneLayer - rat 1	0	0.21820393	0.09655004	false
training	oneLayer	oneLayer - rat 1	0	0.22783412	0.09256108	false
training	oneLayer	oneLayer - rat 1	0	0.23795712	0.088368006	false
training	oneLayer	oneLayer - rat 1	0	0.24770296	0.08433115	false
training	oneLayer	oneLayer - rat 1	0	0.25761786	0.08022427	false
training	oneLayer	oneLayer - rat 1	0	0.2675712	0.07610146	false
training	oneLayer	oneLayer - rat 1	0	0.27682036	0.072270334	false
training	oneLayer	oneLayer - rat 1	0	0.28649676	0.068262234	false
training	oneLayer	oneLayer - rat 1	0	0.29608515	0.0642906	false
training	oneLayer	oneLayer - rat 1	0	0.30589837	0.06022583	false
training	oneLayer	oneLayer - rat 1	0	0.3159361	0.056068078	false
training	oneLayer	oneLayer - rat 1	0	0.32570776	0.05202051	false
training	oneLayer	oneLayer - rat 1	0	0.33548656	0.047970004	false
training	oneLayer	oneLayer - rat 1	0	0.34549034	0.043826304	false
training	oneLayer	oneLayer - rat 1	0	0.35492432	0.039918624	false
training	oneLayer	oneLayer - rat 1	0	0.364505	0.035950188	false
training	oneLayer	oneLayer - rat 1	0	0.37385252	0.03207832	false
training	oneLayer	oneLayer - rat 1	0	0.383917	0.027909476	false
training	oneLayer	oneLayer - rat 1	0	0.39396167	0.023748836	false
training	oneLayer	oneLayer - rat 1	0	0.40369055	0.019719	false
training	oneLayer	oneLayer - rat 1	0	0.4135932	0.015617189	false
training	oneLayer	oneLayer - rat 1	0	0.42132348	0.007886919	false
training	oneLayer	oneLayer - rat 1	0	0.42528826	-0.0016849035	false
training	oneLayer	oneLayer - rat 1	0	0.42528826	-0.012417173	false
training	oneLayer	oneLayer - rat 1	0	0.4213323	-0.02196773	false
training	oneLayer	oneLayer - rat 1	0	0.41366142	-0.029638603	false
training	oneLayer	oneLayer - rat 1	0	0.4035058	-0.0338452	false
training	oneLayer	oneLayer - rat 1	0	0.3927822	-0.033845205	false
training	oneLayer	oneLayer - rat 1	0	0.38211256	-0.033845205	false
training	oneLayer	oneLayer - rat 1	0	0.37131238	-0.033845205	false
training	oneLayer	oneLayer - rat 1	0	0.3607475	-0.033845205	false
training	oneLayer	oneLayer - rat 1	0	0.35018307	-0.03384521	false
training	oneLayer	oneLayer - rat 1	0	0.33940154	-0.03384521	false
training	oneLayer	oneLayer - rat 1	0	0.32862836	-0.03384521	false
training	oneLayer	oneLayer - rat 1	0	0.31850326	-0.03384521	false
training	oneLayer	oneLayer - rat 1	0	0.3077877	-0.033845212	false
training	oneLayer	oneLayer - rat 1	0	0.29765546	-0.033845212	false
training	oneLayer	oneLayer - rat 1	0	0.28729478	-0.033845212	false
training	oneLayer	oneLayer - rat 1	0	0.2766262	-0.033845212	false
training	oneLayer	oneLayer - rat 1	0	0.26563412	-0.033845216	false
training	oneLayer	oneLayer - rat 1	0	0.25549683	-0.033845216	false
training	oneLayer	oneLayer - rat 1	0	0.2447284	-0.033845216	false
training	oneLayer	oneLayer - rat 1	0	0.23381302	-0.033845216	false
training	oneLayer	oneLayer - rat 1	0	0.22314796	-0.03384522	false
training	oneLayer	oneLayer - rat 1	0	0.21312281	-0.03384522	false
training	oneLayer	oneLayer - rat 1	0	0.20293042	-0.03384522	false
training	oneLayer	oneLayer - rat 1	0	0.19275491	-0.03384522	false
training	oneLayer	oneLayer - rat 1	0	0.18191284	-0.03384522	false
training	oneLayer	oneLayer - rat 1	0	0.17119049	-0.033845223	false
training	oneLayer	oneLayer - rat 1	0	0.16092059	-0.033845223	false
training	oneLayer	oneLayer - rat 1	0	0.15001987	-0.033845223	false
training	oneLayer	oneLayer - rat 1	0	0.13996574	-0.033845223	false
training	oneLayer	oneLayer - rat 1	0	0.12913227	-0.033845227	false
training	oneLayer	oneLayer - rat 1	0	0.1185614	-0.033845227	false
training	oneLayer	oneLayer - rat 1	0	0.10818709	-0.033845227	false
training	oneLayer	oneLayer - rat 1	0	0.09800099	-0.033845227	false
training	oneLayer	oneLayer - rat 1	0	0.08783939	-0.03384523	false
training	oneLayer	oneLayer - rat 1	0	0.07742069	-0.03384523	false
training	oneLayer	oneLayer - rat 1	0	0.06702582	-0.03384523	false
training	oneLayer	oneLayer - rat 1	0	0.05697397	-0.03384523	false
training	oneLayer	oneLayer - rat 1	0	0.045982264	-0.033845235	false
training	oneLayer	oneLayer - rat 1	0	0.03522977	-0.033845235	false
training	oneLayer	oneLayer - rat 1	0	0.024722874	-0.033845235	false
training	oneLayer	oneLayer - rat 1	0	0.014250473	-0.033845235	false
training	oneLayer	oneLayer - rat 1	0	0.0037082187	-0.03384524	false
training	oneLayer	oneLayer - rat 1	0	-0.006549816	-0.03384524	false
training	oneLayer	oneLayer - rat 1	0	-0.016798928	-0.03384524	false
training	oneLayer	oneLayer - rat 1	0	-0.026992979	-0.03384524	false
training	oneLayer	oneLayer - rat 1	0	-0.037442554	-0.033845242	false
training	oneLayer	oneLayer - rat 1	0	-0.04779163	-0.033845242	false
training	oneLayer	oneLayer - rat 1	0	-0.058129497	-0.033845242	false
training	oneLayer	oneLayer - rat 1	0	-0.06892434	-0.033845242	false
training	oneLayer	oneLayer - rat 1	0	-0.07975639	-0.033845246	false
training	oneLayer	oneLayer - rat 1	0	-0.090616114	-0.033845246	false
training	oneLayer	oneLayer - rat 1	0	-0.10125271	-0.033845246	false
training	oneLayer	oneLayer - rat 1	0	-0.11142027	-0.033845246	false
training	oneLayer	oneLayer - rat 1	0	-0.12218199	-0.03384525	false
training	oneLayer	oneLayer - rat 1	0	-0.1326594	-0.03384525	false
training	oneLayer	oneLayer - rat 1	0	-0.1432647	-0.03384525	false
training	oneLayer	oneLayer - rat 1	0	-0.15344843	-0.03384525	false
training	oneLayer	oneLayer - rat 1	0	-0.16354732	-0.033845253	false
training	oneLayer	oneLayer - rat 1	0	-0.17442694	-0.033845253	false
training	oneLayer	oneLayer - rat 1	0	-0.1845908	-0.033845253	false
training	oneLayer	oneLayer - rat 1	0	-0.19523087	-0.033845253	false
training	oneLayer	oneLayer - rat 1	0	-0.20580225	-0.033845257	false
training	oneLayer	oneLayer - rat 1	0	-0.21619451	-0.033845257	false
training	oneLayer	oneLayer - rat 1	0	-0.2268566	-0.033845257	false
training	oneLayer	oneLayer - rat 1	0	-0.23746464	-0.033845257	false
training	oneLayer	oneLayer - rat 1	0	-0.24759887	-0.03384526	false
training	oneLayer	oneLayer - rat 1	0	-0.25768164	-0.03384526	false
training	oneLayer	oneLayer - rat 1	0	-0.26843652	-0.03384526	false
training	oneLayer	oneLayer - rat 1	0	-0.27851972	-0.03384526	false
training	oneLayer	oneLayer - rat 1	0	-0.28914452	-0.033845264	false
training	oneLayer	oneLayer - rat 1	0	-0.2995057	-0.033845264	false
training	oneLayer	oneLayer - rat 1	0	-0.30978084	-0.033845264	false
training	oneLayer	oneLayer - rat 1	0	-0.3201633	-0.033845264	false
training	oneLayer	oneLayer - rat 1	0	-0.33071268	-0.03384527	false
training	oneLayer	oneLayer - rat 1	0	-0.3416	-0.03384527	false
training	oneLayer	oneLayer - rat 1	0	-0.3518616	-0.03384527	false
training	oneLayer	oneLayer - rat 1	0	-0.361916	-0.03384527	false
training	oneLayer	oneLayer - rat 1	0	-0.37231353	-0.03384527	false
training	oneLayer	oneLayer - rat 1	0	-0.3821822	-0.029757524	false
training	oneLayer	oneLayer - rat 1	0	-0.39181146	-0.025768962	false
training	oneLayer	oneLayer - rat 1	0	-0.40114102	-0.021904528	false
training	oneLayer	oneLayer - rat 1	0	-0.41040936	-0.018065462	false
training	oneLayer	oneLayer - rat 1	0	-0.41771	-0.010764811	false
training	oneLayer	oneLayer - rat 1	0	-0.42184126	-7.911037E-4	false
training	oneLayer	oneLayer - rat 1	0	-0.42184126	0.009529215	false
training	oneLayer	oneLayer - rat 1	0	-0.41781893	0.019239966	false
training	oneLayer	oneLayer - rat 1	0	-0.4107109	0.026348	false
training	oneLayer	oneLayer - rat 1	0	-0.40136293	0.03022005	false
training	oneLayer	oneLayer - rat 1	0	-0.39076528	0.03022005	false
training	oneLayer	oneLayer - rat 1	0	-0.38067383	0.03022005	false
training	oneLayer	oneLayer - rat 1	0	-0.37037614	0.03022005	false
training	oneLayer	oneLayer - rat 1	0	-0.36031953	0.03022005	false
training	oneLayer	oneLayer - rat 1	0	-0.349847	0.03022005	false
training	oneLayer	oneLayer - rat 1	0	-0.3398066	0.03022005	false
training	oneLayer	oneLayer - rat 1	0	-0.32971084	0.03022005	false
training	oneLayer	oneLayer - rat 1	0	-0.31962252	0.03022005	false
training	oneLayer	oneLayer - rat 1	0	-0.30898392	0.03022005	false
training	oneLayer	oneLayer - rat 1	0	-0.29889354	0.03022005	false
training	oneLayer	oneLayer - rat 1	0	-0.2884307	0.03022005	false
training	oneLayer	oneLayer - rat 1	0	-0.27826914	0.03022005	false
training	oneLayer	oneLayer - rat 1	0	-0.26818624	0.03022005	false
training	oneLayer	oneLayer - rat 1	0	-0.25764942	0.03022005	false
training	oneLayer	oneLayer - rat 1	0	-0.24686001	0.03022005	false
training	oneLayer	oneLayer - rat 1	0	-0.23675527	0.03022005	false
training	oneLayer	oneLayer - rat 1	0	-0.22597174	0.03022005	false
training	oneLayer	oneLayer - rat 1	0	-0.21548142	0.03022005	false
training	oneLayer	oneLayer - rat 1	0	-0.20499158	0.03022005	false
training	oneLayer	oneLayer - rat 1	0	-0.1940125	0.03022005	false
training	oneLayer	oneLayer - rat 1	0	-0.18325678	0.03022005	false
training	oneLayer	oneLayer - rat 1	0	-0.172561	0.03022005	false
training	oneLayer	oneLayer - rat 1	0	-0.16169916	0.03022005	false
training	oneLayer	oneLayer - rat 1	0	-0.15148646	0.03022005	false
training	oneLayer	oneLayer - rat 1	0	-0.14112902	0.03022005	false
training	oneLayer	oneLayer - rat 1	0	-0.13086085	0.03022005	false
training	oneLayer	oneLayer - rat 1	0	-0.120113656	0.03022005	false
training	oneLayer	oneLayer - rat 1	0	-0.10927434	0.03022005	false
training	oneLayer	oneLayer - rat 1	0	-0.09885065	0.03022005	false
training	oneLayer	oneLayer - rat 1	0	-0.08788863	0.03022005	false
training	oneLayer	oneLayer - rat 1	0	-0.07745611	0.03022005	false
training	oneLayer	oneLayer - rat 1	0	-0.06677845	0.03022005	false
training	oneLayer	oneLayer - rat 1	0	-0.056430362	0.03022005	false
training	oneLayer	oneLayer - rat 1	0	-0.04588084	0.03022005	false
training	oneLayer	oneLayer - rat 1	0	-0.035681687	0.03022005	false
training	oneLayer	oneLayer - rat 1	0	-0.02502212	0.03022005	false
training	oneLayer	oneLayer - rat 1	0	-0.01482401	0.03022005	false
training	oneLayer	oneLayer - rat 1	0	-0.0041407864	0.03022005	false
training	oneLayer	oneLayer - rat 1	0	0.0059671965	0.03022005	false
training	oneLayer	oneLayer - rat 1	0	0.016361518	0.03022005	false
training	oneLayer	oneLayer - rat 1	0	0.02665673	0.03022005	false
training	oneLayer	oneLayer - rat 1	0	0.036838192	0.03022005	false
training	oneLayer	oneLayer - rat 1	0	0.047278024	0.03022005	false
training	oneLayer	oneLayer - rat 1	0	0.057349693	0.03022005	false
training	oneLayer	oneLayer - rat 1	0	0.06790158	0.03022005	false
training	oneLayer	oneLayer - rat 1	0	0.07826434	0.03022005	false
training	oneLayer	oneLayer - rat 1	0	0.088987336	0.03022005	false
training	oneLayer	oneLayer - rat 1	0	0.09912117	0.03022005	false
training	oneLayer	oneLayer - rat 1	0	0.10922808	0.03022005	false
training	oneLayer	oneLayer - rat 1	0	0.119617045	0.03022005	false
training	oneLayer	oneLayer - rat 1	0	0.1299878	0.03022005	false
training	oneLayer	oneLayer - rat 1	0	0.140929	0.03022005	false
training	oneLayer	oneLayer - rat 1	0	0.15149638	0.03022005	false
training	oneLayer	oneLayer - rat 1	0	0.16219845	0.03022005	false
training	oneLayer	oneLayer - rat 1	0	0.1731443	0.03022005	false
training	oneLayer	oneLayer - rat 1	0	0.18318316	0.03022005	false
training	oneLayer	oneLayer - rat 1	0	0.19321257	0.03022005	false
training	oneLayer	oneLayer - rat 1	0	0.20341276	0.03022005	false
training	oneLayer	oneLayer - rat 1	0	0.21350352	0.03022005	false
training	oneLayer	oneLayer - rat 1	0	0.22401899	0.03022005	false
training	oneLayer	oneLayer - rat 1	0	0.23457348	0.03022005	false
training	oneLayer	oneLayer - rat 1	0	0.24494126	0.03022005	false
training	oneLayer	oneLayer - rat 1	0	0.25508726	0.03022005	false
training	oneLayer	oneLayer - rat 1	0	0.26580393	0.03022005	false
training	oneLayer	oneLayer - rat 1	0	0.27613732	0.03022005	false
training	oneLayer	oneLayer - rat 1	0	0.2861727	0.03022005	false
training	oneLayer	oneLayer - rat 1	0	0.29692474	0.03022005	false
training	oneLayer	oneLayer - rat 1	0	0.3078292	0.03022005	false
training	oneLayer	oneLayer - rat 1	0	0.31787378	0.03022005	false
training	oneLayer	oneLayer - rat 1	0	0.32802793	0.03022005	false
training	oneLayer	oneLayer - rat 1	0	0.338667	0.03022005	false
training	oneLayer	oneLayer - rat 1	0	0.34954104	0.03022005	false
training	oneLayer	oneLayer - rat 1	0	0.35997075	0.03022005	false
training	oneLayer	oneLayer - rat 1	0	0.3699975	0.03022005	false
training	oneLayer	oneLayer - rat 1	0	0.38099748	0.03022005	false
training	oneLayer	oneLayer - rat 1	0	0.39075437	0.026178604	false
training	oneLayer	oneLayer - rat 1	0	0.40089083	0.021979949	false
training	oneLayer	oneLayer - rat 1	0	0.41026545	0.01809685	false
training	oneLayer	oneLayer - rat 1	0	0.41774353	0.010618775	false
training	oneLayer	oneLayer - rat 1	0	0.42192242	5.300558E-4	false
training	oneLayer	oneLayer - rat 1	0	0.42192242	-0.010281689	false
training	oneLayer	oneLayer - rat 1	0	0.41785774	-0.020094683	false
training	oneLayer	oneLayer - rat 1	0	0.41069546	-0.02725695	false
training	oneLayer	oneLayer - rat 1	0	0.401031	-0.031260107	false
training	oneLayer	oneLayer - rat 1	0	0.390699	-0.031260107	false
training	oneLayer	oneLayer - rat 1	0	0.38088894	-0.027196648	false
training	oneLayer	oneLayer - rat 1	0	0.3709882	-0.023095628	false
training	oneLayer	oneLayer - rat 1	0	0.3609297	-0.018929258	false
training	oneLayer	oneLayer - rat 1	0	0.35080406	-0.01473508	false
training	oneLayer	oneLayer - rat 1	0	0.34151527	-0.0108875325	false
training	oneLayer	oneLayer - rat 1	0	0.33160287	-0.0067816805	false
training	oneLayer	oneLayer - rat 1	0	0.3217942	-0.0027188016	false
training	oneLayer	oneLayer - rat 1	0	0.31236696	0.0011860945	false
training	oneLayer	oneLayer - rat 1	0	0.3029999	0.0050660498	false
training	oneLayer	oneLayer - rat 1	0	0.29287428	0.009260222	false
training	oneLayer	oneLayer - rat 1	0	0.28280163	0.013432462	false
training	oneLayer	oneLayer - rat 1	0	0.27346626	0.017299294	false
training	oneLayer	oneLayer - rat 1	0	0.26371866	0.02133688	false
training	oneLayer	oneLayer - rat 1	0	0.25360742	0.025525095	false
training	oneLayer	oneLayer - rat 1	0	0.24412113	0.029454447	false
training	oneLayer	oneLayer - rat 1	0	0.2347857	0.033321306	false
training	oneLayer	oneLayer - rat 1	0	0.22519948	0.037292056	false
training	oneLayer	oneLayer - rat 1	0	0.21538801	0.041356098	false
training	oneLayer	oneLayer - rat 1	0	0.20593171	0.04527303	false
training	oneLayer	oneLayer - rat 1	0	0.19617184	0.0493157	false
training	oneLayer	oneLayer - rat 1	0	0.18625067	0.053425185	false
training	oneLayer	oneLayer - rat 1	0	0.17669986	0.05738126	false
training	oneLayer	oneLayer - rat 1	0	0.16709927	0.06135796	false
training	oneLayer	oneLayer - rat 1	0	0.15743102	0.06536268	false
training	oneLayer	oneLayer - rat 1	0	0.14762463	0.069424614	false
training	oneLayer	oneLayer - rat 1	0	0.1383617	0.07326145	false
training	oneLayer	oneLayer - rat 1	0	0.12874998	0.077242754	false
training	oneLayer	oneLayer - rat 1	0	0.11862862	0.08143516	false
training	oneLayer	oneLayer - rat 1	0	0.10855695	0.085606985	false
training	oneLayer	oneLayer - rat 1	0	0.09881502	0.08964223	false
training	oneLayer	oneLayer - rat 1	0	0.089063294	0.09368152	false
training	oneLayer	oneLayer - rat 1	0	0.078983866	0.09785657	false
training	oneLayer	oneLayer - rat 1	0	0.06888353	0.10204026	false
training	oneLayer	oneLayer - rat 1	0	0.059514653	0.10592098	false
training	oneLayer	oneLayer - rat 1	0	0.049648985	0.11000747	false
training	oneLayer	oneLayer - rat 1	0	0.039951578	0.11402427	false
training	oneLayer	oneLayer - rat 1	0	0.029789332	0.11823361	false
training	oneLayer	oneLayer - rat 1	0	0.01968088	0.12242067	false
training	oneLayer	oneLayer - rat 1	0	0.009740581	0.12653808	false
training	oneLayer	oneLayer - rat 1	0	-2.9359444E-4	0.13069437	false
training	oneLayer	oneLayer - rat 1	0	-0.009979052	0.13470621	false
training	oneLayer	oneLayer - rat 1	0	-0.02007605	0.13888854	false
training	oneLayer	oneLayer - rat 1	0	-0.030023387	0.14300886	false
training	oneLayer	oneLayer - rat 1	0	-0.039454427	0.14691532	false
training	oneLayer	oneLayer - rat 1	0	-0.049079992	0.15090236	false
training	oneLayer	oneLayer - rat 1	0	-0.05888953	0.15496561	false
training	oneLayer	oneLayer - rat 1	0	-0.06817565	0.15881205	false
training	oneLayer	oneLayer - rat 1	0	-0.0781914	0.16296071	false
training	oneLayer	oneLayer - rat 1	0	-0.08770477	0.16690128	false
training	oneLayer	oneLayer - rat 1	0	-0.09755723	0.1709823	false
training	oneLayer	oneLayer - rat 1	0	-0.10738815	0.1750544	false
training	oneLayer	oneLayer - rat 1	0	-0.11706419	0.17906235	false
training	oneLayer	oneLayer - rat 1	0	-0.12641463	0.18293543	false
training	oneLayer	oneLayer - rat 1	0	-0.13607815	0.18693818	false
training	oneLayer	oneLayer - rat 1	0	-0.14573584	0.19093855	false
training	oneLayer	oneLayer - rat 1	0	-0.1554779	0.19497383	false
training	oneLayer	oneLayer - rat 1	0	-0.16491844	0.19888423	false
training	oneLayer	oneLayer - rat 1	0	-0.17425096	0.2027499	false
training	oneLayer	oneLayer - rat 1	0	-0.18372466	0.20667402	false
training	oneLayer	oneLayer - rat 1	0	-0.19353	0.21073553	false
training	oneLayer	oneLayer - rat 1	0	-0.20317152	0.21472917	false
training	oneLayer	oneLayer - rat 1	0	-0.21262416	0.21864459	false
training	oneLayer	oneLayer - rat 1	0	-0.22246033	0.22271886	false
training	oneLayer	oneLayer - rat 1	0	-0.23174758	0.22656578	false
training	oneLayer	oneLayer - rat 1	0	-0.2391729	0.2339911	false
training	oneLayer	oneLayer - rat 1	0	-0.24624923	0.24106742	false
training	oneLayer	oneLayer - rat 1	0	-0.2535013	0.24831949	false
training	oneLayer	oneLayer - rat 1	0	-0.26066115	0.25547937	false
training	oneLayer	oneLayer - rat 1	0	-0.2678776	0.26269582	false
training	oneLayer	oneLayer - rat 1	0	-0.274973	0.26979122	false
training	oneLayer	oneLayer - rat 1	0	-0.2821627	0.2769809	false
training	oneLayer	oneLayer - rat 1	0	-0.28957212	0.2843903	false
training	oneLayer	oneLayer - rat 1	0	-0.29365742	0.29425314	false
training	oneLayer	oneLayer - rat 1	0	-0.29365742	0.30522898	false
training	oneLayer	oneLayer - rat 1	0	-0.28956348	0.31511262	false
training	oneLayer	oneLayer - rat 1	0	-0.28184724	0.32282886	false
training	oneLayer	oneLayer - rat 1	0	-0.27190527	0.32694694	false
training	oneLayer	oneLayer - rat 1	0	-0.26095346	0.32694694	false
training	oneLayer	oneLayer - rat 1	0	-0.25095066	0.32280365	false
training	oneLayer	oneLayer - rat 1	0	-0.2407941	0.31859666	false
training	oneLayer	oneLayer - rat 1	0	-0.23106432	0.31456643	false
training	oneLayer	oneLayer - rat 1	0	-0.2212334	0.31049433	false
training	oneLayer	oneLayer - rat 1	0	-0.21153955	0.30647904	false
training	oneLayer	oneLayer - rat 1	0	-0.20182292	0.30245426	false
training	oneLayer	oneLayer - rat 1	0	-0.19235015	0.29853052	false
training	oneLayer	oneLayer - rat 1	0	-0.18272658	0.29454428	false
training	oneLayer	oneLayer - rat 1	0	-0.17342183	0.29069012	false
training	oneLayer	oneLayer - rat 1	0	-0.16386108	0.28672993	false
training	oneLayer	oneLayer - rat 1	0	-0.15407795	0.28267762	false
training	oneLayer	oneLayer - rat 1	0	-0.14424759	0.27860576	false
training	oneLayer	oneLayer - rat 1	0	-0.13438049	0.27451867	false
training	oneLayer	oneLayer - rat 1	0	-0.124922514	0.27060103	false
training	oneLayer	oneLayer - rat 1	0	-0.115316465	0.2666221	false
training	oneLayer	oneLayer - rat 1	0	-0.10538036	0.26250643	false
training	oneLayer	oneLayer - rat 1	0	-0.095694005	0.2584942	false
training	oneLayer	oneLayer - rat 1	0	-0.08595416	0.25445983	false
training	oneLayer	oneLayer - rat 1	0	-0.076618694	0.25059295	false
training	oneLayer	oneLayer - rat 1	0	-0.06704626	0.24662791	false
training	oneLayer	oneLayer - rat 1	0	-0.05777491	0.24278758	false
training	oneLayer	oneLayer - rat 1	0	-0.04820786	0.23882478	false
training	oneLayer	oneLayer - rat 1	0	-0.03835163	0.2347422	false
training	oneLayer	oneLayer - rat 1	0	-0.028242163	0.23055471	false
training	oneLayer	oneLayer - rat 1	0	-0.018872458	0.22667365	false
training	oneLayer	oneLayer - rat 1	0	-0.009273301	0.22269756	false
training	oneLayer	oneLayer - rat 1	0	5.3183595E-4	0.21863613	false
training	oneLayer	oneLayer - rat 1	0	0.010419889	0.21454036	false
training	oneLayer	oneLayer - rat 1	0	0.019946858	0.21059416	false
training	oneLayer	oneLayer - rat 1	0	0.02932179	0.20671093	false
training	oneLayer	oneLayer - rat 1	0	0.03903624	0.20268707	false
training	oneLayer	oneLayer - rat 1	0	0.04836046	0.19882485	false
training	oneLayer	oneLayer - rat 1	0	0.057731334	0.19494331	false
training	oneLayer	oneLayer - rat 1	0	0.06698194	0.19111158	false
training	oneLayer	oneLayer - rat 1	0	0.07677935	0.18705335	false
training	oneLayer	oneLayer - rat 1	0	0.08605257	0.18321227	false
training	oneLayer	oneLayer - rat 1	0	0.095878415	0.17914227	false
training	oneLayer	oneLayer - rat 1	0	0.105527304	0.17514555	false
training	oneLayer	oneLayer - rat 1	0	0.11495663	0.1712398	false
training	oneLayer	oneLayer - rat 1	0	0.12420621	0.1674085	false
training	oneLayer	oneLayer - rat 1	0	0.13417524	0.16327919	false
training	oneLayer	oneLayer - rat 1	0	0.14427489	0.15909578	false
training	oneLayer	oneLayer - rat 1	0	0.15357488	0.15524359	false
training	oneLayer	oneLayer - rat 1	0	0.16351338	0.15112692	false
training	oneLayer	oneLayer - rat 1	0	0.1733815	0.14703941	false
training	oneLayer	oneLayer - rat 1	0	0.18264532	0.14320222	false
training	oneLayer	oneLayer - rat 1	0	0.19192997	0.13935639	false
training	oneLayer	oneLayer - rat 1	0	0.20166153	0.13532543	false
training	oneLayer	oneLayer - rat 1	0	0.21152243	0.13124092	false
training	oneLayer	oneLayer - rat 1	0	0.22117262	0.12724368	false
training	oneLayer	oneLayer - rat 1	0	0.23095173	0.12319303	false
training	oneLayer	oneLayer - rat 1	0	0.24037412	0.11929015	false
training	oneLayer	oneLayer - rat 1	0	0.2503911	0.11514098	false
training	oneLayer	oneLayer - rat 1	0	0.2601982	0.11107874	false
training	oneLayer	oneLayer - rat 1	0	0.27035308	0.10687245	false
training	oneLayer	oneLayer - rat 1	0	0.27968737	0.10300606	false
training	oneLayer	oneLayer - rat 1	0	0.2898222	0.09880807	false
training	oneLayer	oneLayer - rat 1	0	0.299394	0.094843306	false
training	oneLayer	oneLayer - rat 1	0	0.30916113	0.09079762	false
training	oneLayer	oneLayer - rat 1	0	0.3185193	0.08692134	false
training	oneLayer	oneLayer - rat 1	0	0.32830545	0.08286778	false
training	oneLayer	oneLayer - rat 1	0	0.33784157	0.078917794	false
training	oneLayer	oneLayer - rat 1	0	0.34713185	0.07506962	false
training	oneLayer	oneLayer - rat 1	0	0.3564198	0.07122243	false
training	oneLayer	oneLayer - rat 1	0	0.36657947	0.06701416	false
training	oneLayer	oneLayer - rat 1	0	0.3762073	0.063026175	false
training	oneLayer	oneLayer - rat 1	0	0.3858261	0.05904193	false
training	oneLayer	oneLayer - rat 1	0	0.39539313	0.055079136	false
training	oneLayer	oneLayer - rat 1	0	0.40248337	0.047988888	false
training	oneLayer	oneLayer - rat 1	0	0.4098234	0.04064887	false
training	oneLayer	oneLayer - rat 1	0	0.41750348	0.032968793	false
training	oneLayer	oneLayer - rat 1	0	0.4214901	0.0233442	false
training	oneLayer	oneLayer - rat 1	0	0.4214901	0.012933882	false
training	oneLayer	oneLayer - rat 1	0	0.41745806	0.003199637	false
training	oneLayer	oneLayer - rat 1	0	0.4103435	-0.0039149127	false
training	oneLayer	oneLayer - rat 1	0	0.40081033	-0.007863672	false
training	oneLayer	oneLayer - rat 1	0	0.39045137	-0.00786367	false
training	oneLayer	oneLayer - rat 1	0	0.3807128	-0.0038298194	false
training	oneLayer	oneLayer - rat 1	0	0.3711694	1.2319625E-4	false
training	oneLayer	oneLayer - rat 1	0	0.3617502	0.0040247547	false
training	oneLayer	oneLayer - rat 1	0	0.35236004	0.007914292	false
training	oneLayer	oneLayer - rat 1	0	0.3425846	0.011963402	false
training	oneLayer	oneLayer - rat 1	0	0.33258414	0.016105738	false
training	oneLayer	oneLayer - rat 1	0	0.32279322	0.020161282	false
training	oneLayer	oneLayer - rat 1	0	0.31341326	0.024046578	false
training	oneLayer	oneLayer - rat 1	0	0.3035974	0.028112456	false
training	oneLayer	oneLayer - rat 1	0	0.29365182	0.032232054	false
training	oneLayer	oneLayer - rat 1	0	0.28425625	0.036123816	false
training	oneLayer	oneLayer - rat 1	0	0.27439067	0.040210288	false
training	oneLayer	oneLayer - rat 1	0	0.26447174	0.044318836	false
training	oneLayer	oneLayer - rat 1	0	0.25448486	0.048455548	false
training	oneLayer	oneLayer - rat 1	0	0.24479051	0.052471083	false
training	oneLayer	oneLayer - rat 1	0	0.234835	0.05659479	false
training	oneLayer	oneLayer - rat 1	0	0.22542952	0.060490668	false
training	oneLayer	oneLayer - rat 1	0	0.21590148	0.06443732	false
training	oneLayer	oneLayer - rat 1	0	0.20582977	0.068609156	false
training	oneLayer	oneLayer - rat 1	0	0.19598702	0.072686166	false
training	oneLayer	oneLayer - rat 1	0	0.18638463	0.076663606	false
training	oneLayer	oneLayer - rat 1	0	0.17682904	0.08062167	false
training	oneLayer	oneLayer - rat 1	0	0.16667661	0.08482694	false
training	oneLayer	oneLayer - rat 1	0	0.1566883	0.08896424	false
training	oneLayer	oneLayer - rat 1	0	0.14716555	0.092908695	false
training	oneLayer	oneLayer - rat 1	0	0.13767172	0.096841164	false
training	oneLayer	oneLayer - rat 1	0	0.12822089	0.10075583	false
training	oneLayer	oneLayer - rat 1	0	0.11882787	0.104646556	false
training	oneLayer	oneLayer - rat 1	0	0.1087781	0.10880931	false
training	oneLayer	oneLayer - rat 1	0	0.09887699	0.11291049	false
training	oneLayer	oneLayer - rat 1	0	0.089415215	0.116829686	false
training	oneLayer	oneLayer - rat 1	0	0.08000035	0.120729454	false
training	oneLayer	oneLayer - rat 1	0	0.069992065	0.124875024	false
training	oneLayer	oneLayer - rat 1	0	0.060145937	0.12895343	false
training	oneLayer	oneLayer - rat 1	0	0.05069248	0.13286918	false
training	oneLayer	oneLayer - rat 1	0	0.04104277	0.13686623	false
training	oneLayer	oneLayer - rat 1	0	0.031207211	0.14094025	false
training	oneLayer	oneLayer - rat 1	0	0.02165094	0.1448986	false
training	oneLayer	oneLayer - rat 1	0	0.011865418	0.14895189	false
training	oneLayer	oneLayer - rat 1	0	0.0018836745	0.15308647	false
training	oneLayer	oneLayer - rat 1	0	-0.0074128034	0.1569372	false
training	oneLayer	oneLayer - rat 1	0	-0.017493783	0.16111287	false
training	oneLayer	oneLayer - rat 1	0	-0.027308509	0.16517827	false
training	oneLayer	oneLayer - rat 1	0	-0.03733603	0.1693318	false
training	oneLayer	oneLayer - rat 1	0	-0.046846602	0.17327122	false
training	oneLayer	oneLayer - rat 1	0	-0.05677025	0.17738174	false
training	oneLayer	oneLayer - rat 1	0	-0.06686047	0.18156125	false
training	oneLayer	oneLayer - rat 1	0	-0.07638121	0.18550487	false
training	oneLayer	oneLayer - rat 1	0	-0.08604085	0.18950602	false
training	oneLayer	oneLayer - rat 1	0	-0.09568307	0.19349997	false
training	oneLayer	oneLayer - rat 1	0	-0.1052101	0.1974462	false
training	oneLayer	oneLayer - rat 1	0	-0.11449603	0.20129256	false
training	oneLayer	oneLayer - rat 1	0	-0.12391413	0.20519365	false
training	oneLayer	oneLayer - rat 1	0	-0.13400367	0.2093729	false
training	oneLayer	oneLayer - rat 1	0	-0.14414246	0.21357252	false
training	oneLayer	oneLayer - rat 1	0	-0.1534398	0.2174236	false
training	oneLayer	oneLayer - rat 1	0	-0.16269253	0.22125621	false
training	oneLayer	oneLayer - rat 1	0	-0.17237641	0.22526741	false
training	oneLayer	oneLayer - rat 1	0	-0.18176548	0.2291565	false
training	oneLayer	oneLayer - rat 1	0	-0.19161494	0.23323628	false
training	oneLayer	oneLayer - rat 1	0	-0.20141523	0.23729569	false
training	oneLayer	oneLayer - rat 1	0	-0.21088405	0.2412178	false
training	oneLayer	oneLayer - rat 1	0	-0.22041094	0.24516398	false
training	oneLayer	oneLayer - rat 1	0	-0.2303561	0.2492834	false
training	oneLayer	oneLayer - rat 1	0	-0.2396613	0.25313774	false
training	oneLayer	oneLayer - rat 1	0	-0.24955162	0.25723445	false
training	oneLayer	oneLayer - rat 1	0	-0.25929925	0.26127204	false
training	oneLayer	oneLayer - rat 1	0	-0.2692456	0.26539198	false
training	oneLayer	oneLayer - rat 1	0	-0.2764229	0.27256927	false
training	oneLayer	oneLayer - rat 1	0	-0.28394434	0.28009072	false
training	oneLayer	oneLayer - rat 1	0	-0.29158378	0.28773016	false
training	oneLayer	oneLayer - rat 1	0	-0.30103686	0.29164577	false
training	oneLayer	oneLayer - rat 1	0	-0.31126234	0.29164577	false
training	oneLayer	oneLayer - rat 1	0	-0.3210887	0.28757557	false
training	oneLayer	oneLayer - rat 1	0	-0.32875234	0.27991194	false
training	oneLayer	oneLayer - rat 1	0	-0.3326263	0.27055934	false
training	oneLayer	oneLayer - rat 1	0	-0.3326263	0.26044306	false
training	oneLayer	oneLayer - rat 1	0	-0.32862255	0.25077713	false
training	oneLayer	oneLayer - rat 1	0	-0.32090288	0.24305744	false
training	oneLayer	oneLayer - rat 1	0	-0.31163174	0.2392172	false
training	oneLayer	oneLayer - rat 1	0	-0.30223662	0.23532563	false
training	oneLayer	oneLayer - rat 1	0	-0.29255125	0.23131382	false
training	oneLayer	oneLayer - rat 1	0	-0.28267795	0.22722416	false
training	oneLayer	oneLayer - rat 1	0	-0.2730577	0.22323932	false
training	oneLayer	oneLayer - rat 1	0	-0.26316935	0.21914342	false
training	oneLayer	oneLayer - rat 1	0	-0.25315642	0.21499594	false
training	oneLayer	oneLayer - rat 1	0	-0.24379423	0.21111798	false
training	oneLayer	oneLayer - rat 1	0	-0.23441482	0.2072329	false
training	oneLayer	oneLayer - rat 1	0	-0.2246202	0.20317584	false
training	oneLayer	oneLayer - rat 1	0	-0.21466424	0.19905195	false
training	oneLayer	oneLayer - rat 1	0	-0.20498578	0.195043	false
training	oneLayer	oneLayer - rat 1	0	-0.19568853	0.19119194	false
training	oneLayer	oneLayer - rat 1	0	-0.18563062	0.18702582	false
training	oneLayer	oneLayer - rat 1	0	-0.1763881	0.18319744	false
training	oneLayer	oneLayer - rat 1	0	-0.16701989	0.179317	false
training	oneLayer	oneLayer - rat 1	0	-0.1573286	0.17530273	false
training	oneLayer	oneLayer - rat 1	0	-0.14729321	0.17114593	false
training	oneLayer	oneLayer - rat 1	0	-0.13759431	0.16712852	false
training	oneLayer	oneLayer - rat 1	0	-0.12759927	0.16298844	false
training	oneLayer	oneLayer - rat 1	0	-0.11782582	0.15894014	false
training	oneLayer	oneLayer - rat 1	0	-0.10833155	0.15500748	false
training	oneLayer	oneLayer - rat 1	0	-0.09840978	0.15089774	false
training	oneLayer	oneLayer - rat 1	0	-0.088679284	0.14686723	false
training	oneLayer	oneLayer - rat 1	0	-0.07922818	0.14295246	false
training	oneLayer	oneLayer - rat 1	0	-0.06974622	0.1390249	false
training	oneLayer	oneLayer - rat 1	0	-0.059689835	0.13485941	false
training	oneLayer	oneLayer - rat 1	0	-0.049894657	0.13080211	false
training	oneLayer	oneLayer - rat 1	0	-0.03980646	0.12662344	false
training	oneLayer	oneLayer - rat 1	0	-0.03016953	0.12263169	false
training	oneLayer	oneLayer - rat 1	0	-0.02049945	0.11862621	false
training	oneLayer	oneLayer - rat 1	0	-0.0103424555	0.11441904	false
training	oneLayer	oneLayer - rat 1	0	-7.6231523E-4	0.11045082	false
training	oneLayer	oneLayer - rat 1	0	0.009282066	0.106290296	false
training	oneLayer	oneLayer - rat 1	0	0.019291759	0.102144144	false
training	oneLayer	oneLayer - rat 1	0	0.029020978	0.09811417	false
training	oneLayer	oneLayer - rat 1	0	0.03887929	0.094030716	false
training	oneLayer	oneLayer - rat 1	0	0.048278913	0.090137266	false
training	oneLayer	oneLayer - rat 1	0	0.058264382	0.08600115	false
training	oneLayer	oneLayer - rat 1	0	0.06821245	0.08188052	false
training	oneLayer	oneLayer - rat 1	0	0.077590294	0.07799609	false
training	oneLayer	oneLayer - rat 1	0	0.08743364	0.073918834	false
training	oneLayer	oneLayer - rat 1	0	0.09739701	0.069791876	false
training	oneLayer	oneLayer - rat 1	0	0.1067087	0.065934844	false
training	oneLayer	oneLayer - rat 1	0	0.11644982	0.061899934	false
training	oneLayer	oneLayer - rat 1	0	0.12630339	0.05781845	false
training	oneLayer	oneLayer - rat 1	0	0.1361049	0.05375853	false
training	oneLayer	oneLayer - rat 1	0	0.14537357	0.049919322	false
training	oneLayer	oneLayer - rat 1	0	0.15494463	0.045954853	false
training	oneLayer	oneLayer - rat 1	0	0.16485938	0.041848026	false
training	oneLayer	oneLayer - rat 1	0	0.17470828	0.03776848	false
training	oneLayer	oneLayer - rat 1	0	0.18483862	0.03357235	false
training	oneLayer	oneLayer - rat 1	0	0.1948258	0.029435525	false
training	oneLayer	oneLayer - rat 1	0	0.20487775	0.025271872	false
training	oneLayer	oneLayer - rat 1	0	0.21415628	0.021428574	false
training	oneLayer	oneLayer - rat 1	0	0.22390433	0.017390797	false
training	oneLayer	oneLayer - rat 1	0	0.23396033	0.013225466	false
training	oneLayer	oneLayer - rat 1	0	0.24376594	0.009163844	false
training	oneLayer	oneLayer - rat 1	0	0.25377822	0.0050166254	false
training	oneLayer	oneLayer - rat 1	0	0.26379636	8.6696405E-4	false
training	oneLayer	oneLayer - rat 1	0	0.27305272	-0.0029671458	false
training	oneLayer	oneLayer - rat 1	0	0.2832222	-0.0029671476	false
training	oneLayer	oneLayer - rat 1	0	0.29420322	-0.0029671495	false
training	oneLayer	oneLayer - rat 1	0	0.30428076	-0.002967151	false
training	oneLayer	oneLayer - rat 1	0	0.31499058	-0.002967153	false
training	oneLayer	oneLayer - rat 1	0	0.32529405	-0.0029671548	false
training	oneLayer	oneLayer - rat 1	0	0.33554667	-0.0029671567	false
training	oneLayer	oneLayer - rat 1	0	0.3463101	-0.0029671586	false
training	oneLayer	oneLayer - rat 1	0	0.35720295	-0.0029671604	false
training	oneLayer	oneLayer - rat 1	0	0.36759093	-0.0029671623	false
training	oneLayer	oneLayer - rat 1	0	0.37826738	-0.0029671642	false
training	oneLayer	oneLayer - rat 1	0	0.38911927	-0.002967166	false
training	oneLayer	oneLayer - rat 1	0	0.39981273	-0.0029671679	false
training	oneLayer	oneLayer - rat 1	0	0.410682	-0.0029671697	false
training	oneLayer	oneLayer - rat 1	0	0.4207147	0.0011885196	false
training	oneLayer	oneLayer - rat 1	0	0.42788875	0.008362562	false
training	oneLayer	oneLayer - rat 1	0	0.4318703	0.017974889	false
training	oneLayer	oneLayer - rat 1	0	0.4318703	0.028736139	false
training	oneLayer	oneLayer - rat 1	0	0.42783543	0.038477216	false
training	oneLayer	oneLayer - rat 1	0	0.42052308	0.04578957	false
training	oneLayer	oneLayer - rat 1	0	0.41043937	0.04996638	false
training	oneLayer	oneLayer - rat 1	0	0.4002737	0.04996638	false
training	oneLayer	oneLayer - rat 1	0	0.3902664	0.049966384	false
training	oneLayer	oneLayer - rat 1	0	0.3796478	0.049966384	false
training	oneLayer	oneLayer - rat 1	0	0.36925462	0.049966384	false
training	oneLayer	oneLayer - rat 1	0	0.35843775	0.049966384	false
training	oneLayer	oneLayer - rat 1	0	0.34764415	0.049966387	false
training	oneLayer	oneLayer - rat 1	0	0.33747184	0.049966387	false
training	oneLayer	oneLayer - rat 1	0	0.3272983	0.049966387	false
training	oneLayer	oneLayer - rat 1	0	0.31688923	0.049966387	false
training	oneLayer	oneLayer - rat 1	0	0.30598274	0.04996639	false
training	oneLayer	oneLayer - rat 1	0	0.29550424	0.04996639	false
training	oneLayer	oneLayer - rat 1	0	0.28501365	0.04996639	false
training	oneLayer	oneLayer - rat 1	0	0.27493116	0.04996639	false
training	oneLayer	oneLayer - rat 1	0	0.26450562	0.049966395	false
training	oneLayer	oneLayer - rat 1	0	0.25389156	0.049966395	false
training	oneLayer	oneLayer - rat 1	0	0.24324915	0.049966395	false
training	oneLayer	oneLayer - rat 1	0	0.2328201	0.049966395	false
training	oneLayer	oneLayer - rat 1	0	0.2218638	0.0499664	false
training	oneLayer	oneLayer - rat 1	0	0.21143942	0.0499664	false
training	oneLayer	oneLayer - rat 1	0	0.2010931	0.0499664	false
training	oneLayer	oneLayer - rat 1	0	0.19064645	0.0499664	false
training	oneLayer	oneLayer - rat 1	0	0.18044083	0.049966402	false
training	oneLayer	oneLayer - rat 1	0	0.17013235	0.049966402	false
training	oneLayer	oneLayer - rat 1	0	0.15973943	0.049966402	false
training	oneLayer	oneLayer - rat 1	0	0.14920247	0.049966402	false
training	oneLayer	oneLayer - rat 1	0	0.13828664	0.049966406	false
training	oneLayer	oneLayer - rat 1	0	0.12750302	0.049966406	false
training	oneLayer	oneLayer - rat 1	0	0.117180765	0.049966406	false
training	oneLayer	oneLayer - rat 1	0	0.106198125	0.049966406	false
training	oneLayer	oneLayer - rat 1	0	0.09522144	0.04996641	false
training	oneLayer	oneLayer - rat 1	0	0.0842994	0.04996641	false
training	oneLayer	oneLayer - rat 1	0	0.07401693	0.04996641	false
training	oneLayer	oneLayer - rat 1	0	0.06339235	0.04996641	false
training	oneLayer	oneLayer - rat 1	0	0.052457117	0.049966414	false
training	oneLayer	oneLayer - rat 1	0	0.042111326	0.049966414	false
training	oneLayer	oneLayer - rat 1	0	0.031213133	0.049966414	false
training	oneLayer	oneLayer - rat 1	0	0.020331776	0.049966414	false
training	oneLayer	oneLayer - rat 1	0	0.009979674	0.049966417	false
training	oneLayer	oneLayer - rat 1	0	-8.802942E-4	0.049966417	false
training	oneLayer	oneLayer - rat 1	0	-0.011720199	0.049966417	false
training	oneLayer	oneLayer - rat 1	0	-0.022019427	0.049966417	false
training	oneLayer	oneLayer - rat 1	0	-0.032063447	0.04996642	false
training	oneLayer	oneLayer - rat 1	0	-0.0425587	0.04996642	false
training	oneLayer	oneLayer - rat 1	0	-0.052621286	0.04996642	false
training	oneLayer	oneLayer - rat 1	0	-0.063119546	0.04996642	false
training	oneLayer	oneLayer - rat 1	0	-0.0734493	0.049966425	false
training	oneLayer	oneLayer - rat 1	0	-0.084140144	0.049966425	false
training	oneLayer	oneLayer - rat 1	0	-0.094785035	0.049966425	false
training	oneLayer	oneLayer - rat 1	0	-0.105598055	0.049966425	false
training	oneLayer	oneLayer - rat 1	0	-0.11651355	0.04996643	false
training	oneLayer	oneLayer - rat 1	0	-0.1270881	0.04996643	false
training	oneLayer	oneLayer - rat 1	0	-0.13730621	0.04996643	false
training	oneLayer	oneLayer - rat 1	0	-0.14799057	0.04996643	false
training	oneLayer	oneLayer - rat 1	0	-0.15800847	0.049966432	false
training	oneLayer	oneLayer - rat 1	0	-0.1686592	0.049966432	false
training	oneLayer	oneLayer - rat 1	0	-0.17902505	0.049966432	false
training	oneLayer	oneLayer - rat 1	0	-0.18948115	0.049966432	false
training	oneLayer	oneLayer - rat 1	0	-0.20017682	0.049966436	false
training	oneLayer	oneLayer - rat 1	0	-0.21026935	0.049966436	false
training	oneLayer	oneLayer - rat 1	0	-0.22117184	0.049966436	false
training	oneLayer	oneLayer - rat 1	0	-0.23217009	0.049966436	false
training	oneLayer	oneLayer - rat 1	0	-0.24237281	0.04996644	false
training	oneLayer	oneLayer - rat 1	0	-0.25331452	0.04996644	false
training	oneLayer	oneLayer - rat 1	0	-0.2636307	0.04996644	false
training	oneLayer	oneLayer - rat 1	0	-0.27411205	0.04996644	false
training	oneLayer	oneLayer - rat 1	0	-0.28450388	0.049966443	false
training	oneLayer	oneLayer - rat 1	0	-0.29526383	0.049966443	false
training	oneLayer	oneLayer - rat 1	0	-0.30560663	0.049966443	false
training	oneLayer	oneLayer - rat 1	0	-0.3156571	0.049966443	false
training	oneLayer	oneLayer - rat 1	0	-0.3262552	0.049966443	false
training	oneLayer	oneLayer - rat 1	0	-0.3371752	0.049966447	false
training	oneLayer	oneLayer - rat 1	0	-0.34697154	0.045908675	false
training	oneLayer	oneLayer - rat 1	0	-0.35676768	0.041850977	false
training	oneLayer	oneLayer - rat 1	0	-0.36636758	0.037874576	false
training	oneLayer	oneLayer - rat 1	0	-0.37597856	0.03389357	false
training	oneLayer	oneLayer - rat 1	0	-0.38576236	0.029840987	false
training	oneLayer	oneLayer - rat 1	0	-0.39553013	0.025795043	false
training	oneLayer	oneLayer - rat 1	0	-0.40491134	0.021909218	false
training	oneLayer	oneLayer - rat 1	0	-0.41499975	0.017730473	false
training	oneLayer	oneLayer - rat 1	0	-0.42261675	0.010113461	false
training	oneLayer	oneLayer - rat 1	0	-0.42660308	4.8964104E-4	false
training	oneLayer	oneLayer - rat 1	0	-0.42660308	-0.01043828	false
training	oneLayer	oneLayer - rat 1	0	-0.42256165	-0.020195123	false
training	oneLayer	oneLayer - rat 1	0	-0.4150671	-0.027689673	false
training	oneLayer	oneLayer - rat 1	0	-0.40550187	-0.031651728	false
training	oneLayer	oneLayer - rat 1	0	-0.39508682	-0.031651728	false
training	oneLayer	oneLayer - rat 1	0	-0.3846636	-0.031651728	false
training	oneLayer	oneLayer - rat 1	0	-0.3741457	-0.031651728	false
training	oneLayer	oneLayer - rat 1	0	-0.36378515	-0.031651728	false
training	oneLayer	oneLayer - rat 1	0	-0.3529718	-0.031651728	false
training	oneLayer	oneLayer - rat 1	0	-0.34245786	-0.031651728	false
training	oneLayer	oneLayer - rat 1	0	-0.3319808	-0.031651728	false
training	oneLayer	oneLayer - rat 1	0	-0.32171154	-0.031651728	false
training	oneLayer	oneLayer - rat 1	0	-0.3114497	-0.031651728	false
training	oneLayer	oneLayer - rat 1	0	-0.30094472	-0.031651728	false
training	oneLayer	oneLayer - rat 1	0	-0.29000652	-0.031651728	false
training	oneLayer	oneLayer - rat 1	0	-0.27992374	-0.031651728	false
training	oneLayer	oneLayer - rat 1	0	-0.26927325	-0.031651728	false
training	oneLayer	oneLayer - rat 1	0	-0.25838548	-0.031651728	false
training	oneLayer	oneLayer - rat 1	0	-0.24740261	-0.031651728	false
training	oneLayer	oneLayer - rat 1	0	-0.23656964	-0.031651728	false
training	oneLayer	oneLayer - rat 1	0	-0.2256441	-0.031651728	false
training	oneLayer	oneLayer - rat 1	0	-0.2152184	-0.031651728	false
training	oneLayer	oneLayer - rat 1	0	-0.20498987	-0.031651728	false
training	oneLayer	oneLayer - rat 1	0	-0.19423716	-0.031651728	false
training	oneLayer	oneLayer - rat 1	0	-0.18340006	-0.031651728	false
training	oneLayer	oneLayer - rat 1	0	-0.17252423	-0.031651728	false
training	oneLayer	oneLayer - rat 1	0	-0.16167259	-0.031651728	false
training	oneLayer	oneLayer - rat 1	0	-0.15112238	-0.031651728	false
training	oneLayer	oneLayer - rat 1	0	-0.14066865	-0.031651728	false
training	oneLayer	oneLayer - rat 1	0	-0.12970115	-0.031651728	false
training	oneLayer	oneLayer - rat 1	0	-0.11919281	-0.031651728	false
training	oneLayer	oneLayer - rat 1	0	-0.10907277	-0.031651728	false
training	oneLayer	oneLayer - rat 1	0	-0.09899531	-0.031651728	false
training	oneLayer	oneLayer - rat 1	0	-0.08817586	-0.031651728	false
training	oneLayer	oneLayer - rat 1	0	-0.07779403	-0.031651728	false
training	oneLayer	oneLayer - rat 1	0	-0.06703238	-0.031651728	false
training	oneLayer	oneLayer - rat 1	0	-0.0561095	-0.031651728	false
training	oneLayer	oneLayer - rat 1	0	-0.04538589	-0.031651728	false
training	oneLayer	oneLayer - rat 1	0	-0.034769833	-0.031651728	false
training	oneLayer	oneLayer - rat 1	0	-0.024205582	-0.031651728	false
training	oneLayer	oneLayer - rat 1	0	-0.013624238	-0.031651728	false
training	oneLayer	oneLayer - rat 1	0	-0.0035848496	-0.031651728	false
training	oneLayer	oneLayer - rat 1	0	0.0068543935	-0.031651728	false
training	oneLayer	oneLayer - rat 1	0	0.017506406	-0.031651728	false
training	oneLayer	oneLayer - rat 1	0	0.027738318	-0.031651728	false
training	oneLayer	oneLayer - rat 1	0	0.038520098	-0.031651728	false
training	oneLayer	oneLayer - rat 1	0	0.049337313	-0.031651728	false
training	oneLayer	oneLayer - rat 1	0	0.060248528	-0.031651728	false
training	oneLayer	oneLayer - rat 1	0	0.07090613	-0.031651728	false
training	oneLayer	oneLayer - rat 1	0	0.08155631	-0.031651728	false
training	oneLayer	oneLayer - rat 1	0	0.09198164	-0.031651728	false
training	oneLayer	oneLayer - rat 1	0	0.10227555	-0.031651728	false
training	oneLayer	oneLayer - rat 1	0	0.11240487	-0.031651728	false
training	oneLayer	oneLayer - rat 1	0	0.122801885	-0.031651728	false
training	oneLayer	oneLayer - rat 1	0	0.13335264	-0.031651728	false
training	oneLayer	oneLayer - rat 1	0	0.14386	-0.031651728	false
training	oneLayer	oneLayer - rat 1	0	0.15434639	-0.031651728	false
training	oneLayer	oneLayer - rat 1	0	0.16450316	-0.031651728	false
training	oneLayer	oneLayer - rat 1	0	0.17512618	-0.031651728	false
training	oneLayer	oneLayer - rat 1	0	0.18582149	-0.031651728	false
training	oneLayer	oneLayer - rat 1	0	0.1966409	-0.031651728	false
training	oneLayer	oneLayer - rat 1	0	0.20750748	-0.031651728	false
training	oneLayer	oneLayer - rat 1	0	0.21762964	-0.031651728	false
training	oneLayer	oneLayer - rat 1	0	0.2285683	-0.031651728	false
training	oneLayer	oneLayer - rat 1	0	0.23859096	-0.031651728	false
training	oneLayer	oneLayer - rat 1	0	0.24915981	-0.031651728	false
training	oneLayer	oneLayer - rat 1	0	0.25916868	-0.031651728	false
training	oneLayer	oneLayer - rat 1	0	0.26963717	-0.031651728	false
training	oneLayer	oneLayer - rat 1	0	0.27988255	-0.031651728	false
training	oneLayer	oneLayer - rat 1	0	0.2903706	-0.031651728	false
training	oneLayer	oneLayer - rat 1	0	0.3010967	-0.031651728	false
training	oneLayer	oneLayer - rat 1	0	0.31117237	-0.031651728	false
training	oneLayer	oneLayer - rat 1	0	0.321939	-0.031651728	false
training	oneLayer	oneLayer - rat 1	0	0.33204293	-0.031651728	false
training	oneLayer	oneLayer - rat 1	0	0.34236413	-0.031651728	false
training	oneLayer	oneLayer - rat 1	0	0.35286582	-0.031651728	false
training	oneLayer	oneLayer - rat 1	0	0.36326823	-0.031651728	false
training	oneLayer	oneLayer - rat 1	0	0.37364125	-0.031651728	false
training	oneLayer	oneLayer - rat 1	0	0.38334516	-0.02763224	false
training	oneLayer	oneLayer - rat 1	0	0.3934495	-0.023446888	false
training	oneLayer	oneLayer - rat 1	0	0.40329972	-0.01936678	false
training	oneLayer	oneLayer - rat 1	0	0.4132613	-0.015240562	false
training	oneLayer	oneLayer - rat 1	0	0.4206284	-0.007873466	false
training	oneLayer	oneLayer - rat 1	0	0.42459133	0.0016938767	false
training	oneLayer	oneLayer - rat 1	0	0.42459133	0.011702068	false
training	oneLayer	oneLayer - rat 1	0	0.42073327	0.021016194	false
training	oneLayer	oneLayer - rat 1	0	0.41302902	0.02872047	false
training	oneLayer	oneLayer - rat 1	0	0.40362504	0.032615714	false
training	oneLayer	oneLayer - rat 1	0	0.39306056	0.03261571	false
training	oneLayer	oneLayer - rat 1	0	0.3828687	0.03261571	false
training	oneLayer	oneLayer - rat 1	0	0.37259197	0.03261571	false
training	oneLayer	oneLayer - rat 1	0	0.36207983	0.03261571	false
training	oneLayer	oneLayer - rat 1	0	0.35179874	0.032615706	false
training	oneLayer	oneLayer - rat 1	0	0.34161532	0.032615706	false
training	oneLayer	oneLayer - rat 1	0	0.33094248	0.032615706	false
training	oneLayer	oneLayer - rat 1	0	0.32011542	0.032615706	false
training	oneLayer	oneLayer - rat 1	0	0.3094585	0.032615703	false
training	oneLayer	oneLayer - rat 1	0	0.29922694	0.032615703	false
training	oneLayer	oneLayer - rat 1	0	0.28915215	0.032615703	false
training	oneLayer	oneLayer - rat 1	0	0.27842388	0.032615703	false
training	oneLayer	oneLayer - rat 1	0	0.2678329	0.0326157	false
training	oneLayer	oneLayer - rat 1	0	0.2576335	0.0326157	false
training	oneLayer	oneLayer - rat 1	0	0.2472166	0.0326157	false
training	oneLayer	oneLayer - rat 1	0	0.2362734	0.0326157	false
training	oneLayer	oneLayer - rat 1	0	0.22574368	0.032615695	false
training	oneLayer	oneLayer - rat 1	0	0.2152195	0.032615695	false
training	oneLayer	oneLayer - rat 1	0	0.20503023	0.032615695	false
training	oneLayer	oneLayer - rat 1	0	0.19414818	0.032615695	false
training	oneLayer	oneLayer - rat 1	0	0.18355404	0.03261569	false
training	oneLayer	oneLayer - rat 1	0	0.17258558	0.03261569	false
training	oneLayer	oneLayer - rat 1	0	0.162562	0.03261569	false
training	oneLayer	oneLayer - rat 1	0	0.1525012	0.03261569	false
training	oneLayer	oneLayer - rat 1	0	0.14225508	0.03261569	false
training	oneLayer	oneLayer - rat 1	0	0.13202867	0.032615688	false
training	oneLayer	oneLayer - rat 1	0	0.12110781	0.032615688	false
training	oneLayer	oneLayer - rat 1	0	0.110203266	0.032615688	false
training	oneLayer	oneLayer - rat 1	0	0.09949211	0.032615688	false
training	oneLayer	oneLayer - rat 1	0	0.0886128	0.032615684	false
training	oneLayer	oneLayer - rat 1	0	0.07775729	0.032615684	false
training	oneLayer	oneLayer - rat 1	0	0.06762505	0.032615684	false
training	oneLayer	oneLayer - rat 1	0	0.05673834	0.032615684	false
training	oneLayer	oneLayer - rat 1	0	0.0464082	0.03261568	false
training	oneLayer	oneLayer - rat 1	0	0.035610307	0.03261568	false
training	oneLayer	oneLayer - rat 1	0	0.025486708	0.03261568	false
training	oneLayer	oneLayer - rat 1	0	0.014826328	0.03261568	false
training	oneLayer	oneLayer - rat 1	0	0.004071357	0.032615677	false
training	oneLayer	oneLayer - rat 1	0	-0.0062550777	0.032615677	false
training	oneLayer	oneLayer - rat 1	0	-0.016490007	0.032615677	false
training	oneLayer	oneLayer - rat 1	0	-0.027209008	0.032615677	false
training	oneLayer	oneLayer - rat 1	0	-0.03731395	0.032615673	false
training	oneLayer	oneLayer - rat 1	0	-0.048302773	0.032615673	false
training	oneLayer	oneLayer - rat 1	0	-0.05875908	0.032615673	false
training	oneLayer	oneLayer - rat 1	0	-0.069694564	0.032615673	false
training	oneLayer	oneLayer - rat 1	0	-0.07974467	0.03261567	false
training	oneLayer	oneLayer - rat 1	0	-0.090278566	0.03261567	false
training	oneLayer	oneLayer - rat 1	0	-0.101194926	0.03261567	false
training	oneLayer	oneLayer - rat 1	0	-0.111728095	0.03261567	false
training	oneLayer	oneLayer - rat 1	0	-0.121884435	0.032615665	false
training	oneLayer	oneLayer - rat 1	0	-0.13220042	0.032615665	false
training	oneLayer	oneLayer - rat 1	0	-0.14307688	0.032615665	false
training	oneLayer	oneLayer - rat 1	0	-0.15310588	0.032615665	false
training	oneLayer	oneLayer - rat 1	0	-0.16366497	0.03261566	false
training	oneLayer	oneLayer - rat 1	0	-0.17396753	0.03261566	false
training	oneLayer	oneLayer - rat 1	0	-0.18469137	0.03261566	false
training	oneLayer	oneLayer - rat 1	0	-0.19475259	0.03261566	false
training	oneLayer	oneLayer - rat 1	0	-0.20545314	0.032615658	false
training	oneLayer	oneLayer - rat 1	0	-0.21591732	0.032615658	false
training	oneLayer	oneLayer - rat 1	0	-0.2261063	0.032615658	false
training	oneLayer	oneLayer - rat 1	0	-0.23690934	0.032615658	false
training	oneLayer	oneLayer - rat 1	0	-0.2476894	0.032615654	false
training	oneLayer	oneLayer - rat 1	0	-0.25784692	0.032615654	false
training	oneLayer	oneLayer - rat 1	0	-0.26811573	0.032615654	false
training	oneLayer	oneLayer - rat 1	0	-0.27829337	0.032615654	false
training	oneLayer	oneLayer - rat 1	0	-0.28886387	0.03261565	false
training	oneLayer	oneLayer - rat 1	0	-0.29925126	0.03261565	false
training	oneLayer	oneLayer - rat 1	0	-0.30991638	0.03261565	false
training	oneLayer	oneLayer - rat 1	0	-0.32072228	0.03261565	false
training	oneLayer	oneLayer - rat 1	0	-0.33144757	0.032615647	false
training	oneLayer	oneLayer - rat 1	0	-0.341589	0.032615647	false
training	oneLayer	oneLayer - rat 1	0	-0.35169205	0.032615647	false
training	oneLayer	oneLayer - rat 1	0	-0.36174732	0.032615647	false
training	oneLayer	oneLayer - rat 1	0	-0.37237495	0.032615643	false
training	oneLayer	oneLayer - rat 1	0	-0.38234147	0.028487368	false
training	oneLayer	oneLayer - rat 1	0	-0.39162147	0.024643464	false
training	oneLayer	oneLayer - rat 1	0	-0.40154698	0.020532181	false
training	oneLayer	oneLayer - rat 1	0	-0.4108833	0.016664958	false
training	oneLayer	oneLayer - rat 1	0	-0.41832602	0.009222232	false
training	oneLayer	oneLayer - rat 1	0	-0.42547962	0.0020686234	false
training	oneLayer	oneLayer - rat 1	0	-0.42966068	-0.008025321	false
training	oneLayer	oneLayer - rat 1	0	-0.43359792	-0.017530713	false
training	oneLayer	oneLayer - rat 1	0	-0.43762538	-0.027253862	false
training	oneLayer	oneLayer - rat 1	0	-0.44151044	-0.036633175	false
training	oneLayer	oneLayer - rat 1	0	-0.4454311	-0.046098568	false
training	oneLayer	oneLayer - rat 1	0	-0.4454311	-0.05647266	false
training	oneLayer	oneLayer - rat 1	0	-0.44133747	-0.06635563	false
training	oneLayer	oneLayer - rat 1	0	-0.43409523	-0.07359787	false
training	oneLayer	oneLayer - rat 1	0	-0.4243979	-0.077614635	false
training	oneLayer	oneLayer - rat 1	0	-0.41391823	-0.07761463	false
training	oneLayer	oneLayer - rat 1	0	-0.40411094	-0.07355231	false
training	oneLayer	oneLayer - rat 1	0	-0.3963829	-0.06582429	false
training	oneLayer	oneLayer - rat 1	0	-0.3923125	-0.05599747	false
training	oneLayer	oneLayer - rat 1	0	-0.38828412	-0.04627203	false
training	oneLayer	oneLayer - rat 1	0	-0.38421488	-0.03644806	false
training	oneLayer	oneLayer - rat 1	0	-0.38015547	-0.026647747	false
training	oneLayer	oneLayer - rat 1	0	-0.37630463	-0.017350996	false
training	oneLayer	oneLayer - rat 1	0	-0.37245002	-0.008045172	false
training	oneLayer	oneLayer - rat 1	0	-0.36838016	0.0017803689	false
training	oneLayer	oneLayer - rat 1	0	-0.36454707	0.011034272	false
training	oneLayer	oneLayer - rat 1	0	-0.3604011	0.021043584	false
training	oneLayer	oneLayer - rat 1	0	-0.3563247	0.030884871	false
training	oneLayer	oneLayer - rat 1	0	-0.35215834	0.040943358	false
training	oneLayer	oneLayer - rat 1	0	-0.34798655	0.05101493	false
training	oneLayer	oneLayer - rat 1	0	-0.3441021	0.06039283	false
training	oneLayer	oneLayer - rat 1	0	-0.34009054	0.07007756	false
training	oneLayer	oneLayer - rat 1	0	-0.33624056	0.07937227	false
training	oneLayer	oneLayer - rat 1	0	-0.33227447	0.08894726	false
training	oneLayer	oneLayer - rat 1	0	-0.32817635	0.09884101	false
training	oneLayer	oneLayer - rat 1	0	-0.3240853	0.1087177	false
training	oneLayer	oneLayer - rat 1	0	-0.3199467	0.118709125	false
training	oneLayer	oneLayer - rat 1	0	-0.3199467	0.12901972	false
training	oneLayer	oneLayer - rat 1	0	-0.3199467	0.13992524	false
training	oneLayer	oneLayer - rat 1	0	-0.3199467	0.15035594	false
training	oneLayer	oneLayer - rat 1	0	-0.31994674	0.16100836	false
training	oneLayer	oneLayer - rat 1	0	-0.31994674	0.17148797	false
training	oneLayer	oneLayer - rat 1	0	-0.31994674	0.18174954	false
training	oneLayer	oneLayer - rat 1	0	-0.31994674	0.19191143	false
training	oneLayer	oneLayer - rat 1	0	-0.31994674	0.20204312	false
training	oneLayer	oneLayer - rat 1	0	-0.31994674	0.2127186	false
training	oneLayer	oneLayer - rat 1	0	-0.31994674	0.22369713	false
training	oneLayer	oneLayer - rat 1	0	-0.31994674	0.2342549	false
training	oneLayer	oneLayer - rat 1	0	-0.31994674	0.24475211	false
training	oneLayer	oneLayer - rat 1	0	-0.31994674	0.25520545	false
training	oneLayer	oneLayer - rat 1	0	-0.31994674	0.26587018	false
training	oneLayer	oneLayer - rat 1	0	-0.31994674	0.2767586	false
training	oneLayer	oneLayer - rat 1	0	-0.31600168	0.28628287	false
training	oneLayer	oneLayer - rat 1	0	-0.30839714	0.2938874	false
training	oneLayer	oneLayer - rat 1	0	-0.2986985	0.2979047	false
training	oneLayer	oneLayer - rat 1	0	-0.28779414	0.2979047	false
training	oneLayer	oneLayer - rat 1	0	-0.27774245	0.29790473	false
training	oneLayer	oneLayer - rat 1	0	-0.26719216	0.29790473	false
training	oneLayer	oneLayer - rat 1	0	-0.25715998	0.29374924	false
training	oneLayer	oneLayer - rat 1	0	-0.24703144	0.28955388	false
training	oneLayer	oneLayer - rat 1	0	-0.23704265	0.2854164	false
training	oneLayer	oneLayer - rat 1	0	-0.2270787	0.2812892	false
training	oneLayer	oneLayer - rat 1	0	-0.21707904	0.2771472	false
training	oneLayer	oneLayer - rat 1	0	-0.20743749	0.2731535	false
training	oneLayer	oneLayer - rat 1	0	-0.19770716	0.2691231	false
training	oneLayer	oneLayer - rat 1	0	-0.18787485	0.2650504	false
training	oneLayer	oneLayer - rat 1	0	-0.17819609	0.26104134	false
training	oneLayer	oneLayer - rat 1	0	-0.16824955	0.25692135	false
training	oneLayer	oneLayer - rat 1	0	-0.1585177	0.25289032	false
training	oneLayer	oneLayer - rat 1	0	-0.14865576	0.24880534	false
training	oneLayer	oneLayer - rat 1	0	-0.13938719	0.2449662	false
training	oneLayer	oneLayer - rat 1	0	-0.12928806	0.24078299	false
training	oneLayer	oneLayer - rat 1	0	-0.11960574	0.23677245	false
training	oneLayer	oneLayer - rat 1	0	-0.10973113	0.23268226	false
training	oneLayer	oneLayer - rat 1	0	-0.10018679	0.22872886	false
training	oneLayer	oneLayer - rat 1	0	-0.090126075	0.22456157	false
training	oneLayer	oneLayer - rat 1	0	-0.080290936	0.22048773	false
training	oneLayer	oneLayer - rat 1	0	-0.07097174	0.2166276	false
training	oneLayer	oneLayer - rat 1	0	-0.061617605	0.21275298	false
training	oneLayer	oneLayer - rat 1	0	-0.051952444	0.20874955	false
training	oneLayer	oneLayer - rat 1	0	-0.042126603	0.20467955	false
training	oneLayer	oneLayer - rat 1	0	-0.03209374	0.20052381	false
training	oneLayer	oneLayer - rat 1	0	-0.02204066	0.19635968	false
training	oneLayer	oneLayer - rat 1	0	-0.012586271	0.19244355	false
training	oneLayer	oneLayer - rat 1	0	-0.0024342616	0.18823846	false
training	oneLayer	oneLayer - rat 1	0	0.0071897013	0.18425208	false
training	oneLayer	oneLayer - rat 1	0	0.016669577	0.18032539	false
training	oneLayer	oneLayer - rat 1	0	0.026630014	0.17619964	false
training	oneLayer	oneLayer - rat 1	0	0.036068298	0.17229018	false
training	oneLayer	oneLayer - rat 1	0	0.045415487	0.16841845	false
training	oneLayer	oneLayer - rat 1	0	0.055478375	0.16425027	false
training	oneLayer	oneLayer - rat 1	0	0.06512354	0.1602551	false
training	oneLayer	oneLayer - rat 1	0	0.07512587	0.15611202	false
training	oneLayer	oneLayer - rat 1	0	0.0845525	0.15220737	false
training	oneLayer	oneLayer - rat 1	0	0.09393572	0.14832072	false
training	oneLayer	oneLayer - rat 1	0	0.104085095	0.14411671	false
training	oneLayer	oneLayer - rat 1	0	0.11332673	0.14028871	false
training	oneLayer	oneLayer - rat 1	0	0.12308665	0.13624601	false
training	oneLayer	oneLayer - rat 1	0	0.13301691	0.13213277	false
training	oneLayer	oneLayer - rat 1	0	0.14304866	0.12797748	false
training	oneLayer	oneLayer - rat 1	0	0.1524651	0.12407707	false
training	oneLayer	oneLayer - rat 1	0	0.16256414	0.11989391	false
training	oneLayer	oneLayer - rat 1	0	0.17198619	0.115991175	false
training	oneLayer	oneLayer - rat 1	0	0.18201025	0.11183907	false
training	oneLayer	oneLayer - rat 1	0	0.19174802	0.10780555	false
training	oneLayer	oneLayer - rat 1	0	0.20184807	0.10362198	false
training	oneLayer	oneLayer - rat 1	0	0.21136154	0.09968137	false
training	oneLayer	oneLayer - rat 1	0	0.22118823	0.09561103	false
training	oneLayer	oneLayer - rat 1	0	0.23116626	0.091478	false
training	oneLayer	oneLayer - rat 1	0	0.24050038	0.08761168	false
training	oneLayer	oneLayer - rat 1	0	0.25034285	0.0835348	false
training	oneLayer	oneLayer - rat 1	0	0.26006672	0.079507045	false
training	oneLayer	oneLayer - rat 1	0	0.2701572	0.07532743	false
training	oneLayer	oneLayer - rat 1	0	0.2797943	0.07133561	false
training	oneLayer	oneLayer - rat 1	0	0.28930932	0.06739436	false
training	oneLayer	oneLayer - rat 1	0	0.29910433	0.06333713	false
training	oneLayer	oneLayer - rat 1	0	0.30914536	0.059178006	false
training	oneLayer	oneLayer - rat 1	0	0.3190749	0.055065062	false
training	oneLayer	oneLayer - rat 1	0	0.32862905	0.051107604	false
training	oneLayer	oneLayer - rat 1	0	0.33872908	0.046924032	false
training	oneLayer	oneLayer - rat 1	0	0.3487849	0.04275878	false
training	oneLayer	oneLayer - rat 1	0	0.35882917	0.038598318	false
training	oneLayer	oneLayer - rat 1	0	0.36838278	0.034641076	false
training	oneLayer	oneLayer - rat 1	0	0.3780486	0.030637369	false
training	oneLayer	oneLayer - rat 1	0	0.38796395	0.026530294	false
training	oneLayer	oneLayer - rat 1	0	0.39740694	0.02261889	false
training	oneLayer	oneLayer - rat 1	0	0.40745294	0.018457698	false
training	oneLayer	oneLayer - rat 1	0	0.41478148	0.011129146	false
training	oneLayer	oneLayer - rat 1	0	0.4186343	0.0018276508	false
training	oneLayer	oneLayer - rat 1	0	0.4186343	-0.008736363	false
training	oneLayer	oneLayer - rat 1	0	0.4144636	-0.018805271	false
training	oneLayer	oneLayer - rat 1	0	0.40710485	-0.026164036	false
training	oneLayer	oneLayer - rat 1	0	0.39766678	-0.030073421	false
training	oneLayer	oneLayer - rat 1	0	0.38746756	-0.030073421	false
training	oneLayer	oneLayer - rat 1	0	0.3767228	-0.030073423	false
training	oneLayer	oneLayer - rat 1	0	0.3661682	-0.030073423	false
training	oneLayer	oneLayer - rat 1	0	0.355178	-0.030073425	false
training	oneLayer	oneLayer - rat 1	0	0.3443319	-0.030073425	false
training	oneLayer	oneLayer - rat 1	0	0.33428082	-0.030073427	false
training	oneLayer	oneLayer - rat 1	0	0.32374272	-0.030073427	false
training	oneLayer	oneLayer - rat 1	0	0.3130003	-0.030073429	false
training	oneLayer	oneLayer - rat 1	0	0.30226636	-0.030073429	false
training	oneLayer	oneLayer - rat 1	0	0.29128587	-0.03007343	false
training	oneLayer	oneLayer - rat 1	0	0.28124836	-0.03007343	false
training	oneLayer	oneLayer - rat 1	0	0.27087757	-0.030073432	false
training	oneLayer	oneLayer - rat 1	0	0.26045296	-0.030073432	false
training	oneLayer	oneLayer - rat 1	0	0.2495599	-0.030073434	false
training	oneLayer	oneLayer - rat 1	0	0.23885609	-0.030073434	false
training	oneLayer	oneLayer - rat 1	0	0.22819845	-0.030073436	false
training	oneLayer	oneLayer - rat 1	0	0.2172704	-0.030073436	false
training	oneLayer	oneLayer - rat 1	0	0.20632641	-0.030073438	false
training	oneLayer	oneLayer - rat 1	0	0.19595996	-0.030073438	false
training	oneLayer	oneLayer - rat 1	0	0.18535389	-0.03007344	false
training	oneLayer	oneLayer - rat 1	0	0.17436893	-0.03007344	false
training	oneLayer	oneLayer - rat 1	0	0.16370226	-0.030073442	false
training	oneLayer	oneLayer - rat 1	0	0.153018	-0.030073442	false
training	oneLayer	oneLayer - rat 1	0	0.14265178	-0.030073443	false
training	oneLayer	oneLayer - rat 1	0	0.1320959	-0.030073443	false
training	oneLayer	oneLayer - rat 1	0	0.12187248	-0.030073445	false
training	oneLayer	oneLayer - rat 1	0	0.110997684	-0.030073445	false
training	oneLayer	oneLayer - rat 1	0	0.10065451	-0.030073447	false
training	oneLayer	oneLayer - rat 1	0	0.09065304	-0.030073447	false
training	oneLayer	oneLayer - rat 1	0	0.08035842	-0.030073449	false
training	oneLayer	oneLayer - rat 1	0	0.06978525	-0.030073449	false
training	oneLayer	oneLayer - rat 1	0	0.059325892	-0.03007345	false
training	oneLayer	oneLayer - rat 1	0	0.04875424	-0.03007345	false
training	oneLayer	oneLayer - rat 1	0	0.037853003	-0.030073453	false
training	oneLayer	oneLayer - rat 1	0	0.026973557	-0.030073453	false
training	oneLayer	oneLayer - rat 1	0	0.016314715	-0.030073455	false
training	oneLayer	oneLayer - rat 1	0	0.0056154616	-0.030073455	false
training	oneLayer	oneLayer - rat 1	0	-0.0050286883	-0.030073456	false
training	oneLayer	oneLayer - rat 1	0	-0.015280926	-0.030073456	false
training	oneLayer	oneLayer - rat 1	0	-0.025973748	-0.030073458	false
training	oneLayer	oneLayer - rat 1	0	-0.036309905	-0.030073458	false
training	oneLayer	oneLayer - rat 1	0	-0.0463103	-0.03007346	false
training	oneLayer	oneLayer - rat 1	0	-0.0567957	-0.03007346	false
training	oneLayer	oneLayer - rat 1	0	-0.06745737	-0.03007346	false
training	oneLayer	oneLayer - rat 1	0	-0.07780293	-0.030073462	false
training	oneLayer	oneLayer - rat 1	0	-0.088483244	-0.030073462	false
training	oneLayer	oneLayer - rat 1	0	-0.099075735	-0.030073464	false
training	oneLayer	oneLayer - rat 1	0	-0.10971588	-0.030073464	false
training	oneLayer	oneLayer - rat 1	0	-0.1203038	-0.030073466	false
training	oneLayer	oneLayer - rat 1	0	-0.13114516	-0.030073466	false
training	oneLayer	oneLayer - rat 1	0	-0.14148936	-0.030073468	false
training	oneLayer	oneLayer - rat 1	0	-0.15213767	-0.030073468	false
training	oneLayer	oneLayer - rat 1	0	-0.16278149	-0.03007347	false
training	oneLayer	oneLayer - rat 1	0	-0.17372726	-0.03007347	false
training	oneLayer	oneLayer - rat 1	0	-0.18392621	-0.030073471	false
training	oneLayer	oneLayer - rat 1	0	-0.19413835	-0.030073471	false
training	oneLayer	oneLayer - rat 1	0	-0.20504044	-0.030073473	false
training	oneLayer	oneLayer - rat 1	0	-0.21539138	-0.030073473	false
training	oneLayer	oneLayer - rat 1	0	-0.22585502	-0.030073475	false
training	oneLayer	oneLayer - rat 1	0	-0.23659432	-0.030073475	false
training	oneLayer	oneLayer - rat 1	0	-0.24732642	-0.030073477	false
training	oneLayer	oneLayer - rat 1	0	-0.25822476	-0.030073477	false
training	oneLayer	oneLayer - rat 1	0	-0.26852873	-0.030073479	false
training	oneLayer	oneLayer - rat 1	0	-0.2792255	-0.030073479	false
training	oneLayer	oneLayer - rat 1	0	-0.28964826	-0.03007348	false
training	oneLayer	oneLayer - rat 1	0	-0.3001018	-0.03007348	false
training	oneLayer	oneLayer - rat 1	0	-0.31040743	-0.030073483	false
training	oneLayer	oneLayer - rat 1	0	-0.32087845	-0.030073483	false
training	oneLayer	oneLayer - rat 1	0	-0.33116284	-0.030073484	false
training	oneLayer	oneLayer - rat 1	0	-0.34144014	-0.030073484	false
training	oneLayer	oneLayer - rat 1	0	-0.3515747	-0.030073486	false
training	oneLayer	oneLayer - rat 1	0	-0.36246142	-0.030073486	false
training	oneLayer	oneLayer - rat 1	0	-0.37292325	-0.030073488	false
training	oneLayer	oneLayer - rat 1	0	-0.38294676	-0.030073488	false
training	oneLayer	oneLayer - rat 1	0	-0.39278048	-0.026000226	false
training	oneLayer	oneLayer - rat 1	0	-0.40209496	-0.02214204	false
training	oneLayer	oneLayer - rat 1	0	-0.4115741	-0.01821566	false
training	oneLayer	oneLayer - rat 1	0	-0.4188814	-0.010908365	false
training	oneLayer	oneLayer - rat 1	0	-0.4227574	-0.0015508608	false
training	oneLayer	oneLayer - rat 1	0	-0.4227574	0.008574083	false
training	oneLayer	oneLayer - rat 1	0	-0.4227574	0.019113628	false
training	oneLayer	oneLayer - rat 1	0	-0.4227574	0.02930797	false
training	oneLayer	oneLayer - rat 1	0	-0.4227574	0.039912257	false
training	oneLayer	oneLayer - rat 1	0	-0.4227574	0.050433893	false
training	oneLayer	oneLayer - rat 1	0	-0.4227574	0.06140632	false
training	oneLayer	oneLayer - rat 1	0	-0.4227574	0.07212479	false
training	oneLayer	oneLayer - rat 1	0	-0.41859102	0.082183264	false
training	oneLayer	oneLayer - rat 1	0	-0.41465965	0.091674455	false
training	oneLayer	oneLayer - rat 1	0	-0.41051674	0.10167633	false
training	oneLayer	oneLayer - rat 1	0	-0.4063873	0.111645706	false
training	oneLayer	oneLayer - rat 1	0	-0.40237907	0.121322416	false
training	oneLayer	oneLayer - rat 1	0	-0.3982724	0.13123678	false
training	oneLayer	oneLayer - rat 1	0	-0.39433184	0.14075015	false
training	oneLayer	oneLayer - rat 1	0	-0.3904812	0.15004638	false
training	oneLayer	oneLayer - rat 1	0	-0.386284	0.16017938	false
training	oneLayer	oneLayer - rat 1	0	-0.3823436	0.16969237	false
training	oneLayer	oneLayer - rat 1	0	-0.37817425	0.17975807	false
training	oneLayer	oneLayer - rat 1	0	-0.37427026	0.18918312	false
training	oneLayer	oneLayer - rat 1	0	-0.37020448	0.19899876	false
training	oneLayer	oneLayer - rat 1	0	-0.36616582	0.20874898	false
training	oneLayer	oneLayer - rat 1	0	-0.36227703	0.21813732	false
training	oneLayer	oneLayer - rat 1	0	-0.35828382	0.22777778	false
training	oneLayer	oneLayer - rat 1	0	-0.35432446	0.23733655	false
training	oneLayer	oneLayer - rat 1	0	-0.35034087	0.24695371	false
training	oneLayer	oneLayer - rat 1	0	-0.3462533	0.25682202	false
training	oneLayer	oneLayer - rat 1	0	-0.3421687	0.26668313	false
training	oneLayer	oneLayer - rat 1	0	-0.33828205	0.27606636	false
training	oneLayer	oneLayer - rat 1	0	-0.33067787	0.2836705	false
training	oneLayer	oneLayer - rat 1	0	-0.32107627	0.2876476	false
training	oneLayer	oneLayer - rat 1	0	-0.31085137	0.2876476	false
training	oneLayer	oneLayer - rat 1	0	-0.30148384	0.28376746	false
training	oneLayer	oneLayer - rat 1	0	-0.29433674	0.27662036	false
training	oneLayer	oneLayer - rat 1	0	-0.2903819	0.26707253	false
training	oneLayer	oneLayer - rat 1	0	-0.2903819	0.2568161	false
training	oneLayer	oneLayer - rat 1	0	-0.29450133	0.2468709	false
training	oneLayer	oneLayer - rat 1	0	-0.298703	0.23672715	false
training	oneLayer	oneLayer - rat 1	0	-0.30274993	0.22695708	false
training	oneLayer	oneLayer - rat 1	0	-0.3065827	0.21770397	false
training	oneLayer	oneLayer - rat 1	0	-0.31064203	0.20790385	false
training	oneLayer	oneLayer - rat 1	0	-0.3146649	0.19819178	false
training	oneLayer	oneLayer - rat 1	0	-0.3188442	0.18810208	false
training	oneLayer	oneLayer - rat 1	0	-0.3227405	0.17869554	false
training	oneLayer	oneLayer - rat 1	0	-0.32657495	0.16943839	false
training	oneLayer	oneLayer - rat 1	0	-0.33049977	0.15996306	false
training	oneLayer	oneLayer - rat 1	0	-0.33440605	0.15053242	false
training	oneLayer	oneLayer - rat 1	0	-0.3382813	0.14117673	false
training	oneLayer	oneLayer - rat 1	0	-0.34240487	0.1312216	false
training	oneLayer	oneLayer - rat 1	0	-0.3463213	0.12176646	false
training	oneLayer	oneLayer - rat 1	0	-0.35048825	0.11170657	false
training	oneLayer	oneLayer - rat 1	0	-0.35457972	0.1018289	false
training	oneLayer	oneLayer - rat 1	0	-0.35846254	0.09245492	false
training	oneLayer	oneLayer - rat 1	0	-0.3623979	0.082954116	false
training	oneLayer	oneLayer - rat 1	0	-0.36993948	0.07541256	false
training	oneLayer	oneLayer - rat 1	0	-0.37701058	0.06834145	false
training	oneLayer	oneLayer - rat 1	0	-0.38422802	0.061124012	false
training	oneLayer	oneLayer - rat 1	0	-0.39144945	0.053902574	false
training	oneLayer	oneLayer - rat 1	0	-0.39869642	0.04665562	false
training	oneLayer	oneLayer - rat 1	0	-0.40612623	0.039225798	false
training	oneLayer	oneLayer - rat 1	0	-0.41380468	0.031547338	false
training	oneLayer	oneLayer - rat 1	0	-0.42143723	0.023914807	false
training	oneLayer	oneLayer - rat 1	0	-0.42915097	0.016201068	false
training	oneLayer	oneLayer - rat 1	0	-0.43321005	0.0064015575	false
training	oneLayer	oneLayer - rat 1	0	-0.43724188	-0.0033321285	false
training	oneLayer	oneLayer - rat 1	0	-0.44107598	-0.0125884395	false
training	oneLayer	oneLayer - rat 1	0	-0.4450181	-0.02210562	false
training	oneLayer	oneLayer - rat 1	0	-0.44913286	-0.032039456	false
training	oneLayer	oneLayer - rat 1	0	-0.44913286	-0.0427663	false
training	oneLayer	oneLayer - rat 1	0	-0.44498935	-0.052769598	false
training	oneLayer	oneLayer - rat 1	0	-0.43728867	-0.060470283	false
training	oneLayer	oneLayer - rat 1	0	-0.42733568	-0.06459294	false
training	oneLayer	oneLayer - rat 1	0	-0.41654348	-0.06459294	false
training	oneLayer	oneLayer - rat 1	0	-0.40678656	-0.060551498	false
training	oneLayer	oneLayer - rat 1	0	-0.39963177	-0.053396706	false
training	oneLayer	oneLayer - rat 1	0	-0.3956598	-0.04380754	false
training	oneLayer	oneLayer - rat 1	0	-0.39166546	-0.034164324	false
training	oneLayer	oneLayer - rat 1	0	-0.38778114	-0.024786761	false
training	oneLayer	oneLayer - rat 1	0	-0.3839196	-0.015464136	false
training	oneLayer	oneLayer - rat 1	0	-0.3799027	-0.0057664774	false
training	oneLayer	oneLayer - rat 1	0	-0.37594953	0.0037773005	false
training	oneLayer	oneLayer - rat 1	0	-0.3720931	0.013087523	false
training	oneLayer	oneLayer - rat 1	0	-0.36795446	0.023079092	false
training	oneLayer	oneLayer - rat 1	0	-0.3640684	0.03246091	false
training	oneLayer	oneLayer - rat 1	0	-0.36020803	0.041780606	false
training	oneLayer	oneLayer - rat 1	0	-0.3561534	0.051569387	false
training	oneLayer	oneLayer - rat 1	0	-0.35228917	0.06089844	false
training	oneLayer	oneLayer - rat 1	0	-0.34836355	0.070375726	false
training	oneLayer	oneLayer - rat 1	0	-0.34421986	0.080379486	false
training	oneLayer	oneLayer - rat 1	0	-0.3403857	0.08963597	false
training	oneLayer	oneLayer - rat 1	0	-0.33624807	0.09962512	false
training	oneLayer	oneLayer - rat 1	0	-0.3323553	0.109023064	false
training	oneLayer	oneLayer - rat 1	0	-0.328344	0.11870724	false
training	oneLayer	oneLayer - rat 1	0	-0.32430202	0.12846541	false
training	oneLayer	oneLayer - rat 1	0	-0.320095	0.13862203	false
training	oneLayer	oneLayer - rat 1	0	-0.31621468	0.14799	false
training	oneLayer	oneLayer - rat 1	0	-0.31621468	0.1584405	false
training	oneLayer	oneLayer - rat 1	0	-0.31621468	0.16913138	false
training	oneLayer	oneLayer - rat 1	0	-0.31621468	0.17999783	false
training	oneLayer	oneLayer - rat 1	0	-0.31621468	0.19026537	false
training	oneLayer	oneLayer - rat 1	0	-0.31621468	0.20085385	false
training	oneLayer	oneLayer - rat 1	0	-0.31621468	0.21090682	false
training	oneLayer	oneLayer - rat 1	0	-0.31621468	0.22171201	false
training	oneLayer	oneLayer - rat 1	0	-0.31621468	0.23187673	false
training	oneLayer	oneLayer - rat 1	0	-0.31621468	0.24222206	false
training	oneLayer	oneLayer - rat 1	0	-0.31621468	0.25296056	false
training	oneLayer	oneLayer - rat 1	0	-0.31621468	0.26307184	false
training	oneLayer	oneLayer - rat 1	0	-0.31621468	0.27327597	false
training	oneLayer	oneLayer - rat 1	0	-0.31621468	0.28404754	false
training	oneLayer	oneLayer - rat 1	0	-0.31621468	0.29457808	false
training	oneLayer	oneLayer - rat 1	0	-0.31229696	0.30403626	false
training	oneLayer	oneLayer - rat 1	0	-0.30834627	0.31357408	false
training	oneLayer	oneLayer - rat 1	0	-0.30441305	0.32306975	false
training	oneLayer	oneLayer - rat 1	0	-0.30054435	0.3324096	false
training	oneLayer	oneLayer - rat 1	0	-0.29665494	0.34179944	false
training	oneLayer	oneLayer - rat 1	0	-0.28913906	0.34931532	false
training	oneLayer	oneLayer - rat 1	0	-0.2798687	0.35315523	false
training	oneLayer	oneLayer - rat 1	0	-0.26940706	0.35315523	false
training	oneLayer	oneLayer - rat 1	0	-0.2593423	0.34898627	false
training	oneLayer	oneLayer - rat 1	0	-0.25160503	0.34124902	false
training	oneLayer	oneLayer - rat 1	0	-0.24760145	0.3315835	false
training	oneLayer	oneLayer - rat 1	0	-0.24760145	0.3207586	false
training	oneLayer	oneLayer - rat 1	0	-0.2516751	0.31092396	false
training	oneLayer	oneLayer - rat 1	0	-0.2555109	0.30166352	false
training	oneLayer	oneLayer - rat 1	0	-0.2593689	0.2923495	false
training	oneLayer	oneLayer - rat 1	0	-0.2632205	0.28305092	false
training	oneLayer	oneLayer - rat 1	0	-0.26719552	0.27345434	false
training	oneLayer	oneLayer - rat 1	0	-0.27123418	0.26370415	false
training	oneLayer	oneLayer - rat 1	0	-0.27538908	0.25367334	false
training	oneLayer	oneLayer - rat 1	0	-0.2793985	0.24399379	false
training	oneLayer	oneLayer - rat 1	0	-0.2834794	0.23414162	false
training	oneLayer	oneLayer - rat 1	0	-0.2875375	0.22434452	false
training	oneLayer	oneLayer - rat 1	0	-0.29157	0.21460916	false
training	oneLayer	oneLayer - rat 1	0	-0.2956236	0.20482288	false
training	oneLayer	oneLayer - rat 1	0	-0.29970837	0.19496138	false
training	oneLayer	oneLayer - rat 1	0	-0.30363053	0.18549249	false
training	oneLayer	oneLayer - rat 1	0	-0.3074991	0.17615291	false
training	oneLayer	oneLayer - rat 1	0	-0.31153998	0.16639733	false
training	oneLayer	oneLayer - rat 1	0	-0.31569737	0.15636054	false
training	oneLayer	oneLayer - rat 1	0	-0.3198138	0.14642262	false
training	oneLayer	oneLayer - rat 1	0	-0.32399014	0.13634	false
training	oneLayer	oneLayer - rat 1	0	-0.32798055	0.12670632	false
training	oneLayer	oneLayer - rat 1	0	-0.3321846	0.116556786	false
training	oneLayer	oneLayer - rat 1	0	-0.3399451	0.1087963	false
training	oneLayer	oneLayer - rat 1	0	-0.34745482	0.101286605	false
training	oneLayer	oneLayer - rat 1	0	-0.35510606	0.09363535	false
training	oneLayer	oneLayer - rat 1	0	-0.36259675	0.08614467	false
training	oneLayer	oneLayer - rat 1	0	-0.36970878	0.07903265	false
training	oneLayer	oneLayer - rat 1	0	-0.37718555	0.07155585	false
training	oneLayer	oneLayer - rat 1	0	-0.3844957	0.064245716	false
training	oneLayer	oneLayer - rat 1	0	-0.39198804	0.05675337	false
training	oneLayer	oneLayer - rat 1	0	-0.39917627	0.049565163	false
training	oneLayer	oneLayer - rat 1	0	-0.40676484	0.041976597	false
training	oneLayer	oneLayer - rat 1	0	-0.4140259	0.034715533	false
training	oneLayer	oneLayer - rat 1	0	-0.4181252	0.024818892	false
training	oneLayer	oneLayer - rat 1	0	-0.4181252	0.014381608	false
training	oneLayer	oneLayer - rat 1	0	-0.4139406	0.0042790617	false
training	oneLayer	oneLayer - rat 1	0	-0.40635982	-0.0033017206	false
training	oneLayer	oneLayer - rat 1	0	-0.39707127	-0.0071491674	false
training	oneLayer	oneLayer - rat 1	0	-0.38623238	-0.0071491674	false
training	oneLayer	oneLayer - rat 1	0	-0.3753332	-0.0071491674	false
training	oneLayer	oneLayer - rat 1	0	-0.36529145	-0.0071491674	false
training	oneLayer	oneLayer - rat 1	0	-0.354748	-0.0071491674	false
training	oneLayer	oneLayer - rat 1	0	-0.34470865	-0.0071491674	false
training	oneLayer	oneLayer - rat 1	0	-0.33435208	-0.0071491674	false
training	oneLayer	oneLayer - rat 1	0	-0.32350072	-0.0071491674	false
training	oneLayer	oneLayer - rat 1	0	-0.31253058	-0.0071491674	false
training	oneLayer	oneLayer - rat 1	0	-0.30229232	-0.0071491674	false
training	oneLayer	oneLayer - rat 1	0	-0.29193905	-0.0071491674	false
training	oneLayer	oneLayer - rat 1	0	-0.28166613	-0.0071491674	false
training	oneLayer	oneLayer - rat 1	0	-0.27159172	-0.0071491674	false
training	oneLayer	oneLayer - rat 1	0	-0.2614741	-0.0071491674	false
training	oneLayer	oneLayer - rat 1	0	-0.25143263	-0.0071491674	false
training	oneLayer	oneLayer - rat 1	0	-0.24108405	-0.0071491674	false
training	oneLayer	oneLayer - rat 1	0	-0.23072243	-0.0071491674	false
training	oneLayer	oneLayer - rat 1	0	-0.22034873	-0.0071491674	false
training	oneLayer	oneLayer - rat 1	0	-0.20961353	-0.0071491674	false
training	oneLayer	oneLayer - rat 1	0	-0.19880763	-0.0071491674	false
training	oneLayer	oneLayer - rat 1	0	-0.18840735	-0.0071491674	false
training	oneLayer	oneLayer - rat 1	0	-0.17771314	-0.0071491674	false
training	oneLayer	oneLayer - rat 1	0	-0.1668086	-0.0071491674	false
training	oneLayer	oneLayer - rat 1	0	-0.15658636	-0.0071491674	false
training	oneLayer	oneLayer - rat 1	0	-0.1457655	-0.0071491674	false
training	oneLayer	oneLayer - rat 1	0	-0.13568448	-0.0071491674	false
training	oneLayer	oneLayer - rat 1	0	-0.12549146	-0.0071491674	false
training	oneLayer	oneLayer - rat 1	0	-0.11451803	-0.0071491674	false
training	oneLayer	oneLayer - rat 1	0	-0.10363804	-0.0071491674	false
training	oneLayer	oneLayer - rat 1	0	-0.09360782	-0.0071491674	false
training	oneLayer	oneLayer - rat 1	0	-0.08290566	-0.0071491674	false
training	oneLayer	oneLayer - rat 1	0	-0.07194548	-0.0071491674	false
training	oneLayer	oneLayer - rat 1	0	-0.06106314	-0.0071491674	false
training	oneLayer	oneLayer - rat 1	0	-0.050585978	-0.0071491674	false
training	oneLayer	oneLayer - rat 1	0	-0.040142033	-0.0071491674	false
training	oneLayer	oneLayer - rat 1	0	-0.029782282	-0.0071491674	false
training	oneLayer	oneLayer - rat 1	0	-0.019189186	-0.0071491674	false
training	oneLayer	oneLayer - rat 1	0	-0.008190189	-0.0071491674	false
training	oneLayer	oneLayer - rat 1	0	0.002178694	-0.0071491674	false
training	oneLayer	oneLayer - rat 1	0	0.0129635865	-0.0071491674	false
training	oneLayer	oneLayer - rat 1	0	0.023189424	-0.0071491674	false
training	oneLayer	oneLayer - rat 1	0	0.033924006	-0.0071491674	false
training	oneLayer	oneLayer - rat 1	0	0.04467413	-0.0071491674	false
training	oneLayer	oneLayer - rat 1	0	0.054923005	-0.0071491674	false
training	oneLayer	oneLayer - rat 1	0	0.065061435	-0.0071491674	false
training	oneLayer	oneLayer - rat 1	0	0.0752081	-0.0071491674	false
training	oneLayer	oneLayer - rat 1	0	0.08553009	-0.0071491674	false
training	oneLayer	oneLayer - rat 1	0	0.09576901	-0.0071491674	false
training	oneLayer	oneLayer - rat 1	0	0.106205896	-0.0071491674	false
training	oneLayer	oneLayer - rat 1	0	0.11711262	-0.0071491674	false
training	oneLayer	oneLayer - rat 1	0	0.12716064	-0.0071491674	false
training	oneLayer	oneLayer - rat 1	0	0.13721769	-0.0071491674	false
training	oneLayer	oneLayer - rat 1	0	0.14805715	-0.0071491674	false
training	oneLayer	oneLayer - rat 1	0	0.15863428	-0.0071491674	false
training	oneLayer	oneLayer - rat 1	0	0.16922456	-0.0071491674	false
training	oneLayer	oneLayer - rat 1	0	0.17948098	-0.0071491674	false
training	oneLayer	oneLayer - rat 1	0	0.18971647	-0.0071491674	false
training	oneLayer	oneLayer - rat 1	0	0.20013298	-0.0071491674	false
training	oneLayer	oneLayer - rat 1	0	0.21050756	-0.0071491674	false
training	oneLayer	oneLayer - rat 1	0	0.2211637	-0.0071491674	false
training	oneLayer	oneLayer - rat 1	0	0.2317306	-0.0071491674	false
training	oneLayer	oneLayer - rat 1	0	0.24255854	-0.0071491674	false
training	oneLayer	oneLayer - rat 1	0	0.25265503	-0.0071491674	false
training	oneLayer	oneLayer - rat 1	0	0.2630934	-0.0071491674	false
training	oneLayer	oneLayer - rat 1	0	0.27325007	-0.0071491674	false
training	oneLayer	oneLayer - rat 1	0	0.28386444	-0.0071491674	false
training	oneLayer	oneLayer - rat 1	0	0.29415414	-0.0071491674	false
training	oneLayer	oneLayer - rat 1	0	0.30440286	-0.0071491674	false
training	oneLayer	oneLayer - rat 1	0	0.31530312	-0.0071491674	false
training	oneLayer	oneLayer - rat 1	0	0.32558462	-0.0071491674	false
training	oneLayer	oneLayer - rat 1	0	0.3360785	-0.0071491674	false
training	oneLayer	oneLayer - rat 1	0	0.34679323	-0.0071491674	false
training	oneLayer	oneLayer - rat 1	0	0.35703877	-0.0071491674	false
training	oneLayer	oneLayer - rat 1	0	0.3676038	-0.0071491674	false
training	oneLayer	oneLayer - rat 1	0	0.37852737	-0.0071491674	false
training	oneLayer	oneLayer - rat 1	0	0.3894305	-0.0071491674	false
training	oneLayer	oneLayer - rat 1	0	0.39955524	-0.0071491674	false
training	oneLayer	oneLayer - rat 1	0	0.410402	-0.0071491674	false
training	oneLayer	oneLayer - rat 1	0	0.4199557	-0.0031919018	false
training	oneLayer	oneLayer - rat 1	0	0.42767587	0.004528289	false
training	oneLayer	oneLayer - rat 1	0	0.4317988	0.014481846	false
training	oneLayer	oneLayer - rat 1	0	0.4317988	0.024656352	false
training	oneLayer	oneLayer - rat 1	0	0.4277177	0.03450897	false
training	oneLayer	oneLayer - rat 1	0	0.42012823	0.042098437	false
training	oneLayer	oneLayer - rat 1	0	0.41064474	0.046026617	false
training	oneLayer	oneLayer - rat 1	0	0.39969534	0.046026614	false
training	oneLayer	oneLayer - rat 1	0	0.38899344	0.046026614	false
training	oneLayer	oneLayer - rat 1	0	0.37847447	0.046026614	false
training	oneLayer	oneLayer - rat 1	0	0.36844513	0.046026614	false
training	oneLayer	oneLayer - rat 1	0	0.35785663	0.04602661	false
training	oneLayer	oneLayer - rat 1	0	0.34785366	0.04602661	false
training	oneLayer	oneLayer - rat 1	0	0.3373712	0.04602661	false
training	oneLayer	oneLayer - rat 1	0	0.3264295	0.04602661	false
training	oneLayer	oneLayer - rat 1	0	0.3159353	0.046026606	false
training	oneLayer	oneLayer - rat 1	0	0.3052222	0.046026606	false
training	oneLayer	oneLayer - rat 1	0	0.2949772	0.046026606	false
training	oneLayer	oneLayer - rat 1	0	0.28425178	0.046026606	false
training	oneLayer	oneLayer - rat 1	0	0.27379155	0.046026602	false
training	oneLayer	oneLayer - rat 1	0	0.26285484	0.046026602	false
training	oneLayer	oneLayer - rat 1	0	0.25259537	0.046026602	false
training	oneLayer	oneLayer - rat 1	0	0.2421629	0.046026602	false
training	oneLayer	oneLayer - rat 1	0	0.23189972	0.0460266	false
training	oneLayer	oneLayer - rat 1	0	0.22110051	0.0460266	false
training	oneLayer	oneLayer - rat 1	0	0.21108659	0.0460266	false
training	oneLayer	oneLayer - rat 1	0	0.20103826	0.0460266	false
training	oneLayer	oneLayer - rat 1	0	0.19103226	0.046026595	false
training	oneLayer	oneLayer - rat 1	0	0.18050659	0.046026595	false
training	oneLayer	oneLayer - rat 1	0	0.17021963	0.046026595	false
training	oneLayer	oneLayer - rat 1	0	0.15922044	0.046026595	false
training	oneLayer	oneLayer - rat 1	0	0.14906286	0.04602659	false
training	oneLayer	oneLayer - rat 1	0	0.1386829	0.04602659	false
training	oneLayer	oneLayer - rat 1	0	0.12850639	0.04602659	false
training	oneLayer	oneLayer - rat 1	0	0.11845929	0.04602659	false
training	oneLayer	oneLayer - rat 1	0	0.10782606	0.046026587	false
training	oneLayer	oneLayer - rat 1	0	0.09683303	0.046026587	false
training	oneLayer	oneLayer - rat 1	0	0.08671051	0.046026587	false
training	oneLayer	oneLayer - rat 1	0	0.07645056	0.046026587	false
training	oneLayer	oneLayer - rat 1	0	0.066120416	0.046026584	false
training	oneLayer	oneLayer - rat 1	0	0.05607657	0.046026584	false
training	oneLayer	oneLayer - rat 1	0	0.04594353	0.046026584	false
training	oneLayer	oneLayer - rat 1	0	0.035468496	0.046026584	false
training	oneLayer	oneLayer - rat 1	0	0.0251754	0.046026584	false
training	oneLayer	oneLayer - rat 1	0	0.0149006685	0.04602658	false
training	oneLayer	oneLayer - rat 1	0	0.004598615	0.04602658	false
training	oneLayer	oneLayer - rat 1	0	-0.0060340245	0.04602658	false
training	oneLayer	oneLayer - rat 1	0	-0.016329432	0.04602658	false
training	oneLayer	oneLayer - rat 1	0	-0.02647677	0.046026576	false
training	oneLayer	oneLayer - rat 1	0	-0.036601327	0.046026576	false
training	oneLayer	oneLayer - rat 1	0	-0.047183886	0.046026576	false
training	oneLayer	oneLayer - rat 1	0	-0.05733107	0.046026576	false
training	oneLayer	oneLayer - rat 1	0	-0.06741611	0.046026573	false
training	oneLayer	oneLayer - rat 1	0	-0.07794401	0.046026573	false
training	oneLayer	oneLayer - rat 1	0	-0.08854371	0.046026573	false
training	oneLayer	oneLayer - rat 1	0	-0.098680004	0.046026573	false
training	oneLayer	oneLayer - rat 1	0	-0.10913582	0.04602657	false
training	oneLayer	oneLayer - rat 1	0	-0.119269125	0.04602657	false
training	oneLayer	oneLayer - rat 1	0	-0.13008113	0.04602657	false
training	oneLayer	oneLayer - rat 1	0	-0.14062722	0.04602657	false
training	oneLayer	oneLayer - rat 1	0	-0.15095697	0.046026565	false
training	oneLayer	oneLayer - rat 1	0	-0.1616438	0.046026565	false
training	oneLayer	oneLayer - rat 1	0	-0.17167097	0.046026565	false
training	oneLayer	oneLayer - rat 1	0	-0.18236311	0.046026565	false
training	oneLayer	oneLayer - rat 1	0	-0.193325	0.04602656	false
training	oneLayer	oneLayer - rat 1	0	-0.20408314	0.04602656	false
training	oneLayer	oneLayer - rat 1	0	-0.21418588	0.04602656	false
training	oneLayer	oneLayer - rat 1	0	-0.2246573	0.04602656	false
training	oneLayer	oneLayer - rat 1	0	-0.23533754	0.046026558	false
training	oneLayer	oneLayer - rat 1	0	-0.24597704	0.046026558	false
training	oneLayer	oneLayer - rat 1	0	-0.25650713	0.046026558	false
training	oneLayer	oneLayer - rat 1	0	-0.26676354	0.046026558	false
training	oneLayer	oneLayer - rat 1	0	-0.2774048	0.046026554	false
training	oneLayer	oneLayer - rat 1	0	-0.28798375	0.046026554	false
training	oneLayer	oneLayer - rat 1	0	-0.2981734	0.046026554	false
training	oneLayer	oneLayer - rat 1	0	-0.30854523	0.046026554	false
training	oneLayer	oneLayer - rat 1	0	-0.31874686	0.04602655	false
training	oneLayer	oneLayer - rat 1	0	-0.32942975	0.04602655	false
training	oneLayer	oneLayer - rat 1	0	-0.34039092	0.04602655	false
training	oneLayer	oneLayer - rat 1	0	-0.34989545	0.042089645	false
training	oneLayer	oneLayer - rat 1	0	-0.35950503	0.038109224	false
training	oneLayer	oneLayer - rat 1	0	-0.3695998	0.033927836	false
training	oneLayer	oneLayer - rat 1	0	-0.379497	0.029828275	false
training	oneLayer	oneLayer - rat 1	0	-0.38923788	0.025793467	false
training	oneLayer	oneLayer - rat 1	0	-0.39915255	0.02168668	false
training	oneLayer	oneLayer - rat 1	0	-0.40925476	0.017502198	false
training	oneLayer	oneLayer - rat 1	0	-0.4168371	0.009919873	false
training	oneLayer	oneLayer - rat 1	0	-0.42401725	0.0027397207	false
training	oneLayer	oneLayer - rat 1	0	-0.43134144	-0.004584484	false
training	oneLayer	oneLayer - rat 1	0	-0.4355492	-0.014742919	false
training	oneLayer	oneLayer - rat 1	0	-0.439677	-0.024708318	false
training	oneLayer	oneLayer - rat 1	0	-0.44387904	-0.03485293	false
training	oneLayer	oneLayer - rat 1	0	-0.44804	-0.044898357	false
training	oneLayer	oneLayer - rat 1	0	-0.44803998	-0.055711046	false
training	oneLayer	oneLayer - rat 1	0	-0.4441215	-0.06517106	false
training	oneLayer	oneLayer - rat 1	0	-0.4368544	-0.072438195	false
training	oneLayer	oneLayer - rat 1	0	-0.4275204	-0.076304466	false
training	oneLayer	oneLayer - rat 1	0	-0.4170546	-0.07630446	false
training	oneLayer	oneLayer - rat 1	0	-0.4076113	-0.07239292	false
training	oneLayer	oneLayer - rat 1	0	-0.40007475	-0.06485637	false
training	oneLayer	oneLayer - rat 1	0	-0.3959533	-0.054906286	false
training	oneLayer	oneLayer - rat 1	0	-0.39190075	-0.04512254	false
training	oneLayer	oneLayer - rat 1	0	-0.3879666	-0.035624728	false
training	oneLayer	oneLayer - rat 1	0	-0.38397604	-0.025990622	false
training	oneLayer	oneLayer - rat 1	0	-0.3800785	-0.01658114	false
training	oneLayer	oneLayer - rat 1	0	-0.3761646	-0.007132099	false
training	oneLayer	oneLayer - rat 1	0	-0.37209782	0.0026859734	false
training	oneLayer	oneLayer - rat 1	0	-0.36795703	0.012682755	false
training	oneLayer	oneLayer - rat 1	0	-0.3639346	0.022393702	false
training	oneLayer	oneLayer - rat 1	0	-0.35977933	0.032425478	false
training	oneLayer	oneLayer - rat 1	0	-0.35572574	0.0422117	false
training	oneLayer	oneLayer - rat 1	0	-0.35174432	0.051823653	false
training	oneLayer	oneLayer - rat 1	0	-0.34781843	0.061301637	false
training	oneLayer	oneLayer - rat 1	0	-0.34376523	0.07108694	false
training	oneLayer	oneLayer - rat 1	0	-0.33974758	0.080786385	false
training	oneLayer	oneLayer - rat 1	0	-0.33576745	0.09039532	false
training	oneLayer	oneLayer - rat 1	0	-0.33164424	0.100349605	false
training	oneLayer	oneLayer - rat 1	0	-0.32759058	0.11013601	false
training	oneLayer	oneLayer - rat 1	0	-0.32362425	0.11971156	false
training	oneLayer	oneLayer - rat 1	0	-0.31953505	0.1295838	false
training	oneLayer	oneLayer - rat 1	0	-0.31953505	0.14001027	false
training	oneLayer	oneLayer - rat 1	0	-0.31953505	0.15089077	false
training	oneLayer	oneLayer - rat 1	0	-0.31953505	0.16141807	false
training	oneLayer	oneLayer - rat 1	0	-0.31953505	0.17191449	false
training	oneLayer	oneLayer - rat 1	0	-0.31953505	0.18198697	false
training	oneLayer	oneLayer - rat 1	0	-0.31953505	0.19297032	false
training	oneLayer	oneLayer - rat 1	0	-0.31953505	0.20395301	false
training	oneLayer	oneLayer - rat 1	0	-0.31953505	0.21467145	false
training	oneLayer	oneLayer - rat 1	0	-0.31953505	0.22503108	false
training	oneLayer	oneLayer - rat 1	0	-0.31953508	0.23580775	false
training	oneLayer	oneLayer - rat 1	0	-0.31953508	0.24635771	false
training	oneLayer	oneLayer - rat 1	0	-0.31953508	0.257147	false
training	oneLayer	oneLayer - rat 1	0	-0.31953508	0.26761588	false
training	oneLayer	oneLayer - rat 1	0	-0.31953508	0.27848724	false
training	oneLayer	oneLayer - rat 1	0	-0.31565404	0.28785688	false
training	oneLayer	oneLayer - rat 1	0	-0.3079551	0.29555583	false
training	oneLayer	oneLayer - rat 1	0	-0.29838526	0.29951978	false
training	oneLayer	oneLayer - rat 1	0	-0.28803948	0.29951978	false
training	oneLayer	oneLayer - rat 1	0	-0.27748	0.29951978	false
training	oneLayer	oneLayer - rat 1	0	-0.26713756	0.29951978	false
training	oneLayer	oneLayer - rat 1	0	-0.2572584	0.29542768	false
training	oneLayer	oneLayer - rat 1	0	-0.24777779	0.29150072	false
training	oneLayer	oneLayer - rat 1	0	-0.23834172	0.28759217	false
training	oneLayer	oneLayer - rat 1	0	-0.22852598	0.28352636	false
training	oneLayer	oneLayer - rat 1	0	-0.21866113	0.2794402	false
training	oneLayer	oneLayer - rat 1	0	-0.2088379	0.27537128	false
training	oneLayer	oneLayer - rat 1	0	-0.19885527	0.27123633	false
training	oneLayer	oneLayer - rat 1	0	-0.18959819	0.26740193	false
training	oneLayer	oneLayer - rat 1	0	-0.18021446	0.26351508	false
training	oneLayer	oneLayer - rat 1	0	-0.17065755	0.25955647	false
training	oneLayer	oneLayer - rat 1	0	-0.16075216	0.25545353	false
training	oneLayer	oneLayer - rat 1	0	-0.15135358	0.2515605	false
training	oneLayer	oneLayer - rat 1	0	-0.14206779	0.2477142	false
training	oneLayer	oneLayer - rat 1	0	-0.13223618	0.24364182	false
training	oneLayer	oneLayer - rat 1	0	-0.12279925	0.23973292	false
training	oneLayer	oneLayer - rat 1	0	-0.11343165	0.23585273	false
training	oneLayer	oneLayer - rat 1	0	-0.103438325	0.23171337	false
training	oneLayer	oneLayer - rat 1	0	-0.09334589	0.22753295	false
training	oneLayer	oneLayer - rat 1	0	-0.08337352	0.22340226	false
training	oneLayer	oneLayer - rat 1	0	-0.07366306	0.21938007	false
training	oneLayer	oneLayer - rat 1	0	-0.06366369	0.21523818	false
training	oneLayer	oneLayer - rat 1	0	-0.05424168	0.21133547	false
training	oneLayer	oneLayer - rat 1	0	-0.0441195	0.20714273	false
training	oneLayer	oneLayer - rat 1	0	-0.034284204	0.20306881	false
training	oneLayer	oneLayer - rat 1	0	-0.024271049	0.19892122	false
training	oneLayer	oneLayer - rat 1	0	-0.014199434	0.19474943	false
training	oneLayer	oneLayer - rat 1	0	-0.004299455	0.19064872	false
training	oneLayer	oneLayer - rat 1	0	0.0050331103	0.18678305	false
training	oneLayer	oneLayer - rat 1	0	0.014318179	0.18293706	false
training	oneLayer	oneLayer - rat 1	0	0.02431192	0.17879751	false
training	oneLayer	oneLayer - rat 1	0	0.033667672	0.17492223	false
training	oneLayer	oneLayer - rat 1	0	0.04293019	0.17108557	false
training	oneLayer	oneLayer - rat 1	0	0.052222528	0.16723657	false
training	oneLayer	oneLayer - rat 1	0	0.061615832	0.16334572	false
training	oneLayer	oneLayer - rat 1	0	0.07131856	0.15932673	false
training	oneLayer	oneLayer - rat 1	0	0.0812886	0.15519701	false
training	oneLayer	oneLayer - rat 1	0	0.0912842	0.15105669	false
training	oneLayer	oneLayer - rat 1	0	0.10061914	0.14719003	false
training	oneLayer	oneLayer - rat 1	0	0.11065869	0.14303152	false
training	oneLayer	oneLayer - rat 1	0	0.12041209	0.13899153	false
training	oneLayer	oneLayer - rat 1	0	0.13004635	0.1350009	false
training	oneLayer	oneLayer - rat 1	0	0.14020407	0.13079344	false
training	oneLayer	oneLayer - rat 1	0	0.15026389	0.12662652	false
training	oneLayer	oneLayer - rat 1	0	0.15983534	0.122661896	false
training	oneLayer	oneLayer - rat 1	0	0.16930252	0.11874046	false
training	oneLayer	oneLayer - rat 1	0	0.17865445	0.11486677	false
training	oneLayer	oneLayer - rat 1	0	0.18841314	0.110824585	false
training	oneLayer	oneLayer - rat 1	0	0.19816828	0.10678388	false
training	oneLayer	oneLayer - rat 1	0	0.20825933	0.10260403	false
training	oneLayer	oneLayer - rat 1	0	0.21782878	0.09864024	false
training	oneLayer	oneLayer - rat 1	0	0.22713985	0.09478347	false
training	oneLayer	oneLayer - rat 1	0	0.23713619	0.090642855	false
training	oneLayer	oneLayer - rat 1	0	0.24686976	0.08661108	false
training	oneLayer	oneLayer - rat 1	0	0.25675446	0.08251671	false
training	oneLayer	oneLayer - rat 1	0	0.26650816	0.07847659	false
training	oneLayer	oneLayer - rat 1	0	0.2762854	0.07442672	false
training	oneLayer	oneLayer - rat 1	0	0.2860785	0.07037029	false
training	oneLayer	oneLayer - rat 1	0	0.2956805	0.066393025	false
training	oneLayer	oneLayer - rat 1	0	0.30521238	0.062444787	false
training	oneLayer	oneLayer - rat 1	0	0.3152909	0.058270127	false
training	oneLayer	oneLayer - rat 1	0	0.324696	0.0543744	false
training	oneLayer	oneLayer - rat 1	0	0.33434597	0.05037727	false
training	oneLayer	oneLayer - rat 1	0	0.3439804	0.046386547	false
training	oneLayer	oneLayer - rat 1	0	0.35391086	0.042273227	false
training	oneLayer	oneLayer - rat 1	0	0.3634632	0.03831652	false
training	oneLayer	oneLayer - rat 1	0	0.37330496	0.03423992	false
training	oneLayer	oneLayer - rat 1	0	0.3830501	0.030203348	false
training	oneLayer	oneLayer - rat 1	0	0.39320883	0.025995478	false
training	oneLayer	oneLayer - rat 1	0	0.40271974	0.022055935	false
training	oneLayer	oneLayer - rat 1	0	0.4124965	0.018006269	false
training	oneLayer	oneLayer - rat 1	0	0.42021132	0.010291444	false
training	oneLayer	oneLayer - rat 1	0	0.42410725	8.8586885E-4	false
training	oneLayer	oneLayer - rat 1	0	0.42410725	-0.009674236	false
training	oneLayer	oneLayer - rat 1	0	0.42022577	-0.01904493	false
training	oneLayer	oneLayer - rat 1	0	0.41290644	-0.026364263	false
training	oneLayer	oneLayer - rat 1	0	0.40322265	-0.03037542	false
training	oneLayer	oneLayer - rat 1	0	0.39253944	-0.03037542	false
training	oneLayer	oneLayer - rat 1	0	0.38300982	-0.026428128	false
training	oneLayer	oneLayer - rat 1	0	0.37364364	-0.022548532	false
training	oneLayer	oneLayer - rat 1	0	0.36368755	-0.018424574	false
training	oneLayer	oneLayer - rat 1	0	0.3540007	-0.014412152	false
training	oneLayer	oneLayer - rat 1	0	0.3445661	-0.010504216	false
training	oneLayer	oneLayer - rat 1	0	0.33494973	-0.0065209884	false
training	oneLayer	oneLayer - rat 1	0	0.3252024	-0.0024835211	false
training	oneLayer	oneLayer - rat 1	0	0.31511495	0.0016948463	false
training	oneLayer	oneLayer - rat 1	0	0.3051781	0.0058108172	false
training	oneLayer	oneLayer - rat 1	0	0.29584178	0.009678052	false
training	oneLayer	oneLayer - rat 1	0	0.28633857	0.0136144115	false
training	oneLayer	oneLayer - rat 1	0	0.27641845	0.017723452	false
training	oneLayer	oneLayer - rat 1	0	0.266802	0.021706708	false
training	oneLayer	oneLayer - rat 1	0	0.2567452	0.025872385	false
training	oneLayer	oneLayer - rat 1	0	0.24706064	0.029883852	false
training	oneLayer	oneLayer - rat 1	0	0.23722772	0.03395678	false
training	oneLayer	oneLayer - rat 1	0	0.22725503	0.038087606	false
training	oneLayer	oneLayer - rat 1	0	0.21794379	0.041944448	false
training	oneLayer	oneLayer - rat 1	0	0.20865911	0.045790285	false
training	oneLayer	oneLayer - rat 1	0	0.19906239	0.04976538	false
training	oneLayer	oneLayer - rat 1	0	0.189143	0.05387412	false
training	oneLayer	oneLayer - rat 1	0	0.17971121	0.057780895	false
training	oneLayer	oneLayer - rat 1	0	0.16988187	0.061852343	false
training	oneLayer	oneLayer - rat 1	0	0.15980873	0.06602477	false
training	oneLayer	oneLayer - rat 1	0	0.1502449	0.06998624	false
training	oneLayer	oneLayer - rat 1	0	0.1407907	0.073902294	false
training	oneLayer	oneLayer - rat 1	0	0.13129734	0.07783458	false
training	oneLayer	oneLayer - rat 1	0	0.12118481	0.08202332	false
training	oneLayer	oneLayer - rat 1	0	0.111469485	0.08604754	false
training	oneLayer	oneLayer - rat 1	0	0.10190959	0.09000738	false
training	oneLayer	oneLayer - rat 1	0	0.092193194	0.09403204	false
training	oneLayer	oneLayer - rat 1	0	0.08226499	0.098144434	false
training	oneLayer	oneLayer - rat 1	0	0.07272528	0.10209591	false
training	oneLayer	oneLayer - rat 1	0	0.06277486	0.10621751	false
training	oneLayer	oneLayer - rat 1	0	0.052902836	0.110306635	false
training	oneLayer	oneLayer - rat 1	0	0.043622617	0.11415063	false
training	oneLayer	oneLayer - rat 1	0	0.03389901	0.11817828	false
training	oneLayer	oneLayer - rat 1	0	0.024526007	0.1220607	false
training	oneLayer	oneLayer - rat 1	0	0.014704885	0.12612873	false
training	oneLayer	oneLayer - rat 1	0	0.0053730602	0.12999411	false
training	oneLayer	oneLayer - rat 1	0	-0.0039401776	0.13385178	false
training	oneLayer	oneLayer - rat 1	0	-0.013444597	0.13778864	false
training	oneLayer	oneLayer - rat 1	0	-0.023506075	0.14195624	false
training	oneLayer	oneLayer - rat 1	0	-0.03312545	0.1459407	false
training	oneLayer	oneLayer - rat 1	0	-0.042980604	0.15002285	false
training	oneLayer	oneLayer - rat 1	0	-0.052625075	0.15401772	false
training	oneLayer	oneLayer - rat 1	0	-0.062095918	0.15794067	false
training	oneLayer	oneLayer - rat 1	0	-0.07224109	0.16214293	false
training	oneLayer	oneLayer - rat 1	0	-0.08177387	0.16609153	false
training	oneLayer	oneLayer - rat 1	0	-0.091780886	0.17023657	false
training	oneLayer	oneLayer - rat 1	0	-0.10152606	0.17427316	false
training	oneLayer	oneLayer - rat 1	0	-0.111495495	0.17840263	false
training	oneLayer	oneLayer - rat 1	0	-0.12094353	0.18231614	false
training	oneLayer	oneLayer - rat 1	0	-0.13091587	0.18644682	false
training	oneLayer	oneLayer - rat 1	0	-0.14073661	0.1905147	false
training	oneLayer	oneLayer - rat 1	0	-0.15072201	0.1946508	false
training	oneLayer	oneLayer - rat 1	0	-0.16015786	0.19855924	false
training	oneLayer	oneLayer - rat 1	0	-0.17011176	0.20268229	false
training	oneLayer	oneLayer - rat 1	0	-0.1796933	0.20665109	false
training	oneLayer	oneLayer - rat 1	0	-0.18903917	0.21052228	false
training	oneLayer	oneLayer - rat 1	0	-0.19842018	0.21440801	false
training	oneLayer	oneLayer - rat 1	0	-0.20825168	0.21848036	false
training	oneLayer	oneLayer - rat 1	0	-0.21794999	0.22249752	false
training	oneLayer	oneLayer - rat 1	0	-0.22726643	0.22635652	false
training	oneLayer	oneLayer - rat 1	0	-0.23457895	0.23366904	false
training	oneLayer	oneLayer - rat 1	0	-0.24217504	0.24126513	false
training	oneLayer	oneLayer - rat 1	0	-0.24944241	0.2485325	false
training	oneLayer	oneLayer - rat 1	0	-0.25712183	0.2562119	false
training	oneLayer	oneLayer - rat 1	0	-0.26454768	0.26363775	false
training	oneLayer	oneLayer - rat 1	0	-0.27198353	0.2710736	false
training	oneLayer	oneLayer - rat 1	0	-0.27917844	0.27826852	false
training	oneLayer	oneLayer - rat 1	0	-0.28643262	0.2855227	false
training	oneLayer	oneLayer - rat 1	0	-0.29567292	0.28935015	false
training	oneLayer	oneLayer - rat 1	0	-0.30586302	0.28935015	false
training	oneLayer	oneLayer - rat 1	0	-0.31534287	0.2854235	false
training	oneLayer	oneLayer - rat 1	0	-0.32268587	0.2780805	false
training	oneLayer	oneLayer - rat 1	0	-0.33041945	0.2703469	false
training	oneLayer	oneLayer - rat 1	0	-0.33798367	0.2627827	false
training	oneLayer	oneLayer - rat 1	0	-0.34569377	0.2550726	false
training	oneLayer	oneLayer - rat 1	0	-0.34965435	0.24551086	false
training	oneLayer	oneLayer - rat 1	0	-0.35377392	0.23556532	false
training	oneLayer	oneLayer - rat 1	0	-0.3578554	0.22571173	false
training	oneLayer	oneLayer - rat 1	0	-0.3620143	0.21567129	false
training	oneLayer	oneLayer - rat 1	0	-0.36592948	0.20621921	false
training	oneLayer	oneLayer - rat 1	0	-0.3700306	0.1963182	false
training	oneLayer	oneLayer - rat 1	0	-0.37394565	0.18686648	false
training	oneLayer	oneLayer - rat 1	0	-0.37811384	0.1768036	false
training	oneLayer	oneLayer - rat 1	0	-0.38222617	0.16687551	false
training	oneLayer	oneLayer - rat 1	0	-0.3863688	0.15687431	false
training	oneLayer	oneLayer - rat 1	0	-0.39052936	0.14682986	false
training	oneLayer	oneLayer - rat 1	0	-0.3946287	0.13693313	false
training	oneLayer	oneLayer - rat 1	0	-0.39883676	0.12677398	false
training	oneLayer	oneLayer - rat 1	0	-0.40299457	0.11673615	false
training	oneLayer	oneLayer - rat 1	0	-0.40684566	0.107438795	false
training	oneLayer	oneLayer - rat 1	0	-0.4108944	0.097664304	false
training	oneLayer	oneLayer - rat 1	0	-0.41505578	0.087617755	false
training	oneLayer	oneLayer - rat 1	0	-0.41895884	0.07819494	false
training	oneLayer	oneLayer - rat 1	0	-0.4228957	0.06869052	false
training	oneLayer	oneLayer - rat 1	0	-0.4270976	0.05854626	false
training	oneLayer	oneLayer - rat 1	0	-0.43128082	0.048447076	false
training	oneLayer	oneLayer - rat 1	0	-0.4354634	0.03834943	false
training	oneLayer	oneLayer - rat 1	0	-0.4354634	0.028255893	false
training	oneLayer	oneLayer - rat 1	0	-0.4315927	0.01891122	false
training	oneLayer	oneLayer - rat 1	0	-0.42429107	0.011609606	false
training	oneLayer	oneLayer - rat 1	0	-0.4148273	0.0076895677	false
training	oneLayer	oneLayer - rat 1	0	-0.40553588	0.003840945	false
training	oneLayer	oneLayer - rat 1	0	-0.3962862	9.60408E-6	false
training	oneLayer	oneLayer - rat 1	0	-0.3861585	-0.0041854284	false
training	oneLayer	oneLayer - rat 1	0	-0.37531847	-0.0041854265	false
training	oneLayer	oneLayer - rat 1	0	-0.36499754	-0.0041854247	false
training	oneLayer	oneLayer - rat 1	0	-0.35485134	-0.0041854233	false
training	oneLayer	oneLayer - rat 1	0	-0.34390008	-0.004185421	false
training	oneLayer	oneLayer - rat 1	0	-0.33341414	-0.0041854195	false
training	oneLayer	oneLayer - rat 1	0	-0.32304692	-0.0041854177	false
training	oneLayer	oneLayer - rat 1	0	-0.31283334	-0.004185416	false
training	oneLayer	oneLayer - rat 1	0	-0.3026863	-0.004185414	false
training	oneLayer	oneLayer - rat 1	0	-0.2919479	-0.004185412	false
training	oneLayer	oneLayer - rat 1	0	-0.28135794	-0.00418541	false
training	oneLayer	oneLayer - rat 1	0	-0.27104855	-0.0041854084	false
training	oneLayer	oneLayer - rat 1	0	-0.2606378	-0.0041854065	false
training	oneLayer	oneLayer - rat 1	0	-0.24974868	-0.0041854046	false
training	oneLayer	oneLayer - rat 1	0	-0.23950355	-0.0041854028	false
training	oneLayer	oneLayer - rat 1	0	-0.22935335	-0.004185401	false
training	oneLayer	oneLayer - rat 1	0	-0.21885559	-0.0041853995	false
training	oneLayer	oneLayer - rat 1	0	-0.20863634	-0.0041853976	false
training	oneLayer	oneLayer - rat 1	0	-0.19846411	-0.004185396	false
training	oneLayer	oneLayer - rat 1	0	-0.18845224	-0.004185394	false
training	oneLayer	oneLayer - rat 1	0	-0.1779893	-0.004185392	false
training	oneLayer	oneLayer - rat 1	0	-0.16776548	-0.00418539	false
training	oneLayer	oneLayer - rat 1	0	-0.15677671	-0.0041853883	false
training	oneLayer	oneLayer - rat 1	0	-0.146401	-0.0041853865	false
training	oneLayer	oneLayer - rat 1	0	-0.13588499	-0.0041853846	false
training	oneLayer	oneLayer - rat 1	0	-0.12576428	-0.004185383	false
training	oneLayer	oneLayer - rat 1	0	-0.11545367	-0.0041853813	false
training	oneLayer	oneLayer - rat 1	0	-0.10466652	-0.0041853795	false
training	oneLayer	oneLayer - rat 1	0	-0.094195746	-0.0041853776	false
training	oneLayer	oneLayer - rat 1	0	-0.08333608	-0.0041853758	false
training	oneLayer	oneLayer - rat 1	0	-0.07243166	-0.004185374	false
training	oneLayer	oneLayer - rat 1	0	-0.06175473	-0.004185372	false
training	oneLayer	oneLayer - rat 1	0	-0.05106654	-0.00418537	false
training	oneLayer	oneLayer - rat 1	0	-0.04052625	-0.0041853683	false
training	oneLayer	oneLayer - rat 1	0	-0.029839054	-0.0041853664	false
training	oneLayer	oneLayer - rat 1	0	-0.019411607	-0.0041853646	false
training	oneLayer	oneLayer - rat 1	0	-0.008995299	-0.0041853627	false
training	oneLayer	oneLayer - rat 1	0	0.0016941698	-0.004185361	false
training	oneLayer	oneLayer - rat 1	0	0.012564688	-0.004185359	false
training	oneLayer	oneLayer - rat 1	0	0.023283882	-0.004185357	false
training	oneLayer	oneLayer - rat 1	0	0.03399705	-0.0041853553	false
training	oneLayer	oneLayer - rat 1	0	0.044365745	-0.0041853534	false
training	oneLayer	oneLayer - rat 1	0	0.054576736	-0.0041853515	false
training	oneLayer	oneLayer - rat 1	0	0.065331	-0.0041853497	false
training	oneLayer	oneLayer - rat 1	0	0.075845785	-0.004185348	false
training	oneLayer	oneLayer - rat 1	0	0.08646099	-0.004185346	false
training	oneLayer	oneLayer - rat 1	0	0.097309895	-0.004185344	false
training	oneLayer	oneLayer - rat 1	0	0.10738377	-0.004185342	false
training	oneLayer	oneLayer - rat 1	0	0.11749579	-0.0041853404	false
training	oneLayer	oneLayer - rat 1	0	0.12799461	-0.0041853385	false
training	oneLayer	oneLayer - rat 1	0	0.13835579	-0.0041853366	false
training	oneLayer	oneLayer - rat 1	0	0.14847268	-0.0041853352	false
training	oneLayer	oneLayer - rat 1	0	0.15935986	-0.0041853334	false
training	oneLayer	oneLayer - rat 1	0	0.17013	-0.004185331	false
training	oneLayer	oneLayer - rat 1	0	0.18075813	-0.004185329	false
training	oneLayer	oneLayer - rat 1	0	0.19103421	-0.004185328	false
training	oneLayer	oneLayer - rat 1	0	0.20124967	-0.004185326	false
training	oneLayer	oneLayer - rat 1	0	0.21222179	-0.004185324	false
training	oneLayer	oneLayer - rat 1	0	0.22303899	-0.004185322	false
training	oneLayer	oneLayer - rat 1	0	0.23343968	-0.0041853203	false
training	oneLayer	oneLayer - rat 1	0	0.24436428	-0.0041853185	false
training	oneLayer	oneLayer - rat 1	0	0.25471246	-0.0041853166	false
training	oneLayer	oneLayer - rat 1	0	0.26476887	-0.0041853148	false
training	oneLayer	oneLayer - rat 1	0	0.2751441	-0.004185313	false
training	oneLayer	oneLayer - rat 1	0	0.28519145	-0.004185311	false
training	oneLayer	oneLayer - rat 1	0	0.29564735	-0.004185309	false
training	oneLayer	oneLayer - rat 1	0	0.3058207	-0.004185308	false
training	oneLayer	oneLayer - rat 1	0	0.31657797	-0.0041853054	false
training	oneLayer	oneLayer - rat 1	0	0.32686108	-0.004185304	false
training	oneLayer	oneLayer - rat 1	0	0.3378358	-0.004185302	false
training	oneLayer	oneLayer - rat 1	0	0.3481996	-0.0041853003	false
training	oneLayer	oneLayer - rat 1	0	0.35893258	-0.0041852985	false
training	oneLayer	oneLayer - rat 1	0	0.3693419	-0.0041852966	false
training	oneLayer	oneLayer - rat 1	0	0.37992913	-0.0041852947	false
training	oneLayer	oneLayer - rat 1	0	0.3907154	-0.004185293	false
training	oneLayer	oneLayer - rat 1	0	0.4016518	-0.004185291	false
training	oneLayer	oneLayer - rat 1	0	0.41094974	-3.3395365E-4	false
training	oneLayer	oneLayer - rat 1	0	0.4183698	0.007086104	false
training	oneLayer	oneLayer - rat 1	0	0.42235467	0.016706407	false
training	oneLayer	oneLayer - rat 1	0	0.42235467	0.02762723	false
training	oneLayer	oneLayer - rat 1	0	0.41846406	0.03701993	false
training	oneLayer	oneLayer - rat 1	0	0.4112442	0.044239786	false
training	oneLayer	oneLayer - rat 1	0	0.40158412	0.04824112	false
training	oneLayer	oneLayer - rat 1	0	0.3913534	0.04824112	false
training	oneLayer	oneLayer - rat 1	0	0.38135165	0.048241116	false
training	oneLayer	oneLayer - rat 1	0	0.3711519	0.048241112	false
training	oneLayer	oneLayer - rat 1	0	0.36090365	0.04824111	false
training	oneLayer	oneLayer - rat 1	0	0.3506468	0.04824111	false
training	oneLayer	oneLayer - rat 1	0	0.34046862	0.048241105	false
training	oneLayer	oneLayer - rat 1	0	0.3299018	0.0482411	false
training	oneLayer	oneLayer - rat 1	0	0.31915534	0.0482411	false
training	oneLayer	oneLayer - rat 1	0	0.30852768	0.048241097	false
training	oneLayer	oneLayer - rat 1	0	0.29783183	0.048241094	false
training	oneLayer	oneLayer - rat 1	0	0.28700033	0.04824109	false
training	oneLayer	oneLayer - rat 1	0	0.27681452	0.04824109	false
training	oneLayer	oneLayer - rat 1	0	0.26605082	0.048241086	false
training	oneLayer	oneLayer - rat 1	0	0.25521666	0.048241083	false
training	oneLayer	oneLayer - rat 1	0	0.24521309	0.04824108	false
training	oneLayer	oneLayer - rat 1	0	0.2347121	0.04824108	false
training	oneLayer	oneLayer - rat 1	0	0.22405532	0.048241075	false
training	oneLayer	oneLayer - rat 1	0	0.21327505	0.04824107	false
training	oneLayer	oneLayer - rat 1	0	0.20245203	0.048241068	false
training	oneLayer	oneLayer - rat 1	0	0.19205453	0.048241068	false
training	oneLayer	oneLayer - rat 1	0	0.18187499	0.048241064	false
training	oneLayer	oneLayer - rat 1	0	0.17165934	0.04824106	false
training	oneLayer	oneLayer - rat 1	0	0.16124701	0.048241057	false
training	oneLayer	oneLayer - rat 1	0	0.15082775	0.048241057	false
training	oneLayer	oneLayer - rat 1	0	0.14052129	0.048241053	false
training	oneLayer	oneLayer - rat 1	0	0.13047737	0.04824105	false
training	oneLayer	oneLayer - rat 1	0	0.12045499	0.04824105	false
training	oneLayer	oneLayer - rat 1	0	0.110298954	0.048241045	false
training	oneLayer	oneLayer - rat 1	0	0.09971088	0.04824104	false
training	oneLayer	oneLayer - rat 1	0	0.08963094	0.048241038	false
training	oneLayer	oneLayer - rat 1	0	0.07869922	0.048241038	false
training	oneLayer	oneLayer - rat 1	0	0.0686032	0.048241034	false
training	oneLayer	oneLayer - rat 1	0	0.05775743	0.04824103	false
training	oneLayer	oneLayer - rat 1	0	0.0469003	0.048241027	false
training	oneLayer	oneLayer - rat 1	0	0.036312953	0.048241027	false
training	oneLayer	oneLayer - rat 1	0	0.026020242	0.048241023	false
training	oneLayer	oneLayer - rat 1	0	0.015309564	0.04824102	false
training	oneLayer	oneLayer - rat 1	0	0.0050275247	0.048241016	false
training	oneLayer	oneLayer - rat 1	0	-0.0051689423	0.048241016	false
training	oneLayer	oneLayer - rat 1	0	-0.015227505	0.04824101	false
training	oneLayer	oneLayer - rat 1	0	-0.025907578	0.048241008	false
training	oneLayer	oneLayer - rat 1	0	-0.036176953	0.048241008	false
training	oneLayer	oneLayer - rat 1	0	-0.04621064	0.048241004	false
training	oneLayer	oneLayer - rat 1	0	-0.056529485	0.048241	false
training	oneLayer	oneLayer - rat 1	0	-0.06744403	0.048240997	false
training	oneLayer	oneLayer - rat 1	0	-0.07783059	0.048240997	false
training	oneLayer	oneLayer - rat 1	0	-0.08853438	0.048240993	false
training	oneLayer	oneLayer - rat 1	0	-0.09859181	0.04824099	false
training	oneLayer	oneLayer - rat 1	0	-0.10884992	0.048240986	false
training	oneLayer	oneLayer - rat 1	0	-0.1197194	0.048240986	false
training	oneLayer	oneLayer - rat 1	0	-0.13043287	0.048240982	false
training	oneLayer	oneLayer - rat 1	0	-0.1409428	0.04824098	false
training	oneLayer	oneLayer - rat 1	0	-0.15125874	0.048240975	false
training	oneLayer	oneLayer - rat 1	0	-0.16173881	0.048240975	false
training	oneLayer	oneLayer - rat 1	0	-0.17244515	0.04824097	false
training	oneLayer	oneLayer - rat 1	0	-0.18334204	0.048240967	false
training	oneLayer	oneLayer - rat 1	0	-0.19334334	0.048240963	false
training	oneLayer	oneLayer - rat 1	0	-0.20431666	0.048240963	false
training	oneLayer	oneLayer - rat 1	0	-0.2151675	0.04824096	false
training	oneLayer	oneLayer - rat 1	0	-0.22517912	0.048240956	false
training	oneLayer	oneLayer - rat 1	0	-0.23577113	0.048240952	false
training	oneLayer	oneLayer - rat 1	0	-0.2465401	0.048240952	false
training	oneLayer	oneLayer - rat 1	0	-0.25667048	0.04824095	false
training	oneLayer	oneLayer - rat 1	0	-0.26713288	0.048240945	false
training	oneLayer	oneLayer - rat 1	0	-0.27786958	0.048240945	false
training	oneLayer	oneLayer - rat 1	0	-0.2886916	0.04824094	false
training	oneLayer	oneLayer - rat 1	0	-0.29958016	0.048240937	false
training	oneLayer	oneLayer - rat 1	0	-0.31031454	0.048240934	false
training	oneLayer	oneLayer - rat 1	0	-0.32114303	0.04824093	false
training	oneLayer	oneLayer - rat 1	0	-0.33137977	0.04824093	false
training	oneLayer	oneLayer - rat 1	0	-0.341864	0.048240926	false
training	oneLayer	oneLayer - rat 1	0	-0.35193685	0.04406861	false
training	oneLayer	oneLayer - rat 1	0	-0.36164078	0.040049113	false
training	oneLayer	oneLayer - rat 1	0	-0.37120625	0.036086954	false
training	oneLayer	oneLayer - rat 1	0	-0.3804693	0.032250077	false
training	oneLayer	oneLayer - rat 1	0	-0.3899745	0.028312888	false
training	oneLayer	oneLayer - rat 1	0	-0.39971069	0.02428003	false
training	oneLayer	oneLayer - rat 1	0	-0.40944287	0.020248821	false
training	oneLayer	oneLayer - rat 1	0	-0.41689482	0.012796855	false
training	oneLayer	oneLayer - rat 1	0	-0.42107078	0.002715224	false
training	oneLayer	oneLayer - rat 1	0	-0.42107078	-0.007464072	false
training	oneLayer	oneLayer - rat 1	0	-0.41689178	-0.01755301	false
training	oneLayer	oneLayer - rat 1	0	-0.40933773	-0.025107056	false
training	oneLayer	oneLayer - rat 1	0	-0.39919984	-0.029306306	false
training	oneLayer	oneLayer - rat 1	0	-0.38839173	-0.029306302	false
training	oneLayer	oneLayer - rat 1	0	-0.37745765	-0.029306298	false
training	oneLayer	oneLayer - rat 1	0	-0.36672387	-0.029306294	false
training	oneLayer	oneLayer - rat 1	0	-0.35588065	-0.02930629	false
training	oneLayer	oneLayer - rat 1	0	-0.34565642	-0.029306287	false
training	oneLayer	oneLayer - rat 1	0	-0.3354362	-0.029306283	false
training	oneLayer	oneLayer - rat 1	0	-0.32504126	-0.02930628	false
training	oneLayer	oneLayer - rat 1	0	-0.31491992	-0.029306276	false
training	oneLayer	oneLayer - rat 1	0	-0.30427858	-0.029306272	false
training	oneLayer	oneLayer - rat 1	0	-0.29398158	-0.029306268	false
training	oneLayer	oneLayer - rat 1	0	-0.2835115	-0.029306265	false
training	oneLayer	oneLayer - rat 1	0	-0.27312285	-0.02930626	false
training	oneLayer	oneLayer - rat 1	0	-0.26232836	-0.029306257	false
training	oneLayer	oneLayer - rat 1	0	-0.25141513	-0.029306253	false
training	oneLayer	oneLayer - rat 1	0	-0.24137715	-0.02930625	false
training	oneLayer	oneLayer - rat 1	0	-0.23084846	-0.029306246	false
training	oneLayer	oneLayer - rat 1	0	-0.21989143	-0.029306242	false
training	oneLayer	oneLayer - rat 1	0	-0.20977312	-0.029306239	false
training	oneLayer	oneLayer - rat 1	0	-0.19929504	-0.029306235	false
training	oneLayer	oneLayer - rat 1	0	-0.18878885	-0.029306231	false
training	oneLayer	oneLayer - rat 1	0	-0.17810489	-0.029306227	false
training	oneLayer	oneLayer - rat 1	0	-0.16791138	-0.029306225	false
training	oneLayer	oneLayer - rat 1	0	-0.1579034	-0.029306222	false
training	oneLayer	oneLayer - rat 1	0	-0.14720175	-0.029306218	false
training	oneLayer	oneLayer - rat 1	0	-0.13639988	-0.029306214	false
training	oneLayer	oneLayer - rat 1	0	-0.12627412	-0.02930621	false
training	oneLayer	oneLayer - rat 1	0	-0.11576003	-0.029306207	false
training	oneLayer	oneLayer - rat 1	0	-0.10502515	-0.029306203	false
training	oneLayer	oneLayer - rat 1	0	-0.094802506	-0.0293062	false
training	oneLayer	oneLayer - rat 1	0	-0.08457402	-0.029306196	false
training	oneLayer	oneLayer - rat 1	0	-0.074082196	-0.029306192	false
training	oneLayer	oneLayer - rat 1	0	-0.06347168	-0.029306188	false
training	oneLayer	oneLayer - rat 1	0	-0.052541222	-0.029306185	false
training	oneLayer	oneLayer - rat 1	0	-0.041997746	-0.02930618	false
training	oneLayer	oneLayer - rat 1	0	-0.031005334	-0.029306177	false
training	oneLayer	oneLayer - rat 1	0	-0.020316642	-0.029306173	false
training	oneLayer	oneLayer - rat 1	0	-0.009851084	-0.02930617	false
training	oneLayer	oneLayer - rat 1	0	3.3868419E-4	-0.029306166	false
training	oneLayer	oneLayer - rat 1	0	0.010795404	-0.029306162	false
training	oneLayer	oneLayer - rat 1	0	0.021050453	-0.029306158	false
training	oneLayer	oneLayer - rat 1	0	0.031392436	-0.029306155	false
training	oneLayer	oneLayer - rat 1	0	0.041728646	-0.029306151	false
training	oneLayer	oneLayer - rat 1	0	0.052113146	-0.029306147	false
training	oneLayer	oneLayer - rat 1	0	0.062429417	-0.029306144	false
training	oneLayer	oneLayer - rat 1	0	0.07336548	-0.02930614	false
training	oneLayer	oneLayer - rat 1	0	0.08409412	-0.029306136	false
training	oneLayer	oneLayer - rat 1	0	0.09466714	-0.029306132	false
training	oneLayer	oneLayer - rat 1	0	0.10484323	-0.029306129	false
training	oneLayer	oneLayer - rat 1	0	0.11555295	-0.029306125	false
training	oneLayer	oneLayer - rat 1	0	0.12652712	-0.029306121	false
training	oneLayer	oneLayer - rat 1	0	0.13661782	-0.029306117	false
training	oneLayer	oneLayer - rat 1	0	0.1470989	-0.029306114	false
training	oneLayer	oneLayer - rat 1	0	0.15723433	-0.029306112	false
training	oneLayer	oneLayer - rat 1	0	0.16743919	-0.029306108	false
training	oneLayer	oneLayer - rat 1	0	0.17831112	-0.029306104	false
training	oneLayer	oneLayer - rat 1	0	0.18841721	-0.0293061	false
training	oneLayer	oneLayer - rat 1	0	0.19861956	-0.029306097	false
training	oneLayer	oneLayer - rat 1	0	0.20934825	-0.029306093	false
training	oneLayer	oneLayer - rat 1	0	0.2196899	-0.02930609	false
training	oneLayer	oneLayer - rat 1	0	0.23048502	-0.029306086	false
training	oneLayer	oneLayer - rat 1	0	0.24087182	-0.029306082	false
training	oneLayer	oneLayer - rat 1	0	0.25133952	-0.029306078	false
training	oneLayer	oneLayer - rat 1	0	0.26226357	-0.029306075	false
training	oneLayer	oneLayer - rat 1	0	0.2723864	-0.02930607	false
training	oneLayer	oneLayer - rat 1	0	0.28333512	-0.029306067	false
training	oneLayer	oneLayer - rat 1	0	0.29428363	-0.029306063	false
training	oneLayer	oneLayer - rat 1	0	0.3049801	-0.02930606	false
training	oneLayer	oneLayer - rat 1	0	0.31536666	-0.029306056	false
training	oneLayer	oneLayer - rat 1	0	0.32576343	-0.029306052	false
training	oneLayer	oneLayer - rat 1	0	0.3359698	-0.029306049	false
training	oneLayer	oneLayer - rat 1	0	0.34618703	-0.029306045	false
training	oneLayer	oneLayer - rat 1	0	0.3568316	-0.029306041	false
training	oneLayer	oneLayer - rat 1	0	0.3675878	-0.029306037	false
training	oneLayer	oneLayer - rat 1	0	0.3778535	-0.029306034	false
training	oneLayer	oneLayer - rat 1	0	0.3884881	-0.02930603	false
training	oneLayer	oneLayer - rat 1	0	0.3981736	-0.025294168	false
training	oneLayer	oneLayer - rat 1	0	0.40764248	-0.02137203	false
training	oneLayer	oneLayer - rat 1	0	0.41535118	-0.0136633245	false
training	oneLayer	oneLayer - rat 1	0	0.41954398	-0.0035409871	false
training	oneLayer	oneLayer - rat 1	0	0.41954398	0.006760016	false
training	oneLayer	oneLayer - rat 1	0	0.41538632	0.016797459	false
training	oneLayer	oneLayer - rat 1	0	0.40798163	0.024202133	false
training	oneLayer	oneLayer - rat 1	0	0.398653	0.028066183	false
training	oneLayer	oneLayer - rat 1	0	0.38856778	0.032243613	false
training	oneLayer	oneLayer - rat 1	0	0.3790021	0.03620584	false
training	oneLayer	oneLayer - rat 1	0	0.36951452	0.04013572	false
training	oneLayer	oneLayer - rat 1	0	0.3594717	0.044295575	false
training	oneLayer	oneLayer - rat 1	0	0.349395	0.048469488	false
training	oneLayer	oneLayer - rat 1	0	0.33965585	0.05250357	false
training	oneLayer	oneLayer - rat 1	0	0.32969964	0.056627557	false
training	oneLayer	oneLayer - rat 1	0	0.3198793	0.060695283	false
training	oneLayer	oneLayer - rat 1	0	0.30995038	0.06480797	false
training	oneLayer	oneLayer - rat 1	0	0.29995307	0.06894898	false
training	oneLayer	oneLayer - rat 1	0	0.29008955	0.07303458	false
training	oneLayer	oneLayer - rat 1	0	0.28034323	0.07707163	false
training	oneLayer	oneLayer - rat 1	0	0.27051795	0.0811414	false
training	oneLayer	oneLayer - rat 1	0	0.26114318	0.08502454	false
training	oneLayer	oneLayer - rat 1	0	0.25160274	0.088976316	false
training	oneLayer	oneLayer - rat 1	0	0.24157082	0.09313167	false
training	oneLayer	oneLayer - rat 1	0	0.23150901	0.0972994	false
training	oneLayer	oneLayer - rat 1	0	0.22206298	0.10121208	false
training	oneLayer	oneLayer - rat 1	0	0.21203981	0.10536379	false
training	oneLayer	oneLayer - rat 1	0	0.20222324	0.10942995	false
training	oneLayer	oneLayer - rat 1	0	0.19238289	0.11350595	false
training	oneLayer	oneLayer - rat 1	0	0.18291281	0.11742858	false
training	oneLayer	oneLayer - rat 1	0	0.1729311	0.12156314	false
training	oneLayer	oneLayer - rat 1	0	0.16368935	0.12539119	false
training	oneLayer	oneLayer - rat 1	0	0.15379444	0.1294898	false
training	oneLayer	oneLayer - rat 1	0	0.1442896	0.13342682	false
training	oneLayer	oneLayer - rat 1	0	0.1343374	0.13754916	false
training	oneLayer	oneLayer - rat 1	0	0.12491246	0.14145309	false
training	oneLayer	oneLayer - rat 1	0	0.115090445	0.14552149	false
training	oneLayer	oneLayer - rat 1	0	0.10528068	0.14958483	false
training	oneLayer	oneLayer - rat 1	0	0.0954648	0.15365069	false
training	oneLayer	oneLayer - rat 1	0	0.085788086	0.15765892	false
training	oneLayer	oneLayer - rat 1	0	0.0759417	0.16173741	false
training	oneLayer	oneLayer - rat 1	0	0.06631604	0.16572449	false
training	oneLayer	oneLayer - rat 1	0	0.05653733	0.16977496	false
training	oneLayer	oneLayer - rat 1	0	0.04662956	0.1738789	false
training	oneLayer	oneLayer - rat 1	0	0.03669031	0.17799586	false
training	oneLayer	oneLayer - rat 1	0	0.02680184	0.18209179	false
training	oneLayer	oneLayer - rat 1	0	0.016668664	0.18628909	false
training	oneLayer	oneLayer - rat 1	0	0.0073373145	0.19015425	false
training	oneLayer	oneLayer - rat 1	0	-0.0024913533	0.19422542	false
training	oneLayer	oneLayer - rat 1	0	-0.011976751	0.19815439	false
training	oneLayer	oneLayer - rat 1	0	-0.021756375	0.20220523	false
training	oneLayer	oneLayer - rat 1	0	-0.031128844	0.20608744	false
training	oneLayer	oneLayer - rat 1	0	-0.041291256	0.21029684	false
training	oneLayer	oneLayer - rat 1	0	-0.051026553	0.21432932	false
training	oneLayer	oneLayer - rat 1	0	-0.060802557	0.21837868	false
training	oneLayer	oneLayer - rat 1	0	-0.070667915	0.22246504	false
training	oneLayer	oneLayer - rat 1	0	-0.08005801	0.22635452	false
training	oneLayer	oneLayer - rat 1	0	-0.08983888	0.2304059	false
training	oneLayer	oneLayer - rat 1	0	-0.099516064	0.23441431	false
training	oneLayer	oneLayer - rat 1	0	-0.10895871	0.23832558	false
training	oneLayer	oneLayer - rat 1	0	-0.11867388	0.24234973	false
training	oneLayer	oneLayer - rat 1	0	-0.12883514	0.24655865	false
training	oneLayer	oneLayer - rat 1	0	-0.13808857	0.25039154	false
training	oneLayer	oneLayer - rat 1	0	-0.14764096	0.25434828	false
training	oneLayer	oneLayer - rat 1	0	-0.15776783	0.25854295	false
training	oneLayer	oneLayer - rat 1	0	-0.16723165	0.262463	false
training	oneLayer	oneLayer - rat 1	0	-0.17690349	0.26646918	false
training	oneLayer	oneLayer - rat 1	0	-0.18659334	0.27048287	false
training	oneLayer	oneLayer - rat 1	0	-0.19587557	0.27432767	false
training	oneLayer	oneLayer - rat 1	0	-0.20586866	0.27846694	false
training	oneLayer	oneLayer - rat 1	0	-0.21577579	0.2825706	false
training	oneLayer	oneLayer - rat 1	0	-0.2257262	0.2866922	false
training	oneLayer	oneLayer - rat 1	0	-0.2355603	0.2907656	false
training	oneLayer	oneLayer - rat 1	0	-0.2451646	0.29474384	false
training	oneLayer	oneLayer - rat 1	0	-0.25454485	0.29862925	false
training	oneLayer	oneLayer - rat 1	0	-0.2642588	0.3026529	false
training	oneLayer	oneLayer - rat 1	0	-0.2740556	0.30671087	false
training	oneLayer	oneLayer - rat 1	0	-0.28471506	0.30671087	false
training	oneLayer	oneLayer - rat 1	0	-0.29408005	0.30283174	false
training	oneLayer	oneLayer - rat 1	0	-0.3013207	0.29559112	false
training	oneLayer	oneLayer - rat 1	0	-0.308957	0.28795478	false
training	oneLayer	oneLayer - rat 1	0	-0.31604564	0.28086612	false
training	oneLayer	oneLayer - rat 1	0	-0.32366356	0.27324823	false
training	oneLayer	oneLayer - rat 1	0	-0.33093137	0.2659804	false
training	oneLayer	oneLayer - rat 1	0	-0.3384331	0.25847867	false
training	oneLayer	oneLayer - rat 1	0	-0.34553602	0.25137573	false
training	oneLayer	oneLayer - rat 1	0	-0.3528402	0.24407157	false
training	oneLayer	oneLayer - rat 1	0	-0.35670152	0.2347494	false
training	oneLayer	oneLayer - rat 1	0	-0.36082694	0.22478975	false
training	oneLayer	oneLayer - rat 1	0	-0.36481857	0.21515311	false
training	oneLayer	oneLayer - rat 1	0	-0.36881423	0.20550673	false
training	oneLayer	oneLayer - rat 1	0	-0.37268665	0.19615787	false
training	oneLayer	oneLayer - rat 1	0	-0.37666142	0.18656191	false
training	oneLayer	oneLayer - rat 1	0	-0.3808595	0.17642684	false
training	oneLayer	oneLayer - rat 1	0	-0.38485292	0.16678587	false
training	oneLayer	oneLayer - rat 1	0	-0.3888382	0.15716451	false
training	oneLayer	oneLayer - rat 1	0	-0.392828	0.14753233	false
training	oneLayer	oneLayer - rat 1	0	-0.39698902	0.1374867	false
training	oneLayer	oneLayer - rat 1	0	-0.40100205	0.12779833	false
training	oneLayer	oneLayer - rat 1	0	-0.40495753	0.118248954	false
training	oneLayer	oneLayer - rat 1	0	-0.40879384	0.10898729	false
training	oneLayer	oneLayer - rat 1	0	-0.4128887	0.09910137	false
training	oneLayer	oneLayer - rat 1	0	-0.416916	0.08937858	false
training	oneLayer	oneLayer - rat 1	0	-0.42086783	0.07983807	false
training	oneLayer	oneLayer - rat 1	0	-0.42477047	0.070416234	false
training	oneLayer	oneLayer - rat 1	0	-0.42864114	0.06107157	false
training	oneLayer	oneLayer - rat 1	0	-0.43254426	0.051648654	false
training	oneLayer	oneLayer - rat 1	0	-0.4364907	0.04212105	false
training	oneLayer	oneLayer - rat 1	0	-0.4364907	0.031580605	false
training	oneLayer	oneLayer - rat 1	0	-0.43266335	0.022340564	false
training	oneLayer	oneLayer - rat 1	0	-0.42535937	0.015036586	false
training	oneLayer	oneLayer - rat 1	0	-0.4156975	0.011034514	false
training	oneLayer	oneLayer - rat 1	0	-0.40484977	0.011034519	false
training	oneLayer	oneLayer - rat 1	0	-0.3947071	0.0152357565	false
training	oneLayer	oneLayer - rat 1	0	-0.3875609	0.022381952	false
training	oneLayer	oneLayer - rat 1	0	-0.38355008	0.032064978	false
training	oneLayer	oneLayer - rat 1	0	-0.3796532	0.04147296	false
training	oneLayer	oneLayer - rat 1	0	-0.37571213	0.050987482	false
training	oneLayer	oneLayer - rat 1	0	-0.37170547	0.06066045	false
training	oneLayer	oneLayer - rat 1	0	-0.36787528	0.069907345	false
training	oneLayer	oneLayer - rat 1	0	-0.36387992	0.07955307	false
training	oneLayer	oneLayer - rat 1	0	-0.35967335	0.08970859	false
training	oneLayer	oneLayer - rat 1	0	-0.35578597	0.09909357	false
training	oneLayer	oneLayer - rat 1	0	-0.35172305	0.108902365	false
training	oneLayer	oneLayer - rat 1	0	-0.34752375	0.119040355	false
training	oneLayer	oneLayer - rat 1	0	-0.34359822	0.12851751	false
training	oneLayer	oneLayer - rat 1	0	-0.33941847	0.13860832	false
training	oneLayer	oneLayer - rat 1	0	-0.33557525	0.14788665	false
training	oneLayer	oneLayer - rat 1	0	-0.33145282	0.15783907	false
training	oneLayer	oneLayer - rat 1	0	-0.32759482	0.16715313	false
training	oneLayer	oneLayer - rat 1	0	-0.32347518	0.17709884	false
training	oneLayer	oneLayer - rat 1	0	-0.31941167	0.18690906	false
training	oneLayer	oneLayer - rat 1	0	-0.31941167	0.19701938	false
training	oneLayer	oneLayer - rat 1	0	-0.31941167	0.20774323	false
training	oneLayer	oneLayer - rat 1	0	-0.3194117	0.21827686	false
training	oneLayer	oneLayer - rat 1	0	-0.3194117	0.22916284	false
training	oneLayer	oneLayer - rat 1	0	-0.3194117	0.23991184	false
training	oneLayer	oneLayer - rat 1	0	-0.3194117	0.25052938	false
training	oneLayer	oneLayer - rat 1	0	-0.3194117	0.26061186	false
training	oneLayer	oneLayer - rat 1	0	-0.31941172	0.27133992	false
training	oneLayer	oneLayer - rat 1	0	-0.31941172	0.28208563	false
training	oneLayer	oneLayer - rat 1	0	-0.31941172	0.29274914	false
training	oneLayer	oneLayer - rat 1	0	-0.3154863	0.30222595	false
training	oneLayer	oneLayer - rat 1	0	-0.3116497	0.31148833	false
training	oneLayer	oneLayer - rat 1	0	-0.307493	0.32152352	false
training	oneLayer	oneLayer - rat 1	0	-0.3034168	0.33136433	false
training	oneLayer	oneLayer - rat 1	0	-0.2994873	0.34085104	false
training	oneLayer	oneLayer - rat 1	0	-0.29201877	0.34831956	false
training	oneLayer	oneLayer - rat 1	0	-0.28254235	0.35224482	false
training	oneLayer	oneLayer - rat 1	0	-0.27233952	0.35224482	false
training	oneLayer	oneLayer - rat 1	0	-0.26288366	0.34832808	false
training	oneLayer	oneLayer - rat 1	0	-0.2556716	0.341116	false
training	oneLayer	oneLayer - rat 1	0	-0.25162795	0.33135384	false
training	oneLayer	oneLayer - rat 1	0	-0.25162795	0.32090116	false
training	oneLayer	oneLayer - rat 1	0	-0.25578493	0.3108653	false
training	oneLayer	oneLayer - rat 1	0	-0.2598661	0.3010125	false
training	oneLayer	oneLayer - rat 1	0	-0.26370734	0.29173884	false
training	oneLayer	oneLayer - rat 1	0	-0.26779413	0.28187245	false
training	oneLayer	oneLayer - rat 1	0	-0.27194843	0.27184314	false
training	oneLayer	oneLayer - rat 1	0	-0.27582476	0.26248482	false
training	oneLayer	oneLayer - rat 1	0	-0.27985814	0.25274733	false
training	oneLayer	oneLayer - rat 1	0	-0.28373563	0.24338621	false
training	oneLayer	oneLayer - rat 1	0	-0.28760764	0.23403838	false
training	oneLayer	oneLayer - rat 1	0	-0.29144603	0.22477163	false
training	oneLayer	oneLayer - rat 1	0	-0.29538086	0.21527216	false
training	oneLayer	oneLayer - rat 1	0	-0.29948992	0.20535198	false
training	oneLayer	oneLayer - rat 1	0	-0.30338365	0.19595169	false
training	oneLayer	oneLayer - rat 1	0	-0.30731538	0.18645962	false
training	oneLayer	oneLayer - rat 1	0	-0.3112943	0.17685367	false
training	oneLayer	oneLayer - rat 1	0	-0.3152802	0.16723081	false
training	oneLayer	oneLayer - rat 1	0	-0.31912008	0.1579605	false
training	oneLayer	oneLayer - rat 1	0	-0.32311386	0.14831865	false
training	oneLayer	oneLayer - rat 1	0	-0.3270269	0.13887174	false
training	oneLayer	oneLayer - rat 1	0	-0.33123332	0.1287165	false
training	oneLayer	oneLayer - rat 1	0	-0.33523217	0.11906247	false
training	oneLayer	oneLayer - rat 1	0	-0.3391708	0.10955369	false
training	oneLayer	oneLayer - rat 1	0	-0.34637028	0.102354206	false
training	oneLayer	oneLayer - rat 1	0	-0.35388252	0.09484197	false
training	oneLayer	oneLayer - rat 1	0	-0.3611961	0.08752838	false
training	oneLayer	oneLayer - rat 1	0	-0.36829662	0.08042786	false
training	oneLayer	oneLayer - rat 1	0	-0.37599936	0.072725125	false
training	oneLayer	oneLayer - rat 1	0	-0.38317388	0.06555057	false
training	oneLayer	oneLayer - rat 1	0	-0.3905915	0.05813296	false
training	oneLayer	oneLayer - rat 1	0	-0.3980727	0.05065177	false
training	oneLayer	oneLayer - rat 1	0	-0.4052897	0.043434735	false
training	oneLayer	oneLayer - rat 1	0	-0.4130461	0.035678335	false
training	oneLayer	oneLayer - rat 1	0	-0.42039776	0.02832668	false
training	oneLayer	oneLayer - rat 1	0	-0.4243244	0.018846888	false
training	oneLayer	oneLayer - rat 1	0	-0.4243244	0.008219966	false
training	oneLayer	oneLayer - rat 1	0	-0.42033347	-0.0014149677	false
training	oneLayer	oneLayer - rat 1	0	-0.413095	-0.008653438	false
training	oneLayer	oneLayer - rat 1	0	-0.403826	-0.012492773	false
training	oneLayer	oneLayer - rat 1	0	-0.3933635	-0.012492768	false
training	oneLayer	oneLayer - rat 1	0	-0.38257432	-0.012492762	false
training	oneLayer	oneLayer - rat 1	0	-0.37163484	-0.012492756	false
training	oneLayer	oneLayer - rat 1	0	-0.3611782	-0.012492751	false
training	oneLayer	oneLayer - rat 1	0	-0.35077393	-0.012492745	false
training	oneLayer	oneLayer - rat 1	0	-0.339798	-0.01249274	false
training	oneLayer	oneLayer - rat 1	0	-0.32957354	-0.012492734	false
training	oneLayer	oneLayer - rat 1	0	-0.31941748	-0.012492729	false
training	oneLayer	oneLayer - rat 1	0	-0.30885288	-0.012492724	false
training	oneLayer	oneLayer - rat 1	0	-0.29879725	-0.012492718	false
training	oneLayer	oneLayer - rat 1	0	-0.28844634	-0.012492713	false
training	oneLayer	oneLayer - rat 1	0	-0.27754134	-0.012492707	false
training	oneLayer	oneLayer - rat 1	0	-0.26747593	-0.012492701	false
training	oneLayer	oneLayer - rat 1	0	-0.25677523	-0.012492696	false
training	oneLayer	oneLayer - rat 1	0	-0.24603672	-0.01249269	false
training	oneLayer	oneLayer - rat 1	0	-0.2358548	-0.012492686	false
training	oneLayer	oneLayer - rat 1	0	-0.22526439	-0.01249268	false
training	oneLayer	oneLayer - rat 1	0	-0.21502912	-0.012492674	false
training	oneLayer	oneLayer - rat 1	0	-0.2044302	-0.012492669	false
training	oneLayer	oneLayer - rat 1	0	-0.19430172	-0.012492663	false
training	oneLayer	oneLayer - rat 1	0	-0.18353513	-0.012492658	false
training	oneLayer	oneLayer - rat 1	0	-0.17270224	-0.012492652	false
training	oneLayer	oneLayer - rat 1	0	-0.1626105	-0.012492646	false
training	oneLayer	oneLayer - rat 1	0	-0.15233235	-0.012492642	false
training	oneLayer	oneLayer - rat 1	0	-0.14164655	-0.012492635	false
training	oneLayer	oneLayer - rat 1	0	-0.13106799	-0.012492631	false
training	oneLayer	oneLayer - rat 1	0	-0.12037275	-0.012492625	false
training	oneLayer	oneLayer - rat 1	0	-0.11017999	-0.012492619	false
training	oneLayer	oneLayer - rat 1	0	-0.099352255	-0.012492614	false
training	oneLayer	oneLayer - rat 1	0	-0.08896521	-0.012492608	false
training	oneLayer	oneLayer - rat 1	0	-0.078406654	-0.012492603	false
training	oneLayer	oneLayer - rat 1	0	-0.0677483	-0.012492597	false
training	oneLayer	oneLayer - rat 1	0	-0.057549514	-0.0124925915	false
training	oneLayer	oneLayer - rat 1	0	-0.046851788	-0.012492586	false
training	oneLayer	oneLayer - rat 1	0	-0.036005814	-0.01249258	false
training	oneLayer	oneLayer - rat 1	0	-0.025963748	-0.012492575	false
training	oneLayer	oneLayer - rat 1	0	-0.01547198	-0.012492569	false
training	oneLayer	oneLayer - rat 1	0	-0.0047633452	-0.012492564	false
training	oneLayer	oneLayer - rat 1	0	0.0057778126	-0.012492558	false
training	oneLayer	oneLayer - rat 1	0	0.016292993	-0.012492553	false
training	oneLayer	oneLayer - rat 1	0	0.026795657	-0.012492548	false
training	oneLayer	oneLayer - rat 1	0	0.037016805	-0.012492542	false
training	oneLayer	oneLayer - rat 1	0	0.047865536	-0.012492537	false
training	oneLayer	oneLayer - rat 1	0	0.058233377	-0.012492531	false
training	oneLayer	oneLayer - rat 1	0	0.06917555	-0.012492525	false
training	oneLayer	oneLayer - rat 1	0	0.07984271	-0.01249252	false
training	oneLayer	oneLayer - rat 1	0	0.09048919	-0.012492514	false
training	oneLayer	oneLayer - rat 1	0	0.10052816	-0.012492509	false
training	oneLayer	oneLayer - rat 1	0	0.11115305	-0.012492503	false
training	oneLayer	oneLayer - rat 1	0	0.12170963	-0.012492497	false
training	oneLayer	oneLayer - rat 1	0	0.13262065	-0.012492492	false
training	oneLayer	oneLayer - rat 1	0	0.14334914	-0.012492486	false
training	oneLayer	oneLayer - rat 1	0	0.15392625	-0.012492481	false
training	oneLayer	oneLayer - rat 1	0	0.16393183	-0.012492475	false
training	oneLayer	oneLayer - rat 1	0	0.17443022	-0.0124924695	false
training	oneLayer	oneLayer - rat 1	0	0.1850347	-0.012492464	false
training	oneLayer	oneLayer - rat 1	0	0.19514701	-0.012492459	false
training	oneLayer	oneLayer - rat 1	0	0.20534766	-0.012492454	false
training	oneLayer	oneLayer - rat 1	0	0.21623926	-0.012492448	false
training	oneLayer	oneLayer - rat 1	0	0.22698632	-0.0124924425	false
training	oneLayer	oneLayer - rat 1	0	0.2373484	-0.012492437	false
training	oneLayer	oneLayer - rat 1	0	0.24817784	-0.012492431	false
training	oneLayer	oneLayer - rat 1	0	0.259021	-0.012492426	false
training	oneLayer	oneLayer - rat 1	0	0.2691817	-0.01249242	false
training	oneLayer	oneLayer - rat 1	0	0.27954605	-0.012492415	false
training	oneLayer	oneLayer - rat 1	0	0.29017738	-0.012492409	false
training	oneLayer	oneLayer - rat 1	0	0.30067745	-0.012492403	false
training	oneLayer	oneLayer - rat 1	0	0.31137836	-0.012492398	false
training	oneLayer	oneLayer - rat 1	0	0.3219309	-0.012492392	false
training	oneLayer	oneLayer - rat 1	0	0.3324946	-0.012492387	false
training	oneLayer	oneLayer - rat 1	0	0.34306574	-0.012492381	false
training	oneLayer	oneLayer - rat 1	0	0.35389838	-0.012492375	false
training	oneLayer	oneLayer - rat 1	0	0.36471364	-0.01249237	false
training	oneLayer	oneLayer - rat 1	0	0.3754907	-0.012492364	false
training	oneLayer	oneLayer - rat 1	0	0.38584915	-0.012492359	false
training	oneLayer	oneLayer - rat 1	0	0.3962601	-0.012492354	false
training	oneLayer	oneLayer - rat 1	0	0.40686667	-0.012492348	false
training	oneLayer	oneLayer - rat 1	0	0.4164842	-0.008508634	false
training	oneLayer	oneLayer - rat 1	0	0.42369202	-0.0013008085	false
training	oneLayer	oneLayer - rat 1	0	0.42782202	0.0086699575	false
training	oneLayer	oneLayer - rat 1	0	0.42782202	0.018763155	false
training	oneLayer	oneLayer - rat 1	0	0.4237789	0.028524134	false
training	oneLayer	oneLayer - rat 1	0	0.4166383	0.035664715	false
training	oneLayer	oneLayer - rat 1	0	0.4071644	0.039588932	false
training	oneLayer	oneLayer - rat 1	0	0.3972054	0.043714073	false
training	oneLayer	oneLayer - rat 1	0	0.38742507	0.04776521	false
training	oneLayer	oneLayer - rat 1	0	0.37748164	0.05188391	false
training	oneLayer	oneLayer - rat 1	0	0.36822644	0.055717524	false
training	oneLayer	oneLayer - rat 1	0	0.35859665	0.05970631	false
training	oneLayer	oneLayer - rat 1	0	0.3492504	0.06357765	false
training	oneLayer	oneLayer - rat 1	0	0.33951384	0.06761066	false
training	oneLayer	oneLayer - rat 1	0	0.33000913	0.07154763	false
training	oneLayer	oneLayer - rat 1	0	0.3207595	0.07537895	false
training	oneLayer	oneLayer - rat 1	0	0.31113344	0.079366185	false
training	oneLayer	oneLayer - rat 1	0	0.30101204	0.0835586	false
training	oneLayer	oneLayer - rat 1	0	0.2911496	0.08764376	false
training	oneLayer	oneLayer - rat 1	0	0.28184468	0.091497965	false
training	oneLayer	oneLayer - rat 1	0	0.2725545	0.095346086	false
training	oneLayer	oneLayer - rat 1	0	0.262658	0.09944533	false
training	oneLayer	oneLayer - rat 1	0	0.2530236	0.10343603	false
training	oneLayer	oneLayer - rat 1	0	0.2431577	0.107522614	false
training	oneLayer	oneLayer - rat 1	0	0.23341015	0.11156017	false
training	oneLayer	oneLayer - rat 1	0	0.22376107	0.11555695	false
training	oneLayer	oneLayer - rat 1	0	0.21437329	0.11944548	false
training	oneLayer	oneLayer - rat 1	0	0.20474683	0.12343289	false
training	oneLayer	oneLayer - rat 1	0	0.19485329	0.12753092	false
training	oneLayer	oneLayer - rat 1	0	0.1847298	0.1317242	false
training	oneLayer	oneLayer - rat 1	0	0.17547736	0.13555668	false
training	oneLayer	oneLayer - rat 1	0	0.1660738	0.13945176	false
training	oneLayer	oneLayer - rat 1	0	0.15614922	0.14356264	false
training	oneLayer	oneLayer - rat 1	0	0.14651012	0.14755528	false
training	oneLayer	oneLayer - rat 1	0	0.13679618	0.15157892	false
training	oneLayer	oneLayer - rat 1	0	0.12719095	0.15555753	false
training	oneLayer	oneLayer - rat 1	0	0.1171612	0.15971199	false
training	oneLayer	oneLayer - rat 1	0	0.107827455	0.16357814	false
training	oneLayer	oneLayer - rat 1	0	0.0984125	0.16747794	false
training	oneLayer	oneLayer - rat 1	0	0.0889613	0.17139274	false
training	oneLayer	oneLayer - rat 1	0	0.078862585	0.17557576	false
training	oneLayer	oneLayer - rat 1	0	0.06923041	0.17956553	false
training	oneLayer	oneLayer - rat 1	0	0.059178572	0.18372913	false
training	oneLayer	oneLayer - rat 1	0	0.049315933	0.18781437	false
training	oneLayer	oneLayer - rat 1	0	0.03928205	0.19197053	false
training	oneLayer	oneLayer - rat 1	0	0.029784821	0.1959044	false
training	oneLayer	oneLayer - rat 1	0	0.020058382	0.19993322	false
training	oneLayer	oneLayer - rat 1	0	0.009951334	0.20411968	false
training	oneLayer	oneLayer - rat 1	0	2.9350218E-4	0.20812008	false
training	oneLayer	oneLayer - rat 1	0	-0.0093010375	0.21209426	false
training	oneLayer	oneLayer - rat 1	0	-0.019265871	0.21622182	false
training	oneLayer	oneLayer - rat 1	0	-0.028833134	0.22018471	false
training	oneLayer	oneLayer - rat 1	0	-0.038270943	0.22409397	false
training	oneLayer	oneLayer - rat 1	0	-0.048293304	0.22824536	false
training	oneLayer	oneLayer - rat 1	0	-0.058087252	0.23230214	false
training	oneLayer	oneLayer - rat 1	0	-0.067788824	0.23632066	false
training	oneLayer	oneLayer - rat 1	0	-0.0775844	0.24037811	false
training	oneLayer	oneLayer - rat 1	0	-0.08695968	0.24426147	false
training	oneLayer	oneLayer - rat 1	0	-0.09646533	0.24819884	false
training	oneLayer	oneLayer - rat 1	0	-0.10640125	0.25231442	false
training	oneLayer	oneLayer - rat 1	0	-0.115708634	0.25616965	false
training	oneLayer	oneLayer - rat 1	0	-0.12538835	0.26017913	false
training	oneLayer	oneLayer - rat 1	0	-0.1354692	0.26435474	false
training	oneLayer	oneLayer - rat 1	0	-0.1454981	0.26850885	false
training	oneLayer	oneLayer - rat 1	0	-0.15489978	0.27240315	false
training	oneLayer	oneLayer - rat 1	0	-0.16496338	0.2765716	false
training	oneLayer	oneLayer - rat 1	0	-0.1748275	0.28065747	false
training	oneLayer	oneLayer - rat 1	0	-0.1849081	0.28483298	false
training	oneLayer	oneLayer - rat 1	0	-0.19430032	0.28872335	false
training	oneLayer	oneLayer - rat 1	0	-0.20429559	0.29286352	false
training	oneLayer	oneLayer - rat 1	0	-0.21425048	0.29698697	false
training	oneLayer	oneLayer - rat 1	0	-0.22402792	0.3010369	false
training	oneLayer	oneLayer - rat 1	0	-0.23365405	0.30502418	false
training	oneLayer	oneLayer - rat 1	0	-0.2433905	0.30905712	false
training	oneLayer	oneLayer - rat 1	0	-0.25264552	0.31289068	false
training	oneLayer	oneLayer - rat 1	0	-0.26237231	0.31691965	false
training	oneLayer	oneLayer - rat 1	0	-0.27292168	0.31691965	false
training	oneLayer	oneLayer - rat 1	0	-0.28234088	0.31301808	false
training	oneLayer	oneLayer - rat 1	0	-0.28967443	0.30568454	false
training	oneLayer	oneLayer - rat 1	0	-0.2972637	0.29809523	false
training	oneLayer	oneLayer - rat 1	0	-0.3050212	0.29033774	false
training	oneLayer	oneLayer - rat 1	0	-0.31245646	0.28290245	false
training	oneLayer	oneLayer - rat 1	0	-0.31979483	0.2755641	false
training	oneLayer	oneLayer - rat 1	0	-0.32731616	0.26804274	false
training	oneLayer	oneLayer - rat 1	0	-0.33490944	0.26044944	false
training	oneLayer	oneLayer - rat 1	0	-0.34262127	0.25273764	false
training	oneLayer	oneLayer - rat 1	0	-0.34975523	0.24560365	false
training	oneLayer	oneLayer - rat 1	0	-0.3537395	0.23598479	false
training	oneLayer	oneLayer - rat 1	0	-0.35762948	0.22659348	false
training	oneLayer	oneLayer - rat 1	0	-0.36146167	0.21734177	false
training	oneLayer	oneLayer - rat 1	0	-0.36529544	0.20808618	false
training	oneLayer	oneLayer - rat 1	0	-0.36929923	0.19842014	false
training	oneLayer	oneLayer - rat 1	0	-0.37349072	0.18830103	false
training	oneLayer	oneLayer - rat 1	0	-0.37765053	0.1782583	false
training	oneLayer	oneLayer - rat 1	0	-0.3817967	0.16824861	false
training	oneLayer	oneLayer - rat 1	0	-0.38600284	0.15809402	false
training	oneLayer	oneLayer - rat 1	0	-0.39003477	0.1483601	false
training	oneLayer	oneLayer - rat 1	0	-0.39421454	0.13826917	false
training	oneLayer	oneLayer - rat 1	0	-0.39813897	0.12879477	false
training	oneLayer	oneLayer - rat 1	0	-0.40215397	0.11910168	false
training	oneLayer	oneLayer - rat 1	0	-0.40613487	0.10949089	false
training	oneLayer	oneLayer - rat 1	0	-0.41010824	0.09989832	false
training	oneLayer	oneLayer - rat 1	0	-0.41416937	0.0900939	false
training	oneLayer	oneLayer - rat 1	0	-0.41830537	0.0801087	false
training	oneLayer	oneLayer - rat 1	0	-0.42229757	0.07047067	false
training	oneLayer	oneLayer - rat 1	0	-0.42614087	0.061192036	false
training	oneLayer	oneLayer - rat 1	0	-0.43005496	0.05174258	false
training	oneLayer	oneLayer - rat 1	0	-0.4341485	0.041859947	false
training	oneLayer	oneLayer - rat 1	0	-0.4341485	0.031306777	false
training	oneLayer	oneLayer - rat 1	0	-0.42996243	0.021200802	false
training	oneLayer	oneLayer - rat 1	0	-0.4223244	0.013562753	false
training	oneLayer	oneLayer - rat 1	0	-0.4129017	0.009659763	false
training	oneLayer	oneLayer - rat 1	0	-0.40308088	0.0055918503	false
training	oneLayer	oneLayer - rat 1	0	-0.3934871	0.0016179873	false
training	oneLayer	oneLayer - rat 1	0	-0.38338783	-0.0025652582	false
training	oneLayer	oneLayer - rat 1	0	-0.3731303	-0.002565251	false
training	oneLayer	oneLayer - rat 1	0	-0.36258554	-0.0025652435	false
training	oneLayer	oneLayer - rat 1	0	-0.3521514	-0.0025652363	false
training	oneLayer	oneLayer - rat 1	0	-0.34186018	-0.002565229	false
training	oneLayer	oneLayer - rat 1	0	-0.33148137	-0.0025652219	false
training	oneLayer	oneLayer - rat 1	0	-0.32118964	-0.0025652146	false
training	oneLayer	oneLayer - rat 1	0	-0.3111673	-0.0025652077	false
training	oneLayer	oneLayer - rat 1	0	-0.30109343	-0.0025652007	false
training	oneLayer	oneLayer - rat 1	0	-0.29054904	-0.0025651932	false
training	oneLayer	oneLayer - rat 1	0	-0.28004023	-0.0025651858	false
training	oneLayer	oneLayer - rat 1	0	-0.2697396	-0.0025651786	false
training	oneLayer	oneLayer - rat 1	0	-0.2592264	-0.0025651713	false
training	oneLayer	oneLayer - rat 1	0	-0.24900533	-0.0025651641	false
training	oneLayer	oneLayer - rat 1	0	-0.23884417	-0.0025651571	false
training	oneLayer	oneLayer - rat 1	0	-0.22833954	-0.0025651497	false
training	oneLayer	oneLayer - rat 1	0	-0.217877	-0.0025651425	false
training	oneLayer	oneLayer - rat 1	0	-0.20712443	-0.0025651348	false
training	oneLayer	oneLayer - rat 1	0	-0.19684814	-0.0025651276	false
training	oneLayer	oneLayer - rat 1	0	-0.18608579	-0.00256512	false
training	oneLayer	oneLayer - rat 1	0	-0.17537999	-0.0025651127	false
training	oneLayer	oneLayer - rat 1	0	-0.1648474	-0.0025651052	false
training	oneLayer	oneLayer - rat 1	0	-0.15439858	-0.002565098	false
training	oneLayer	oneLayer - rat 1	0	-0.14427696	-0.002565091	false
training	oneLayer	oneLayer - rat 1	0	-0.1339622	-0.0025650838	false
training	oneLayer	oneLayer - rat 1	0	-0.12341255	-0.0025650763	false
training	oneLayer	oneLayer - rat 1	0	-0.11285646	-0.002565069	false
training	oneLayer	oneLayer - rat 1	0	-0.102497876	-0.0025650617	false
training	oneLayer	oneLayer - rat 1	0	-0.092169404	-0.0025650545	false
training	oneLayer	oneLayer - rat 1	0	-0.08177857	-0.0025650472	false
training	oneLayer	oneLayer - rat 1	0	-0.07139701	-0.00256504	false
training	oneLayer	oneLayer - rat 1	0	-0.061179273	-0.0025650328	false
training	oneLayer	oneLayer - rat 1	0	-0.050271053	-0.0025650251	false
training	oneLayer	oneLayer - rat 1	0	-0.03999183	-0.002565018	false
training	oneLayer	oneLayer - rat 1	0	-0.029161498	-0.0025650105	false
training	oneLayer	oneLayer - rat 1	0	-0.01895489	-0.0025650032	false
training	oneLayer	oneLayer - rat 1	0	-0.008599753	-0.002564996	false
training	oneLayer	oneLayer - rat 1	0	0.0018045828	-0.0025649888	false
training	oneLayer	oneLayer - rat 1	0	0.012008768	-0.0025649816	false
training	oneLayer	oneLayer - rat 1	0	0.02221569	-0.0025649744	false
training	oneLayer	oneLayer - rat 1	0	0.033202372	-0.0025649667	false
training	oneLayer	oneLayer - rat 1	0	0.043861777	-0.0025649592	false
training	oneLayer	oneLayer - rat 1	0	0.05459136	-0.0025649518	false
training	oneLayer	oneLayer - rat 1	0	0.06537473	-0.0025649443	false
training	oneLayer	oneLayer - rat 1	0	0.07627067	-0.0025649366	false
training	oneLayer	oneLayer - rat 1	0	0.086711615	-0.0025649294	false
training	oneLayer	oneLayer - rat 1	0	0.09699662	-0.0025649222	false
training	oneLayer	oneLayer - rat 1	0	0.107376866	-0.002564915	false
training	oneLayer	oneLayer - rat 1	0	0.11835632	-0.0025649073	false
training	oneLayer	oneLayer - rat 1	0	0.12909415	-0.0025648996	false
training	oneLayer	oneLayer - rat 1	0	0.13943797	-0.0025648924	false
training	oneLayer	oneLayer - rat 1	0	0.14959705	-0.0025648854	false
training	oneLayer	oneLayer - rat 1	0	0.16016836	-0.002564878	false
training	oneLayer	oneLayer - rat 1	0	0.1706461	-0.0025648708	false
training	oneLayer	oneLayer - rat 1	0	0.1814351	-0.002564863	false
training	oneLayer	oneLayer - rat 1	0	0.19152048	-0.002564856	false
training	oneLayer	oneLayer - rat 1	0	0.2020098	-0.0025648486	false
training	oneLayer	oneLayer - rat 1	0	0.21218841	-0.0025648416	false
training	oneLayer	oneLayer - rat 1	0	0.22249971	-0.0025648344	false
training	oneLayer	oneLayer - rat 1	0	0.2330135	-0.002564827	false
training	oneLayer	oneLayer - rat 1	0	0.24312682	-0.00256482	false
training	oneLayer	oneLayer - rat 1	0	0.2533923	-0.0025648128	false
training	oneLayer	oneLayer - rat 1	0	0.26437935	-0.002564805	false
training	oneLayer	oneLayer - rat 1	0	0.27455112	-0.0025647979	false
training	oneLayer	oneLayer - rat 1	0	0.2846163	-0.002564791	false
training	oneLayer	oneLayer - rat 1	0	0.29472166	-0.002564784	false
training	oneLayer	oneLayer - rat 1	0	0.30494255	-0.0025647767	false
training	oneLayer	oneLayer - rat 1	0	0.31574103	-0.0025647692	false
training	oneLayer	oneLayer - rat 1	0	0.32645068	-0.0025647618	false
training	oneLayer	oneLayer - rat 1	0	0.33713126	-0.002564754	false
training	oneLayer	oneLayer - rat 1	0	0.3478263	-0.0025647467	false
training	oneLayer	oneLayer - rat 1	0	0.35841888	-0.0025647394	false
training	oneLayer	oneLayer - rat 1	0	0.36924937	-0.0025647318	false
training	oneLayer	oneLayer - rat 1	0	0.37970826	-0.0025647245	false
training	oneLayer	oneLayer - rat 1	0	0.38983038	-0.0025647173	false
training	oneLayer	oneLayer - rat 1	0	0.40004203	-0.00256471	false
training	oneLayer	oneLayer - rat 1	0	0.40996048	-0.0066730566	false
training	oneLayer	oneLayer - rat 1	0	0.41728088	-0.013993464	false
training	oneLayer	oneLayer - rat 1	0	0.42128077	-0.02365004	false
training	oneLayer	oneLayer - rat 1	0	0.42128077	-0.03378873	false
training	oneLayer	oneLayer - rat 1	0	0.41745386	-0.043027777	false
training	oneLayer	oneLayer - rat 1	0	0.41031808	-0.050163552	false
training	oneLayer	oneLayer - rat 1	0	0.40067044	-0.05415975	false
training	oneLayer	oneLayer - rat 1	0	0.3904717	-0.054159757	false
training	oneLayer	oneLayer - rat 1	0	0.37956163	-0.054159764	false
training	oneLayer	oneLayer - rat 1	0	0.3690155	-0.054159768	false
training	oneLayer	oneLayer - rat 1	0	0.35830253	-0.054159775	false
training	oneLayer	oneLayer - rat 1	0	0.34813005	-0.054159783	false
training	oneLayer	oneLayer - rat 1	0	0.33743024	-0.05415979	false
training	oneLayer	oneLayer - rat 1	0	0.32658696	-0.054159794	false
training	oneLayer	oneLayer - rat 1	0	0.31570977	-0.0541598	false
training	oneLayer	oneLayer - rat 1	0	0.3053797	-0.05415981	false
training	oneLayer	oneLayer - rat 1	0	0.29474837	-0.054159816	false
training	oneLayer	oneLayer - rat 1	0	0.28422055	-0.05415982	false
training	oneLayer	oneLayer - rat 1	0	0.2732641	-0.054159828	false
training	oneLayer	oneLayer - rat 1	0	0.26286015	-0.054159835	false
training	oneLayer	oneLayer - rat 1	0	0.25258613	-0.054159842	false
training	oneLayer	oneLayer - rat 1	0	0.24257699	-0.054159846	false
training	oneLayer	oneLayer - rat 1	0	0.23206866	-0.054159854	false
training	oneLayer	oneLayer - rat 1	0	0.22117648	-0.05415986	false
training	oneLayer	oneLayer - rat 1	0	0.21064994	-0.054159865	false
training	oneLayer	oneLayer - rat 1	0	0.20024002	-0.054159872	false
training	oneLayer	oneLayer - rat 1	0	0.18985176	-0.05415988	false
training	oneLayer	oneLayer - rat 1	0	0.17895918	-0.054159887	false
training	oneLayer	oneLayer - rat 1	0	0.16814205	-0.05415989	false
training	oneLayer	oneLayer - rat 1	0	0.15793617	-0.0541599	false
training	oneLayer	oneLayer - rat 1	0	0.14730942	-0.054159906	false
training	oneLayer	oneLayer - rat 1	0	0.13716514	-0.054159913	false
training	oneLayer	oneLayer - rat 1	0	0.12706022	-0.054159917	false
training	oneLayer	oneLayer - rat 1	0	0.11694462	-0.054159924	false
training	oneLayer	oneLayer - rat 1	0	0.10616598	-0.05415993	false
training	oneLayer	oneLayer - rat 1	0	0.09569468	-0.054159936	false
training	oneLayer	oneLayer - rat 1	0	0.085499056	-0.054159943	false
training	oneLayer	oneLayer - rat 1	0	0.07501052	-0.05415995	false
training	oneLayer	oneLayer - rat 1	0	0.06469737	-0.054159954	false
training	oneLayer	oneLayer - rat 1	0	0.054052144	-0.05415996	false
training	oneLayer	oneLayer - rat 1	0	0.043472793	-0.05415997	false
training	oneLayer	oneLayer - rat 1	0	0.032683734	-0.054159977	false
training	oneLayer	oneLayer - rat 1	0	0.022511043	-0.05415998	false
training	oneLayer	oneLayer - rat 1	0	0.011982546	-0.054159988	false
training	oneLayer	oneLayer - rat 1	0	0.0011519511	-0.054159995	false
training	oneLayer	oneLayer - rat 1	0	-0.009196986	-0.054160003	false
training	oneLayer	oneLayer - rat 1	0	-0.01929265	-0.054160006	false
training	oneLayer	oneLayer - rat 1	0	-0.029718954	-0.054160014	false
training	oneLayer	oneLayer - rat 1	0	-0.040240254	-0.05416002	false
training	oneLayer	oneLayer - rat 1	0	-0.05106597	-0.054160025	false
training	oneLayer	oneLayer - rat 1	0	-0.06167306	-0.054160032	false
training	oneLayer	oneLayer - rat 1	0	-0.07190581	-0.05416004	false
training	oneLayer	oneLayer - rat 1	0	-0.0829036	-0.054160047	false
training	oneLayer	oneLayer - rat 1	0	-0.09364034	-0.05416005	false
training	oneLayer	oneLayer - rat 1	0	-0.10387892	-0.05416006	false
training	oneLayer	oneLayer - rat 1	0	-0.114517085	-0.054160066	false
training	oneLayer	oneLayer - rat 1	0	-0.12497242	-0.054160073	false
training	oneLayer	oneLayer - rat 1	0	-0.13533182	-0.054160077	false
training	oneLayer	oneLayer - rat 1	0	-0.14631559	-0.054160085	false
training	oneLayer	oneLayer - rat 1	0	-0.15703547	-0.054160092	false
training	oneLayer	oneLayer - rat 1	0	-0.1677187	-0.0541601	false
training	oneLayer	oneLayer - rat 1	0	-0.17855442	-0.054160103	false
training	oneLayer	oneLayer - rat 1	0	-0.18908331	-0.05416011	false
training	oneLayer	oneLayer - rat 1	0	-0.19983937	-0.054160118	false
training	oneLayer	oneLayer - rat 1	0	-0.20992327	-0.054160126	false
training	oneLayer	oneLayer - rat 1	0	-0.22039482	-0.05416013	false
training	oneLayer	oneLayer - rat 1	0	-0.23052117	-0.054160137	false
training	oneLayer	oneLayer - rat 1	0	-0.24104388	-0.054160144	false
training	oneLayer	oneLayer - rat 1	0	-0.25138882	-0.054160148	false
training	oneLayer	oneLayer - rat 1	0	-0.26192084	-0.054160155	false
training	oneLayer	oneLayer - rat 1	0	-0.27225322	-0.054160163	false
training	oneLayer	oneLayer - rat 1	0	-0.28321487	-0.05416017	false
training	oneLayer	oneLayer - rat 1	0	-0.29415196	-0.054160174	false
training	oneLayer	oneLayer - rat 1	0	-0.30484113	-0.05416018	false
training	oneLayer	oneLayer - rat 1	0	-0.31505468	-0.05416019	false
training	oneLayer	oneLayer - rat 1	0	-0.325167	-0.054160193	false
training	oneLayer	oneLayer - rat 1	0	-0.33487573	-0.05013871	false
training	oneLayer	oneLayer - rat 1	0	-0.34416348	-0.046291616	false
training	oneLayer	oneLayer - rat 1	0	-0.35404426	-0.042198867	false
training	oneLayer	oneLayer - rat 1	0	-0.36374167	-0.03818207	false
training	oneLayer	oneLayer - rat 1	0	-0.37379888	-0.034016244	false
training	oneLayer	oneLayer - rat 1	0	-0.3832983	-0.030081466	false
training	oneLayer	oneLayer - rat 1	0	-0.39321232	-0.025974955	false
training	oneLayer	oneLayer - rat 1	0	-0.40317315	-0.021849042	false
training	oneLayer	oneLayer - rat 1	0	-0.41299814	-0.017779412	false
training	oneLayer	oneLayer - rat 1	0	-0.42049402	-0.010283545	false
training	oneLayer	oneLayer - rat 1	0	-0.42465788	-2.3108291E-4	false
training	oneLayer	oneLayer - rat 1	0	-0.42465788	0.010281765	false
training	oneLayer	oneLayer - rat 1	0	-0.4206244	0.02001948	false
training	oneLayer	oneLayer - rat 1	0	-0.41296896	0.027674936	false
training	oneLayer	oneLayer - rat 1	0	-0.40332627	0.031669065	false
training	oneLayer	oneLayer - rat 1	0	-0.39292383	0.031669073	false
training	oneLayer	oneLayer - rat 1	0	-0.38207158	0.031669077	false
training	oneLayer	oneLayer - rat 1	0	-0.37181032	0.031669084	false
training	oneLayer	oneLayer - rat 1	0	-0.36139876	0.031669088	false
training	oneLayer	oneLayer - rat 1	0	-0.3511878	0.031669095	false
training	oneLayer	oneLayer - rat 1	0	-0.34108013	0.0316691	false
training	oneLayer	oneLayer - rat 1	0	-0.3307164	0.031669106	false
training	oneLayer	oneLayer - rat 1	0	-0.3199259	0.03166911	false
training	oneLayer	oneLayer - rat 1	0	-0.30916306	0.031669118	false
training	oneLayer	oneLayer - rat 1	0	-0.29826874	0.03166912	false
training	oneLayer	oneLayer - rat 1	0	-0.28809255	0.03166913	false
training	oneLayer	oneLayer - rat 1	0	-0.2775008	0.031669132	false
training	oneLayer	oneLayer - rat 1	0	-0.26739892	0.03166914	false
training	oneLayer	oneLayer - rat 1	0	-0.2567648	0.031669144	false
training	oneLayer	oneLayer - rat 1	0	-0.24648888	0.03166915	false
training	oneLayer	oneLayer - rat 1	0	-0.23632477	0.031669155	false
training	oneLayer	oneLayer - rat 1	0	-0.22549273	0.03166916	false
training	oneLayer	oneLayer - rat 1	0	-0.21454138	0.031669166	false
training	oneLayer	oneLayer - rat 1	0	-0.20425563	0.03166917	false
training	oneLayer	oneLayer - rat 1	0	-0.19344328	0.031669177	false
training	oneLayer	oneLayer - rat 1	0	-0.18254782	0.031669185	false
training	oneLayer	oneLayer - rat 1	0	-0.17170662	0.03166919	false
training	oneLayer	oneLayer - rat 1	0	-0.1612497	0.031669196	false
training	oneLayer	oneLayer - rat 1	0	-0.15114278	0.0316692	false
training	oneLayer	oneLayer - rat 1	0	-0.14111489	0.031669203	false
training	oneLayer	oneLayer - rat 1	0	-0.13040979	0.03166921	false
training	oneLayer	oneLayer - rat 1	0	-0.12023928	0.031669214	false
training	oneLayer	oneLayer - rat 1	0	-0.10997624	0.03166922	false
training	oneLayer	oneLayer - rat 1	0	-0.099680796	0.031669226	false
training	oneLayer	oneLayer - rat 1	0	-0.08946579	0.031669233	false
training	oneLayer	oneLayer - rat 1	0	-0.07872262	0.031669237	false
training	oneLayer	oneLayer - rat 1	0	-0.067797005	0.031669244	false
training	oneLayer	oneLayer - rat 1	0	-0.057065282	0.031669248	false
training	oneLayer	oneLayer - rat 1	0	-0.04699615	0.031669255	false
training	oneLayer	oneLayer - rat 1	0	-0.036935396	0.03166926	false
training	oneLayer	oneLayer - rat 1	0	-0.026091594	0.031669267	false
training	oneLayer	oneLayer - rat 1	0	-0.015916353	0.03166927	false
training	oneLayer	oneLayer - rat 1	0	-0.0050997413	0.031669274	false
training	oneLayer	oneLayer - rat 1	0	0.005360942	0.03166928	false
training	oneLayer	oneLayer - rat 1	0	0.0154065285	0.031669285	false
training	oneLayer	oneLayer - rat 1	0	0.025749002	0.031669293	false
training	oneLayer	oneLayer - rat 1	0	0.03664961	0.031669296	false
training	oneLayer	oneLayer - rat 1	0	0.047115866	0.031669304	false
training	oneLayer	oneLayer - rat 1	0	0.05784164	0.031669308	false
training	oneLayer	oneLayer - rat 1	0	0.06807196	0.031669315	false
training	oneLayer	oneLayer - rat 1	0	0.07842795	0.03166932	false
training	oneLayer	oneLayer - rat 1	0	0.08869683	0.031669326	false
training	oneLayer	oneLayer - rat 1	0	0.09904581	0.03166933	false
training	oneLayer	oneLayer - rat 1	0	0.109372035	0.031669337	false
training	oneLayer	oneLayer - rat 1	0	0.11989577	0.03166934	false
training	oneLayer	oneLayer - rat 1	0	0.13069907	0.03166935	false
training	oneLayer	oneLayer - rat 1	0	0.14086343	0.031669352	false
training	oneLayer	oneLayer - rat 1	0	0.1514622	0.03166936	false
training	oneLayer	oneLayer - rat 1	0	0.16239813	0.031669363	false
training	oneLayer	oneLayer - rat 1	0	0.17334214	0.03166937	false
training	oneLayer	oneLayer - rat 1	0	0.18354098	0.031669375	false
training	oneLayer	oneLayer - rat 1	0	0.19433108	0.031669382	false
training	oneLayer	oneLayer - rat 1	0	0.20521285	0.031669386	false
training	oneLayer	oneLayer - rat 1	0	0.21567008	0.031669393	false
training	oneLayer	oneLayer - rat 1	0	0.22627006	0.031669397	false
training	oneLayer	oneLayer - rat 1	0	0.23633571	0.0316694	false
training	oneLayer	oneLayer - rat 1	0	0.24726407	0.031669408	false
training	oneLayer	oneLayer - rat 1	0	0.25806597	0.031669416	false
training	oneLayer	oneLayer - rat 1	0	0.2690145	0.03166942	false
training	oneLayer	oneLayer - rat 1	0	0.27970454	0.031669427	false
training	oneLayer	oneLayer - rat 1	0	0.2898632	0.03166943	false
training	oneLayer	oneLayer - rat 1	0	0.300574	0.031669438	false
training	oneLayer	oneLayer - rat 1	0	0.3112048	0.03166944	false
training	oneLayer	oneLayer - rat 1	0	0.3217994	0.03166945	false
training	oneLayer	oneLayer - rat 1	0	0.3322906	0.031669453	false
training	oneLayer	oneLayer - rat 1	0	0.3432473	0.03166946	false
training	oneLayer	oneLayer - rat 1	0	0.35385278	0.031669464	false
training	oneLayer	oneLayer - rat 1	0	0.3647676	0.03166947	false
training	oneLayer	oneLayer - rat 1	0	0.3752697	0.031669475	false
training	oneLayer	oneLayer - rat 1	0	0.38470104	0.027762894	false
training	oneLayer	oneLayer - rat 1	0	0.39396277	0.023926567	false
training	oneLayer	oneLayer - rat 1	0	0.40322486	0.020090086	false
training	oneLayer	oneLayer - rat 1	0	0.41250885	0.016244534	false
training	oneLayer	oneLayer - rat 1	0	0.42014438	0.008609011	false
training	oneLayer	oneLayer - rat 1	0	0.42423308	-0.0012619378	false
training	oneLayer	oneLayer - rat 1	0	0.42423308	-0.0120853465	false
training	oneLayer	oneLayer - rat 1	0	0.42021295	-0.021790765	false
training	oneLayer	oneLayer - rat 1	0	0.41255966	-0.02944409	false
training	oneLayer	oneLayer - rat 1	0	0.4029128	-0.033439945	false
training	oneLayer	oneLayer - rat 1	0	0.3922241	-0.03343995	false
training	oneLayer	oneLayer - rat 1	0	0.38220224	-0.033439957	false
training	oneLayer	oneLayer - rat 1	0	0.37187228	-0.03343996	false
training	oneLayer	oneLayer - rat 1	0	0.3613981	-0.033439964	false
training	oneLayer	oneLayer - rat 1	0	0.35113937	-0.033439968	false
training	oneLayer	oneLayer - rat 1	0	0.3404435	-0.03343997	false
training	oneLayer	oneLayer - rat 1	0	0.32975486	-0.03343998	false
training	oneLayer	oneLayer - rat 1	0	0.31931415	-0.033439983	false
training	oneLayer	oneLayer - rat 1	0	0.30902976	-0.033439986	false
training	oneLayer	oneLayer - rat 1	0	0.29880497	-0.03343999	false
training	oneLayer	oneLayer - rat 1	0	0.28781432	-0.033439998	false
training	oneLayer	oneLayer - rat 1	0	0.2776038	-0.03344	false
training	oneLayer	oneLayer - rat 1	0	0.26690215	-0.033440005	false
training	oneLayer	oneLayer - rat 1	0	0.25656804	-0.03344001	false
training	oneLayer	oneLayer - rat 1	0	0.24563481	-0.033440016	false
training	oneLayer	oneLayer - rat 1	0	0.23527178	-0.03344002	false
training	oneLayer	oneLayer - rat 1	0	0.22503194	-0.033440024	false
training	oneLayer	oneLayer - rat 1	0	0.21417417	-0.033440027	false
training	oneLayer	oneLayer - rat 1	0	0.20364685	-0.033440035	false
training	oneLayer	oneLayer - rat 1	0	0.19295336	-0.03344004	false
training	oneLayer	oneLayer - rat 1	0	0.18203427	-0.033440042	false
training	oneLayer	oneLayer - rat 1	0	0.17122655	-0.033440046	false
training	oneLayer	oneLayer - rat 1	0	0.1604566	-0.033440053	false
training	oneLayer	oneLayer - rat 1	0	0.15029733	-0.033440057	false
training	oneLayer	oneLayer - rat 1	0	0.14000912	-0.03344006	false
training	oneLayer	oneLayer - rat 1	0	0.1299318	-0.033440065	false
training	oneLayer	oneLayer - rat 1	0	0.1194522	-0.03344007	false
training	oneLayer	oneLayer - rat 1	0	0.10923047	-0.033440076	false
training	oneLayer	oneLayer - rat 1	0	0.09834819	-0.03344008	false
training	oneLayer	oneLayer - rat 1	0	0.08747832	-0.033440083	false
training	oneLayer	oneLayer - rat 1	0	0.07742573	-0.033440087	false
training	oneLayer	oneLayer - rat 1	0	0.06706835	-0.033440094	false
training	oneLayer	oneLayer - rat 1	0	0.05668262	-0.0334401	false
training	oneLayer	oneLayer - rat 1	0	0.04585427	-0.033440102	false
training	oneLayer	oneLayer - rat 1	0	0.035842486	-0.033440106	false
training	oneLayer	oneLayer - rat 1	0	0.02505152	-0.03344011	false
training	oneLayer	oneLayer - rat 1	0	0.014901573	-0.033440117	false
training	oneLayer	oneLayer - rat 1	0	0.004285741	-0.03344012	false
training	oneLayer	oneLayer - rat 1	0	-0.0060280315	-0.033440124	false
training	oneLayer	oneLayer - rat 1	0	-0.01692453	-0.033440128	false
training	oneLayer	oneLayer - rat 1	0	-0.026956957	-0.033440135	false
training	oneLayer	oneLayer - rat 1	0	-0.03733205	-0.03344014	false
training	oneLayer	oneLayer - rat 1	0	-0.048180994	-0.033440143	false
training	oneLayer	oneLayer - rat 1	0	-0.05875184	-0.033440147	false
training	oneLayer	oneLayer - rat 1	0	-0.0691273	-0.033440154	false
training	oneLayer	oneLayer - rat 1	0	-0.07944865	-0.033440158	false
training	oneLayer	oneLayer - rat 1	0	-0.089576066	-0.03344016	false
training	oneLayer	oneLayer - rat 1	0	-0.099723026	-0.033440165	false
training	oneLayer	oneLayer - rat 1	0	-0.10978627	-0.03344017	false
training	oneLayer	oneLayer - rat 1	0	-0.12059799	-0.033440176	false
training	oneLayer	oneLayer - rat 1	0	-0.13082714	-0.03344018	false
training	oneLayer	oneLayer - rat 1	0	-0.14104357	-0.033440184	false
training	oneLayer	oneLayer - rat 1	0	-0.15112947	-0.033440188	false
training	oneLayer	oneLayer - rat 1	0	-0.16138227	-0.03344019	false
training	oneLayer	oneLayer - rat 1	0	-0.17203856	-0.0334402	false
training	oneLayer	oneLayer - rat 1	0	-0.18221231	-0.033440202	false
training	oneLayer	oneLayer - rat 1	0	-0.19316955	-0.033440206	false
training	oneLayer	oneLayer - rat 1	0	-0.20407085	-0.03344021	false
training	oneLayer	oneLayer - rat 1	0	-0.21435373	-0.033440217	false
training	oneLayer	oneLayer - rat 1	0	-0.2249381	-0.03344022	false
training	oneLayer	oneLayer - rat 1	0	-0.23554441	-0.033440225	false
training	oneLayer	oneLayer - rat 1	0	-0.2457119	-0.03344023	false
training	oneLayer	oneLayer - rat 1	0	-0.2562468	-0.033440232	false
training	oneLayer	oneLayer - rat 1	0	-0.26687288	-0.03344024	false
training	oneLayer	oneLayer - rat 1	0	-0.27745646	-0.033440243	false
training	oneLayer	oneLayer - rat 1	0	-0.28785074	-0.033440247	false
training	oneLayer	oneLayer - rat 1	0	-0.29807007	-0.03344025	false
training	oneLayer	oneLayer - rat 1	0	-0.30905738	-0.03344026	false
training	oneLayer	oneLayer - rat 1	0	-0.31967667	-0.033440262	false
training	oneLayer	oneLayer - rat 1	0	-0.33047542	-0.033440266	false
training	oneLayer	oneLayer - rat 1	0	-0.34093451	-0.03344027	false
training	oneLayer	oneLayer - rat 1	0	-0.35141265	-0.033440277	false
training	oneLayer	oneLayer - rat 1	0	-0.36204472	-0.03344028	false
training	oneLayer	oneLayer - rat 1	0	-0.37281415	-0.033440284	false
training	oneLayer	oneLayer - rat 1	0	-0.38263842	-0.029370949	false
training	oneLayer	oneLayer - rat 1	0	-0.39231446	-0.025363	false
training	oneLayer	oneLayer - rat 1	0	-0.40178442	-0.021440418	false
training	oneLayer	oneLayer - rat 1	0	-0.41104522	-0.017604474	false
training	oneLayer	oneLayer - rat 1	0	-0.4187745	-0.009875217	false
training	oneLayer	oneLayer - rat 1	0	-0.4229704	2.5459155E-4	false
training	oneLayer	oneLayer - rat 1	0	-0.4229704	0.010356335	false
training	oneLayer	oneLayer - rat 1	0	-0.41882798	0.020357009	false
training	oneLayer	oneLayer - rat 1	0	-0.4115175	0.027667515	false
training	oneLayer	oneLayer - rat 1	0	-0.40150514	0.031814773	false
training	oneLayer	oneLayer - rat 1	0	-0.391383	0.031814776	false
training	oneLayer	oneLayer - rat 1	0	-0.38123846	0.03181478	false
training	oneLayer	oneLayer - rat 1	0	-0.37089264	0.031814784	false
training	oneLayer	oneLayer - rat 1	0	-0.36079046	0.031814784	false
training	oneLayer	oneLayer - rat 1	0	-0.35006255	0.031814788	false
training	oneLayer	oneLayer - rat 1	0	-0.34004372	0.03181479	false
training	oneLayer	oneLayer - rat 1	0	-0.32971427	0.031814795	false
training	oneLayer	oneLayer - rat 1	0	-0.31911913	0.0318148	false
training	oneLayer	oneLayer - rat 1	0	-0.308776	0.031814802	false
training	oneLayer	oneLayer - rat 1	0	-0.29788023	0.031814806	false
training	oneLayer	oneLayer - rat 1	0	-0.28769743	0.03181481	false
training	oneLayer	oneLayer - rat 1	0	-0.27731484	0.031814814	false
training	oneLayer	oneLayer - rat 1	0	-0.26670575	0.031814817	false
training	oneLayer	oneLayer - rat 1	0	-0.25584713	0.03181482	false
training	oneLayer	oneLayer - rat 1	0	-0.24580146	0.031814825	false
training	oneLayer	oneLayer - rat 1	0	-0.2349647	0.03181483	false
training	oneLayer	oneLayer - rat 1	0	-0.22431251	0.031814832	false
training	oneLayer	oneLayer - rat 1	0	-0.21415477	0.031814836	false
training	oneLayer	oneLayer - rat 1	0	-0.20406722	0.03181484	false
training	oneLayer	oneLayer - rat 1	0	-0.19320911	0.031814843	false
training	oneLayer	oneLayer - rat 1	0	-0.18234742	0.031814847	false
training	oneLayer	oneLayer - rat 1	0	-0.17189674	0.03181485	false
training	oneLayer	oneLayer - rat 1	0	-0.16168517	0.031814855	false
training	oneLayer	oneLayer - rat 1	0	-0.1509557	0.03181486	false
training	oneLayer	oneLayer - rat 1	0	-0.14018477	0.031814862	false
training	oneLayer	oneLayer - rat 1	0	-0.12974522	0.031814866	false
training	oneLayer	oneLayer - rat 1	0	-0.11907719	0.03181487	false
training	oneLayer	oneLayer - rat 1	0	-0.10841974	0.031814873	false
training	oneLayer	oneLayer - rat 1	0	-0.09841118	0.031814877	false
training	oneLayer	oneLayer - rat 1	0	-0.087445326	0.03181488	false
training	oneLayer	oneLayer - rat 1	0	-0.07668831	0.031814884	false
training	oneLayer	oneLayer - rat 1	0	-0.06654242	0.031814888	false
training	oneLayer	oneLayer - rat 1	0	-0.055703796	0.03181489	false
training	oneLayer	oneLayer - rat 1	0	-0.045139305	0.031814896	false
training	oneLayer	oneLayer - rat 1	0	-0.034754027	0.0318149	false
training	oneLayer	oneLayer - rat 1	0	-0.023825152	0.031814903	false
training	oneLayer	oneLayer - rat 1	0	-0.0130825145	0.031814907	false
training	oneLayer	oneLayer - rat 1	0	-0.0030822365	0.03181491	false
training	oneLayer	oneLayer - rat 1	0	0.0070454692	0.031814914	false
training	oneLayer	oneLayer - rat 1	0	0.017821971	0.031814918	false
training	oneLayer	oneLayer - rat 1	0	0.02878483	0.03181492	false
training	oneLayer	oneLayer - rat 1	0	0.03927072	0.031814925	false
training	oneLayer	oneLayer - rat 1	0	0.049483757	0.03181493	false
training	oneLayer	oneLayer - rat 1	0	0.059958454	0.031814933	false
training	oneLayer	oneLayer - rat 1	0	0.07035243	0.031814937	false
training	oneLayer	oneLayer - rat 1	0	0.08093947	0.03181494	false
training	oneLayer	oneLayer - rat 1	0	0.09134302	0.031814944	false
training	oneLayer	oneLayer - rat 1	0	0.10176325	0.031814948	false
training	oneLayer	oneLayer - rat 1	0	0.11231423	0.03181495	false
training	oneLayer	oneLayer - rat 1	0	0.12298344	0.031814955	false
training	oneLayer	oneLayer - rat 1	0	0.13397151	0.03181496	false
training	oneLayer	oneLayer - rat 1	0	0.1446842	0.031814963	false
training	oneLayer	oneLayer - rat 1	0	0.154855	0.031814966	false
training	oneLayer	oneLayer - rat 1	0	0.16577062	0.03181497	false
training	oneLayer	oneLayer - rat 1	0	0.17662777	0.031814974	false
training	oneLayer	oneLayer - rat 1	0	0.1870119	0.031814978	false
training	oneLayer	oneLayer - rat 1	0	0.1974019	0.03181498	false
training	oneLayer	oneLayer - rat 1	0	0.20773835	0.031814985	false
training	oneLayer	oneLayer - rat 1	0	0.21810192	0.03181499	false
training	oneLayer	oneLayer - rat 1	0	0.22869389	0.031814992	false
training	oneLayer	oneLayer - rat 1	0	0.2396842	0.031814996	false
training	oneLayer	oneLayer - rat 1	0	0.2503456	0.031815	false
training	oneLayer	oneLayer - rat 1	0	0.26049456	0.031815004	false
training	oneLayer	oneLayer - rat 1	0	0.27086815	0.031815007	false
training	oneLayer	oneLayer - rat 1	0	0.28114074	0.03181501	false
training	oneLayer	oneLayer - rat 1	0	0.2917768	0.031815015	false
training	oneLayer	oneLayer - rat 1	0	0.3018469	0.03181502	false
training	oneLayer	oneLayer - rat 1	0	0.31236014	0.031815022	false
training	oneLayer	oneLayer - rat 1	0	0.32260442	0.031815026	false
training	oneLayer	oneLayer - rat 1	0	0.33316216	0.03181503	false
training	oneLayer	oneLayer - rat 1	0	0.3439688	0.031815033	false
training	oneLayer	oneLayer - rat 1	0	0.35422614	0.031815037	false
training	oneLayer	oneLayer - rat 1	0	0.3647708	0.03181504	false
training	oneLayer	oneLayer - rat 1	0	0.37498793	0.031815045	false
training	oneLayer	oneLayer - rat 1	0	0.38440767	0.027913265	false
training	oneLayer	oneLayer - rat 1	0	0.39371526	0.02405794	false
training	oneLayer	oneLayer - rat 1	0	0.40360108	0.0199631	false
training	oneLayer	oneLayer - rat 1	0	0.4129616	0.016085852	false
training	oneLayer	oneLayer - rat 1	0	0.42060855	0.008438913	false
training	oneLayer	oneLayer - rat 1	0	0.42479995	-0.0016799842	false
training	oneLayer	oneLayer - rat 1	0	0.42479995	-0.012668321	false
training	oneLayer	oneLayer - rat 1	0	0.4206827	-0.022608235	false
training	oneLayer	oneLayer - rat 1	0	0.4134762	-0.029814731	false
training	oneLayer	oneLayer - rat 1	0	0.4038846	-0.03378771	false
training	oneLayer	oneLayer - rat 1	0	0.3931499	-0.033787712	false
training	oneLayer	oneLayer - rat 1	0	0.38275784	-0.033787716	false
training	oneLayer	oneLayer - rat 1	0	0.37208205	-0.03378772	false
training	oneLayer	oneLayer - rat 1	0	0.36153072	-0.03378772	false
training	oneLayer	oneLayer - rat 1	0	0.35079077	-0.033787724	false
training	oneLayer	oneLayer - rat 1	0	0.34071776	-0.033787727	false
training	oneLayer	oneLayer - rat 1	0	0.33019024	-0.033787727	false
training	oneLayer	oneLayer - rat 1	0	0.32018942	-0.03378773	false
training	oneLayer	oneLayer - rat 1	0	0.3101805	-0.033787735	false
training	oneLayer	oneLayer - rat 1	0	0.29940614	-0.03378774	false
training	oneLayer	oneLayer - rat 1	0	0.28913477	-0.03378774	false
training	oneLayer	oneLayer - rat 1	0	0.2783615	-0.033787742	false
training	oneLayer	oneLayer - rat 1	0	0.26792458	-0.033787746	false
training	oneLayer	oneLayer - rat 1	0	0.2571273	-0.03378775	false
training	oneLayer	oneLayer - rat 1	0	0.24654478	-0.03378775	false
training	oneLayer	oneLayer - rat 1	0	0.23571788	-0.033787753	false
training	oneLayer	oneLayer - rat 1	0	0.22522606	-0.033787757	false
training	oneLayer	oneLayer - rat 1	0	0.21441267	-0.03378776	false
training	oneLayer	oneLayer - rat 1	0	0.20371094	-0.03378776	false
training	oneLayer	oneLayer - rat 1	0	0.19310066	-0.033787765	false
training	oneLayer	oneLayer - rat 1	0	0.1828393	-0.03378777	false
training	oneLayer	oneLayer - rat 1	0	0.17219213	-0.033787772	false
training	oneLayer	oneLayer - rat 1	0	0.1616599	-0.033787772	false
training	oneLayer	oneLayer - rat 1	0	0.15084249	-0.033787776	false
training	oneLayer	oneLayer - rat 1	0	0.1400222	-0.03378778	false
training	oneLayer	oneLayer - rat 1	0	0.12959377	-0.033787783	false
training	oneLayer	oneLayer - rat 1	0	0.119301125	-0.033787783	false
training	oneLayer	oneLayer - rat 1	0	0.10880365	-0.033787787	false
training	oneLayer	oneLayer - rat 1	0	0.09807621	-0.03378779	false
training	oneLayer	oneLayer - rat 1	0	0.08741084	-0.033787794	false
training	oneLayer	oneLayer - rat 1	0	0.07723617	-0.033787794	false
training	oneLayer	oneLayer - rat 1	0	0.067164086	-0.033787798	false
training	oneLayer	oneLayer - rat 1	0	0.05618835	-0.0337878	false
training	oneLayer	oneLayer - rat 1	0	0.045300603	-0.033787806	false
training	oneLayer	oneLayer - rat 1	0	0.03482368	-0.033787806	false
training	oneLayer	oneLayer - rat 1	0	0.023863638	-0.03378781	false
training	oneLayer	oneLayer - rat 1	0	0.012954314	-0.033787813	false
training	oneLayer	oneLayer - rat 1	0	0.0026311327	-0.033787817	false
training	oneLayer	oneLayer - rat 1	0	-0.007866262	-0.033787817	false
training	oneLayer	oneLayer - rat 1	0	-0.018520808	-0.03378782	false
training	oneLayer	oneLayer - rat 1	0	-0.028522795	-0.033787824	false
training	oneLayer	oneLayer - rat 1	0	-0.039413407	-0.033787824	false
training	oneLayer	oneLayer - rat 1	0	-0.050199963	-0.033787828	false
training	oneLayer	oneLayer - rat 1	0	-0.06030927	-0.03378783	false
training	oneLayer	oneLayer - rat 1	0	-0.07112546	-0.033787835	false
training	oneLayer	oneLayer - rat 1	0	-0.08148453	-0.033787835	false
training	oneLayer	oneLayer - rat 1	0	-0.0922141	-0.03378784	false
training	oneLayer	oneLayer - rat 1	0	-0.1028199	-0.033787843	false
training	oneLayer	oneLayer - rat 1	0	-0.11351393	-0.033787847	false
training	oneLayer	oneLayer - rat 1	0	-0.124389395	-0.033787847	false
training	oneLayer	oneLayer - rat 1	0	-0.13521442	-0.03378785	false
training	oneLayer	oneLayer - rat 1	0	-0.14571117	-0.033787854	false
training	oneLayer	oneLayer - rat 1	0	-0.15610415	-0.033787858	false
training	oneLayer	oneLayer - rat 1	0	-0.16692048	-0.033787858	false
training	oneLayer	oneLayer - rat 1	0	-0.1771856	-0.03378786	false
training	oneLayer	oneLayer - rat 1	0	-0.18740022	-0.033787865	false
training	oneLayer	oneLayer - rat 1	0	-0.19818947	-0.03378787	false
training	oneLayer	oneLayer - rat 1	0	-0.20913178	-0.03378787	false
training	oneLayer	oneLayer - rat 1	0	-0.21966958	-0.033787873	false
training	oneLayer	oneLayer - rat 1	0	-0.2298359	-0.033787876	false
training	oneLayer	oneLayer - rat 1	0	-0.24059688	-0.03378788	false
training	oneLayer	oneLayer - rat 1	0	-0.2515532	-0.03378788	false
training	oneLayer	oneLayer - rat 1	0	-0.26225746	-0.033787884	false
training	oneLayer	oneLayer - rat 1	0	-0.27246988	-0.033787888	false
training	oneLayer	oneLayer - rat 1	0	-0.2833705	-0.03378789	false
training	oneLayer	oneLayer - rat 1	0	-0.29344365	-0.03378789	false
training	oneLayer	oneLayer - rat 1	0	-0.30347064	-0.033787895	false
training	oneLayer	oneLayer - rat 1	0	-0.3143107	-0.0337879	false
training	oneLayer	oneLayer - rat 1	0	-0.32473308	-0.033787902	false
training	oneLayer	oneLayer - rat 1	0	-0.3354181	-0.033787902	false
training	oneLayer	oneLayer - rat 1	0	-0.34631068	-0.033787906	false
training	oneLayer	oneLayer - rat 1	0	-0.3566498	-0.03378791	false
training	oneLayer	oneLayer - rat 1	0	-0.36701766	-0.033787914	false
training	oneLayer	oneLayer - rat 1	0	-0.37724447	-0.033787914	false
training	oneLayer	oneLayer - rat 1	0	-0.38654092	-0.029937204	false
training	oneLayer	oneLayer - rat 1	0	-0.39668694	-0.025734585	false
training	oneLayer	oneLayer - rat 1	0	-0.406302	-0.021751909	false
training	oneLayer	oneLayer - rat 1	0	-0.41371477	-0.0143391425	false
training	oneLayer	oneLayer - rat 1	0	-0.4176986	-0.0047213067	false
training	oneLayer	oneLayer - rat 1	0	-0.4176986	0.0053298245	false
training	oneLayer	oneLayer - rat 1	0	-0.41381347	0.014709339	false
training	oneLayer	oneLayer - rat 1	0	-0.40665072	0.021872088	false
training	oneLayer	oneLayer - rat 1	0	-0.39740008	0.025703834	false
training	oneLayer	oneLayer - rat 1	0	-0.3866531	0.025703836	false
training	oneLayer	oneLayer - rat 1	0	-0.37617135	0.025703838	false
training	oneLayer	oneLayer - rat 1	0	-0.36535168	0.02570384	false
training	oneLayer	oneLayer - rat 1	0	-0.3548968	0.025703842	false
training	oneLayer	oneLayer - rat 1	0	-0.34403792	0.025703844	false
training	oneLayer	oneLayer - rat 1	0	-0.33391857	0.025703846	false
training	oneLayer	oneLayer - rat 1	0	-0.32313752	0.025703847	false
training	oneLayer	oneLayer - rat 1	0	-0.3131345	0.02570385	false
training	oneLayer	oneLayer - rat 1	0	-0.30234092	0.025703851	false
training	oneLayer	oneLayer - rat 1	0	-0.29160494	0.025703853	false
training	oneLayer	oneLayer - rat 1	0	-0.28130487	0.025703855	false
training	oneLayer	oneLayer - rat 1	0	-0.27046356	0.025703857	false
training	oneLayer	oneLayer - rat 1	0	-0.26013735	0.025703859	false
training	oneLayer	oneLayer - rat 1	0	-0.25010824	0.02570386	false
training	oneLayer	oneLayer - rat 1	0	-0.23978677	0.025703862	false
training	oneLayer	oneLayer - rat 1	0	-0.22905806	0.025703864	false
training	oneLayer	oneLayer - rat 1	0	-0.2183996	0.025703866	false
training	oneLayer	oneLayer - rat 1	0	-0.2082522	0.025703868	false
training	oneLayer	oneLayer - rat 1	0	-0.19769125	0.02570387	false
training	oneLayer	oneLayer - rat 1	0	-0.18720673	0.025703872	false
training	oneLayer	oneLayer - rat 1	0	-0.1771024	0.025703873	false
training	oneLayer	oneLayer - rat 1	0	-0.16702965	0.025703875	false
training	oneLayer	oneLayer - rat 1	0	-0.15630573	0.025703877	false
training	oneLayer	oneLayer - rat 1	0	-0.14588948	0.02570388	false
training	oneLayer	oneLayer - rat 1	0	-0.13540305	0.025703881	false
training	oneLayer	oneLayer - rat 1	0	-0.12477323	0.025703883	false
training	oneLayer	oneLayer - rat 1	0	-0.1146873	0.025703885	false
training	oneLayer	oneLayer - rat 1	0	-0.10415896	0.025703887	false
training	oneLayer	oneLayer - rat 1	0	-0.09371303	0.025703888	false
training	oneLayer	oneLayer - rat 1	0	-0.08299012	0.02570389	false
training	oneLayer	oneLayer - rat 1	0	-0.072694965	0.025703892	false
training	oneLayer	oneLayer - rat 1	0	-0.06252975	0.025703894	false
training	oneLayer	oneLayer - rat 1	0	-0.05225405	0.025703896	false
training	oneLayer	oneLayer - rat 1	0	-0.04172008	0.025703898	false
training	oneLayer	oneLayer - rat 1	0	-0.03162797	0.0257039	false
training	oneLayer	oneLayer - rat 1	0	-0.021181064	0.025703901	false
training	oneLayer	oneLayer - rat 1	0	-0.01023222	0.025703903	false
training	oneLayer	oneLayer - rat 1	0	-6.997908E-5	0.025703905	false
training	oneLayer	oneLayer - rat 1	0	0.0099471165	0.025703905	false
training	oneLayer	oneLayer - rat 1	0	0.020246478	0.025703907	false
training	oneLayer	oneLayer - rat 1	0	0.030476145	0.025703909	false
training	oneLayer	oneLayer - rat 1	0	0.041377183	0.02570391	false
training	oneLayer	oneLayer - rat 1	0	0.05149206	0.025703913	false
training	oneLayer	oneLayer - rat 1	0	0.061616674	0.025703914	false
training	oneLayer	oneLayer - rat 1	0	0.07250934	0.025703916	false
training	oneLayer	oneLayer - rat 1	0	0.08275343	0.025703918	false
training	oneLayer	oneLayer - rat 1	0	0.09352906	0.02570392	false
training	oneLayer	oneLayer - rat 1	0	0.1044027	0.025703922	false
training	oneLayer	oneLayer - rat 1	0	0.114410184	0.025703924	false
training	oneLayer	oneLayer - rat 1	0	0.12454187	0.025703926	false
training	oneLayer	oneLayer - rat 1	0	0.13494897	0.025703928	false
training	oneLayer	oneLayer - rat 1	0	0.14546198	0.02570393	false
training	oneLayer	oneLayer - rat 1	0	0.1556494	0.025703931	false
training	oneLayer	oneLayer - rat 1	0	0.16639157	0.025703933	false
training	oneLayer	oneLayer - rat 1	0	0.17652625	0.025703935	false
training	oneLayer	oneLayer - rat 1	0	0.18723044	0.025703937	false
training	oneLayer	oneLayer - rat 1	0	0.19744131	0.025703939	false
training	oneLayer	oneLayer - rat 1	0	0.20825532	0.02570394	false
training	oneLayer	oneLayer - rat 1	0	0.21899791	0.025703942	false
training	oneLayer	oneLayer - rat 1	0	0.22990595	0.025703944	false
training	oneLayer	oneLayer - rat 1	0	0.24026333	0.025703946	false
training	oneLayer	oneLayer - rat 1	0	0.25114697	0.025703948	false
training	oneLayer	oneLayer - rat 1	0	0.26187256	0.02570395	false
training	oneLayer	oneLayer - rat 1	0	0.27188304	0.025703952	false
training	oneLayer	oneLayer - rat 1	0	0.28257263	0.025703954	false
training	oneLayer	oneLayer - rat 1	0	0.2930748	0.025703955	false
training	oneLayer	oneLayer - rat 1	0	0.30356196	0.025703957	false
training	oneLayer	oneLayer - rat 1	0	0.314392	0.02570396	false
training	oneLayer	oneLayer - rat 1	0	0.32530615	0.025703961	false
training	oneLayer	oneLayer - rat 1	0	0.33549383	0.025703963	false
training	oneLayer	oneLayer - rat 1	0	0.3463046	0.025703965	false
training	oneLayer	oneLayer - rat 1	0	0.3570183	0.025703967	false
training	oneLayer	oneLayer - rat 1	0	0.36738047	0.025703968	false
training	oneLayer	oneLayer - rat 1	0	0.3779066	0.02570397	false
training	oneLayer	oneLayer - rat 1	0	0.388654	0.025703972	false
training	oneLayer	oneLayer - rat 1	0	0.39796975	0.021845264	false
training	oneLayer	oneLayer - rat 1	0	0.4078403	0.017756743	false
training	oneLayer	oneLayer - rat 1	0	0.41535127	0.010245773	false
training	oneLayer	oneLayer - rat 1	0	0.41946718	3.0914278E-4	false
training	oneLayer	oneLayer - rat 1	0	0.41946718	-0.010188218	false
training	oneLayer	oneLayer - rat 1	0	0.415339	-0.020154553	false
training	oneLayer	oneLayer - rat 1	0	0.40767625	-0.0278173	false
training	oneLayer	oneLayer - rat 1	0	0.39802644	-0.03181438	false
training	oneLayer	oneLayer - rat 1	0	0.38795623	-0.031814385	false
training	oneLayer	oneLayer - rat 1	0	0.37785602	-0.02763074	false
training	oneLayer	oneLayer - rat 1	0	0.36825535	-0.023654012	false
training	oneLayer	oneLayer - rat 1	0	0.35898945	-0.019815957	false
training	oneLayer	oneLayer - rat 1	0	0.34912694	-0.015730774	false
training	oneLayer	oneLayer - rat 1	0	0.33902034	-0.0115444865	false
training	oneLayer	oneLayer - rat 1	0	0.32923216	-0.0074900817	false
training	oneLayer	oneLayer - rat 1	0	0.31919596	-0.0033329506	false
training	oneLayer	oneLayer - rat 1	0	0.30966038	6.1681616E-4	false
training	oneLayer	oneLayer - rat 1	0	0.3001382	0.004561022	false
training	oneLayer	oneLayer - rat 1	0	0.29080343	0.008427607	false
training	oneLayer	oneLayer - rat 1	0	0.2811392	0.012430671	false
training	oneLayer	oneLayer - rat 1	0	0.2710124	0.016625322	false
training	oneLayer	oneLayer - rat 1	0	0.26165333	0.020501968	false
training	oneLayer	oneLayer - rat 1	0	0.252036	0.0244856	false
training	oneLayer	oneLayer - rat 1	0	0.24250808	0.028432196	false
training	oneLayer	oneLayer - rat 1	0	0.23321809	0.032280233	false
training	oneLayer	oneLayer - rat 1	0	0.22377008	0.036193725	false
training	oneLayer	oneLayer - rat 1	0	0.21408767	0.040204316	false
training	oneLayer	oneLayer - rat 1	0	0.20408337	0.04434823	false
training	oneLayer	oneLayer - rat 1	0	0.19478674	0.048199017	false
training	oneLayer	oneLayer - rat 1	0	0.18477672	0.0523453	false
training	oneLayer	oneLayer - rat 1	0	0.17490162	0.056435704	false
training	oneLayer	oneLayer - rat 1	0	0.16550548	0.06032771	false
training	oneLayer	oneLayer - rat 1	0	0.1556844	0.06439573	false
training	oneLayer	oneLayer - rat 1	0	0.14584514	0.06847129	false
training	oneLayer	oneLayer - rat 1	0	0.1364471	0.072364084	false
training	oneLayer	oneLayer - rat 1	0	0.126565	0.07645738	false
training	oneLayer	oneLayer - rat 1	0	0.11699309	0.08042219	false
training	oneLayer	oneLayer - rat 1	0	0.10713557	0.08450531	false
training	oneLayer	oneLayer - rat 1	0	0.09727612	0.08858923	false
training	oneLayer	oneLayer - rat 1	0	0.08792542	0.09246242	false
training	oneLayer	oneLayer - rat 1	0	0.07783782	0.09664084	false
training	oneLayer	oneLayer - rat 1	0	0.06848516	0.10051484	false
training	oneLayer	oneLayer - rat 1	0	0.0587916	0.10453004	false
training	oneLayer	oneLayer - rat 1	0	0.049134538	0.10853012	false
training	oneLayer	oneLayer - rat 1	0	0.03932973	0.11259141	false
training	oneLayer	oneLayer - rat 1	0	0.029541707	0.11664574	false
training	oneLayer	oneLayer - rat 1	0	0.020262577	0.12048928	false
training	oneLayer	oneLayer - rat 1	0	0.010789451	0.12441318	false
training	oneLayer	oneLayer - rat 1	0	0.0010795881	0.12843513	false
training	oneLayer	oneLayer - rat 1	0	-0.008752763	0.13250782	false
training	oneLayer	oneLayer - rat 1	0	-0.01850328	0.13654661	false
training	oneLayer	oneLayer - rat 1	0	-0.027842773	0.14041516	false
training	oneLayer	oneLayer - rat 1	0	-0.037411354	0.1443786	false
training	oneLayer	oneLayer - rat 1	0	-0.04713079	0.14840452	false
training	oneLayer	oneLayer - rat 1	0	-0.05720122	0.15257582	false
training	oneLayer	oneLayer - rat 1	0	-0.06680051	0.15655199	false
training	oneLayer	oneLayer - rat 1	0	-0.07662674	0.16062213	false
training	oneLayer	oneLayer - rat 1	0	-0.08622978	0.16459985	false
training	oneLayer	oneLayer - rat 1	0	-0.09574073	0.1685394	false
training	oneLayer	oneLayer - rat 1	0	-0.10506605	0.17240208	false
training	oneLayer	oneLayer - rat 1	0	-0.11476639	0.1764201	false
training	oneLayer	oneLayer - rat 1	0	-0.12432207	0.18037818	false
training	oneLayer	oneLayer - rat 1	0	-0.13366303	0.18424734	false
training	oneLayer	oneLayer - rat 1	0	-0.1435596	0.18834662	false
training	oneLayer	oneLayer - rat 1	0	-0.15298866	0.19225226	false
training	oneLayer	oneLayer - rat 1	0	-0.16245684	0.19617411	false
training	oneLayer	oneLayer - rat 1	0	-0.17211017	0.20017266	false
training	oneLayer	oneLayer - rat 1	0	-0.18219602	0.20435035	false
training	oneLayer	oneLayer - rat 1	0	-0.19172204	0.20829615	false
training	oneLayer	oneLayer - rat 1	0	-0.20177937	0.21246204	false
training	oneLayer	oneLayer - rat 1	0	-0.21143243	0.21646047	false
training	oneLayer	oneLayer - rat 1	0	-0.22120309	0.2205076	false
training	oneLayer	oneLayer - rat 1	0	-0.22880356	0.22810808	false
training	oneLayer	oneLayer - rat 1	0	-0.23606335	0.23536786	false
training	oneLayer	oneLayer - rat 1	0	-0.24324685	0.24255137	false
training	oneLayer	oneLayer - rat 1	0	-0.25056872	0.24987322	false
training	oneLayer	oneLayer - rat 1	0	-0.25817236	0.25747687	false
training	oneLayer	oneLayer - rat 1	0	-0.26528767	0.2645922	false
training	oneLayer	oneLayer - rat 1	0	-0.27249578	0.27180028	false
training	oneLayer	oneLayer - rat 1	0	-0.28005773	0.27936223	false
training	oneLayer	oneLayer - rat 1	0	-0.28774592	0.28705043	false
training	oneLayer	oneLayer - rat 1	0	-0.29761395	0.2911379	false
training	oneLayer	oneLayer - rat 1	0	-0.30780715	0.2911379	false
training	oneLayer	oneLayer - rat 1	0	-0.31774133	0.287023	false
training	oneLayer	oneLayer - rat 1	0	-0.32494476	0.27981958	false
training	oneLayer	oneLayer - rat 1	0	-0.3324528	0.27231154	false
training	oneLayer	oneLayer - rat 1	0	-0.34008464	0.2646797	false
training	oneLayer	oneLayer - rat 1	0	-0.34782627	0.25693807	false
training	oneLayer	oneLayer - rat 1	0	-0.351895	0.24711525	false
training	oneLayer	oneLayer - rat 1	0	-0.3557251	0.23786859	false
training	oneLayer	oneLayer - rat 1	0	-0.35958892	0.22854051	false
training	oneLayer	oneLayer - rat 1	0	-0.36357537	0.21891636	false
training	oneLayer	oneLayer - rat 1	0	-0.367514	0.20940766	false
training	oneLayer	oneLayer - rat 1	0	-0.37162876	0.19947377	false
training	oneLayer	oneLayer - rat 1	0	-0.37582353	0.18934669	false
training	oneLayer	oneLayer - rat 1	0	-0.3798221	0.17969325	false
training	oneLayer	oneLayer - rat 1	0	-0.38384816	0.1699735	false
training	oneLayer	oneLayer - rat 1	0	-0.38772726	0.16060853	false
training	oneLayer	oneLayer - rat 1	0	-0.39166492	0.1511022	false
training	oneLayer	oneLayer - rat 1	0	-0.39560902	0.14158025	false
training	oneLayer	oneLayer - rat 1	0	-0.3996386	0.131852	false
training	oneLayer	oneLayer - rat 1	0	-0.40379626	0.12181451	false
training	oneLayer	oneLayer - rat 1	0	-0.40799016	0.11168952	false
training	oneLayer	oneLayer - rat 1	0	-0.41203547	0.1019233	false
training	oneLayer	oneLayer - rat 1	0	-0.4158747	0.09265461	false
training	oneLayer	oneLayer - rat 1	0	-0.42007455	0.08251522	false
training	oneLayer	oneLayer - rat 1	0	-0.4241996	0.07255646	false
training	oneLayer	oneLayer - rat 1	0	-0.42835608	0.06252185	false
training	oneLayer	oneLayer - rat 1	0	-0.4322965	0.053008832	false
training	oneLayer	oneLayer - rat 1	0	-0.43640018	0.0431017	false
training	oneLayer	oneLayer - rat 1	0	-0.43640018	0.032559916	false
training	oneLayer	oneLayer - rat 1	0	-0.4324228	0.022957694	false
training	oneLayer	oneLayer - rat 1	0	-0.4251628	0.015697686	false
training	oneLayer	oneLayer - rat 1	0	-0.41564575	0.011755597	false
training	oneLayer	oneLayer - rat 1	0	-0.4061202	0.0078099943	false
training	oneLayer	oneLayer - rat 1	0	-0.39620575	0.0037032994	false
training	oneLayer	oneLayer - rat 1	0	-0.38677558	-2.0281046E-4	false
training	oneLayer	oneLayer - rat 1	0	-0.37692988	-0.0042810244	false
training	oneLayer	oneLayer - rat 1	0	-0.36627108	-0.0042810226	false
training	oneLayer	oneLayer - rat 1	0	-0.3558108	-0.0042810207	false
training	oneLayer	oneLayer - rat 1	0	-0.34507877	-0.004281019	false
training	oneLayer	oneLayer - rat 1	0	-0.33490193	-0.004281017	false
training	oneLayer	oneLayer - rat 1	0	-0.32484305	-0.004281015	false
training	oneLayer	oneLayer - rat 1	0	-0.3141045	-0.0042810133	false
training	oneLayer	oneLayer - rat 1	0	-0.30310598	-0.0042810114	false
training	oneLayer	oneLayer - rat 1	0	-0.29305586	-0.0042810095	false
training	oneLayer	oneLayer - rat 1	0	-0.28206754	-0.0042810077	false
training	oneLayer	oneLayer - rat 1	0	-0.27156943	-0.004281006	false
training	oneLayer	oneLayer - rat 1	0	-0.26156652	-0.004281004	false
training	oneLayer	oneLayer - rat 1	0	-0.25125813	-0.004281002	false
training	oneLayer	oneLayer - rat 1	0	-0.240652	-0.0042810002	false
training	oneLayer	oneLayer - rat 1	0	-0.23041025	-0.004280999	false
training	oneLayer	oneLayer - rat 1	0	-0.22007485	-0.004280997	false
training	oneLayer	oneLayer - rat 1	0	-0.20913763	-0.004280995	false
training	oneLayer	oneLayer - rat 1	0	-0.19886056	-0.0042809932	false
training	oneLayer	oneLayer - rat 1	0	-0.18845561	-0.0042809914	false
training	oneLayer	oneLayer - rat 1	0	-0.1782011	-0.0042809895	false
training	oneLayer	oneLayer - rat 1	0	-0.16760987	-0.0042809877	false
training	oneLayer	oneLayer - rat 1	0	-0.15734856	-0.004280986	false
training	oneLayer	oneLayer - rat 1	0	-0.14701062	-0.004280984	false
training	oneLayer	oneLayer - rat 1	0	-0.1363006	-0.004280982	false
training	oneLayer	oneLayer - rat 1	0	-0.12590075	-0.00428098	false
training	oneLayer	oneLayer - rat 1	0	-0.11547731	-0.0042809783	false
training	oneLayer	oneLayer - rat 1	0	-0.1051244	-0.004280977	false
training	oneLayer	oneLayer - rat 1	0	-0.09457996	-0.004280975	false
training	oneLayer	oneLayer - rat 1	0	-0.08368778	-0.004280973	false
training	oneLayer	oneLayer - rat 1	0	-0.07285317	-0.004280971	false
training	oneLayer	oneLayer - rat 1	0	-0.06260666	-0.0042809695	false
training	oneLayer	oneLayer - rat 1	0	-0.051678985	-0.004280967	false
training	oneLayer	oneLayer - rat 1	0	-0.041563157	-0.004280966	false
training	oneLayer	oneLayer - rat 1	0	-0.030699361	-0.004280964	false
training	oneLayer	oneLayer - rat 1	0	-0.020476198	-0.004280962	false
training	oneLayer	oneLayer - rat 1	0	-0.009652539	-0.00428096	false
training	oneLayer	oneLayer - rat 1	0	5.1871245E-4	-0.0042809583	false
training	oneLayer	oneLayer - rat 1	0	0.011031528	-0.0042809565	false
training	oneLayer	oneLayer - rat 1	0	0.021061137	-0.0042809546	false
training	oneLayer	oneLayer - rat 1	0	0.031805485	-0.0042809527	false
training	oneLayer	oneLayer - rat 1	0	0.04238115	-0.004280951	false
training	oneLayer	oneLayer - rat 1	0	0.053089004	-0.004280949	false
training	oneLayer	oneLayer - rat 1	0	0.06318186	-0.004280947	false
training	oneLayer	oneLayer - rat 1	0	0.07386232	-0.0042809453	false
training	oneLayer	oneLayer - rat 1	0	0.08482488	-0.0042809434	false
training	oneLayer	oneLayer - rat 1	0	0.095337994	-0.0042809416	false
training	oneLayer	oneLayer - rat 1	0	0.10567441	-0.0042809397	false
training	oneLayer	oneLayer - rat 1	0	0.11586539	-0.0042809383	false
training	oneLayer	oneLayer - rat 1	0	0.12619564	-0.0042809364	false
training	oneLayer	oneLayer - rat 1	0	0.13631412	-0.0042809346	false
training	oneLayer	oneLayer - rat 1	0	0.1465377	-0.0042809327	false
training	oneLayer	oneLayer - rat 1	0	0.15701431	-0.004280931	false
training	oneLayer	oneLayer - rat 1	0	0.16720103	-0.004280929	false
training	oneLayer	oneLayer - rat 1	0	0.17746118	-0.004280927	false
training	oneLayer	oneLayer - rat 1	0	0.18754311	-0.0042809257	false
training	oneLayer	oneLayer - rat 1	0	0.19812894	-0.004280924	false
training	oneLayer	oneLayer - rat 1	0	0.20900361	-0.004280922	false
training	oneLayer	oneLayer - rat 1	0	0.21944161	-0.00428092	false
training	oneLayer	oneLayer - rat 1	0	0.22970471	-0.0042809183	false
training	oneLayer	oneLayer - rat 1	0	0.2399324	-0.0042809164	false
training	oneLayer	oneLayer - rat 1	0	0.24996375	-0.0042809146	false
training	oneLayer	oneLayer - rat 1	0	0.26017392	-0.0042809127	false
training	oneLayer	oneLayer - rat 1	0	0.2702218	-0.0042809113	false
training	oneLayer	oneLayer - rat 1	0	0.28047937	-0.0042809094	false
training	oneLayer	oneLayer - rat 1	0	0.29133105	-0.0042809076	false
training	oneLayer	oneLayer - rat 1	0	0.30230156	-0.0042809057	false
training	oneLayer	oneLayer - rat 1	0	0.3126963	-0.004280904	false
training	oneLayer	oneLayer - rat 1	0	0.32337552	-0.004280902	false
training	oneLayer	oneLayer - rat 1	0	0.3334371	-0.0042809	false
training	oneLayer	oneLayer - rat 1	0	0.34367254	-0.0042808983	false
training	oneLayer	oneLayer - rat 1	0	0.35445777	-0.0042808964	false
training	oneLayer	oneLayer - rat 1	0	0.36467105	-0.0042808945	false
training	oneLayer	oneLayer - rat 1	0	0.3749407	-0.0042808927	false
training	oneLayer	oneLayer - rat 1	0	0.3851572	-0.004280891	false
training	oneLayer	oneLayer - rat 1	0	0.3959338	-0.004280889	false
training	oneLayer	oneLayer - rat 1	0	0.4064909	-0.004280887	false
training	oneLayer	oneLayer - rat 1	0	0.41629457	-2.2006531E-4	false
training	oneLayer	oneLayer - rat 1	0	0.42363325	0.007118606	false
training	oneLayer	oneLayer - rat 1	0	0.42764834	0.016811915	false
training	oneLayer	oneLayer - rat 1	0	0.42764834	0.027642671	false
training	oneLayer	oneLayer - rat 1	0	0.42371842	0.03713032	false
training	oneLayer	oneLayer - rat 1	0	0.41602278	0.04482595	false
training	oneLayer	oneLayer - rat 1	0	0.40606812	0.04894931	false
training	oneLayer	oneLayer - rat 1	0	0.39581108	0.048949305	false
training	oneLayer	oneLayer - rat 1	0	0.38533536	0.0489493	false
training	oneLayer	oneLayer - rat 1	0	0.37514585	0.0489493	false
training	oneLayer	oneLayer - rat 1	0	0.3650861	0.048949298	false
training	oneLayer	oneLayer - rat 1	0	0.35446912	0.048949294	false
training	oneLayer	oneLayer - rat 1	0	0.34349	0.04894929	false
training	oneLayer	oneLayer - rat 1	0	0.33256218	0.04894929	false
training	oneLayer	oneLayer - rat 1	0	0.32198724	0.048949286	false
training	oneLayer	oneLayer - rat 1	0	0.3115687	0.048949283	false
training	oneLayer	oneLayer - rat 1	0	0.3010208	0.04894928	false
training	oneLayer	oneLayer - rat 1	0	0.29022527	0.04894928	false
training	oneLayer	oneLayer - rat 1	0	0.2793838	0.048949275	false
training	oneLayer	oneLayer - rat 1	0	0.26870912	0.04894927	false
training	oneLayer	oneLayer - rat 1	0	0.2586298	0.048949268	false
training	oneLayer	oneLayer - rat 1	0	0.24860375	0.048949268	false
training	oneLayer	oneLayer - rat 1	0	0.23781565	0.048949264	false
training	oneLayer	oneLayer - rat 1	0	0.2269186	0.04894926	false
training	oneLayer	oneLayer - rat 1	0	0.21667789	0.048949257	false
training	oneLayer	oneLayer - rat 1	0	0.20654096	0.048949257	false
training	oneLayer	oneLayer - rat 1	0	0.19627167	0.048949253	false
training	oneLayer	oneLayer - rat 1	0	0.18623848	0.04894925	false
training	oneLayer	oneLayer - rat 1	0	0.17608947	0.04894925	false
training	oneLayer	oneLayer - rat 1	0	0.16600966	0.048949245	false
training	oneLayer	oneLayer - rat 1	0	0.15587774	0.04894924	false
training	oneLayer	oneLayer - rat 1	0	0.14550237	0.048949238	false
training	oneLayer	oneLayer - rat 1	0	0.13500376	0.048949238	false
training	oneLayer	oneLayer - rat 1	0	0.12477866	0.048949234	false
training	oneLayer	oneLayer - rat 1	0	0.114672236	0.04894923	false
training	oneLayer	oneLayer - rat 1	0	0.10388192	0.048949227	false
training	oneLayer	oneLayer - rat 1	0	0.09290031	0.048949227	false
training	oneLayer	oneLayer - rat 1	0	0.08270603	0.048949223	false
training	oneLayer	oneLayer - rat 1	0	0.07200573	0.04894922	false
training	oneLayer	oneLayer - rat 1	0	0.061354034	0.048949216	false
training	oneLayer	oneLayer - rat 1	0	0.050750565	0.048949216	false
training	oneLayer	oneLayer - rat 1	0	0.040402435	0.04894921	false
training	oneLayer	oneLayer - rat 1	0	0.030122846	0.048949208	false
training	oneLayer	oneLayer - rat 1	0	0.019273201	0.048949204	false
training	oneLayer	oneLayer - rat 1	0	0.008411048	0.048949204	false
training	oneLayer	oneLayer - rat 1	0	-0.0020116626	0.0489492	false
training	oneLayer	oneLayer - rat 1	0	-0.012616922	0.048949197	false
training	oneLayer	oneLayer - rat 1	0	-0.022813214	0.048949197	false
training	oneLayer	oneLayer - rat 1	0	-0.03307448	0.048949193	false
training	oneLayer	oneLayer - rat 1	0	-0.04375198	0.04894919	false
training	oneLayer	oneLayer - rat 1	0	-0.05399306	0.048949186	false
training	oneLayer	oneLayer - rat 1	0	-0.06469026	0.048949186	false
training	oneLayer	oneLayer - rat 1	0	-0.07538825	0.048949182	false
training	oneLayer	oneLayer - rat 1	0	-0.085464686	0.04894918	false
training	oneLayer	oneLayer - rat 1	0	-0.09598318	0.048949175	false
training	oneLayer	oneLayer - rat 1	0	-0.10692323	0.048949175	false
training	oneLayer	oneLayer - rat 1	0	-0.11786609	0.04894917	false
training	oneLayer	oneLayer - rat 1	0	-0.12798777	0.048949167	false
training	oneLayer	oneLayer - rat 1	0	-0.13830411	0.048949163	false
training	oneLayer	oneLayer - rat 1	0	-0.14858758	0.048949163	false
training	oneLayer	oneLayer - rat 1	0	-0.15952255	0.04894916	false
training	oneLayer	oneLayer - rat 1	0	-0.16978757	0.048949156	false
training	oneLayer	oneLayer - rat 1	0	-0.18012604	0.048949152	false
training	oneLayer	oneLayer - rat 1	0	-0.19025277	0.048949152	false
training	oneLayer	oneLayer - rat 1	0	-0.20047005	0.04894915	false
training	oneLayer	oneLayer - rat 1	0	-0.21066336	0.048949145	false
training	oneLayer	oneLayer - rat 1	0	-0.22148888	0.048949145	false
training	oneLayer	oneLayer - rat 1	0	-0.23205131	0.04894914	false
training	oneLayer	oneLayer - rat 1	0	-0.24215257	0.048949137	false
training	oneLayer	oneLayer - rat 1	0	-0.25215536	0.048949134	false
training	oneLayer	oneLayer - rat 1	0	-0.26289257	0.048949134	false
training	oneLayer	oneLayer - rat 1	0	-0.27290606	0.04894913	false
training	oneLayer	oneLayer - rat 1	0	-0.28389618	0.048949126	false
training	oneLayer	oneLayer - rat 1	0	-0.29433143	0.048949122	false
training	oneLayer	oneLayer - rat 1	0	-0.30489057	0.048949122	false
training	oneLayer	oneLayer - rat 1	0	-0.3156804	0.04894912	false
training	oneLayer	oneLayer - rat 1	0	-0.32568693	0.048949115	false
training	oneLayer	oneLayer - rat 1	0	-0.33657905	0.04894911	false
training	oneLayer	oneLayer - rat 1	0	-0.3465203	0.04483131	false
training	oneLayer	oneLayer - rat 1	0	-0.35633475	0.04076603	false
training	oneLayer	oneLayer - rat 1	0	-0.36613414	0.036706988	false
training	oneLayer	oneLayer - rat 1	0	-0.37547934	0.03283608	false
training	oneLayer	oneLayer - rat 1	0	-0.38521475	0.028803537	false
training	oneLayer	oneLayer - rat 1	0	-0.39525184	0.02464603	false
training	oneLayer	oneLayer - rat 1	0	-0.40528694	0.020489356	false
training	oneLayer	oneLayer - rat 1	0	-0.41508	0.016432935	false
training	oneLayer	oneLayer - rat 1	0	-0.42251736	0.008995559	false
training	oneLayer	oneLayer - rat 1	0	-0.42979747	0.0017154448	false
training	oneLayer	oneLayer - rat 1	0	-0.4340006	-0.008431788	false
training	oneLayer	oneLayer - rat 1	0	-0.43794814	-0.017961973	false
training	oneLayer	oneLayer - rat 1	0	-0.4420799	-0.027936937	false
training	oneLayer	oneLayer - rat 1	0	-0.44207987	-0.03822469	false
training	oneLayer	oneLayer - rat 1	0	-0.43823257	-0.047512926	false
training	oneLayer	oneLayer - rat 1	0	-0.43092123	-0.054824248	false
training	oneLayer	oneLayer - rat 1	0	-0.4214789	-0.05873539	false
training	oneLayer	oneLayer - rat 1	0	-0.41132954	-0.058735386	false
training	oneLayer	oneLayer - rat 1	0	-0.40158153	-0.05469762	false
training	oneLayer	oneLayer - rat 1	0	-0.39384085	-0.046956956	false
training	oneLayer	oneLayer - rat 1	0	-0.389993	-0.03766742	false
training	oneLayer	oneLayer - rat 1	0	-0.38597748	-0.027973032	false
training	oneLayer	oneLayer - rat 1	0	-0.3821462	-0.01872356	false
training	oneLayer	oneLayer - rat 1	0	-0.37814373	-0.009060684	false
training	oneLayer	oneLayer - rat 1	0	-0.3743119	1.9018602E-4	false
training	oneLayer	oneLayer - rat 1	0	-0.37012863	0.010289456	false
training	oneLayer	oneLayer - rat 1	0	-0.36614397	0.019909345	false
training	oneLayer	oneLayer - rat 1	0	-0.3622256	0.029369159	false
training	oneLayer	oneLayer - rat 1	0	-0.35832417	0.03878803	false
training	oneLayer	oneLayer - rat 1	0	-0.3543274	0.048437078	false
training	oneLayer	oneLayer - rat 1	0	-0.35034123	0.058060516	false
training	oneLayer	oneLayer - rat 1	0	-0.34619555	0.06806911	false
training	oneLayer	oneLayer - rat 1	0	-0.34230033	0.07747299	false
training	oneLayer	oneLayer - rat 1	0	-0.3383034	0.08712252	false
training	oneLayer	oneLayer - rat 1	0	-0.33444923	0.09642723	false
training	oneLayer	oneLayer - rat 1	0	-0.33043307	0.10612316	false
training	oneLayer	oneLayer - rat 1	0	-0.32654715	0.11550463	false
training	oneLayer	oneLayer - rat 1	0	-0.3224204	0.12546752	false
training	oneLayer	oneLayer - rat 1	0	-0.3185103	0.13490732	false
training	oneLayer	oneLayer - rat 1	0	-0.3185103	0.14588204	false
training	oneLayer	oneLayer - rat 1	0	-0.3185103	0.15657003	false
training	oneLayer	oneLayer - rat 1	0	-0.3185103	0.16689083	false
training	oneLayer	oneLayer - rat 1	0	-0.3185103	0.17695142	false
training	oneLayer	oneLayer - rat 1	0	-0.31851032	0.18731187	false
training	oneLayer	oneLayer - rat 1	0	-0.31851032	0.19793011	false
training	oneLayer	oneLayer - rat 1	0	-0.31851032	0.20845596	false
training	oneLayer	oneLayer - rat 1	0	-0.31851032	0.2190984	false
training	oneLayer	oneLayer - rat 1	0	-0.31851032	0.22956267	false
training	oneLayer	oneLayer - rat 1	0	-0.31851032	0.240518	false
training	oneLayer	oneLayer - rat 1	0	-0.31851032	0.25124797	false
training	oneLayer	oneLayer - rat 1	0	-0.31851035	0.26141864	false
training	oneLayer	oneLayer - rat 1	0	-0.31851035	0.27148435	false
training	oneLayer	oneLayer - rat 1	0	-0.31851035	0.2818737	false
training	oneLayer	oneLayer - rat 1	0	-0.31851035	0.29233426	false
training	oneLayer	oneLayer - rat 1	0	-0.31455705	0.3018784	false
training	oneLayer	oneLayer - rat 1	0	-0.31070852	0.31116953	false
training	oneLayer	oneLayer - rat 1	0	-0.3068203	0.32055655	false
training	oneLayer	oneLayer - rat 1	0	-0.30273262	0.33042514	false
training	oneLayer	oneLayer - rat 1	0	-0.29556552	0.33759227	false
training	oneLayer	oneLayer - rat 1	0	-0.2856013	0.3417196	false
training	oneLayer	oneLayer - rat 1	0	-0.27555653	0.3417196	false
training	oneLayer	oneLayer - rat 1	0	-0.26591673	0.33772665	false
training	oneLayer	oneLayer - rat 1	0	-0.25841665	0.33022657	false
training	oneLayer	oneLayer - rat 1	0	-0.25451666	0.32081118	false
training	oneLayer	oneLayer - rat 1	0	-0.25451666	0.30989245	false
training	oneLayer	oneLayer - rat 1	0	-0.25862986	0.29996228	false
training	oneLayer	oneLayer - rat 1	0	-0.26247448	0.29068056	false
training	oneLayer	oneLayer - rat 1	0	-0.26644668	0.28109083	false
training	oneLayer	oneLayer - rat 1	0	-0.27045837	0.2714057	false
training	oneLayer	oneLayer - rat 1	0	-0.27431953	0.26208404	false
training	oneLayer	oneLayer - rat 1	0	-0.27820787	0.25269672	false
training	oneLayer	oneLayer - rat 1	0	-0.28213763	0.24320945	false
training	oneLayer	oneLayer - rat 1	0	-0.28626493	0.23324531	false
training	oneLayer	oneLayer - rat 1	0	-0.2903098	0.22348015	false
training	oneLayer	oneLayer - rat 1	0	-0.2943771	0.21366073	false
training	oneLayer	oneLayer - rat 1	0	-0.2984318	0.2038718	false
training	oneLayer	oneLayer - rat 1	0	-0.30255044	0.19392857	false
training	oneLayer	oneLayer - rat 1	0	-0.30672234	0.18385665	false
training	oneLayer	oneLayer - rat 1	0	-0.31056497	0.17457974	false
training	oneLayer	oneLayer - rat 1	0	-0.31470537	0.16458389	false
training	oneLayer	oneLayer - rat 1	0	-0.31877035	0.15477017	false
training	oneLayer	oneLayer - rat 1	0	-0.32287598	0.14485833	false
training	oneLayer	oneLayer - rat 1	0	-0.32705146	0.13477783	false
training	oneLayer	oneLayer - rat 1	0	-0.33119544	0.1247733	false
training	oneLayer	oneLayer - rat 1	0	-0.33525234	0.11497911	false
training	oneLayer	oneLayer - rat 1	0	-0.33919206	0.105467774	false
training	oneLayer	oneLayer - rat 1	0	-0.34693658	0.097723246	false
training	oneLayer	oneLayer - rat 1	0	-0.3542812	0.09037863	false
training	oneLayer	oneLayer - rat 1	0	-0.36145857	0.083201244	false
training	oneLayer	oneLayer - rat 1	0	-0.36860418	0.07605563	false
training	oneLayer	oneLayer - rat 1	0	-0.37607914	0.06858067	false
training	oneLayer	oneLayer - rat 1	0	-0.38375494	0.06090486	false
training	oneLayer	oneLayer - rat 1	0	-0.39131567	0.053344123	false
training	oneLayer	oneLayer - rat 1	0	-0.39875254	0.045907248	false
training	oneLayer	oneLayer - rat 1	0	-0.4064383	0.038221497	false
training	oneLayer	oneLayer - rat 1	0	-0.413799	0.030860795	false
training	oneLayer	oneLayer - rat 1	0	-0.42154554	0.023114258	false
training	oneLayer	oneLayer - rat 1	0	-0.42572883	0.013014849	false
training	oneLayer	oneLayer - rat 1	0	-0.4334224	0.0053212936	false
training	oneLayer	oneLayer - rat 1	0	-0.43755943	-0.004666392	false
training	oneLayer	oneLayer - rat 1	0	-0.44165033	-0.014542754	false
training	oneLayer	oneLayer - rat 1	0	-0.4455816	-0.024033608	false
training	oneLayer	oneLayer - rat 1	0	-0.44962558	-0.03379668	false
training	oneLayer	oneLayer - rat 1	0	-0.44962555	-0.04394168	false
training	oneLayer	oneLayer - rat 1	0	-0.445482	-0.05394513	false
training	oneLayer	oneLayer - rat 1	0	-0.4382505	-0.061176617	false
training	oneLayer	oneLayer - rat 1	0	-0.42852682	-0.06520429	false
training	oneLayer	oneLayer - rat 1	0	-0.41762587	-0.06520429	false
training	oneLayer	oneLayer - rat 1	0	-0.40812486	-0.061268847	false
training	oneLayer	oneLayer - rat 1	0	-0.40073907	-0.053883042	false
training	oneLayer	oneLayer - rat 1	0	-0.39655456	-0.043780725	false
training	oneLayer	oneLayer - rat 1	0	-0.3925396	-0.03408771	false
training	oneLayer	oneLayer - rat 1	0	-0.38838047	-0.024046678	false
training	oneLayer	oneLayer - rat 1	0	-0.3845412	-0.014777895	false
training	oneLayer	oneLayer - rat 1	0	-0.38056564	-0.005180007	false
training	oneLayer	oneLayer - rat 1	0	-0.37646297	0.004724705	false
training	oneLayer	oneLayer - rat 1	0	-0.37234902	0.014656637	false
training	oneLayer	oneLayer - rat 1	0	-0.36823887	0.02457946	false
training	oneLayer	oneLayer - rat 1	0	-0.36422715	0.034264617	false
training	oneLayer	oneLayer - rat 1	0	-0.36017182	0.044055067	false
training	oneLayer	oneLayer - rat 1	0	-0.3562493	0.053524878	false
training	oneLayer	oneLayer - rat 1	0	-0.35208744	0.06357252	false
training	oneLayer	oneLayer - rat 1	0	-0.34797415	0.0735029	false
training	oneLayer	oneLayer - rat 1	0	-0.34397125	0.083166756	false
training	oneLayer	oneLayer - rat 1	0	-0.33994368	0.09289014	false
training	oneLayer	oneLayer - rat 1	0	-0.33580813	0.1028743	false
training	oneLayer	oneLayer - rat 1	0	-0.33167437	0.11285407	false
training	oneLayer	oneLayer - rat 1	0	-0.327634	0.122608386	false
training	oneLayer	oneLayer - rat 1	0	-0.32366788	0.13218348	false
training	oneLayer	oneLayer - rat 1	0	-0.31972072	0.1417128	false
training	oneLayer	oneLayer - rat 1	0	-0.31972072	0.15244439	false
training	oneLayer	oneLayer - rat 1	0	-0.31972072	0.16265003	false
training	oneLayer	oneLayer - rat 1	0	-0.31972072	0.1727457	false
training	oneLayer	oneLayer - rat 1	0	-0.31972072	0.18329674	false
training	oneLayer	oneLayer - rat 1	0	-0.31972072	0.19366868	false
training	oneLayer	oneLayer - rat 1	0	-0.31972075	0.20463164	false
training	oneLayer	oneLayer - rat 1	0	-0.31972075	0.21527348	false
training	oneLayer	oneLayer - rat 1	0	-0.31972075	0.22557089	false
training	oneLayer	oneLayer - rat 1	0	-0.31972075	0.23596606	false
training	oneLayer	oneLayer - rat 1	0	-0.31972075	0.24662001	false
training	oneLayer	oneLayer - rat 1	0	-0.31972075	0.25689146	false
training	oneLayer	oneLayer - rat 1	0	-0.31972075	0.2675757	false
training	oneLayer	oneLayer - rat 1	0	-0.31972077	0.2777798	false
training	oneLayer	oneLayer - rat 1	0	-0.31972077	0.28798178	false
training	oneLayer	oneLayer - rat 1	0	-0.3156327	0.29785126	false
training	oneLayer	oneLayer - rat 1	0	-0.3114763	0.3078857	false
training	oneLayer	oneLayer - rat 1	0	-0.3042506	0.3151114	false
training	oneLayer	oneLayer - rat 1	0	-0.2945554	0.3191273	false
training	oneLayer	oneLayer - rat 1	0	-0.2842312	0.3191273	false
training	oneLayer	oneLayer - rat 1	0	-0.27446616	0.3150825	false
training	oneLayer	oneLayer - rat 1	0	-0.26671994	0.30733627	false
training	oneLayer	oneLayer - rat 1	0	-0.26285088	0.2979956	false
training	oneLayer	oneLayer - rat 1	0	-0.26285088	0.28752357	false
training	oneLayer	oneLayer - rat 1	0	-0.2669375	0.27765757	false
training	oneLayer	oneLayer - rat 1	0	-0.270929	0.26802123	false
training	oneLayer	oneLayer - rat 1	0	-0.27498877	0.2582201	false
training	oneLayer	oneLayer - rat 1	0	-0.27885827	0.24887826	false
training	oneLayer	oneLayer - rat 1	0	-0.28277758	0.2394162	false
training	oneLayer	oneLayer - rat 1	0	-0.28668317	0.22998725	false
training	oneLayer	oneLayer - rat 1	0	-0.29075018	0.2201687	false
training	oneLayer	oneLayer - rat 1	0	-0.2948387	0.21029809	false
training	oneLayer	oneLayer - rat 1	0	-0.29896212	0.20034325	false
training	oneLayer	oneLayer - rat 1	0	-0.30305606	0.19045962	false
training	oneLayer	oneLayer - rat 1	0	-0.3069553	0.181046	false
training	oneLayer	oneLayer - rat 1	0	-0.310873	0.17158784	false
training	oneLayer	oneLayer - rat 1	0	-0.31485358	0.16197786	false
training	oneLayer	oneLayer - rat 1	0	-0.3189706	0.15203846	false
training	oneLayer	oneLayer - rat 1	0	-0.32286632	0.14263333	false
training	oneLayer	oneLayer - rat 1	0	-0.3270368	0.13256495	false
training	oneLayer	oneLayer - rat 1	0	-0.33100852	0.12297631	false
training	oneLayer	oneLayer - rat 1	0	-0.33514467	0.11299079	false
training	oneLayer	oneLayer - rat 1	0	-0.34282485	0.10531059	false
training	oneLayer	oneLayer - rat 1	0	-0.35034525	0.09779019	false
training	oneLayer	oneLayer - rat 1	0	-0.3579823	0.09015313	false
training	oneLayer	oneLayer - rat 1	0	-0.36542374	0.08271168	false
training	oneLayer	oneLayer - rat 1	0	-0.3731552	0.07498022	false
training	oneLayer	oneLayer - rat 1	0	-0.38038713	0.067748286	false
training	oneLayer	oneLayer - rat 1	0	-0.38781887	0.060316537	false
training	oneLayer	oneLayer - rat 1	0	-0.39508134	0.05305408	false
training	oneLayer	oneLayer - rat 1	0	-0.40216342	0.045971986	false
training	oneLayer	oneLayer - rat 1	0	-0.4093646	0.038770784	false
training	oneLayer	oneLayer - rat 1	0	-0.41706982	0.031065578	false
training	oneLayer	oneLayer - rat 1	0	-0.4211514	0.021211805	false
training	oneLayer	oneLayer - rat 1	0	-0.4211514	0.010602111	false
training	oneLayer	oneLayer - rat 1	0	-0.4171868	0.0010307805	false
training	oneLayer	oneLayer - rat 1	0	-0.40972227	-0.0064337645	false
training	oneLayer	oneLayer - rat 1	0	-0.4004634	-0.010268901	false
training	oneLayer	oneLayer - rat 1	0	-0.3899418	-0.010268897	false
training	oneLayer	oneLayer - rat 1	0	-0.3797188	-0.010268893	false
training	oneLayer	oneLayer - rat 1	0	-0.3695228	-0.010268889	false
training	oneLayer	oneLayer - rat 1	0	-0.35933137	-0.010268886	false
training	oneLayer	oneLayer - rat 1	0	-0.34900546	-0.010268883	false
training	oneLayer	oneLayer - rat 1	0	-0.3385708	-0.010268879	false
training	oneLayer	oneLayer - rat 1	0	-0.3279514	-0.010268875	false
training	oneLayer	oneLayer - rat 1	0	-0.317569	-0.010268872	false
training	oneLayer	oneLayer - rat 1	0	-0.3068386	-0.010268868	false
training	oneLayer	oneLayer - rat 1	0	-0.29602775	-0.010268864	false
training	oneLayer	oneLayer - rat 1	0	-0.28599733	-0.0102688605	false
training	oneLayer	oneLayer - rat 1	0	-0.27581474	-0.010268857	false
training	oneLayer	oneLayer - rat 1	0	-0.26549506	-0.010268853	false
training	oneLayer	oneLayer - rat 1	0	-0.2552736	-0.010268849	false
training	oneLayer	oneLayer - rat 1	0	-0.24451394	-0.010268846	false
training	oneLayer	oneLayer - rat 1	0	-0.23372726	-0.010268842	false
training	oneLayer	oneLayer - rat 1	0	-0.22349073	-0.010268838	false
training	oneLayer	oneLayer - rat 1	0	-0.21273102	-0.010268834	false
training	oneLayer	oneLayer - rat 1	0	-0.20227756	-0.010268831	false
training	oneLayer	oneLayer - rat 1	0	-0.191748	-0.010268827	false
training	oneLayer	oneLayer - rat 1	0	-0.180954	-0.010268823	false
training	oneLayer	oneLayer - rat 1	0	-0.17032531	-0.0102688195	false
training	oneLayer	oneLayer - rat 1	0	-0.16019633	-0.010268817	false
training	oneLayer	oneLayer - rat 1	0	-0.15008733	-0.010268813	false
training	oneLayer	oneLayer - rat 1	0	-0.13920358	-0.010268809	false
training	oneLayer	oneLayer - rat 1	0	-0.1283943	-0.010268806	false
training	oneLayer	oneLayer - rat 1	0	-0.11822269	-0.010268802	false
training	oneLayer	oneLayer - rat 1	0	-0.107892	-0.010268798	false
training	oneLayer	oneLayer - rat 1	0	-0.097625166	-0.010268794	false
training	oneLayer	oneLayer - rat 1	0	-0.087605044	-0.010268791	false
training	oneLayer	oneLayer - rat 1	0	-0.07745578	-0.010268788	false
training	oneLayer	oneLayer - rat 1	0	-0.067246854	-0.010268784	false
training	oneLayer	oneLayer - rat 1	0	-0.05657023	-0.01026878	false
training	oneLayer	oneLayer - rat 1	0	-0.045866173	-0.010268777	false
training	oneLayer	oneLayer - rat 1	0	-0.03514284	-0.010268773	false
training	oneLayer	oneLayer - rat 1	0	-0.024698462	-0.010268769	false
training	oneLayer	oneLayer - rat 1	0	-0.01377876	-0.0102687655	false
training	oneLayer	oneLayer - rat 1	0	-0.002989122	-0.010268762	false
training	oneLayer	oneLayer - rat 1	0	0.007931197	-0.010268757	false
training	oneLayer	oneLayer - rat 1	0	0.01867982	-0.010268753	false
training	oneLayer	oneLayer - rat 1	0	0.02938273	-0.01026875	false
training	oneLayer	oneLayer - rat 1	0	0.039589535	-0.010268747	false
training	oneLayer	oneLayer - rat 1	0	0.050078698	-0.010268743	false
training	oneLayer	oneLayer - rat 1	0	0.060240768	-0.010268739	false
training	oneLayer	oneLayer - rat 1	0	0.0704574	-0.010268736	false
training	oneLayer	oneLayer - rat 1	0	0.081360236	-0.010268732	false
training	oneLayer	oneLayer - rat 1	0	0.09205257	-0.010268728	false
training	oneLayer	oneLayer - rat 1	0	0.10284984	-0.0102687245	false
training	oneLayer	oneLayer - rat 1	0	0.11311581	-0.010268721	false
training	oneLayer	oneLayer - rat 1	0	0.12343698	-0.010268717	false
training	oneLayer	oneLayer - rat 1	0	0.13349468	-0.010268713	false
training	oneLayer	oneLayer - rat 1	0	0.14423561	-0.01026871	false
training	oneLayer	oneLayer - rat 1	0	0.15517868	-0.010268706	false
training	oneLayer	oneLayer - rat 1	0	0.16613953	-0.010268702	false
training	oneLayer	oneLayer - rat 1	0	0.17705593	-0.010268698	false
training	oneLayer	oneLayer - rat 1	0	0.18721743	-0.010268695	false
training	oneLayer	oneLayer - rat 1	0	0.19782706	-0.010268691	false
training	oneLayer	oneLayer - rat 1	0	0.2083405	-0.010268687	false
training	oneLayer	oneLayer - rat 1	0	0.21925063	-0.010268684	false
training	oneLayer	oneLayer - rat 1	0	0.22961695	-0.01026868	false
training	oneLayer	oneLayer - rat 1	0	0.2406161	-0.010268676	false
training	oneLayer	oneLayer - rat 1	0	0.2509656	-0.010268672	false
training	oneLayer	oneLayer - rat 1	0	0.26104042	-0.010268669	false
training	oneLayer	oneLayer - rat 1	0	0.27117193	-0.010268666	false
training	oneLayer	oneLayer - rat 1	0	0.2820399	-0.010268662	false
training	oneLayer	oneLayer - rat 1	0	0.29287902	-0.010268658	false
training	oneLayer	oneLayer - rat 1	0	0.30289435	-0.010268655	false
training	oneLayer	oneLayer - rat 1	0	0.3131057	-0.010268651	false
training	oneLayer	oneLayer - rat 1	0	0.32385245	-0.010268647	false
training	oneLayer	oneLayer - rat 1	0	0.33433563	-0.0102686435	false
training	oneLayer	oneLayer - rat 1	0	0.34475836	-0.01026864	false
training	oneLayer	oneLayer - rat 1	0	0.35494155	-0.010268636	false
training	oneLayer	oneLayer - rat 1	0	0.36531228	-0.010268632	false
training	oneLayer	oneLayer - rat 1	0	0.37601277	-0.010268629	false
training	oneLayer	oneLayer - rat 1	0	0.38687065	-0.010268625	false
training	oneLayer	oneLayer - rat 1	0	0.3976555	-0.010268621	false
training	oneLayer	oneLayer - rat 1	0	0.40786782	-0.010268617	false
training	oneLayer	oneLayer - rat 1	0	0.41724655	-0.0063838144	false
training	oneLayer	oneLayer - rat 1	0	0.42477182	0.0011414376	false
training	oneLayer	oneLayer - rat 1	0	0.42883325	0.010946633	false
training	oneLayer	oneLayer - rat 1	0	0.42883325	0.021289524	false
training	oneLayer	oneLayer - rat 1	0	0.4249485	0.030668074	false
training	oneLayer	oneLayer - rat 1	0	0.4172414	0.038375176	false
training	oneLayer	oneLayer - rat 1	0	0.40798554	0.042209074	false
training	oneLayer	oneLayer - rat 1	0	0.39747697	0.04220907	false
training	oneLayer	oneLayer - rat 1	0	0.38735914	0.042209066	false
training	oneLayer	oneLayer - rat 1	0	0.37653393	0.042209063	false
training	oneLayer	oneLayer - rat 1	0	0.3655569	0.042209055	false
training	oneLayer	oneLayer - rat 1	0	0.35507992	0.04220905	false
training	oneLayer	oneLayer - rat 1	0	0.3449633	0.042209048	false
training	oneLayer	oneLayer - rat 1	0	0.33473307	0.042209044	false
training	oneLayer	oneLayer - rat 1	0	0.32409632	0.04220904	false
training	oneLayer	oneLayer - rat 1	0	0.3134384	0.042209033	false
training	oneLayer	oneLayer - rat 1	0	0.30279788	0.04220903	false
training	oneLayer	oneLayer - rat 1	0	0.29195988	0.042209025	false
training	oneLayer	oneLayer - rat 1	0	0.2809902	0.042209018	false
training	oneLayer	oneLayer - rat 1	0	0.27053654	0.042209014	false
training	oneLayer	oneLayer - rat 1	0	0.25967854	0.04220901	false
training	oneLayer	oneLayer - rat 1	0	0.24928205	0.042209007	false
training	oneLayer	oneLayer - rat 1	0	0.23858507	0.042209	false
training	oneLayer	oneLayer - rat 1	0	0.22830892	0.042208996	false
training	oneLayer	oneLayer - rat 1	0	0.21790724	0.042208992	false
training	oneLayer	oneLayer - rat 1	0	0.20720896	0.04220899	false
training	oneLayer	oneLayer - rat 1	0	0.19632359	0.042208984	false
training	oneLayer	oneLayer - rat 1	0	0.18551148	0.042208977	false
training	oneLayer	oneLayer - rat 1	0	0.17493868	0.042208973	false
training	oneLayer	oneLayer - rat 1	0	0.16457029	0.04220897	false
training	oneLayer	oneLayer - rat 1	0	0.15402584	0.042208966	false
training	oneLayer	oneLayer - rat 1	0	0.14355114	0.04220896	false
training	oneLayer	oneLayer - rat 1	0	0.13341928	0.042208955	false
training	oneLayer	oneLayer - rat 1	0	0.12327092	0.04220895	false
training	oneLayer	oneLayer - rat 1	0	0.11314507	0.042208947	false
training	oneLayer	oneLayer - rat 1	0	0.10244031	0.04220894	false
training	oneLayer	oneLayer - rat 1	0	0.09190158	0.042208936	false
training	oneLayer	oneLayer - rat 1	0	0.0817743	0.042208932	false
training	oneLayer	oneLayer - rat 1	0	0.07157133	0.04220893	false
training	oneLayer	oneLayer - rat 1	0	0.06115739	0.042208925	false
training	oneLayer	oneLayer - rat 1	0	0.050788015	0.042208917	false
training	oneLayer	oneLayer - rat 1	0	0.04054901	0.042208914	false
training	oneLayer	oneLayer - rat 1	0	0.030510576	0.04220891	false
training	oneLayer	oneLayer - rat 1	0	0.019936556	0.042208906	false
training	oneLayer	oneLayer - rat 1	0	0.009225566	0.042208903	false
training	oneLayer	oneLayer - rat 1	0	-0.0014384938	0.042208895	false
training	oneLayer	oneLayer - rat 1	0	-0.011444817	0.04220889	false
training	oneLayer	oneLayer - rat 1	0	-0.022168946	0.042208888	false
training	oneLayer	oneLayer - rat 1	0	-0.032604862	0.042208884	false
training	oneLayer	oneLayer - rat 1	0	-0.042915437	0.042208876	false
training	oneLayer	oneLayer - rat 1	0	-0.05365322	0.042208873	false
training	oneLayer	oneLayer - rat 1	0	-0.06397046	0.04220887	false
training	oneLayer	oneLayer - rat 1	0	-0.074740626	0.042208865	false
training	oneLayer	oneLayer - rat 1	0	-0.08550891	0.042208858	false
training	oneLayer	oneLayer - rat 1	0	-0.09632044	0.042208854	false
training	oneLayer	oneLayer - rat 1	0	-0.10645234	0.04220885	false
training	oneLayer	oneLayer - rat 1	0	-0.11645235	0.042208847	false
training	oneLayer	oneLayer - rat 1	0	-0.127385	0.042208843	false
training	oneLayer	oneLayer - rat 1	0	-0.13802014	0.042208835	false
training	oneLayer	oneLayer - rat 1	0	-0.14899388	0.04220883	false
training	oneLayer	oneLayer - rat 1	0	-0.15980375	0.042208828	false
training	oneLayer	oneLayer - rat 1	0	-0.16988698	0.042208824	false
training	oneLayer	oneLayer - rat 1	0	-0.17991772	0.042208817	false
training	oneLayer	oneLayer - rat 1	0	-0.19067864	0.042208813	false
training	oneLayer	oneLayer - rat 1	0	-0.20142417	0.04220881	false
training	oneLayer	oneLayer - rat 1	0	-0.21185462	0.042208806	false
training	oneLayer	oneLayer - rat 1	0	-0.22189094	0.0422088	false
training	oneLayer	oneLayer - rat 1	0	-0.2319647	0.042208795	false
training	oneLayer	oneLayer - rat 1	0	-0.24271137	0.04220879	false
training	oneLayer	oneLayer - rat 1	0	-0.25285557	0.042208787	false
training	oneLayer	oneLayer - rat 1	0	-0.26301852	0.042208783	false
training	oneLayer	oneLayer - rat 1	0	-0.2736779	0.042208776	false
training	oneLayer	oneLayer - rat 1	0	-0.2844043	0.042208772	false
training	oneLayer	oneLayer - rat 1	0	-0.2953071	0.04220877	false
training	oneLayer	oneLayer - rat 1	0	-0.3062623	0.042208765	false
training	oneLayer	oneLayer - rat 1	0	-0.31658995	0.042208757	false
training	oneLayer	oneLayer - rat 1	0	-0.3274922	0.042208754	false
training	oneLayer	oneLayer - rat 1	0	-0.33793354	0.04220875	false
training	oneLayer	oneLayer - rat 1	0	-0.3481404	0.042208746	false
training	oneLayer	oneLayer - rat 1	0	-0.35745716	0.038349606	false
training	oneLayer	oneLayer - rat 1	0	-0.36743367	0.034217197	false
training	oneLayer	oneLayer - rat 1	0	-0.37681177	0.030332662	false
training	oneLayer	oneLayer - rat 1	0	-0.3867189	0.026228985	false
training	oneLayer	oneLayer - rat 1	0	-0.39626545	0.02227467	false
training	oneLayer	oneLayer - rat 1	0	-0.4062268	0.018148538	false
training	oneLayer	oneLayer - rat 1	0	-0.4139732	0.010402114	false
training	oneLayer	oneLayer - rat 1	0	-0.4180473	5.664069E-4	false
training	oneLayer	oneLayer - rat 1	0	-0.41804728	-0.010426872	false
training	oneLayer	oneLayer - rat 1	0	-0.4141355	-0.019870812	false
training	oneLayer	oneLayer - rat 1	0	-0.40672818	-0.027278114	false
training	oneLayer	oneLayer - rat 1	0	-0.39714074	-0.031249346	false
training	oneLayer	oneLayer - rat 1	0	-0.38665324	-0.031249342	false
training	oneLayer	oneLayer - rat 1	0	-0.37609395	-0.031249337	false
training	oneLayer	oneLayer - rat 1	0	-0.36607012	-0.031249331	false
training	oneLayer	oneLayer - rat 1	0	-0.35595185	-0.031249326	false
training	oneLayer	oneLayer - rat 1	0	-0.34543213	-0.03124932	false
training	oneLayer	oneLayer - rat 1	0	-0.3348045	-0.031249315	false
training	oneLayer	oneLayer - rat 1	0	-0.32431453	-0.031249309	false
training	oneLayer	oneLayer - rat 1	0	-0.3140775	-0.031249303	false
training	oneLayer	oneLayer - rat 1	0	-0.3032505	-0.031249298	false
training	oneLayer	oneLayer - rat 1	0	-0.29283428	-0.031249292	false
training	oneLayer	oneLayer - rat 1	0	-0.28216264	-0.031249287	false
training	oneLayer	oneLayer - rat 1	0	-0.27148116	-0.031249281	false
training	oneLayer	oneLayer - rat 1	0	-0.26097766	-0.031249275	false
training	oneLayer	oneLayer - rat 1	0	-0.2503394	-0.03124927	false
training	oneLayer	oneLayer - rat 1	0	-0.23987643	-0.031249264	false
training	oneLayer	oneLayer - rat 1	0	-0.22948305	-0.031249259	false
training	oneLayer	oneLayer - rat 1	0	-0.21902096	-0.031249253	false
training	oneLayer	oneLayer - rat 1	0	-0.20867991	-0.031249247	false
training	oneLayer	oneLayer - rat 1	0	-0.19812702	-0.031249242	false
training	oneLayer	oneLayer - rat 1	0	-0.18735988	-0.031249236	false
training	oneLayer	oneLayer - rat 1	0	-0.17730148	-0.031249233	false
training	oneLayer	oneLayer - rat 1	0	-0.16682933	-0.031249227	false
training	oneLayer	oneLayer - rat 1	0	-0.15611288	-0.031249221	false
training	oneLayer	oneLayer - rat 1	0	-0.14547099	-0.031249216	false
training	oneLayer	oneLayer - rat 1	0	-0.1346351	-0.03124921	false
training	oneLayer	oneLayer - rat 1	0	-0.12369268	-0.031249203	false
training	oneLayer	oneLayer - rat 1	0	-0.11297041	-0.031249197	false
training	oneLayer	oneLayer - rat 1	0	-0.102748826	-0.031249193	false
training	oneLayer	oneLayer - rat 1	0	-0.09192218	-0.031249188	false
training	oneLayer	oneLayer - rat 1	0	-0.081054404	-0.03124918	false
training	oneLayer	oneLayer - rat 1	0	-0.070571564	-0.031249177	false
training	oneLayer	oneLayer - rat 1	0	-0.0603903	-0.031249171	false
training	oneLayer	oneLayer - rat 1	0	-0.050230257	-0.031249166	false
training	oneLayer	oneLayer - rat 1	0	-0.039699532	-0.03124916	false
training	oneLayer	oneLayer - rat 1	0	-0.028871473	-0.031249154	false
training	oneLayer	oneLayer - rat 1	0	-0.01853205	-0.031249149	false
training	oneLayer	oneLayer - rat 1	0	-0.0085039195	-0.031249143	false
training	oneLayer	oneLayer - rat 1	0	0.0015504584	-0.031249138	false
training	oneLayer	oneLayer - rat 1	0	0.011951885	-0.031249132	false
training	oneLayer	oneLayer - rat 1	0	0.022567099	-0.031249126	false
training	oneLayer	oneLayer - rat 1	0	0.03336536	-0.03124912	false
training	oneLayer	oneLayer - rat 1	0	0.04365504	-0.031249115	false
training	oneLayer	oneLayer - rat 1	0	0.054465532	-0.03124911	false
training	oneLayer	oneLayer - rat 1	0	0.065327264	-0.031249104	false
training	oneLayer	oneLayer - rat 1	0	0.07609207	-0.031249098	false
training	oneLayer	oneLayer - rat 1	0	0.08681188	-0.031249093	false
training	oneLayer	oneLayer - rat 1	0	0.09691434	-0.031249087	false
training	oneLayer	oneLayer - rat 1	0	0.107017934	-0.031249082	false
training	oneLayer	oneLayer - rat 1	0	0.11706014	-0.031249078	false
training	oneLayer	oneLayer - rat 1	0	0.12791218	-0.031249072	false
training	oneLayer	oneLayer - rat 1	0	0.13875896	-0.031249067	false
training	oneLayer	oneLayer - rat 1	0	0.14943072	-0.031249061	false
training	oneLayer	oneLayer - rat 1	0	0.15996076	-0.031249056	false
training	oneLayer	oneLayer - rat 1	0	0.1705668	-0.03124905	false
training	oneLayer	oneLayer - rat 1	0	0.18107738	-0.031249044	false
training	oneLayer	oneLayer - rat 1	0	0.19205208	-0.031249039	false
training	oneLayer	oneLayer - rat 1	0	0.20217958	-0.031249033	false
training	oneLayer	oneLayer - rat 1	0	0.21258107	-0.031249028	false
training	oneLayer	oneLayer - rat 1	0	0.22302845	-0.031249022	false
training	oneLayer	oneLayer - rat 1	0	0.23347887	-0.031249017	false
training	oneLayer	oneLayer - rat 1	0	0.24415825	-0.031249011	false
training	oneLayer	oneLayer - rat 1	0	0.25477898	-0.031249005	false
training	oneLayer	oneLayer - rat 1	0	0.2652866	-0.031249	false
training	oneLayer	oneLayer - rat 1	0	0.2757088	-0.031248994	false
training	oneLayer	oneLayer - rat 1	0	0.28573915	-0.031248989	false
training	oneLayer	oneLayer - rat 1	0	0.29585993	-0.031248983	false
training	oneLayer	oneLayer - rat 1	0	0.30618146	-0.031248977	false
training	oneLayer	oneLayer - rat 1	0	0.3171615	-0.031248972	false
training	oneLayer	oneLayer - rat 1	0	0.32739678	-0.031248966	false
training	oneLayer	oneLayer - rat 1	0	0.3381119	-0.03124896	false
training	oneLayer	oneLayer - rat 1	0	0.3487778	-0.031248955	false
training	oneLayer	oneLayer - rat 1	0	0.35977146	-0.03124895	false
training	oneLayer	oneLayer - rat 1	0	0.37073126	-0.031248944	false
training	oneLayer	oneLayer - rat 1	0	0.3813747	-0.031248938	false
training	oneLayer	oneLayer - rat 1	0	0.39095798	-0.027279403	false
training	oneLayer	oneLayer - rat 1	0	0.40101779	-0.023112485	false
training	oneLayer	oneLayer - rat 1	0	0.4103599	-0.019242847	false
training	oneLayer	oneLayer - rat 1	0	0.41762722	-0.011975527	false
training	oneLayer	oneLayer - rat 1	0	0.4217779	-0.0019548405	false
training	oneLayer	oneLayer - rat 1	0	0.4217779	0.008335539	false
training	oneLayer	oneLayer - rat 1	0	0.41778576	0.01797341	false
training	oneLayer	oneLayer - rat 1	0	0.41034237	0.025416786	false
training	oneLayer	oneLayer - rat 1	0	0.40030044	0.02957628	false
training	oneLayer	oneLayer - rat 1	0	0.3894849	0.029576272	false
training	oneLayer	oneLayer - rat 1	0	0.37875938	0.029576266	false
training	oneLayer	oneLayer - rat 1	0	0.36795822	0.029576259	false
training	oneLayer	oneLayer - rat 1	0	0.35755774	0.029576253	false
training	oneLayer	oneLayer - rat 1	0	0.3474525	0.029576246	false
training	oneLayer	oneLayer - rat 1	0	0.33686638	0.02957624	false
training	oneLayer	oneLayer - rat 1	0	0.32618544	0.029576233	false
training	oneLayer	oneLayer - rat 1	0	0.3160145	0.029576227	false
training	oneLayer	oneLayer - rat 1	0	0.3051103	0.029576221	false
training	oneLayer	oneLayer - rat 1	0	0.2943389	0.029576214	false
training	oneLayer	oneLayer - rat 1	0	0.2839469	0.029576208	false
training	oneLayer	oneLayer - rat 1	0	0.27324116	0.029576201	false
training	oneLayer	oneLayer - rat 1	0	0.26257712	0.029576195	false
training	oneLayer	oneLayer - rat 1	0	0.25222576	0.029576188	false
training	oneLayer	oneLayer - rat 1	0	0.24184127	0.029576182	false
training	oneLayer	oneLayer - rat 1	0	0.23123193	0.029576175	false
training	oneLayer	oneLayer - rat 1	0	0.22030938	0.02957617	false
training	oneLayer	oneLayer - rat 1	0	0.2094755	0.029576162	false
training	oneLayer	oneLayer - rat 1	0	0.19891931	0.029576156	false
training	oneLayer	oneLayer - rat 1	0	0.18868674	0.029576149	false
training	oneLayer	oneLayer - rat 1	0	0.17770037	0.029576143	false
training	oneLayer	oneLayer - rat 1	0	0.16747135	0.029576136	false
training	oneLayer	oneLayer - rat 1	0	0.15735957	0.02957613	false
training	oneLayer	oneLayer - rat 1	0	0.14656888	0.029576123	false
training	oneLayer	oneLayer - rat 1	0	0.13598517	0.029576117	false
training	oneLayer	oneLayer - rat 1	0	0.12559742	0.029576112	false
training	oneLayer	oneLayer - rat 1	0	0.11478192	0.029576104	false
training	oneLayer	oneLayer - rat 1	0	0.10413378	0.029576097	false
training	oneLayer	oneLayer - rat 1	0	0.094000794	0.029576091	false
training	oneLayer	oneLayer - rat 1	0	0.083601706	0.029576086	false
training	oneLayer	oneLayer - rat 1	0	0.07293762	0.029576078	false
training	oneLayer	oneLayer - rat 1	0	0.06198442	0.029576072	false
training	oneLayer	oneLayer - rat 1	0	0.051740695	0.029576065	false
training	oneLayer	oneLayer - rat 1	0	0.04105771	0.02957606	false
training	oneLayer	oneLayer - rat 1	0	0.030738018	0.029576052	false
training	oneLayer	oneLayer - rat 1	0	0.020704523	0.029576046	false
training	oneLayer	oneLayer - rat 1	0	0.010624548	0.02957604	false
training	oneLayer	oneLayer - rat 1	0	4.2673727E-4	0.029576033	false
training	oneLayer	oneLayer - rat 1	0	-0.0102232285	0.029576028	false
training	oneLayer	oneLayer - rat 1	0	-0.020607969	0.02957602	false
training	oneLayer	oneLayer - rat 1	0	-0.03131481	0.029576015	false
training	oneLayer	oneLayer - rat 1	0	-0.042240962	0.029576007	false
training	oneLayer	oneLayer - rat 1	0	-0.05270693	0.029576002	false
training	oneLayer	oneLayer - rat 1	0	-0.06293489	0.029575996	false
training	oneLayer	oneLayer - rat 1	0	-0.07299187	0.029575989	false
training	oneLayer	oneLayer - rat 1	0	-0.08369539	0.029575983	false
training	oneLayer	oneLayer - rat 1	0	-0.09434395	0.029575976	false
training	oneLayer	oneLayer - rat 1	0	-0.10444329	0.02957597	false
training	oneLayer	oneLayer - rat 1	0	-0.11484476	0.029575964	false
training	oneLayer	oneLayer - rat 1	0	-0.124988094	0.029575957	false
training	oneLayer	oneLayer - rat 1	0	-0.13515227	0.029575951	false
training	oneLayer	oneLayer - rat 1	0	-0.14566088	0.029575944	false
training	oneLayer	oneLayer - rat 1	0	-0.1561421	0.029575938	false
training	oneLayer	oneLayer - rat 1	0	-0.16668773	0.029575933	false
training	oneLayer	oneLayer - rat 1	0	-0.17689401	0.029575925	false
training	oneLayer	oneLayer - rat 1	0	-0.18734702	0.02957592	false
training	oneLayer	oneLayer - rat 1	0	-0.1974235	0.029575912	false
training	oneLayer	oneLayer - rat 1	0	-0.20832723	0.029575907	false
training	oneLayer	oneLayer - rat 1	0	-0.21861626	0.0295759	false
training	oneLayer	oneLayer - rat 1	0	-0.22919853	0.029575894	false
training	oneLayer	oneLayer - rat 1	0	-0.24002957	0.029575886	false
training	oneLayer	oneLayer - rat 1	0	-0.25087443	0.02957588	false
training	oneLayer	oneLayer - rat 1	0	-0.26168594	0.029575873	false
training	oneLayer	oneLayer - rat 1	0	-0.2723863	0.029575868	false
training	oneLayer	oneLayer - rat 1	0	-0.28255615	0.02957586	false
training	oneLayer	oneLayer - rat 1	0	-0.2931048	0.029575855	false
training	oneLayer	oneLayer - rat 1	0	-0.30354357	0.029575849	false
training	oneLayer	oneLayer - rat 1	0	-0.3143707	0.029575842	false
training	oneLayer	oneLayer - rat 1	0	-0.32460162	0.029575836	false
training	oneLayer	oneLayer - rat 1	0	-0.33499777	0.029575828	false
training	oneLayer	oneLayer - rat 1	0	-0.34509516	0.029575823	false
training	oneLayer	oneLayer - rat 1	0	-0.35568172	0.029575815	false
training	oneLayer	oneLayer - rat 1	0	-0.36625412	0.02957581	false
training	oneLayer	oneLayer - rat 1	0	-0.37676623	0.029575802	false
training	oneLayer	oneLayer - rat 1	0	-0.3876122	0.029575797	false
training	oneLayer	oneLayer - rat 1	0	-0.3974389	0.025505427	false
training	oneLayer	oneLayer - rat 1	0	-0.40711805	0.021496193	false
training	oneLayer	oneLayer - rat 1	0	-0.4148404	0.013773851	false
training	oneLayer	oneLayer - rat 1	0	-0.4187757	0.004273153	false
training	oneLayer	oneLayer - rat 1	0	-0.41877568	-0.0059655877	false
training	oneLayer	oneLayer - rat 1	0	-0.414811	-0.015537189	false
training	oneLayer	oneLayer - rat 1	0	-0.4074286	-0.02291959	false
training	oneLayer	oneLayer - rat 1	0	-0.39754638	-0.027012922	false
training	oneLayer	oneLayer - rat 1	0	-0.38737008	-0.027012914	false
training	oneLayer	oneLayer - rat 1	0	-0.37670356	-0.027012907	false
training	oneLayer	oneLayer - rat 1	0	-0.36647764	-0.027012901	false
training	oneLayer	oneLayer - rat 1	0	-0.35588798	-0.027012894	false
training	oneLayer	oneLayer - rat 1	0	-0.34543347	-0.027012886	false
training	oneLayer	oneLayer - rat 1	0	-0.33469903	-0.027012879	false
training	oneLayer	oneLayer - rat 1	0	-0.32404006	-0.027012872	false
training	oneLayer	oneLayer - rat 1	0	-0.31398854	-0.027012864	false
training	oneLayer	oneLayer - rat 1	0	-0.30369544	-0.027012857	false
training	oneLayer	oneLayer - rat 1	0	-0.2935656	-0.02701285	false
training	oneLayer	oneLayer - rat 1	0	-0.28305453	-0.027012842	false
training	oneLayer	oneLayer - rat 1	0	-0.27262956	-0.027012834	false
training	oneLayer	oneLayer - rat 1	0	-0.2623135	-0.027012827	false
training	oneLayer	oneLayer - rat 1	0	-0.251981	-0.027012821	false
training	oneLayer	oneLayer - rat 1	0	-0.2418648	-0.027012814	false
training	oneLayer	oneLayer - rat 1	0	-0.23112091	-0.027012806	false
training	oneLayer	oneLayer - rat 1	0	-0.22016801	-0.027012799	false
training	oneLayer	oneLayer - rat 1	0	-0.20950107	-0.027012791	false
training	oneLayer	oneLayer - rat 1	0	-0.19872268	-0.027012784	false
training	oneLayer	oneLayer - rat 1	0	-0.18800431	-0.027012777	false
training	oneLayer	oneLayer - rat 1	0	-0.17775136	-0.02701277	false
training	oneLayer	oneLayer - rat 1	0	-0.16679949	-0.027012762	false
training	oneLayer	oneLayer - rat 1	0	-0.15655626	-0.027012754	false
training	oneLayer	oneLayer - rat 1	0	-0.1464702	-0.027012747	false
training	oneLayer	oneLayer - rat 1	0	-0.13630292	-0.02701274	false
training	oneLayer	oneLayer - rat 1	0	-0.1253654	-0.027012732	false
training	oneLayer	oneLayer - rat 1	0	-0.11533778	-0.027012724	false
training	oneLayer	oneLayer - rat 1	0	-0.10519944	-0.027012717	false
training	oneLayer	oneLayer - rat 1	0	-0.0947676	-0.027012711	false
training	oneLayer	oneLayer - rat 1	0	-0.084098645	-0.027012704	false
training	oneLayer	oneLayer - rat 1	0	-0.073427886	-0.027012696	false
training	oneLayer	oneLayer - rat 1	0	-0.06322211	-0.027012689	false
training	oneLayer	oneLayer - rat 1	0	-0.05319663	-0.027012682	false
training	oneLayer	oneLayer - rat 1	0	-0.043182384	-0.027012674	false
training	oneLayer	oneLayer - rat 1	0	-0.03267202	-0.027012667	false
training	oneLayer	oneLayer - rat 1	0	-0.022465743	-0.02701266	false
training	oneLayer	oneLayer - rat 1	0	-0.012111579	-0.027012652	false
training	oneLayer	oneLayer - rat 1	0	-0.0020519984	-0.027012646	false
training	oneLayer	oneLayer - rat 1	0	0.008654755	-0.027012639	false
training	oneLayer	oneLayer - rat 1	0	0.019235658	-0.027012631	false
training	oneLayer	oneLayer - rat 1	0	0.030049467	-0.027012624	false
training	oneLayer	oneLayer - rat 1	0	0.040069442	-0.027012616	false
training	oneLayer	oneLayer - rat 1	0	0.050803743	-0.027012609	false
training	oneLayer	oneLayer - rat 1	0	0.06121253	-0.027012601	false
training	oneLayer	oneLayer - rat 1	0	0.071712434	-0.027012594	false
training	oneLayer	oneLayer - rat 1	0	0.08214573	-0.027012587	false
training	oneLayer	oneLayer - rat 1	0	0.092781894	-0.02701258	false
training	oneLayer	oneLayer - rat 1	0	0.10304309	-0.027012572	false
training	oneLayer	oneLayer - rat 1	0	0.113499835	-0.027012564	false
training	oneLayer	oneLayer - rat 1	0	0.12367657	-0.027012557	false
training	oneLayer	oneLayer - rat 1	0	0.13451059	-0.02701255	false
training	oneLayer	oneLayer - rat 1	0	0.14468957	-0.027012544	false
training	oneLayer	oneLayer - rat 1	0	0.15521781	-0.027012536	false
training	oneLayer	oneLayer - rat 1	0	0.16603972	-0.027012529	false
training	oneLayer	oneLayer - rat 1	0	0.17624073	-0.027012521	false
training	oneLayer	oneLayer - rat 1	0	0.18648517	-0.027012514	false
training	oneLayer	oneLayer - rat 1	0	0.19723158	-0.027012506	false
training	oneLayer	oneLayer - rat 1	0	0.20760143	-0.027012499	false
training	oneLayer	oneLayer - rat 1	0	0.21812311	-0.027012492	false
training	oneLayer	oneLayer - rat 1	0	0.22912097	-0.027012484	false
training	oneLayer	oneLayer - rat 1	0	0.23978673	-0.027012477	false
training	oneLayer	oneLayer - rat 1	0	0.2504518	-0.02701247	false
training	oneLayer	oneLayer - rat 1	0	0.2605173	-0.027012462	false
training	oneLayer	oneLayer - rat 1	0	0.27134258	-0.027012454	false
training	oneLayer	oneLayer - rat 1	0	0.2817764	-0.027012447	false
training	oneLayer	oneLayer - rat 1	0	0.29223046	-0.02701244	false
training	oneLayer	oneLayer - rat 1	0	0.30303863	-0.027012432	false
training	oneLayer	oneLayer - rat 1	0	0.31346348	-0.027012425	false
training	oneLayer	oneLayer - rat 1	0	0.32375017	-0.027012417	false
training	oneLayer	oneLayer - rat 1	0	0.333902	-0.027012412	false
training	oneLayer	oneLayer - rat 1	0	0.3439508	-0.027012404	false
training	oneLayer	oneLayer - rat 1	0	0.35433933	-0.027012397	false
training	oneLayer	oneLayer - rat 1	0	0.3646152	-0.02701239	false
training	oneLayer	oneLayer - rat 1	0	0.37499762	-0.027012382	false
training	oneLayer	oneLayer - rat 1	0	0.38526136	-0.027012374	false
training	oneLayer	oneLayer - rat 1	0	0.3951917	-0.022899084	false
training	oneLayer	oneLayer - rat 1	0	0.40470612	-0.018958064	false
training	oneLayer	oneLayer - rat 1	0	0.41191164	-0.011752559	false
training	oneLayer	oneLayer - rat 1	0	0.41601455	-0.0018471935	false
training	oneLayer	oneLayer - rat 1	0	0.41601455	0.008170429	false
training	oneLayer	oneLayer - rat 1	0	0.41187993	0.01815229	false
training	oneLayer	oneLayer - rat 1	0	0.40468815	0.025344037	false
training	oneLayer	oneLayer - rat 1	0	0.39487448	0.02940899	false
training	oneLayer	oneLayer - rat 1	0	0.38498163	0.03350672	false
training	oneLayer	oneLayer - rat 1	0	0.37511554	0.037593395	false
training	oneLayer	oneLayer - rat 1	0	0.36546543	0.04159059	false
training	oneLayer	oneLayer - rat 1	0	0.35550097	0.04571799	false
training	oneLayer	oneLayer - rat 1	0	0.3462551	0.049547747	false
training	oneLayer	oneLayer - rat 1	0	0.3363933	0.05363263	false
training	oneLayer	oneLayer - rat 1	0	0.3271211	0.05747329	false
training	oneLayer	oneLayer - rat 1	0	0.31768888	0.06138023	false
training	oneLayer	oneLayer - rat 1	0	0.30754235	0.06558306	false
training	oneLayer	oneLayer - rat 1	0	0.29749367	0.069745354	false
training	oneLayer	oneLayer - rat 1	0	0.287681	0.07380988	false
training	oneLayer	oneLayer - rat 1	0	0.27780625	0.077900134	false
training	oneLayer	oneLayer - rat 1	0	0.26845372	0.08177406	false
training	oneLayer	oneLayer - rat 1	0	0.25883833	0.08575688	false
training	oneLayer	oneLayer - rat 1	0	0.24937128	0.08967826	false
training	oneLayer	oneLayer - rat 1	0	0.24011362	0.09351289	false
training	oneLayer	oneLayer - rat 1	0	0.23056625	0.097467534	false
training	oneLayer	oneLayer - rat 1	0	0.2207016	0.1015536	false
training	oneLayer	oneLayer - rat 1	0	0.21098387	0.1055788	false
training	oneLayer	oneLayer - rat 1	0	0.2009934	0.10971698	false
training	oneLayer	oneLayer - rat 1	0	0.19158147	0.11361552	false
training	oneLayer	oneLayer - rat 1	0	0.18148704	0.117796764	false
training	oneLayer	oneLayer - rat 1	0	0.171366	0.12198902	false
training	oneLayer	oneLayer - rat 1	0	0.16174692	0.12597337	false
training	oneLayer	oneLayer - rat 1	0	0.15229844	0.12988706	false
training	oneLayer	oneLayer - rat 1	0	0.14251748	0.13393845	false
training	oneLayer	oneLayer - rat 1	0	0.13247366	0.13809872	false
training	oneLayer	oneLayer - rat 1	0	0.12261268	0.14218327	false
training	oneLayer	oneLayer - rat 1	0	0.11281386	0.14624207	false
training	oneLayer	oneLayer - rat 1	0	0.10308214	0.15027307	false
training	oneLayer	oneLayer - rat 1	0	0.09357417	0.15421139	false
training	oneLayer	oneLayer - rat 1	0	0.083785124	0.15826613	false
training	oneLayer	oneLayer - rat 1	0	0.07369306	0.1624464	false
training	oneLayer	oneLayer - rat 1	0	0.063550204	0.16664769	false
training	oneLayer	oneLayer - rat 1	0	0.05384385	0.17066818	false
training	oneLayer	oneLayer - rat 1	0	0.043896336	0.17478858	false
training	oneLayer	oneLayer - rat 1	0	0.034478158	0.1786897	false
training	oneLayer	oneLayer - rat 1	0	0.024557704	0.18279888	false
training	oneLayer	oneLayer - rat 1	0	0.014868756	0.18681216	false
training	oneLayer	oneLayer - rat 1	0	0.0050749877	0.19086887	false
training	oneLayer	oneLayer - rat 1	0	-0.0049357796	0.19501546	false
training	oneLayer	oneLayer - rat 1	0	-0.014829918	0.19911373	false
training	oneLayer	oneLayer - rat 1	0	-0.024797693	0.20324251	false
training	oneLayer	oneLayer - rat 1	0	-0.034768783	0.20737267	false
training	oneLayer	oneLayer - rat 1	0	-0.04428364	0.21131383	false
training	oneLayer	oneLayer - rat 1	0	-0.053791936	0.2152523	false
training	oneLayer	oneLayer - rat 1	0	-0.063915074	0.21944542	false
training	oneLayer	oneLayer - rat 1	0	-0.07364098	0.22347401	false
training	oneLayer	oneLayer - rat 1	0	-0.08289831	0.22730853	false
training	oneLayer	oneLayer - rat 1	0	-0.092353225	0.23122486	false
training	oneLayer	oneLayer - rat 1	0	-0.10170329	0.23509778	false
training	oneLayer	oneLayer - rat 1	0	-0.11095995	0.238932	false
training	oneLayer	oneLayer - rat 1	0	-0.12063446	0.24293931	false
training	oneLayer	oneLayer - rat 1	0	-0.1300258	0.24682932	false
training	oneLayer	oneLayer - rat 1	0	-0.13976589	0.2508638	false
training	oneLayer	oneLayer - rat 1	0	-0.14949927	0.25489548	false
training	oneLayer	oneLayer - rat 1	0	-0.15907495	0.25886184	false
training	oneLayer	oneLayer - rat 1	0	-0.16879645	0.2628886	false
training	oneLayer	oneLayer - rat 1	0	-0.17864506	0.26696804	false
training	oneLayer	oneLayer - rat 1	0	-0.1880183	0.27085057	false
training	oneLayer	oneLayer - rat 1	0	-0.19744268	0.27475426	false
training	oneLayer	oneLayer - rat 1	0	-0.20717144	0.27878404	false
training	oneLayer	oneLayer - rat 1	0	-0.21676889	0.2827594	false
training	oneLayer	oneLayer - rat 1	0	-0.22654891	0.28681043	false
training	oneLayer	oneLayer - rat 1	0	-0.2364371	0.29090622	false
training	oneLayer	oneLayer - rat 1	0	-0.24634217	0.29500905	false
training	oneLayer	oneLayer - rat 1	0	-0.25588462	0.29896164	false
training	oneLayer	oneLayer - rat 1	0	-0.26591063	0.30311453	false
training	oneLayer	oneLayer - rat 1	0	-0.27536353	0.30703005	false
training	oneLayer	oneLayer - rat 1	0	-0.28611022	0.30703005	false
training	oneLayer	oneLayer - rat 1	0	-0.29622284	0.30284125	false
training	oneLayer	oneLayer - rat 1	0	-0.30388534	0.29517874	false
training	oneLayer	oneLayer - rat 1	0	-0.30778965	0.28575283	false
training	oneLayer	oneLayer - rat 1	0	-0.30778965	0.27542403	false
training	oneLayer	oneLayer - rat 1	0	-0.30372417	0.26560906	false
training	oneLayer	oneLayer - rat 1	0	-0.29625595	0.25814086	false
training	oneLayer	oneLayer - rat 1	0	-0.28647768	0.25409058	false
training	oneLayer	oneLayer - rat 1	0	-0.27721813	0.25025517	false
training	oneLayer	oneLayer - rat 1	0	-0.26751906	0.2462377	false
training	oneLayer	oneLayer - rat 1	0	-0.25782344	0.24222164	false
training	oneLayer	oneLayer - rat 1	0	-0.24838687	0.2383129	false
training	oneLayer	oneLayer - rat 1	0	-0.23859513	0.23425704	false
training	oneLayer	oneLayer - rat 1	0	-0.22886811	0.23022798	false
training	oneLayer	oneLayer - rat 1	0	-0.21901093	0.22614501	false
training	oneLayer	oneLayer - rat 1	0	-0.20907357	0.22202884	false
training	oneLayer	oneLayer - rat 1	0	-0.19913481	0.21791208	false
training	oneLayer	oneLayer - rat 1	0	-0.18946195	0.21390545	false
training	oneLayer	oneLayer - rat 1	0	-0.17965654	0.20984393	false
training	oneLayer	oneLayer - rat 1	0	-0.17002462	0.20585427	false
training	oneLayer	oneLayer - rat 1	0	-0.16044973	0.20188823	false
training	oneLayer	oneLayer - rat 1	0	-0.15085545	0.19791415	false
training	oneLayer	oneLayer - rat 1	0	-0.14081448	0.19375508	false
training	oneLayer	oneLayer - rat 1	0	-0.13079825	0.18960622	false
training	oneLayer	oneLayer - rat 1	0	-0.1214039	0.18571496	false
training	oneLayer	oneLayer - rat 1	0	-0.11208178	0.18185362	false
training	oneLayer	oneLayer - rat 1	0	-0.102496624	0.17788333	false
training	oneLayer	oneLayer - rat 1	0	-0.0924893	0.17373817	false
training	oneLayer	oneLayer - rat 1	0	-0.08304448	0.169826	false
training	oneLayer	oneLayer - rat 1	0	-0.073735245	0.16597	false
training	oneLayer	oneLayer - rat 1	0	-0.063956305	0.16191944	false
training	oneLayer	oneLayer - rat 1	0	-0.054466113	0.15798849	false
training	oneLayer	oneLayer - rat 1	0	-0.04452716	0.15387164	false
training	oneLayer	oneLayer - rat 1	0	-0.034437172	0.14969225	false
training	oneLayer	oneLayer - rat 1	0	-0.024342114	0.14551075	false
training	oneLayer	oneLayer - rat 1	0	-0.014537452	0.14144954	false
training	oneLayer	oneLayer - rat 1	0	-0.0049045994	0.13745949	false
training	oneLayer	oneLayer - rat 1	0	0.0049473597	0.13337868	false
training	oneLayer	oneLayer - rat 1	0	0.014920752	0.12924758	false
training	oneLayer	oneLayer - rat 1	0	0.024905931	0.1251116	false
training	oneLayer	oneLayer - rat 1	0	0.034604426	0.12109435	false
training	oneLayer	oneLayer - rat 1	0	0.044300016	0.11707832	false
training	oneLayer	oneLayer - rat 1	0	0.054414757	0.112888664	false
training	oneLayer	oneLayer - rat 1	0	0.06411073	0.108872466	false
training	oneLayer	oneLayer - rat 1	0	0.07339044	0.1050287	false
training	oneLayer	oneLayer - rat 1	0	0.08290195	0.10108891	false
training	oneLayer	oneLayer - rat 1	0	0.09268485	0.09703671	false
training	oneLayer	oneLayer - rat 1	0	0.102568485	0.09294278	false
training	oneLayer	oneLayer - rat 1	0	0.11191245	0.0890724	false
training	oneLayer	oneLayer - rat 1	0	0.12203351	0.08488013	false
training	oneLayer	oneLayer - rat 1	0	0.1316158	0.080911025	false
training	oneLayer	oneLayer - rat 1	0	0.14116798	0.07695439	false
training	oneLayer	oneLayer - rat 1	0	0.15059863	0.0730481	false
training	oneLayer	oneLayer - rat 1	0	0.1607085	0.06886046	false
training	oneLayer	oneLayer - rat 1	0	0.17076403	0.064695336	false
training	oneLayer	oneLayer - rat 1	0	0.18063033	0.06060859	false
training	oneLayer	oneLayer - rat 1	0	0.18988821	0.056773856	false
training	oneLayer	oneLayer - rat 1	0	0.19972019	0.05270133	false
training	oneLayer	oneLayer - rat 1	0	0.2093747	0.048702314	false
training	oneLayer	oneLayer - rat 1	0	0.21875879	0.0448153	false
training	oneLayer	oneLayer - rat 1	0	0.2280838	0.040952764	false
training	oneLayer	oneLayer - rat 1	0	0.23811598	0.03679731	false
training	oneLayer	oneLayer - rat 1	0	0.24822192	0.032611307	false
training	oneLayer	oneLayer - rat 1	0	0.25760955	0.02872283	false
training	oneLayer	oneLayer - rat 1	0	0.26707542	0.024801943	false
training	oneLayer	oneLayer - rat 1	0	0.27655417	0.020875728	false
training	oneLayer	oneLayer - rat 1	0	0.28594983	0.016983932	false
training	oneLayer	oneLayer - rat 1	0	0.29602206	0.012811886	false
training	oneLayer	oneLayer - rat 1	0	0.30599198	0.008682219	false
training	oneLayer	oneLayer - rat 1	0	0.3156855	0.0046670362	false
training	oneLayer	oneLayer - rat 1	0	0.32535058	6.636448E-4	false
training	oneLayer	oneLayer - rat 1	0	0.33530566	-0.003459875	false
training	oneLayer	oneLayer - rat 1	0	0.34590498	-0.0034598657	false
training	oneLayer	oneLayer - rat 1	0	0.35690254	-0.0034598561	false
training	oneLayer	oneLayer - rat 1	0	0.36728138	-0.003459847	false
training	oneLayer	oneLayer - rat 1	0	0.3776254	-0.003459838	false
training	oneLayer	oneLayer - rat 1	0	0.3880686	-0.003459829	false
training	oneLayer	oneLayer - rat 1	0	0.39882597	-0.0034598194	false
training	oneLayer	oneLayer - rat 1	0	0.40903538	-0.0034598105	false
training	oneLayer	oneLayer - rat 1	0	0.41833118	3.906443E-4	false
training	oneLayer	oneLayer - rat 1	0	0.4256004	0.0076599033	false
training	oneLayer	oneLayer - rat 1	0	0.42953795	0.017165976	false
training	oneLayer	oneLayer - rat 1	0	0.42953795	0.027507441	false
training	oneLayer	oneLayer - rat 1	0	0.42564088	0.036915753	false
training	oneLayer	oneLayer - rat 1	0	0.41825068	0.04430593	false
training	oneLayer	oneLayer - rat 1	0	0.40870723	0.048258953	false
training	oneLayer	oneLayer - rat 1	0	0.39927673	0.05216518	false
training	oneLayer	oneLayer - rat 1	0	0.3894421	0.05623881	false
training	oneLayer	oneLayer - rat 1	0	0.37942854	0.060386553	false
training	oneLayer	oneLayer - rat 1	0	0.37000582	0.06428956	false
training	oneLayer	oneLayer - rat 1	0	0.3603087	0.06830622	false
training	oneLayer	oneLayer - rat 1	0	0.3509272	0.072192155	false
training	oneLayer	oneLayer - rat 1	0	0.34141907	0.07613055	false
training	oneLayer	oneLayer - rat 1	0	0.33159176	0.08020114	false
training	oneLayer	oneLayer - rat 1	0	0.32176447	0.08427172	false
training	oneLayer	oneLayer - rat 1	0	0.31181914	0.08839121	false
training	oneLayer	oneLayer - rat 1	0	0.30231375	0.09232845	false
training	oneLayer	oneLayer - rat 1	0	0.2925428	0.09637571	false
training	oneLayer	oneLayer - rat 1	0	0.28309885	0.10028751	false
training	oneLayer	oneLayer - rat 1	0	0.27361172	0.10421719	false
training	oneLayer	oneLayer - rat 1	0	0.26424906	0.10809532	false
training	oneLayer	oneLayer - rat 1	0	0.25479123	0.11201287	false
training	oneLayer	oneLayer - rat 1	0	0.24507178	0.11603879	false
training	oneLayer	oneLayer - rat 1	0	0.2354605	0.1200199	false
training	oneLayer	oneLayer - rat 1	0	0.22567035	0.12407511	false
training	oneLayer	oneLayer - rat 1	0	0.21586855	0.12813513	false
training	oneLayer	oneLayer - rat 1	0	0.20652476	0.13200545	false
training	oneLayer	oneLayer - rat 1	0	0.19707777	0.13591851	false
training	oneLayer	oneLayer - rat 1	0	0.18692091	0.1401256	false
training	oneLayer	oneLayer - rat 1	0	0.17692046	0.14426792	false
training	oneLayer	oneLayer - rat 1	0	0.16721135	0.14828955	false
training	oneLayer	oneLayer - rat 1	0	0.15714985	0.15245715	false
training	oneLayer	oneLayer - rat 1	0	0.14723724	0.15656307	false
training	oneLayer	oneLayer - rat 1	0	0.13785465	0.16044946	false
training	oneLayer	oneLayer - rat 1	0	0.12820734	0.16444549	false
training	oneLayer	oneLayer - rat 1	0	0.118458234	0.1684837	false
training	oneLayer	oneLayer - rat 1	0	0.10867843	0.17253461	false
training	oneLayer	oneLayer - rat 1	0	0.09863558	0.17669448	false
training	oneLayer	oneLayer - rat 1	0	0.08889539	0.180729	false
training	oneLayer	oneLayer - rat 1	0	0.07951088	0.18461618	false
training	oneLayer	oneLayer - rat 1	0	0.07023186	0.18845966	false
training	oneLayer	oneLayer - rat 1	0	0.060401484	0.19253153	false
training	oneLayer	oneLayer - rat 1	0	0.050370213	0.19668661	false
training	oneLayer	oneLayer - rat 1	0	0.040641602	0.20071632	false
training	oneLayer	oneLayer - rat 1	0	0.031242449	0.20460956	false
training	oneLayer	oneLayer - rat 1	0	0.021416152	0.20867974	false
training	oneLayer	oneLayer - rat 1	0	0.011361866	0.21284434	false
training	oneLayer	oneLayer - rat 1	0	0.0018151139	0.21679874	false
training	oneLayer	oneLayer - rat 1	0	-0.007854702	0.2208041	false
training	oneLayer	oneLayer - rat 1	0	-0.017430173	0.22477037	false
training	oneLayer	oneLayer - rat 1	0	-0.027085366	0.22876967	false
training	oneLayer	oneLayer - rat 1	0	-0.037150316	0.23293869	false
training	oneLayer	oneLayer - rat 1	0	-0.046686437	0.23688868	false
training	oneLayer	oneLayer - rat 1	0	-0.056164395	0.24081457	false
training	oneLayer	oneLayer - rat 1	0	-0.065876834	0.24483758	false
training	oneLayer	oneLayer - rat 1	0	-0.07571085	0.24891095	false
training	oneLayer	oneLayer - rat 1	0	-0.08575286	0.25307047	false
training	oneLayer	oneLayer - rat 1	0	-0.095439166	0.25708267	false
training	oneLayer	oneLayer - rat 1	0	-0.10479713	0.26095885	false
training	oneLayer	oneLayer - rat 1	0	-0.11444009	0.26495308	false
training	oneLayer	oneLayer - rat 1	0	-0.12393969	0.26888794	false
training	oneLayer	oneLayer - rat 1	0	-0.13407592	0.2730865	false
training	oneLayer	oneLayer - rat 1	0	-0.14367954	0.27706444	false
training	oneLayer	oneLayer - rat 1	0	-0.15299957	0.2809249	false
training	oneLayer	oneLayer - rat 1	0	-0.1629695	0.28505456	false
training	oneLayer	oneLayer - rat 1	0	-0.17226823	0.28890622	false
training	oneLayer	oneLayer - rat 1	0	-0.1815979	0.29277068	false
training	oneLayer	oneLayer - rat 1	0	-0.19104566	0.29668406	false
training	oneLayer	oneLayer - rat 1	0	-0.20046024	0.3005837	false
training	oneLayer	oneLayer - rat 1	0	-0.21062063	0.30479226	false
training	oneLayer	oneLayer - rat 1	0	-0.21994314	0.30865377	false
training	oneLayer	oneLayer - rat 1	0	-0.22989352	0.31277534	false
training	oneLayer	oneLayer - rat 1	0	-0.239133	0.31660244	false
training	oneLayer	oneLayer - rat 1	0	-0.24915077	0.32075194	false
training	oneLayer	oneLayer - rat 1	0	-0.25946108	0.3207519	false
training	oneLayer	oneLayer - rat 1	0	-0.2701923	0.3207519	false
training	oneLayer	oneLayer - rat 1	0	-0.27996698	0.31670308	false
training	oneLayer	oneLayer - rat 1	0	-0.28736186	0.3093082	false
training	oneLayer	oneLayer - rat 1	0	-0.29469988	0.30197015	false
training	oneLayer	oneLayer - rat 1	0	-0.30219933	0.29447067	false
training	oneLayer	oneLayer - rat 1	0	-0.30945927	0.28721073	false
training	oneLayer	oneLayer - rat 1	0	-0.31690955	0.27976042	false
training	oneLayer	oneLayer - rat 1	0	-0.32453245	0.27213752	false
training	oneLayer	oneLayer - rat 1	0	-0.33173203	0.26493794	false
training	oneLayer	oneLayer - rat 1	0	-0.3392288	0.25744113	false
training	oneLayer	oneLayer - rat 1	0	-0.346811	0.24985893	false
training	oneLayer	oneLayer - rat 1	0	-0.35071793	0.24042675	false
training	oneLayer	oneLayer - rat 1	0	-0.3549168	0.23028973	false
training	oneLayer	oneLayer - rat 1	0	-0.35877973	0.22096382	false
training	oneLayer	oneLayer - rat 1	0	-0.36265326	0.21161225	false
training	oneLayer	oneLayer - rat 1	0	-0.36652625	0.202262	false
training	oneLayer	oneLayer - rat 1	0	-0.37042415	0.19285157	false
training	oneLayer	oneLayer - rat 1	0	-0.37444487	0.18314466	false
training	oneLayer	oneLayer - rat 1	0	-0.37834513	0.17372857	false
training	oneLayer	oneLayer - rat 1	0	-0.3823236	0.16412376	false
training	oneLayer	oneLayer - rat 1	0	-0.38641986	0.15423444	false
training	oneLayer	oneLayer - rat 1	0	-0.3904746	0.14444543	false
training	oneLayer	oneLayer - rat 1	0	-0.39445025	0.13484728	false
training	oneLayer	oneLayer - rat 1	0	-0.39853424	0.12498763	false
training	oneLayer	oneLayer - rat 1	0	-0.40260348	0.11516363	false
training	oneLayer	oneLayer - rat 1	0	-0.406444	0.105891705	false
training	oneLayer	oneLayer - rat 1	0	-0.4104607	0.09619453	false
training	oneLayer	oneLayer - rat 1	0	-0.41453603	0.086355835	false
training	oneLayer	oneLayer - rat 1	0	-0.41847584	0.076844245	false
training	oneLayer	oneLayer - rat 1	0	-0.42239618	0.06737965	false
training	oneLayer	oneLayer - rat 1	0	-0.42626816	0.058031883	false
training	oneLayer	oneLayer - rat 1	0	-0.430447	0.047943205	false
training	oneLayer	oneLayer - rat 1	0	-0.43434218	0.038539376	false
training	oneLayer	oneLayer - rat 1	0	-0.4383652	0.028826987	false
training	oneLayer	oneLayer - rat 1	0	-0.4424219	0.019033134	false
training	oneLayer	oneLayer - rat 1	0	-0.44646788	0.0092653185	false
training	oneLayer	oneLayer - rat 1	0	-0.45036715	-1.4839538E-4	false
training	oneLayer	oneLayer - rat 1	0	-0.45420736	-0.009419503	false
training	oneLayer	oneLayer - rat 1	0	-0.45420733	-0.019940494	false
training	oneLayer	oneLayer - rat 1	0	-0.45031375	-0.029340422	false
training	oneLayer	oneLayer - rat 1	0	-0.4428798	-0.036774363	false
training	oneLayer	oneLayer - rat 1	0	-0.4336158	-0.040611617	false
training	oneLayer	oneLayer - rat 1	0	-0.42330006	-0.040611606	false
training	oneLayer	oneLayer - rat 1	0	-0.413969	-0.03674654	false
training	oneLayer	oneLayer - rat 1	0	-0.4067684	-0.029545937	false
training	oneLayer	oneLayer - rat 1	0	-0.40265328	-0.019611103	false
training	oneLayer	oneLayer - rat 1	0	-0.39857942	-0.009775898	false
training	oneLayer	oneLayer - rat 1	0	-0.39457774	-1.15003735E-4	false
training	oneLayer	oneLayer - rat 1	0	-0.39063695	0.009398968	false
training	oneLayer	oneLayer - rat 1	0	-0.3864449	0.019519478	false
training	oneLayer	oneLayer - rat 1	0	-0.38225713	0.029629668	false
training	oneLayer	oneLayer - rat 1	0	-0.37812403	0.039607905	false
training	oneLayer	oneLayer - rat 1	0	-0.37394482	0.049697448	false
training	oneLayer	oneLayer - rat 1	0	-0.37008792	0.059008844	false
training	oneLayer	oneLayer - rat 1	0	-0.36620098	0.068392776	false
training	oneLayer	oneLayer - rat 1	0	-0.36209056	0.07831628	false
training	oneLayer	oneLayer - rat 1	0	-0.35802025	0.08814287	false
training	oneLayer	oneLayer - rat 1	0	-0.35393894	0.09799611	false
training	oneLayer	oneLayer - rat 1	0	-0.3498491	0.10786981	false
training	oneLayer	oneLayer - rat 1	0	-0.34578225	0.117688105	false
training	oneLayer	oneLayer - rat 1	0	-0.341586	0.1278188	false
training	oneLayer	oneLayer - rat 1	0	-0.3376588	0.13729997	false
training	oneLayer	oneLayer - rat 1	0	-0.33350807	0.1473207	false
training	oneLayer	oneLayer - rat 1	0	-0.32934618	0.15736844	false
training	oneLayer	oneLayer - rat 1	0	-0.32529768	0.16714239	false
training	oneLayer	oneLayer - rat 1	0	-0.32126722	0.1768728	false
training	oneLayer	oneLayer - rat 1	0	-0.317337	0.1863612	false
training	oneLayer	oneLayer - rat 1	0	-0.31733704	0.19679105	false
training	oneLayer	oneLayer - rat 1	0	-0.31733704	0.20729731	false
training	oneLayer	oneLayer - rat 1	0	-0.31733707	0.21752362	false
training	oneLayer	oneLayer - rat 1	0	-0.31733707	0.22806655	false
training	oneLayer	oneLayer - rat 1	0	-0.31733707	0.23806675	false
training	oneLayer	oneLayer - rat 1	0	-0.3173371	0.248133	false
training	oneLayer	oneLayer - rat 1	0	-0.3173371	0.2587335	false
training	oneLayer	oneLayer - rat 1	0	-0.3173371	0.2692855	false
training	oneLayer	oneLayer - rat 1	0	-0.31733713	0.28026542	false
training	oneLayer	oneLayer - rat 1	0	-0.31733713	0.29040578	false
training	oneLayer	oneLayer - rat 1	0	-0.31317583	0.30045208	false
training	oneLayer	oneLayer - rat 1	0	-0.3092058	0.3100366	false
training	oneLayer	oneLayer - rat 1	0	-0.3050978	0.31995428	false
training	oneLayer	oneLayer - rat 1	0	-0.30117935	0.32941428	false
training	oneLayer	oneLayer - rat 1	0	-0.2970441	0.33939764	false
training	oneLayer	oneLayer - rat 1	0	-0.2894967	0.34694508	false
training	oneLayer	oneLayer - rat 1	0	-0.27940002	0.35112727	false
training	oneLayer	oneLayer - rat 1	0	-0.26911888	0.35112727	false
training	oneLayer	oneLayer - rat 1	0	-0.2593704	0.34708932	false
training	oneLayer	oneLayer - rat 1	0	-0.25198922	0.33970818	false
training	oneLayer	oneLayer - rat 1	0	-0.24788608	0.32980236	false
training	oneLayer	oneLayer - rat 1	0	-0.24788608	0.31898052	false
training	oneLayer	oneLayer - rat 1	0	-0.2519358	0.30920357	false
training	oneLayer	oneLayer - rat 1	0	-0.25613576	0.29906395	false
training	oneLayer	oneLayer - rat 1	0	-0.26000878	0.28971362	false
training	oneLayer	oneLayer - rat 1	0	-0.2638465	0.28044856	false
training	oneLayer	oneLayer - rat 1	0	-0.26800022	0.27042058	false
training	oneLayer	oneLayer - rat 1	0	-0.27196467	0.2608495	false
training	oneLayer	oneLayer - rat 1	0	-0.27612445	0.2508069	false
training	oneLayer	oneLayer - rat 1	0	-0.28026828	0.24080276	false
training	oneLayer	oneLayer - rat 1	0	-0.28411412	0.231518	false
training	oneLayer	oneLayer - rat 1	0	-0.28801948	0.22208962	false
training	oneLayer	oneLayer - rat 1	0	-0.29222396	0.21193907	false
training	oneLayer	oneLayer - rat 1	0	-0.29639024	0.20188083	false
training	oneLayer	oneLayer - rat 1	0	-0.3002781	0.1924946	false
training	oneLayer	oneLayer - rat 1	0	-0.30420214	0.18302113	false
training	oneLayer	oneLayer - rat 1	0	-0.3082661	0.17320985	false
training	oneLayer	oneLayer - rat 1	0	-0.3121523	0.1638277	false
training	oneLayer	oneLayer - rat 1	0	-0.31633946	0.15371895	false
training	oneLayer	oneLayer - rat 1	0	-0.32040283	0.14390907	false
training	oneLayer	oneLayer - rat 1	0	-0.32425666	0.13460511	false
training	oneLayer	oneLayer - rat 1	0	-0.328291	0.124865286	false
training	oneLayer	oneLayer - rat 1	0	-0.33215502	0.11553673	false
training	oneLayer	oneLayer - rat 1	0	-0.33949658	0.10819515	false
training	oneLayer	oneLayer - rat 1	0	-0.34690574	0.10078598	false
training	oneLayer	oneLayer - rat 1	0	-0.35403022	0.093661465	false
training	oneLayer	oneLayer - rat 1	0	-0.36130843	0.08638326	false
training	oneLayer	oneLayer - rat 1	0	-0.36904803	0.07864364	false
training	oneLayer	oneLayer - rat 1	0	-0.37636834	0.07132332	false
training	oneLayer	oneLayer - rat 1	0	-0.3836297	0.06406194	false
training	oneLayer	oneLayer - rat 1	0	-0.39133784	0.056353785	false
training	oneLayer	oneLayer - rat 1	0	-0.39873198	0.048959646	false
training	oneLayer	oneLayer - rat 1	0	-0.40582478	0.041866817	false
training	oneLayer	oneLayer - rat 1	0	-0.4132803	0.034411274	false
training	oneLayer	oneLayer - rat 1	0	-0.42052618	0.027165402	false
training	oneLayer	oneLayer - rat 1	0	-0.42451167	0.017543506	false
training	oneLayer	oneLayer - rat 1	0	-0.42451167	0.0073927976	false
training	oneLayer	oneLayer - rat 1	0	-0.42044273	-0.0024304257	false
training	oneLayer	oneLayer - rat 1	0	-0.41304436	-0.0098288	false
training	oneLayer	oneLayer - rat 1	0	-0.403263	-0.013880351	false
training	oneLayer	oneLayer - rat 1	0	-0.39254126	-0.013880339	false
training	oneLayer	oneLayer - rat 1	0	-0.38230896	-0.013880328	false
training	oneLayer	oneLayer - rat 1	0	-0.371662	-0.013880317	false
training	oneLayer	oneLayer - rat 1	0	-0.36100727	-0.013880306	false
training	oneLayer	oneLayer - rat 1	0	-0.35086986	-0.013880296	false
training	oneLayer	oneLayer - rat 1	0	-0.3403457	-0.0138802845	false
training	oneLayer	oneLayer - rat 1	0	-0.32979742	-0.013880273	false
training	oneLayer	oneLayer - rat 1	0	-0.31928706	-0.013880262	false
training	oneLayer	oneLayer - rat 1	0	-0.30841947	-0.013880251	false
training	oneLayer	oneLayer - rat 1	0	-0.2978561	-0.01388024	false
training	oneLayer	oneLayer - rat 1	0	-0.2869852	-0.013880229	false
training	oneLayer	oneLayer - rat 1	0	-0.27630788	-0.013880217	false
training	oneLayer	oneLayer - rat 1	0	-0.2662235	-0.013880207	false
training	oneLayer	oneLayer - rat 1	0	-0.2557052	-0.013880196	false
training	oneLayer	oneLayer - rat 1	0	-0.24497117	-0.013880185	false
training	oneLayer	oneLayer - rat 1	0	-0.23441936	-0.013880174	false
training	oneLayer	oneLayer - rat 1	0	-0.2236702	-0.0138801625	false
training	oneLayer	oneLayer - rat 1	0	-0.21307829	-0.013880151	false
training	oneLayer	oneLayer - rat 1	0	-0.20265628	-0.01388014	false
training	oneLayer	oneLayer - rat 1	0	-0.1918568	-0.013880129	false
training	oneLayer	oneLayer - rat 1	0	-0.18153721	-0.013880118	false
training	oneLayer	oneLayer - rat 1	0	-0.17094266	-0.013880107	false
training	oneLayer	oneLayer - rat 1	0	-0.16002218	-0.013880095	false
training	oneLayer	oneLayer - rat 1	0	-0.14999945	-0.013880085	false
training	oneLayer	oneLayer - rat 1	0	-0.13997875	-0.013880074	false
training	oneLayer	oneLayer - rat 1	0	-0.12909545	-0.013880063	false
training	oneLayer	oneLayer - rat 1	0	-0.118868105	-0.013880053	false
training	oneLayer	oneLayer - rat 1	0	-0.108689204	-0.013880041	false
training	oneLayer	oneLayer - rat 1	0	-0.09800289	-0.01388003	false
training	oneLayer	oneLayer - rat 1	0	-0.08745122	-0.013880019	false
training	oneLayer	oneLayer - rat 1	0	-0.077377	-0.013880009	false
training	oneLayer	oneLayer - rat 1	0	-0.06715146	-0.013879998	false
training	oneLayer	oneLayer - rat 1	0	-0.056521043	-0.0138799865	false
training	oneLayer	oneLayer - rat 1	0	-0.045555633	-0.013879975	false
training	oneLayer	oneLayer - rat 1	0	-0.034664046	-0.013879964	false
training	oneLayer	oneLayer - rat 1	0	-0.024203662	-0.013879953	false
training	oneLayer	oneLayer - rat 1	0	-0.013367893	-0.013879942	false
training	oneLayer	oneLayer - rat 1	0	-0.002993426	-0.013879931	false
training	oneLayer	oneLayer - rat 1	0	0.0070497673	-0.01387992	false
training	oneLayer	oneLayer - rat 1	0	0.01763189	-0.013879909	false
training	oneLayer	oneLayer - rat 1	0	0.027767448	-0.013879898	false
training	oneLayer	oneLayer - rat 1	0	0.03843389	-0.013879887	false
training	oneLayer	oneLayer - rat 1	0	0.049224634	-0.013879876	false
training	oneLayer	oneLayer - rat 1	0	0.059925288	-0.0138798645	false
training	oneLayer	oneLayer - rat 1	0	0.0707198	-0.013879853	false
training	oneLayer	oneLayer - rat 1	0	0.08098315	-0.013879842	false
training	oneLayer	oneLayer - rat 1	0	0.091853015	-0.013879831	false
training	oneLayer	oneLayer - rat 1	0	0.10229746	-0.01387982	false
training	oneLayer	oneLayer - rat 1	0	0.11285369	-0.0138798095	false
training	oneLayer	oneLayer - rat 1	0	0.12326742	-0.013879798	false
training	oneLayer	oneLayer - rat 1	0	0.13363644	-0.013879787	false
training	oneLayer	oneLayer - rat 1	0	0.14446735	-0.013879776	false
training	oneLayer	oneLayer - rat 1	0	0.15500702	-0.013879765	false
training	oneLayer	oneLayer - rat 1	0	0.16523124	-0.013879755	false
training	oneLayer	oneLayer - rat 1	0	0.17534854	-0.013879743	false
training	oneLayer	oneLayer - rat 1	0	0.18583605	-0.013879732	false
training	oneLayer	oneLayer - rat 1	0	0.19602601	-0.013879722	false
training	oneLayer	oneLayer - rat 1	0	0.20663714	-0.013879711	false
training	oneLayer	oneLayer - rat 1	0	0.21744865	-0.0138797	false
training	oneLayer	oneLayer - rat 1	0	0.2279929	-0.013879688	false
training	oneLayer	oneLayer - rat 1	0	0.2380733	-0.013879677	false
training	oneLayer	oneLayer - rat 1	0	0.24821061	-0.013879667	false
training	oneLayer	oneLayer - rat 1	0	0.25888914	-0.013879656	false
training	oneLayer	oneLayer - rat 1	0	0.2690748	-0.013879646	false
training	oneLayer	oneLayer - rat 1	0	0.27992916	-0.0138796335	false
training	oneLayer	oneLayer - rat 1	0	0.29043782	-0.013879622	false
training	oneLayer	oneLayer - rat 1	0	0.30135226	-0.013879611	false
training	oneLayer	oneLayer - rat 1	0	0.3115654	-0.013879601	false
training	oneLayer	oneLayer - rat 1	0	0.32201844	-0.01387959	false
training	oneLayer	oneLayer - rat 1	0	0.33244696	-0.013879579	false
training	oneLayer	oneLayer - rat 1	0	0.3433001	-0.013879567	false
training	oneLayer	oneLayer - rat 1	0	0.3542358	-0.013879556	false
training	oneLayer	oneLayer - rat 1	0	0.36510333	-0.013879544	false
training	oneLayer	oneLayer - rat 1	0	0.37581193	-0.013879533	false
training	oneLayer	oneLayer - rat 1	0	0.38596952	-0.013879523	false
training	oneLayer	oneLayer - rat 1	0	0.39690033	-0.0138795115	false
training	oneLayer	oneLayer - rat 1	0	0.4070537	-0.0138795	false
training	oneLayer	oneLayer - rat 1	0	0.4169715	-0.009771397	false
training	oneLayer	oneLayer - rat 1	0	0.42450634	-0.0022365584	false
training	oneLayer	oneLayer - rat 1	0	0.42837292	0.007098241	false
training	oneLayer	oneLayer - rat 1	0	0.42837292	0.018071808	false
training	oneLayer	oneLayer - rat 1	0	0.42425087	0.028023284	false
training	oneLayer	oneLayer - rat 1	0	0.41687804	0.03539608	false
training	oneLayer	oneLayer - rat 1	0	0.4070618	0.039462093	false
training	oneLayer	oneLayer - rat 1	0	0.3971216	0.04357944	false
training	oneLayer	oneLayer - rat 1	0	0.38735023	0.04762686	false
training	oneLayer	oneLayer - rat 1	0	0.37737337	0.051759407	false
training	oneLayer	oneLayer - rat 1	0	0.36787543	0.055693563	false
training	oneLayer	oneLayer - rat 1	0	0.35777527	0.05987718	false
training	oneLayer	oneLayer - rat 1	0	0.34806368	0.06389984	false
training	oneLayer	oneLayer - rat 1	0	0.33855897	0.0678368	false
training	oneLayer	oneLayer - rat 1	0	0.3288751	0.07184798	false
training	oneLayer	oneLayer - rat 1	0	0.31950358	0.07572978	false
training	oneLayer	oneLayer - rat 1	0	0.3102419	0.07956608	false
training	oneLayer	oneLayer - rat 1	0	0.30024314	0.08370769	false
training	oneLayer	oneLayer - rat 1	0	0.29023042	0.08785508	false
training	oneLayer	oneLayer - rat 1	0	0.28083655	0.09174614	false
training	oneLayer	oneLayer - rat 1	0	0.2707733	0.09591446	false
training	oneLayer	oneLayer - rat 1	0	0.2612981	0.0998392	false
training	oneLayer	oneLayer - rat 1	0	0.2511706	0.104034126	false
training	oneLayer	oneLayer - rat 1	0	0.24115312	0.108183496	false
training	oneLayer	oneLayer - rat 1	0	0.23152131	0.11217311	false
training	oneLayer	oneLayer - rat 1	0	0.22144996	0.11634479	false
training	oneLayer	oneLayer - rat 1	0	0.21158545	0.12043079	false
training	oneLayer	oneLayer - rat 1	0	0.20147096	0.12462033	false
training	oneLayer	oneLayer - rat 1	0	0.19169058	0.12867148	false
training	oneLayer	oneLayer - rat 1	0	0.18187934	0.13273542	false
training	oneLayer	oneLayer - rat 1	0	0.1725676	0.13659246	false
training	oneLayer	oneLayer - rat 1	0	0.16326176	0.14044705	false
training	oneLayer	oneLayer - rat 1	0	0.15369882	0.14440814	false
training	oneLayer	oneLayer - rat 1	0	0.14389142	0.14847048	false
training	oneLayer	oneLayer - rat 1	0	0.13442837	0.1523902	false
training	oneLayer	oneLayer - rat 1	0	0.12461528	0.15645489	false
training	oneLayer	oneLayer - rat 1	0	0.11523083	0.16034205	false
training	oneLayer	oneLayer - rat 1	0	0.105225995	0.16448617	false
training	oneLayer	oneLayer - rat 1	0	0.095747225	0.1684124	false
training	oneLayer	oneLayer - rat 1	0	0.08596024	0.1724663	false
training	oneLayer	oneLayer - rat 1	0	0.0764819	0.17639233	false
training	oneLayer	oneLayer - rat 1	0	0.06687628	0.18037109	false
training	oneLayer	oneLayer - rat 1	0	0.056875695	0.18451346	false
training	oneLayer	oneLayer - rat 1	0	0.046916418	0.18863872	false
training	oneLayer	oneLayer - rat 1	0	0.037459284	0.19255598	false
training	oneLayer	oneLayer - rat 1	0	0.028045913	0.1964551	false
training	oneLayer	oneLayer - rat 1	0	0.018650534	0.20034678	false
training	oneLayer	oneLayer - rat 1	0	0.008875753	0.20439562	false
training	oneLayer	oneLayer - rat 1	0	-8.9213776E-4	0.2084416	false
training	oneLayer	oneLayer - rat 1	0	-0.010183253	0.2122901	false
training	oneLayer	oneLayer - rat 1	0	-0.020305356	0.2164828	false
training	oneLayer	oneLayer - rat 1	0	-0.029550947	0.22031243	false
training	oneLayer	oneLayer - rat 1	0	-0.039064284	0.22425297	false
training	oneLayer	oneLayer - rat 1	0	-0.04862652	0.22821377	false
training	oneLayer	oneLayer - rat 1	0	-0.058250543	0.23220016	false
training	oneLayer	oneLayer - rat 1	0	-0.06804728	0.23625809	false
training	oneLayer	oneLayer - rat 1	0	-0.07775735	0.24028012	false
training	oneLayer	oneLayer - rat 1	0	-0.08714035	0.24416667	false
training	oneLayer	oneLayer - rat 1	0	-0.09652278	0.24805298	false
training	oneLayer	oneLayer - rat 1	0	-0.10580197	0.25189653	false
training	oneLayer	oneLayer - rat 1	0	-0.115492634	0.25591055	false
training	oneLayer	oneLayer - rat 1	0	-0.12502047	0.2598571	false
training	oneLayer	oneLayer - rat 1	0	-0.13473368	0.2638804	false
training	oneLayer	oneLayer - rat 1	0	-0.14422582	0.26781216	false
training	oneLayer	oneLayer - rat 1	0	-0.15355271	0.2716755	false
training	oneLayer	oneLayer - rat 1	0	-0.1630084	0.27559215	false
training	oneLayer	oneLayer - rat 1	0	-0.17263229	0.27957848	false
training	oneLayer	oneLayer - rat 1	0	-0.18201151	0.28346348	false
training	oneLayer	oneLayer - rat 1	0	-0.19131537	0.28731725	false
training	oneLayer	oneLayer - rat 1	0	-0.20135103	0.29147413	false
training	oneLayer	oneLayer - rat 1	0	-0.21117125	0.2955418	false
training	oneLayer	oneLayer - rat 1	0	-0.22081764	0.29953745	false
training	oneLayer	oneLayer - rat 1	0	-0.23071943	0.30363888	false
training	oneLayer	oneLayer - rat 1	0	-0.24015823	0.30754855	false
training	oneLayer	oneLayer - rat 1	0	-0.24996133	0.31160912	false
training	oneLayer	oneLayer - rat 1	0	-0.2593003	0.31547743	false
training	oneLayer	oneLayer - rat 1	0	-0.2690011	0.31949562	false
training	oneLayer	oneLayer - rat 1	0	-0.2791043	0.31949562	false
training	oneLayer	oneLayer - rat 1	0	-0.28862184	0.3155533	false
training	oneLayer	oneLayer - rat 1	0	-0.29604098	0.30813414	false
training	oneLayer	oneLayer - rat 1	0	-0.30337778	0.3007973	false
training	oneLayer	oneLayer - rat 1	0	-0.31046146	0.29371363	false
training	oneLayer	oneLayer - rat 1	0	-0.31768402	0.28649104	false
training	oneLayer	oneLayer - rat 1	0	-0.3253294	0.27884567	false
training	oneLayer	oneLayer - rat 1	0	-0.33287624	0.2712988	false
training	oneLayer	oneLayer - rat 1	0	-0.34057036	0.26360464	false
training	oneLayer	oneLayer - rat 1	0	-0.34832305	0.25585192	false
training	oneLayer	oneLayer - rat 1	0	-0.35230184	0.2462463	false
training	oneLayer	oneLayer - rat 1	0	-0.35640845	0.23633203	false
training	oneLayer	oneLayer - rat 1	0	-0.36023623	0.22709092	false
training	oneLayer	oneLayer - rat 1	0	-0.36438853	0.21706635	false
training	oneLayer	oneLayer - rat 1	0	-0.36824957	0.20774491	false
training	oneLayer	oneLayer - rat 1	0	-0.37222266	0.19815299	false
training	oneLayer	oneLayer - rat 1	0	-0.37610376	0.18878318	false
training	oneLayer	oneLayer - rat 1	0	-0.3801419	0.17903414	false
training	oneLayer	oneLayer - rat 1	0	-0.38424158	0.16913667	false
training	oneLayer	oneLayer - rat 1	0	-0.38833168	0.15926225	false
training	oneLayer	oneLayer - rat 1	0	-0.39247572	0.14925763	false
training	oneLayer	oneLayer - rat 1	0	-0.3966362	0.13921335	false
training	oneLayer	oneLayer - rat 1	0	-0.40060297	0.12963665	false
training	oneLayer	oneLayer - rat 1	0	-0.40462673	0.11992236	false
training	oneLayer	oneLayer - rat 1	0	-0.4085744	0.11039186	false
training	oneLayer	oneLayer - rat 1	0	-0.41251045	0.10088934	false
training	oneLayer	oneLayer - rat 1	0	-0.4165573	0.09111929	false
training	oneLayer	oneLayer - rat 1	0	-0.42043054	0.08176851	false
training	oneLayer	oneLayer - rat 1	0	-0.42450887	0.07192251	false
training	oneLayer	oneLayer - rat 1	0	-0.42841166	0.06250028	false
training	oneLayer	oneLayer - rat 1	0	-0.4322646	0.05319849	false
training	oneLayer	oneLayer - rat 1	0	-0.43626526	0.043539975	false
training	oneLayer	oneLayer - rat 1	0	-0.43626526	0.033070147	false
training	oneLayer	oneLayer - rat 1	0	-0.43206617	0.022932697	false
training	oneLayer	oneLayer - rat 1	0	-0.42439273	0.015259274	false
training	oneLayer	oneLayer - rat 1	0	-0.41457498	0.011192643	false
training	oneLayer	oneLayer - rat 1	0	-0.4044356	0.006992801	false
training	oneLayer	oneLayer - rat 1	0	-0.39509216	0.0031226312	false
training	oneLayer	oneLayer - rat 1	0	-0.38582736	-7.1497E-4	false
training	oneLayer	oneLayer - rat 1	0	-0.37520543	-7.1495696E-4	false
training	oneLayer	oneLayer - rat 1	0	-0.36496973	-7.1494444E-4	false
training	oneLayer	oneLayer - rat 1	0	-0.35436386	-7.1493146E-4	false
training	oneLayer	oneLayer - rat 1	0	-0.34427446	-7.149191E-4	false
training	oneLayer	oneLayer - rat 1	0	-0.33407488	-7.1490667E-4	false
training	oneLayer	oneLayer - rat 1	0	-0.32310757	-7.148932E-4	false
training	oneLayer	oneLayer - rat 1	0	-0.3122967	-7.1488E-4	false
training	oneLayer	oneLayer - rat 1	0	-0.3013558	-7.148666E-4	false
training	oneLayer	oneLayer - rat 1	0	-0.2905902	-7.148534E-4	false
training	oneLayer	oneLayer - rat 1	0	-0.28000453	-7.148405E-4	false
training	oneLayer	oneLayer - rat 1	0	-0.26991037	-7.148281E-4	false
training	oneLayer	oneLayer - rat 1	0	-0.25952807	-7.148154E-4	false
training	oneLayer	oneLayer - rat 1	0	-0.248542	-7.1480195E-4	false
training	oneLayer	oneLayer - rat 1	0	-0.23804325	-7.147891E-4	false
training	oneLayer	oneLayer - rat 1	0	-0.22788563	-7.147767E-4	false
training	oneLayer	oneLayer - rat 1	0	-0.2173543	-7.1476377E-4	false
training	oneLayer	oneLayer - rat 1	0	-0.20658517	-7.147506E-4	false
training	oneLayer	oneLayer - rat 1	0	-0.19632854	-7.1473804E-4	false
training	oneLayer	oneLayer - rat 1	0	-0.18612772	-7.147256E-4	false
training	oneLayer	oneLayer - rat 1	0	-0.17555645	-7.147126E-4	false
training	oneLayer	oneLayer - rat 1	0	-0.16550729	-7.147003E-4	false
training	oneLayer	oneLayer - rat 1	0	-0.15490182	-7.1468734E-4	false
training	oneLayer	oneLayer - rat 1	0	-0.14473304	-7.146749E-4	false
training	oneLayer	oneLayer - rat 1	0	-0.13465224	-7.1466254E-4	false
training	oneLayer	oneLayer - rat 1	0	-0.124267444	-7.1464985E-4	false
training	oneLayer	oneLayer - rat 1	0	-0.11341316	-7.146366E-4	false
training	oneLayer	oneLayer - rat 1	0	-0.10249779	-7.146232E-4	false
training	oneLayer	oneLayer - rat 1	0	-0.092092864	-7.146105E-4	false
training	oneLayer	oneLayer - rat 1	0	-0.08181585	-7.145979E-4	false
training	oneLayer	oneLayer - rat 1	0	-0.071565196	-7.1458536E-4	false
training	oneLayer	oneLayer - rat 1	0	-0.06113429	-7.145726E-4	false
training	oneLayer	oneLayer - rat 1	0	-0.051026955	-7.145602E-4	false
training	oneLayer	oneLayer - rat 1	0	-0.040585414	-7.145474E-4	false
training	oneLayer	oneLayer - rat 1	0	-0.030441936	-7.14535E-4	false
training	oneLayer	oneLayer - rat 1	0	-0.019443221	-7.1452156E-4	false
training	oneLayer	oneLayer - rat 1	0	-0.00868224	-7.145084E-4	false
training	oneLayer	oneLayer - rat 1	0	0.0014351499	-7.14496E-4	false
training	oneLayer	oneLayer - rat 1	0	0.012301433	-7.144827E-4	false
training	oneLayer	oneLayer - rat 1	0	0.023216119	-7.1446935E-4	false
training	oneLayer	oneLayer - rat 1	0	0.03386154	-7.144563E-4	false
training	oneLayer	oneLayer - rat 1	0	0.043991376	-7.144439E-4	false
training	oneLayer	oneLayer - rat 1	0	0.054828394	-7.1443064E-4	false
training	oneLayer	oneLayer - rat 1	0	0.06495556	-7.1441825E-4	false
training	oneLayer	oneLayer - rat 1	0	0.075453006	-7.1440544E-4	false
training	oneLayer	oneLayer - rat 1	0	0.08567546	-7.143929E-4	false
training	oneLayer	oneLayer - rat 1	0	0.09578938	-7.143805E-4	false
training	oneLayer	oneLayer - rat 1	0	0.10595342	-7.1436807E-4	false
training	oneLayer	oneLayer - rat 1	0	0.11653408	-7.1435515E-4	false
training	oneLayer	oneLayer - rat 1	0	0.12669641	-7.143427E-4	false
training	oneLayer	oneLayer - rat 1	0	0.13686581	-7.1433024E-4	false
training	oneLayer	oneLayer - rat 1	0	0.14709589	-7.143177E-4	false
training	oneLayer	oneLayer - rat 1	0	0.15801448	-7.143044E-4	false
training	oneLayer	oneLayer - rat 1	0	0.16805252	-7.1429205E-4	false
training	oneLayer	oneLayer - rat 1	0	0.17902792	-7.1427866E-4	false
training	oneLayer	oneLayer - rat 1	0	0.18959063	-7.1426574E-4	false
training	oneLayer	oneLayer - rat 1	0	0.19990763	-7.142531E-4	false
training	oneLayer	oneLayer - rat 1	0	0.21026239	-7.142404E-4	false
training	oneLayer	oneLayer - rat 1	0	0.22035466	-7.142281E-4	false
training	oneLayer	oneLayer - rat 1	0	0.23038998	-7.142158E-4	false
training	oneLayer	oneLayer - rat 1	0	0.24131782	-7.142024E-4	false
training	oneLayer	oneLayer - rat 1	0	0.2516844	-7.141897E-4	false
training	oneLayer	oneLayer - rat 1	0	0.2624288	-7.1417657E-4	false
training	oneLayer	oneLayer - rat 1	0	0.27262187	-7.141641E-4	false
training	oneLayer	oneLayer - rat 1	0	0.2830847	-7.141513E-4	false
training	oneLayer	oneLayer - rat 1	0	0.29381615	-7.1413815E-4	false
training	oneLayer	oneLayer - rat 1	0	0.30479977	-7.141247E-4	false
training	oneLayer	oneLayer - rat 1	0	0.3153912	-7.141117E-4	false
training	oneLayer	oneLayer - rat 1	0	0.32623905	-7.1409845E-4	false
training	oneLayer	oneLayer - rat 1	0	0.33662423	-7.1408576E-4	false
training	oneLayer	oneLayer - rat 1	0	0.34759519	-7.140723E-4	false
training	oneLayer	oneLayer - rat 1	0	0.35857183	-7.140589E-4	false
training	oneLayer	oneLayer - rat 1	0	0.36908913	-7.14046E-4	false
training	oneLayer	oneLayer - rat 1	0	0.3797396	-7.1403297E-4	false
training	oneLayer	oneLayer - rat 1	0	0.39056447	-7.1401976E-4	false
training	oneLayer	oneLayer - rat 1	0	0.40092087	-7.1400707E-4	false
training	oneLayer	oneLayer - rat 1	0	0.41036645	0.0031984905	false
training	oneLayer	oneLayer - rat 1	0	0.4176917	0.010523752	false
training	oneLayer	oneLayer - rat 1	0	0.42178303	0.02040111	false
training	oneLayer	oneLayer - rat 1	0	0.421783	0.031251237	false
training	oneLayer	oneLayer - rat 1	0	0.41770893	0.041086886	false
training	oneLayer	oneLayer - rat 1	0	0.4105428	0.048252996	false
training	oneLayer	oneLayer - rat 1	0	0.4011501	0.052143563	false
training	oneLayer	oneLayer - rat 1	0	0.39047298	0.052143548	false
training	oneLayer	oneLayer - rat 1	0	0.37994805	0.052143533	false
training	oneLayer	oneLayer - rat 1	0	0.36927444	0.052143518	false
training	oneLayer	oneLayer - rat 1	0	0.35880014	0.052143507	false
training	oneLayer	oneLayer - rat 1	0	0.34800074	0.05214349	false
training	oneLayer	oneLayer - rat 1	0	0.33732522	0.052143477	false
training	oneLayer	oneLayer - rat 1	0	0.3265198	0.052143462	false
training	oneLayer	oneLayer - rat 1	0	0.3158282	0.05214345	false
training	oneLayer	oneLayer - rat 1	0	0.30568615	0.052143436	false
training	oneLayer	oneLayer - rat 1	0	0.29482758	0.05214342	false
training	oneLayer	oneLayer - rat 1	0	0.28474754	0.05214341	false
training	oneLayer	oneLayer - rat 1	0	0.27438793	0.052143395	false
training	oneLayer	oneLayer - rat 1	0	0.2635316	0.05214338	false
training	oneLayer	oneLayer - rat 1	0	0.25306728	0.052143365	false
training	oneLayer	oneLayer - rat 1	0	0.24295656	0.052143354	false
training	oneLayer	oneLayer - rat 1	0	0.23231909	0.05214334	false
training	oneLayer	oneLayer - rat 1	0	0.2216484	0.052143324	false
training	oneLayer	oneLayer - rat 1	0	0.21076588	0.052143313	false
training	oneLayer	oneLayer - rat 1	0	0.2003125	0.052143298	false
training	oneLayer	oneLayer - rat 1	0	0.18950836	0.052143283	false
training	oneLayer	oneLayer - rat 1	0	0.17925878	0.052143272	false
training	oneLayer	oneLayer - rat 1	0	0.16849315	0.052143257	false
training	oneLayer	oneLayer - rat 1	0	0.15814163	0.052143242	false
training	oneLayer	oneLayer - rat 1	0	0.1472356	0.052143227	false
training	oneLayer	oneLayer - rat 1	0	0.13631056	0.052143212	false
training	oneLayer	oneLayer - rat 1	0	0.12598342	0.0521432	false
training	oneLayer	oneLayer - rat 1	0	0.115444295	0.052143186	false
training	oneLayer	oneLayer - rat 1	0	0.104653336	0.05214317	false
training	oneLayer	oneLayer - rat 1	0	0.0939925	0.052143157	false
training	oneLayer	oneLayer - rat 1	0	0.083699346	0.052143145	false
training	oneLayer	oneLayer - rat 1	0	0.073609136	0.05214313	false
training	oneLayer	oneLayer - rat 1	0	0.0631942	0.05214312	false
training	oneLayer	oneLayer - rat 1	0	0.05316422	0.052143104	false
training	oneLayer	oneLayer - rat 1	0	0.04294924	0.052143093	false
training	oneLayer	oneLayer - rat 1	0	0.032854952	0.05214308	false
training	oneLayer	oneLayer - rat 1	0	0.021979205	0.052143063	false
training	oneLayer	oneLayer - rat 1	0	0.011639288	0.05214305	false
training	oneLayer	oneLayer - rat 1	0	9.897593E-4	0.052143037	false
training	oneLayer	oneLayer - rat 1	0	-0.009437194	0.052143022	false
training	oneLayer	oneLayer - rat 1	0	-0.020404233	0.052143008	false
training	oneLayer	oneLayer - rat 1	0	-0.031026915	0.052142993	false
training	oneLayer	oneLayer - rat 1	0	-0.04166359	0.05214298	false
training	oneLayer	oneLayer - rat 1	0	-0.051751602	0.052142967	false
training	oneLayer	oneLayer - rat 1	0	-0.06252515	0.05214295	false
training	oneLayer	oneLayer - rat 1	0	-0.07259829	0.05214294	false
training	oneLayer	oneLayer - rat 1	0	-0.08320773	0.052142926	false
training	oneLayer	oneLayer - rat 1	0	-0.09398458	0.05214291	false
training	oneLayer	oneLayer - rat 1	0	-0.10475717	0.0521429	false
training	oneLayer	oneLayer - rat 1	0	-0.11498959	0.052142885	false
training	oneLayer	oneLayer - rat 1	0	-0.12499242	0.05214287	false
training	oneLayer	oneLayer - rat 1	0	-0.13536985	0.05214286	false
training	oneLayer	oneLayer - rat 1	0	-0.14605269	0.052142844	false
training	oneLayer	oneLayer - rat 1	0	-0.15667471	0.05214283	false
training	oneLayer	oneLayer - rat 1	0	-0.1670952	0.052142818	false
training	oneLayer	oneLayer - rat 1	0	-0.1771974	0.052142803	false
training	oneLayer	oneLayer - rat 1	0	-0.18796709	0.052142788	false
training	oneLayer	oneLayer - rat 1	0	-0.19815972	0.052142777	false
training	oneLayer	oneLayer - rat 1	0	-0.20895071	0.05214276	false
training	oneLayer	oneLayer - rat 1	0	-0.21994972	0.052142747	false
training	oneLayer	oneLayer - rat 1	0	-0.23058099	0.05214273	false
training	oneLayer	oneLayer - rat 1	0	-0.24135605	0.052142717	false
training	oneLayer	oneLayer - rat 1	0	-0.2513569	0.052142706	false
training	oneLayer	oneLayer - rat 1	0	-0.26194137	0.05214269	false
training	oneLayer	oneLayer - rat 1	0	-0.27227134	0.05214268	false
training	oneLayer	oneLayer - rat 1	0	-0.28291127	0.052142665	false
training	oneLayer	oneLayer - rat 1	0	-0.29301468	0.05214265	false
training	oneLayer	oneLayer - rat 1	0	-0.30324662	0.05214264	false
training	oneLayer	oneLayer - rat 1	0	-0.31342742	0.052142624	false
training	oneLayer	oneLayer - rat 1	0	-0.324323	0.05214261	false
training	oneLayer	oneLayer - rat 1	0	-0.3337931	0.048219945	false
training	oneLayer	oneLayer - rat 1	0	-0.34307823	0.04437392	false
training	oneLayer	oneLayer - rat 1	0	-0.3528902	0.040309653	false
training	oneLayer	oneLayer - rat 1	0	-0.36267564	0.03625637	false
training	oneLayer	oneLayer - rat 1	0	-0.37227696	0.032279354	false
training	oneLayer	oneLayer - rat 1	0	-0.38182372	0.028324945	false
training	oneLayer	oneLayer - rat 1	0	-0.39157218	0.024286993	false
training	oneLayer	oneLayer - rat 1	0	-0.40148604	0.02018052	false
training	oneLayer	oneLayer - rat 1	0	-0.41156894	0.016004024	false
training	oneLayer	oneLayer - rat 1	0	-0.41925126	0.0083217	false
training	oneLayer	oneLayer - rat 1	0	-0.4234	-0.0016943096	false
training	oneLayer	oneLayer - rat 1	0	-0.42339998	-0.012536452	false
training	oneLayer	oneLayer - rat 1	0	-0.41921657	-0.022636078	false
training	oneLayer	oneLayer - rat 1	0	-0.41210067	-0.029751956	false
training	oneLayer	oneLayer - rat 1	0	-0.40238544	-0.033776123	false
training	oneLayer	oneLayer - rat 1	0	-0.39149743	-0.03377611	false
training	oneLayer	oneLayer - rat 1	0	-0.38095653	-0.033776093	false
training	oneLayer	oneLayer - rat 1	0	-0.37066087	-0.03377608	false
training	oneLayer	oneLayer - rat 1	0	-0.3602567	-0.033776063	false
training	oneLayer	oneLayer - rat 1	0	-0.34957284	-0.03377605	false
training	oneLayer	oneLayer - rat 1	0	-0.33928636	-0.033776034	false
training	oneLayer	oneLayer - rat 1	0	-0.32834738	-0.03377602	false
training	oneLayer	oneLayer - rat 1	0	-0.318135	-0.033776004	false
training	oneLayer	oneLayer - rat 1	0	-0.30734932	-0.03377599	false
training	oneLayer	oneLayer - rat 1	0	-0.2971158	-0.033775974	false
training	oneLayer	oneLayer - rat 1	0	-0.2867661	-0.03377596	false
training	oneLayer	oneLayer - rat 1	0	-0.2759471	-0.033775944	false
training	oneLayer	oneLayer - rat 1	0	-0.26555833	-0.03377593	false
training	oneLayer	oneLayer - rat 1	0	-0.2549491	-0.033775914	false
training	oneLayer	oneLayer - rat 1	0	-0.24460883	-0.0337759	false
training	oneLayer	oneLayer - rat 1	0	-0.23378947	-0.033775885	false
training	oneLayer	oneLayer - rat 1	0	-0.22289225	-0.03377587	false
training	oneLayer	oneLayer - rat 1	0	-0.21273881	-0.033775855	false
training	oneLayer	oneLayer - rat 1	0	-0.20225665	-0.033775844	false
training	oneLayer	oneLayer - rat 1	0	-0.19128223	-0.033775825	false
training	oneLayer	oneLayer - rat 1	0	-0.18064216	-0.03377581	false
training	oneLayer	oneLayer - rat 1	0	-0.16977793	-0.033775795	false
training	oneLayer	oneLayer - rat 1	0	-0.15910996	-0.03377578	false
training	oneLayer	oneLayer - rat 1	0	-0.1484318	-0.033775765	false
training	oneLayer	oneLayer - rat 1	0	-0.13776976	-0.03377575	false
training	oneLayer	oneLayer - rat 1	0	-0.12725623	-0.033775736	false
training	oneLayer	oneLayer - rat 1	0	-0.11647899	-0.03377572	false
training	oneLayer	oneLayer - rat 1	0	-0.106423154	-0.03377571	false
training	oneLayer	oneLayer - rat 1	0	-0.096302204	-0.033775695	false
training	oneLayer	oneLayer - rat 1	0	-0.08564138	-0.03377568	false
training	oneLayer	oneLayer - rat 1	0	-0.07529355	-0.033775665	false
training	oneLayer	oneLayer - rat 1	0	-0.065147035	-0.03377565	false
training	oneLayer	oneLayer - rat 1	0	-0.05478087	-0.033775635	false
training	oneLayer	oneLayer - rat 1	0	-0.044070713	-0.03377562	false
training	oneLayer	oneLayer - rat 1	0	-0.033144798	-0.033775605	false
training	oneLayer	oneLayer - rat 1	0	-0.022857582	-0.03377559	false
training	oneLayer	oneLayer - rat 1	0	-0.012631262	-0.033775575	false
training	oneLayer	oneLayer - rat 1	0	-0.002013727	-0.03377556	false
training	oneLayer	oneLayer - rat 1	0	0.008771197	-0.033775546	false
training	oneLayer	oneLayer - rat 1	0	0.019608283	-0.03377553	false
training	oneLayer	oneLayer - rat 1	0	0.029661765	-0.033775516	false
training	oneLayer	oneLayer - rat 1	0	0.040239103	-0.0337755	false
training	oneLayer	oneLayer - rat 1	0	0.050321903	-0.03377549	false
training	oneLayer	oneLayer - rat 1	0	0.06049768	-0.033775475	false
training	oneLayer	oneLayer - rat 1	0	0.070621446	-0.03377546	false
training	oneLayer	oneLayer - rat 1	0	0.08135308	-0.033775445	false
training	oneLayer	oneLayer - rat 1	0	0.09138411	-0.03377543	false
training	oneLayer	oneLayer - rat 1	0	0.10159176	-0.033775415	false
training	oneLayer	oneLayer - rat 1	0	0.112142	-0.0337754	false
training	oneLayer	oneLayer - rat 1	0	0.12297339	-0.033775385	false
training	oneLayer	oneLayer - rat 1	0	0.13342482	-0.03377537	false
training	oneLayer	oneLayer - rat 1	0	0.14357811	-0.03377536	false
training	oneLayer	oneLayer - rat 1	0	0.15407953	-0.033775344	false
training	oneLayer	oneLayer - rat 1	0	0.16421294	-0.03377533	false
training	oneLayer	oneLayer - rat 1	0	0.17511135	-0.033775315	false
training	oneLayer	oneLayer - rat 1	0	0.18568382	-0.0337753	false
training	oneLayer	oneLayer - rat 1	0	0.19570185	-0.033775285	false
training	oneLayer	oneLayer - rat 1	0	0.20600693	-0.03377527	false
training	oneLayer	oneLayer - rat 1	0	0.21694545	-0.033775255	false
training	oneLayer	oneLayer - rat 1	0	0.22750391	-0.03377524	false
training	oneLayer	oneLayer - rat 1	0	0.23761947	-0.033775225	false
training	oneLayer	oneLayer - rat 1	0	0.24798277	-0.03377521	false
training	oneLayer	oneLayer - rat 1	0	0.25864258	-0.033775195	false
training	oneLayer	oneLayer - rat 1	0	0.26950744	-0.03377518	false
training	oneLayer	oneLayer - rat 1	0	0.27979404	-0.03377517	false
training	oneLayer	oneLayer - rat 1	0	0.29004458	-0.033775155	false
training	oneLayer	oneLayer - rat 1	0	0.30052617	-0.03377514	false
training	oneLayer	oneLayer - rat 1	0	0.3112493	-0.033775125	false
training	oneLayer	oneLayer - rat 1	0	0.3218313	-0.03377511	false
training	oneLayer	oneLayer - rat 1	0	0.33235165	-0.033775095	false
training	oneLayer	oneLayer - rat 1	0	0.34236664	-0.03377508	false
training	oneLayer	oneLayer - rat 1	0	0.3524417	-0.033775065	false
training	oneLayer	oneLayer - rat 1	0	0.36296263	-0.03377505	false
training	oneLayer	oneLayer - rat 1	0	0.37381452	-0.033775035	false
training	oneLayer	oneLayer - rat 1	0	0.38337958	-0.029813038	false
training	oneLayer	oneLayer - rat 1	0	0.3930638	-0.025801677	false
training	oneLayer	oneLayer - rat 1	0	0.4030418	-0.02166864	false
training	oneLayer	oneLayer - rat 1	0	0.41260675	-0.017706707	false
training	oneLayer	oneLayer - rat 1	0	0.41988066	-0.010432771	false
training	oneLayer	oneLayer - rat 1	0	0.42383534	-8.8527624E-4	false
training	oneLayer	oneLayer - rat 1	0	0.4238353	0.009902431	false
training	oneLayer	oneLayer - rat 1	0	0.41989255	0.01942111	false
training	oneLayer	oneLayer - rat 1	0	0.4127205	0.02659312	false
training	oneLayer	oneLayer - rat 1	0	0.4028868	0.030666351	false
training	oneLayer	oneLayer - rat 1	0	0.39339325	0.0345987	false
training	oneLayer	oneLayer - rat 1	0	0.38337365	0.03874893	false
training	oneLayer	oneLayer - rat 1	0	0.37325227	0.042941324	false
training	oneLayer	oneLayer - rat 1	0	0.36325508	0.047082286	false
training	oneLayer	oneLayer - rat 1	0	0.35341004	0.051160216	false
training	oneLayer	oneLayer - rat 1	0	0.3433932	0.055309303	false
training	oneLayer	oneLayer - rat 1	0	0.33406457	0.059173334	false
training	oneLayer	oneLayer - rat 1	0	0.32463413	0.06307953	false
training	oneLayer	oneLayer - rat 1	0	0.31517932	0.06699583	false
training	oneLayer	oneLayer - rat 1	0	0.30534694	0.071068525	false
training	oneLayer	oneLayer - rat 1	0	0.295216	0.075264886	false
training	oneLayer	oneLayer - rat 1	0	0.28593317	0.07910994	false
training	oneLayer	oneLayer - rat 1	0	0.27622232	0.08313229	false
training	oneLayer	oneLayer - rat 1	0	0.2668241	0.08702514	false
training	oneLayer	oneLayer - rat 1	0	0.2575347	0.09087291	false
training	oneLayer	oneLayer - rat 1	0	0.24794407	0.09484547	false
training	oneLayer	oneLayer - rat 1	0	0.23806222	0.09893865	false
training	oneLayer	oneLayer - rat 1	0	0.22836652	0.10295472	false
training	oneLayer	oneLayer - rat 1	0	0.21879244	0.10692042	false
training	oneLayer	oneLayer - rat 1	0	0.2092936	0.11085495	false
training	oneLayer	oneLayer - rat 1	0	0.19930509	0.11499231	false
training	oneLayer	oneLayer - rat 1	0	0.19004571	0.118827656	false
training	oneLayer	oneLayer - rat 1	0	0.18014185	0.12292995	false
training	oneLayer	oneLayer - rat 1	0	0.17003223	0.12711747	false
training	oneLayer	oneLayer - rat 1	0	0.15991253	0.13130918	false
training	oneLayer	oneLayer - rat 1	0	0.15062279	0.1351571	false
training	oneLayer	oneLayer - rat 1	0	0.14059943	0.13930888	false
training	oneLayer	oneLayer - rat 1	0	0.13108842	0.14324847	false
training	oneLayer	oneLayer - rat 1	0	0.121110715	0.14738135	false
training	oneLayer	oneLayer - rat 1	0	0.11185657	0.15121453	false
training	oneLayer	oneLayer - rat 1	0	0.102583	0.15505575	false
training	oneLayer	oneLayer - rat 1	0	0.09293032	0.159054	false
training	oneLayer	oneLayer - rat 1	0	0.08331621	0.16303627	false
training	oneLayer	oneLayer - rat 1	0	0.07331942	0.16717707	false
training	oneLayer	oneLayer - rat 1	0	0.06355464	0.17122175	false
training	oneLayer	oneLayer - rat 1	0	0.053522244	0.1753773	false
training	oneLayer	oneLayer - rat 1	0	0.04368839	0.17945059	false
training	oneLayer	oneLayer - rat 1	0	0.03374106	0.18357089	false
training	oneLayer	oneLayer - rat 1	0	0.023617158	0.18776433	false
training	oneLayer	oneLayer - rat 1	0	0.014100497	0.19170624	false
training	oneLayer	oneLayer - rat 1	0	0.0046976064	0.19560103	false
training	oneLayer	oneLayer - rat 1	0	-0.0048909103	0.19957271	false
training	oneLayer	oneLayer - rat 1	0	-0.0146548	0.20361704	false
training	oneLayer	oneLayer - rat 1	0	-0.02479846	0.20781866	false
training	oneLayer	oneLayer - rat 1	0	-0.034113843	0.2116772	false
training	oneLayer	oneLayer - rat 1	0	-0.04391472	0.21573684	false
training	oneLayer	oneLayer - rat 1	0	-0.054051064	0.21993543	false
training	oneLayer	oneLayer - rat 1	0	-0.06335132	0.22378771	false
training	oneLayer	oneLayer - rat 1	0	-0.07278602	0.22769567	false
training	oneLayer	oneLayer - rat 1	0	-0.08259887	0.23176026	false
training	oneLayer	oneLayer - rat 1	0	-0.091879666	0.23560448	false
training	oneLayer	oneLayer - rat 1	0	-0.10202067	0.23980501	false
training	oneLayer	oneLayer - rat 1	0	-0.11138875	0.24368538	false
training	oneLayer	oneLayer - rat 1	0	-0.12082904	0.24759565	false
training	oneLayer	oneLayer - rat 1	0	-0.1308211	0.2517345	false
training	oneLayer	oneLayer - rat 1	0	-0.1409284	0.25592104	false
training	oneLayer	oneLayer - rat 1	0	-0.15054461	0.2599042	false
training	oneLayer	oneLayer - rat 1	0	-0.16068485	0.2641044	false
training	oneLayer	oneLayer - rat 1	0	-0.17008477	0.26799798	false
training	oneLayer	oneLayer - rat 1	0	-0.18019345	0.2721851	false
training	oneLayer	oneLayer - rat 1	0	-0.18989903	0.27620527	false
training	oneLayer	oneLayer - rat 1	0	-0.19976012	0.28028986	false
training	oneLayer	oneLayer - rat 1	0	-0.2091429	0.2841763	false
training	oneLayer	oneLayer - rat 1	0	-0.21873692	0.28815025	false
training	oneLayer	oneLayer - rat 1	0	-0.2288562	0.2923418	false
training	oneLayer	oneLayer - rat 1	0	-0.238475	0.296326	false
training	oneLayer	oneLayer - rat 1	0	-0.24847022	0.30046615	false
training	oneLayer	oneLayer - rat 1	0	-0.2579932	0.30441067	false
training	oneLayer	oneLayer - rat 1	0	-0.2677199	0.30843958	false
training	oneLayer	oneLayer - rat 1	0	-0.27763143	0.31254506	false
training	oneLayer	oneLayer - rat 1	0	-0.28814355	0.31254506	false
training	oneLayer	oneLayer - rat 1	0	-0.2975591	0.30864498	false
training	oneLayer	oneLayer - rat 1	0	-0.30486047	0.30134362	false
training	oneLayer	oneLayer - rat 1	0	-0.31247586	0.2937282	false
training	oneLayer	oneLayer - rat 1	0	-0.3197387	0.28646535	false
training	oneLayer	oneLayer - rat 1	0	-0.32709616	0.27910784	false
training	oneLayer	oneLayer - rat 1	0	-0.33483082	0.27137315	false
training	oneLayer	oneLayer - rat 1	0	-0.3422162	0.26398775	false
training	oneLayer	oneLayer - rat 1	0	-0.34634772	0.25401333	false
training	oneLayer	oneLayer - rat 1	0	-0.35051015	0.24396428	false
training	oneLayer	oneLayer - rat 1	0	-0.35451257	0.23430155	false
training	oneLayer	oneLayer - rat 1	0	-0.35861287	0.22440258	false
training	oneLayer	oneLayer - rat 1	0	-0.36273554	0.21444945	false
training	oneLayer	oneLayer - rat 1	0	-0.36670208	0.2048734	false
training	oneLayer	oneLayer - rat 1	0	-0.3705762	0.19552033	false
training	oneLayer	oneLayer - rat 1	0	-0.37443054	0.18621513	false
training	oneLayer	oneLayer - rat 1	0	-0.37853998	0.17629398	false
training	oneLayer	oneLayer - rat 1	0	-0.38257357	0.16655599	false
training	oneLayer	oneLayer - rat 1	0	-0.38640082	0.15731616	false
training	oneLayer	oneLayer - rat 1	0	-0.39034596	0.14779171	false
training	oneLayer	oneLayer - rat 1	0	-0.3944198	0.13795659	false
training	oneLayer	oneLayer - rat 1	0	-0.39848706	0.12813728	false
training	oneLayer	oneLayer - rat 1	0	-0.40257028	0.11827949	false
training	oneLayer	oneLayer - rat 1	0	-0.4065507	0.10866987	false
training	oneLayer	oneLayer - rat 1	0	-0.4104775	0.09918973	false
training	oneLayer	oneLayer - rat 1	0	-0.4143117	0.08993303	false
training	oneLayer	oneLayer - rat 1	0	-0.41816458	0.08063138	false
training	oneLayer	oneLayer - rat 1	0	-0.42218935	0.070914686	false
training	oneLayer	oneLayer - rat 1	0	-0.42608663	0.061505783	false
training	oneLayer	oneLayer - rat 1	0	-0.42993268	0.05222055	false
training	oneLayer	oneLayer - rat 1	0	-0.43382034	0.042834826	false
training	oneLayer	oneLayer - rat 1	0	-0.4378401	0.033130247	false
training	oneLayer	oneLayer - rat 1	0	-0.44202313	0.023031484	false
training	oneLayer	oneLayer - rat 1	0	-0.44586253	0.013762315	false
training	oneLayer	oneLayer - rat 1	0	-0.4458625	0.0037541783	false
training	oneLayer	oneLayer - rat 1	0	-0.44196138	-0.005663975	false
training	oneLayer	oneLayer - rat 1	0	-0.43442386	-0.013201466	false
training	oneLayer	oneLayer - rat 1	0	-0.4251643	-0.017036881	false
training	oneLayer	oneLayer - rat 1	0	-0.41441014	-0.017036865	false
training	oneLayer	oneLayer - rat 1	0	-0.40443942	-0.012906845	false
training	oneLayer	oneLayer - rat 1	0	-0.3972146	-0.0056819697	false
training	oneLayer	oneLayer - rat 1	0	-0.39304772	0.0043777907	false
training	oneLayer	oneLayer - rat 1	0	-0.38891035	0.014366314	false
training	oneLayer	oneLayer - rat 1	0	-0.38496006	0.023903238	false
training	oneLayer	oneLayer - rat 1	0	-0.38084182	0.033845555	false
training	oneLayer	oneLayer - rat 1	0	-0.3768301	0.04353075	false
training	oneLayer	oneLayer - rat 1	0	-0.3726741	0.053564265	false
training	oneLayer	oneLayer - rat 1	0	-0.36852947	0.0635703	false
training	oneLayer	oneLayer - rat 1	0	-0.3644533	0.07341113	false
training	oneLayer	oneLayer - rat 1	0	-0.36062017	0.08266513	false
training	oneLayer	oneLayer - rat 1	0	-0.3564136	0.09282077	false
training	oneLayer	oneLayer - rat 1	0	-0.35231468	0.10271644	false
training	oneLayer	oneLayer - rat 1	0	-0.34827158	0.11247744	false
training	oneLayer	oneLayer - rat 1	0	-0.3444171	0.12178305	false
training	oneLayer	oneLayer - rat 1	0	-0.34031382	0.13168924	false
training	oneLayer	oneLayer - rat 1	0	-0.33623838	0.14152826	false
training	oneLayer	oneLayer - rat 1	0	-0.33204243	0.15165822	false
training	oneLayer	oneLayer - rat 1	0	-0.32800728	0.16140002	false
training	oneLayer	oneLayer - rat 1	0	-0.32384622	0.1714457	false
training	oneLayer	oneLayer - rat 1	0	-0.31964514	0.18158811	false
training	oneLayer	oneLayer - rat 1	0	-0.31964514	0.19180144	false
training	oneLayer	oneLayer - rat 1	0	-0.31964517	0.20271246	false
training	oneLayer	oneLayer - rat 1	0	-0.31964517	0.21310541	false
training	oneLayer	oneLayer - rat 1	0	-0.3196452	0.2234564	false
training	oneLayer	oneLayer - rat 1	0	-0.3196452	0.2340949	false
training	oneLayer	oneLayer - rat 1	0	-0.31964523	0.24418235	false
training	oneLayer	oneLayer - rat 1	0	-0.31964523	0.25424334	false
training	oneLayer	oneLayer - rat 1	0	-0.31964526	0.26501954	false
training	oneLayer	oneLayer - rat 1	0	-0.3196453	0.2756433	false
recall	oneLayer	oneLayer - rat 1	0	0.010777503	-0.35	false
recall	oneLayer	oneLayer - rat 1	0	0.021152101	-0.35	false
recall	oneLayer	oneLayer - rat 1	0	0.030617967	-0.3460791	false
recall	oneLayer	oneLayer - rat 1	0	0.040592834	-0.34194738	false
recall	oneLayer	oneLayer - rat 1	0	0.050106745	-0.3380066	false
recall	oneLayer	oneLayer - rat 1	0	0.059577066	-0.33408386	false
recall	oneLayer	oneLayer - rat 1	0	0.06905781	-0.3301568	false
recall	oneLayer	oneLayer - rat 1	0	0.07916085	-0.325972	false
recall	oneLayer	oneLayer - rat 1	0	0.08911489	-0.32184887	false
recall	oneLayer	oneLayer - rat 1	0	0.09857789	-0.31792918	false
recall	oneLayer	oneLayer - rat 1	0	0.105817765	-0.3106893	false
recall	oneLayer	oneLayer - rat 1	0	0.112971984	-0.30353507	false
recall	oneLayer	oneLayer - rat 1	0	0.1201633	-0.29634377	false
recall	oneLayer	oneLayer - rat 1	0	0.124059916	-0.2869365	false
recall	oneLayer	oneLayer - rat 1	0	0.12812531	-0.27712175	false
recall	oneLayer	oneLayer - rat 1	0	0.13218875	-0.26731175	false
recall	oneLayer	oneLayer - rat 1	0	0.13218875	-0.25641203	false
recall	oneLayer	oneLayer - rat 1	0	0.13218874	-0.24612758	false
recall	oneLayer	oneLayer - rat 1	0	0.13218874	-0.23545802	false
recall	oneLayer	oneLayer - rat 1	0	0.13218874	-0.22454019	false
recall	oneLayer	oneLayer - rat 1	0	0.13218874	-0.2141956	false
recall	oneLayer	oneLayer - rat 1	0	0.13218874	-0.20398694	false
recall	oneLayer	oneLayer - rat 1	0	0.13218874	-0.1936173	false
recall	oneLayer	oneLayer - rat 1	0	0.13218874	-0.18300708	false
recall	oneLayer	oneLayer - rat 1	0	0.13218874	-0.17212039	false
recall	oneLayer	oneLayer - rat 1	0	0.13218874	-0.16180886	false
recall	oneLayer	oneLayer - rat 1	0	0.12835564	-0.15255493	false
recall	oneLayer	oneLayer - rat 1	0	0.124447405	-0.14311962	false
recall	oneLayer	oneLayer - rat 1	0	0.1168562	-0.13552843	false
recall	oneLayer	oneLayer - rat 1	0	0.10924066	-0.12791288	false
recall	oneLayer	oneLayer - rat 1	0	0.10151733	-0.120189555	false
recall	oneLayer	oneLayer - rat 1	0	0.091729335	-0.11613523	false
recall	oneLayer	oneLayer - rat 1	0	0.08138422	-0.11613523	false
recall	oneLayer	oneLayer - rat 1	0	0.071096405	-0.11613523	false
recall	oneLayer	oneLayer - rat 1	0	0.06143958	-0.120135225	false
recall	oneLayer	oneLayer - rat 1	0	0.051954456	-0.124064095	false
recall	oneLayer	oneLayer - rat 1	0	0.042605445	-0.12793659	false
recall	oneLayer	oneLayer - rat 1	0	0.03516793	-0.1353741	false
recall	oneLayer	oneLayer - rat 1	0	0.027993921	-0.14254811	false
recall	oneLayer	oneLayer - rat 1	0	0.024124872	-0.15188882	false
recall	oneLayer	oneLayer - rat 1	0	0.020266317	-0.1612042	false
recall	oneLayer	oneLayer - rat 1	0	0.01634842	-0.17066285	false
recall	oneLayer	oneLayer - rat 1	0	0.012226493	-0.18061405	false
recall	oneLayer	oneLayer - rat 1	0	0.004778557	-0.188062	false
recall	oneLayer	oneLayer - rat 1	0	6.324685E-4	-0.19807154	false
recall	oneLayer	oneLayer - rat 1	0	-0.0032659539	-0.20748317	false
recall	oneLayer	oneLayer - rat 1	0	-0.007457585	-0.21760267	false
recall	oneLayer	oneLayer - rat 1	0	-0.014666268	-0.22481135	false
recall	oneLayer	oneLayer - rat 1	0	-0.018683443	-0.23450968	false
recall	oneLayer	oneLayer - rat 1	0	-0.022854986	-0.24458067	false
recall	oneLayer	oneLayer - rat 1	0	-0.030329086	-0.25205478	false
recall	oneLayer	oneLayer - rat 1	0	-0.03425281	-0.26152748	false
recall	oneLayer	oneLayer - rat 1	0	-0.04192812	-0.2692028	false
recall	oneLayer	oneLayer - rat 1	0	-0.0461139	-0.27930817	false
recall	oneLayer	oneLayer - rat 1	0	-0.050236445	-0.28926086	false
recall	oneLayer	oneLayer - rat 1	0	-0.057549052	-0.2965735	false
recall	oneLayer	oneLayer - rat 1	0	-0.06475708	-0.3037815	false
recall	oneLayer	oneLayer - rat 1	0	-0.07421926	-0.30770087	false
recall	oneLayer	oneLayer - rat 1	0	-0.084164456	-0.31182033	false
recall	oneLayer	oneLayer - rat 1	0	-0.093570486	-0.31571642	false
recall	oneLayer	oneLayer - rat 1	0	-0.100757174	-0.3229031	false
recall	oneLayer	oneLayer - rat 1	0	-0.104631275	-0.33225602	false
recall	oneLayer	oneLayer - rat 1	0	-0.104631275	-0.3425535	false
recall	oneLayer	oneLayer - rat 1	0	-0.10463127	-0.35317445	false
recall	oneLayer	oneLayer - rat 1	0	-0.10463127	-0.36374044	false
recall	oneLayer	oneLayer - rat 1	0	-0.10463127	-0.37391764	false
recall	oneLayer	oneLayer - rat 1	0	-0.10463127	-0.38476095	false
recall	oneLayer	oneLayer - rat 1	0	-0.10463127	-0.39572474	false
recall	oneLayer	oneLayer - rat 1	0	-0.10047567	-0.40575725	false
recall	oneLayer	oneLayer - rat 1	0	-0.093068115	-0.4131648	false
recall	oneLayer	oneLayer - rat 1	0	-0.08569417	-0.42053875	false
recall	oneLayer	oneLayer - rat 1	0	-0.076120846	-0.42450413	false
recall	oneLayer	oneLayer - rat 1	0	-0.0651226	-0.42450413	false
recall	oneLayer	oneLayer - rat 1	0	-0.055834938	-0.42065707	false
recall	oneLayer	oneLayer - rat 1	0	-0.04843003	-0.41325215	false
recall	oneLayer	oneLayer - rat 1	0	-0.04438317	-0.40348217	false
recall	oneLayer	oneLayer - rat 1	0	-0.044383172	-0.39314142	false
recall	oneLayer	oneLayer - rat 1	0	-0.04051208	-0.3837958	false
recall	oneLayer	oneLayer - rat 1	0	-0.040512085	-0.37293008	false
recall	oneLayer	oneLayer - rat 1	0	-0.040512085	-0.36245662	false
recall	oneLayer	oneLayer - rat 1	0	-0.04051209	-0.35245052	false
recall	oneLayer	oneLayer - rat 1	0	-0.044465594	-0.34290594	false
recall	oneLayer	oneLayer - rat 1	0	-0.04867009	-0.3327554	false
recall	oneLayer	oneLayer - rat 1	0	-0.04867009	-0.3225788	false
recall	oneLayer	oneLayer - rat 1	0	-0.048670094	-0.3123247	false
recall	oneLayer	oneLayer - rat 1	0	-0.0486701	-0.30148908	false
recall	oneLayer	oneLayer - rat 1	0	-0.0486701	-0.29093325	false
recall	oneLayer	oneLayer - rat 1	0	-0.048670102	-0.28048483	false
recall	oneLayer	oneLayer - rat 1	0	-0.052661445	-0.27084887	false
recall	oneLayer	oneLayer - rat 1	0	-0.05996289	-0.26354745	false
recall	oneLayer	oneLayer - rat 1	0	-0.067547016	-0.25596333	false
recall	oneLayer	oneLayer - rat 1	0	-0.074657835	-0.2488525	false
recall	oneLayer	oneLayer - rat 1	0	-0.08468297	-0.24469995	false
recall	oneLayer	oneLayer - rat 1	0	-0.094612524	-0.24058701	false
recall	oneLayer	oneLayer - rat 1	0	-0.105326906	-0.24058701	false
recall	oneLayer	oneLayer - rat 1	0	-0.1161186	-0.24058701	false
recall	oneLayer	oneLayer - rat 1	0	-0.12690552	-0.24058701	false
recall	oneLayer	oneLayer - rat 1	0	-0.1376966	-0.24058701	false
recall	oneLayer	oneLayer - rat 1	0	-0.14796382	-0.24058703	false
recall	oneLayer	oneLayer - rat 1	0	-0.15741947	-0.24450368	false
recall	oneLayer	oneLayer - rat 1	0	-0.1672912	-0.24859269	false
recall	oneLayer	oneLayer - rat 1	0	-0.17772032	-0.24859269	false
recall	oneLayer	oneLayer - rat 1	0	-0.18791361	-0.24859269	false
recall	oneLayer	oneLayer - rat 1	0	-0.19757463	-0.2525944	false
recall	oneLayer	oneLayer - rat 1	0	-0.20718949	-0.25657701	false
recall	oneLayer	oneLayer - rat 1	0	-0.21457942	-0.26396698	false
recall	oneLayer	oneLayer - rat 1	0	-0.224426	-0.26804554	false
recall	oneLayer	oneLayer - rat 1	0	-0.2316653	-0.27528486	false
recall	oneLayer	oneLayer - rat 1	0	-0.23574282	-0.2851289	false
recall	oneLayer	oneLayer - rat 1	0	-0.24333216	-0.29271823	false
recall	oneLayer	oneLayer - rat 1	0	-0.25094795	-0.300334	false
recall	oneLayer	oneLayer - rat 1	0	-0.26106367	-0.3045241	false
recall	oneLayer	oneLayer - rat 1	0	-0.2706784	-0.30850664	false
recall	oneLayer	oneLayer - rat 1	0	-0.2810236	-0.30850664	false
recall	oneLayer	oneLayer - rat 1	0	-0.29196936	-0.30850667	false
recall	oneLayer	oneLayer - rat 1	0	-0.30243602	-0.30850667	false
recall	oneLayer	oneLayer - rat 1	0	-0.31189942	-0.3045868	false
recall	oneLayer	oneLayer - rat 1	0	-0.32117	-0.3007468	false
recall	oneLayer	oneLayer - rat 1	0	-0.3305987	-0.2968413	false
recall	oneLayer	oneLayer - rat 1	0	-0.33985615	-0.29300675	false
recall	oneLayer	oneLayer - rat 1	0	-0.34693882	-0.28592408	false
recall	oneLayer	oneLayer - rat 1	0	-0.35432687	-0.27853602	false
recall	oneLayer	oneLayer - rat 1	0	-0.36208615	-0.27077675	false
recall	oneLayer	oneLayer - rat 1	0	-0.36971444	-0.26314846	false
recall	oneLayer	oneLayer - rat 1	0	-0.3736046	-0.2537568	false
recall	oneLayer	oneLayer - rat 1	0	-0.37780538	-0.24361521	false
recall	oneLayer	oneLayer - rat 1	0	-0.37780538	-0.23284365	false
recall	oneLayer	oneLayer - rat 1	0	-0.37780538	-0.22253482	false
recall	oneLayer	oneLayer - rat 1	0	-0.37780538	-0.21235861	false
recall	oneLayer	oneLayer - rat 1	0	-0.38192895	-0.20240343	false
recall	oneLayer	oneLayer - rat 1	0	-0.38578174	-0.19310203	false
recall	oneLayer	oneLayer - rat 1	0	-0.393336	-0.18554777	false
recall	oneLayer	oneLayer - rat 1	0	-0.39735967	-0.1758338	false
recall	oneLayer	oneLayer - rat 1	0	-0.39735967	-0.16516772	false
recall	oneLayer	oneLayer - rat 1	0	-0.39735967	-0.15506619	false
recall	oneLayer	oneLayer - rat 1	0	-0.39735967	-0.14501795	false
recall	oneLayer	oneLayer - rat 1	0	-0.39735967	-0.13459727	false
recall	oneLayer	oneLayer - rat 1	0	-0.39735967	-0.12419671	false
recall	oneLayer	oneLayer - rat 1	0	-0.40133607	-0.114596836	false
recall	oneLayer	oneLayer - rat 1	0	-0.40538284	-0.1048271	false
recall	oneLayer	oneLayer - rat 1	0	-0.41257936	-0.09763056	false
recall	oneLayer	oneLayer - rat 1	0	-0.4200168	-0.090193145	false
recall	oneLayer	oneLayer - rat 1	0	-0.42421252	-0.080063745	false
recall	oneLayer	oneLayer - rat 1	0	-0.42421252	-0.069557555	false
recall	oneLayer	oneLayer - rat 1	0	-0.42421255	-0.058824643	false
recall	oneLayer	oneLayer - rat 1	0	-0.42421255	-0.048577998	false
recall	oneLayer	oneLayer - rat 1	0	-0.42835543	-0.038576193	false
recall	oneLayer	oneLayer - rat 1	0	-0.42835543	-0.028467923	false
recall	oneLayer	oneLayer - rat 1	0	-0.4323747	-0.018764604	false
recall	oneLayer	oneLayer - rat 1	0	-0.4323747	-0.008586796	false
recall	oneLayer	oneLayer - rat 1	0	-0.43642408	0.0011893307	false
recall	oneLayer	oneLayer - rat 1	0	-0.43642408	0.012136302	false
recall	oneLayer	oneLayer - rat 1	0	-0.4402516	0.021376733	false
recall	oneLayer	oneLayer - rat 1	0	-0.4402516	0.032013185	false
recall	oneLayer	oneLayer - rat 1	0	-0.44409242	0.041285735	false
recall	oneLayer	oneLayer - rat 1	0	-0.44409242	0.051414162	false
recall	oneLayer	oneLayer - rat 1	0	-0.44018477	0.060848054	false
recall	oneLayer	oneLayer - rat 1	0	-0.44018477	0.07155885	false
recall	oneLayer	oneLayer - rat 1	0	-0.4362574	0.0810404	false
recall	oneLayer	oneLayer - rat 1	0	-0.4362574	0.0920034	false
recall	oneLayer	oneLayer - rat 1	0	-0.4323277	0.10149056	false
recall	oneLayer	oneLayer - rat 1	0	-0.4323277	0.11235349	false
recall	oneLayer	oneLayer - rat 1	0	-0.42835137	0.12195315	false
recall	oneLayer	oneLayer - rat 1	0	-0.42426306	0.13182321	false
recall	oneLayer	oneLayer - rat 1	0	-0.42426306	0.14206614	false
recall	oneLayer	oneLayer - rat 1	0	-0.42013633	0.152029	false
recall	oneLayer	oneLayer - rat 1	0	-0.42013633	0.1627905	false
recall	oneLayer	oneLayer - rat 1	0	-0.41614464	0.17242727	false
recall	oneLayer	oneLayer - rat 1	0	-0.41614467	0.18324614	false
recall	oneLayer	oneLayer - rat 1	0	-0.4121386	0.19291757	false
recall	oneLayer	oneLayer - rat 1	0	-0.40823638	0.20233838	false
recall	oneLayer	oneLayer - rat 1	0	-0.40405688	0.2124286	false
recall	oneLayer	oneLayer - rat 1	0	-0.40010506	0.22196919	false
recall	oneLayer	oneLayer - rat 1	0	-0.39281955	0.22925468	false
recall	oneLayer	oneLayer - rat 1	0	-0.38892055	0.23866771	false
recall	oneLayer	oneLayer - rat 1	0	-0.38481218	0.24858624	false
recall	oneLayer	oneLayer - rat 1	0	-0.37704015	0.25635827	false
recall	oneLayer	oneLayer - rat 1	0	-0.37312067	0.26582077	false
recall	oneLayer	oneLayer - rat 1	0	-0.36896232	0.2758599	false
recall	oneLayer	oneLayer - rat 1	0	-0.36492455	0.28560793	false
recall	oneLayer	oneLayer - rat 1	0	-0.3608747	0.2953851	false
recall	oneLayer	oneLayer - rat 1	0	-0.35378775	0.30247205	false
recall	oneLayer	oneLayer - rat 1	0	-0.34615254	0.31010726	false
recall	oneLayer	oneLayer - rat 1	0	-0.3385702	0.3176896	false
recall	oneLayer	oneLayer - rat 1	0	-0.33146113	0.3247987	false
recall	oneLayer	oneLayer - rat 1	0	-0.32377318	0.33248663	false
recall	oneLayer	oneLayer - rat 1	0	-0.31644845	0.33981138	false
recall	oneLayer	oneLayer - rat 1	0	-0.30928597	0.34697384	false
recall	oneLayer	oneLayer - rat 1	0	-0.29994258	0.350844	false
recall	oneLayer	oneLayer - rat 1	0	-0.29018712	0.35488486	false
recall	oneLayer	oneLayer - rat 1	0	-0.2807226	0.3588052	false
recall	oneLayer	oneLayer - rat 1	0	-0.2712721	0.3627197	false
recall	oneLayer	oneLayer - rat 1	0	-0.26156148	0.36674199	false
recall	oneLayer	oneLayer - rat 1	0	-0.25205362	0.37068027	false
recall	oneLayer	oneLayer - rat 1	0	-0.24165204	0.37068027	false
recall	oneLayer	oneLayer - rat 1	0	-0.23213726	0.36673912	false
recall	oneLayer	oneLayer - rat 1	0	-0.22496516	0.35956702	false
recall	oneLayer	oneLayer - rat 1	0	-0.21759187	0.35219374	false
recall	oneLayer	oneLayer - rat 1	0	-0.20996189	0.34456375	false
recall	oneLayer	oneLayer - rat 1	0	-0.20589773	0.33475202	false
recall	oneLayer	oneLayer - rat 1	0	-0.20589772	0.32433474	false
recall	oneLayer	oneLayer - rat 1	0	-0.20589772	0.31408107	false
recall	oneLayer	oneLayer - rat 1	0	-0.20990758	0.3044004	false
recall	oneLayer	oneLayer - rat 1	0	-0.2141029	0.294272	false
recall	oneLayer	oneLayer - rat 1	0	-0.22134618	0.28702873	false
recall	oneLayer	oneLayer - rat 1	0	-0.22872475	0.27965015	false
recall	oneLayer	oneLayer - rat 1	0	-0.23613532	0.2722396	false
recall	oneLayer	oneLayer - rat 1	0	-0.24025916	0.26228377	false
recall	oneLayer	oneLayer - rat 1	0	-0.24780086	0.25474206	false
recall	oneLayer	oneLayer - rat 1	0	-0.25733343	0.25079355	false
recall	oneLayer	oneLayer - rat 1	0	-0.2673035	0.2466638	false
recall	oneLayer	oneLayer - rat 1	0	-0.27658904	0.2428176	false
recall	oneLayer	oneLayer - rat 1	0	-0.28660485	0.2386689	false
recall	oneLayer	oneLayer - rat 1	0	-0.2968387	0.2386689	false
recall	oneLayer	oneLayer - rat 1	0	-0.3076492	0.2386689	false
recall	oneLayer	oneLayer - rat 1	0	-0.31758302	0.24278362	false
recall	oneLayer	oneLayer - rat 1	0	-0.32523254	0.25043315	false
recall	oneLayer	oneLayer - rat 1	0	-0.3292166	0.26005155	false
recall	oneLayer	oneLayer - rat 1	0	-0.3292166	0.27008107	false
recall	oneLayer	oneLayer - rat 1	0	-0.3292166	0.28036955	false
recall	oneLayer	oneLayer - rat 1	0	-0.32515392	0.29017776	false
recall	oneLayer	oneLayer - rat 1	0	-0.3210316	0.30012992	false
recall	oneLayer	oneLayer - rat 1	0	-0.31694037	0.31000704	false
recall	oneLayer	oneLayer - rat 1	0	-0.30965462	0.31729278	false
recall	oneLayer	oneLayer - rat 1	0	-0.30021942	0.32120097	false
recall	oneLayer	oneLayer - rat 1	0	-0.2908086	0.32509905	false
recall	oneLayer	oneLayer - rat 1	0	-0.28123692	0.32906377	false
recall	oneLayer	oneLayer - rat 1	0	-0.27193555	0.33291653	false
recall	oneLayer	oneLayer - rat 1	0	-0.26175475	0.33291653	false
recall	oneLayer	oneLayer - rat 1	0	-0.25213596	0.3289323	false
recall	oneLayer	oneLayer - rat 1	0	-0.24248073	0.32493296	false
recall	oneLayer	oneLayer - rat 1	0	-0.23206484	0.32493296	false
recall	oneLayer	oneLayer - rat 1	0	-0.22267027	0.3210416	false
recall	oneLayer	oneLayer - rat 1	0	-0.21491261	0.31328395	false
recall	oneLayer	oneLayer - rat 1	0	-0.20750917	0.30588052	false
recall	oneLayer	oneLayer - rat 1	0	-0.20040105	0.2987724	false
recall	oneLayer	oneLayer - rat 1	0	-0.19630589	0.28888577	false
recall	oneLayer	oneLayer - rat 1	0	-0.19245721	0.27959424	false
recall	oneLayer	oneLayer - rat 1	0	-0.18854378	0.2701464	false
recall	oneLayer	oneLayer - rat 1	0	-0.18135528	0.2629579	false
recall	oneLayer	oneLayer - rat 1	0	-0.1742805	0.2558831	false
recall	oneLayer	oneLayer - rat 1	0	-0.16498469	0.25203267	false
recall	oneLayer	oneLayer - rat 1	0	-0.15746428	0.24451225	false
recall	oneLayer	oneLayer - rat 1	0	-0.15015778	0.23720574	false
recall	oneLayer	oneLayer - rat 1	0	-0.14611739	0.22745138	false
recall	oneLayer	oneLayer - rat 1	0	-0.14197366	0.21744755	false
recall	oneLayer	oneLayer - rat 1	0	-0.14197366	0.2073776	false
recall	oneLayer	oneLayer - rat 1	0	-0.13802141	0.197836	false
recall	oneLayer	oneLayer - rat 1	0	-0.13417764	0.18855634	false
recall	oneLayer	oneLayer - rat 1	0	-0.126754	0.1811327	false
recall	oneLayer	oneLayer - rat 1	0	-0.119126715	0.17350541	false
recall	oneLayer	oneLayer - rat 1	0	-0.11167158	0.16605029	false
recall	oneLayer	oneLayer - rat 1	0	-0.10449065	0.15886936	false
recall	oneLayer	oneLayer - rat 1	0	-0.09706692	0.15144563	false
recall	oneLayer	oneLayer - rat 1	0	-0.08995772	0.14433642	false
recall	oneLayer	oneLayer - rat 1	0	-0.085877374	0.13448559	false
recall	oneLayer	oneLayer - rat 1	0	-0.085877374	0.1237446	false
recall	oneLayer	oneLayer - rat 1	0	-0.085877374	0.11313375	false
recall	oneLayer	oneLayer - rat 1	0	-0.089944154	0.10331568	false
recall	oneLayer	oneLayer - rat 1	0	-0.089944154	0.09232721	false
recall	oneLayer	oneLayer - rat 1	0	-0.089944154	0.08196254	false
recall	oneLayer	oneLayer - rat 1	0	-0.09390301	0.072405	false
recall	oneLayer	oneLayer - rat 1	0	-0.09810053	0.062271316	false
recall	oneLayer	oneLayer - rat 1	0	-0.10222804	0.052306615	false
recall	oneLayer	oneLayer - rat 1	0	-0.10978044	0.044754215	false
recall	oneLayer	oneLayer - rat 1	0	-0.113798745	0.03505318	false
recall	oneLayer	oneLayer - rat 1	0	-0.113798745	0.024397193	false
recall	oneLayer	oneLayer - rat 1	0	-0.10995304	0.015112847	false
recall	oneLayer	oneLayer - rat 1	0	-0.10995304	0.004609966	false
recall	oneLayer	oneLayer - rat 1	0	-0.10995304	-0.0056635193	false
recall	oneLayer	oneLayer - rat 1	0	-0.109953046	-0.016095389	false
recall	oneLayer	oneLayer - rat 1	0	-0.11407563	-0.026048196	false
recall	oneLayer	oneLayer - rat 1	0	-0.11407563	-0.036146082	false
recall	oneLayer	oneLayer - rat 1	0	-0.10993951	-0.046131562	false
recall	oneLayer	oneLayer - rat 1	0	-0.102312066	-0.05375901	false
recall	oneLayer	oneLayer - rat 1	0	-0.094931066	-0.06114001	false
recall	oneLayer	oneLayer - rat 1	0	-0.08769795	-0.06837312	false
recall	oneLayer	oneLayer - rat 1	0	-0.07780604	-0.072470486	false
recall	oneLayer	oneLayer - rat 1	0	-0.07020739	-0.08006913	false
recall	oneLayer	oneLayer - rat 1	0	-0.06264054	-0.08763599	false
recall	oneLayer	oneLayer - rat 1	0	-0.058583777	-0.09742987	false
recall	oneLayer	oneLayer - rat 1	0	-0.054403465	-0.10752204	false
recall	oneLayer	oneLayer - rat 1	0	-0.050416864	-0.117146544	false
recall	oneLayer	oneLayer - rat 1	0	-0.042930976	-0.12463244	false
recall	oneLayer	oneLayer - rat 1	0	-0.035604313	-0.1319591	false
recall	oneLayer	oneLayer - rat 1	0	-0.02561886	-0.13609521	false
recall	oneLayer	oneLayer - rat 1	0	-0.014743898	-0.13609521	false
recall	oneLayer	oneLayer - rat 1	0	-0.0050856075	-0.1400958	false
recall	oneLayer	oneLayer - rat 1	0	0.004270457	-0.14397122	false
recall	oneLayer	oneLayer - rat 1	0	0.01161192	-0.15131268	false
recall	oneLayer	oneLayer - rat 1	0	0.018964393	-0.15866515	false
recall	oneLayer	oneLayer - rat 1	0	0.022853384	-0.168054	false
recall	oneLayer	oneLayer - rat 1	0	0.02686097	-0.17772917	false
recall	oneLayer	oneLayer - rat 1	0	0.034353137	-0.18522134	false
recall	oneLayer	oneLayer - rat 1	0	0.041445527	-0.19231373	false
recall	oneLayer	oneLayer - rat 1	0	0.051168054	-0.19634093	false
recall	oneLayer	oneLayer - rat 1	0	0.061380595	-0.19634093	false
recall	oneLayer	oneLayer - rat 1	0	0.0714181	-0.20049861	false
recall	oneLayer	oneLayer - rat 1	0	0.080783054	-0.2043777	false
recall	oneLayer	oneLayer - rat 1	0	0.08837791	-0.21197255	false
recall	oneLayer	oneLayer - rat 1	0	0.095824726	-0.21941938	false
recall	oneLayer	oneLayer - rat 1	0	0.1055638	-0.22345343	false
recall	oneLayer	oneLayer - rat 1	0	0.11650843	-0.22345343	false
recall	oneLayer	oneLayer - rat 1	0	0.12620099	-0.21943864	false
recall	oneLayer	oneLayer - rat 1	0	0.13661264	-0.21943864	false
recall	oneLayer	oneLayer - rat 1	0	0.14737748	-0.21943864	false
recall	oneLayer	oneLayer - rat 1	0	0.15682459	-0.22335176	false
recall	oneLayer	oneLayer - rat 1	0	0.16684692	-0.22335176	false
recall	oneLayer	oneLayer - rat 1	0	0.17750728	-0.22335176	false
recall	oneLayer	oneLayer - rat 1	0	0.18750359	-0.21921115	false
recall	oneLayer	oneLayer - rat 1	0	0.19742762	-0.21510048	false
recall	oneLayer	oneLayer - rat 1	0	0.20744169	-0.21095252	false
recall	oneLayer	oneLayer - rat 1	0	0.21735689	-0.2068455	false
recall	oneLayer	oneLayer - rat 1	0	0.22735743	-0.20270315	false
recall	oneLayer	oneLayer - rat 1	0	0.23807415	-0.20270315	false
recall	oneLayer	oneLayer - rat 1	0	0.2479621	-0.19860743	false
recall	oneLayer	oneLayer - rat 1	0	0.25742528	-0.19468765	false
recall	oneLayer	oneLayer - rat 1	0	0.26494154	-0.1871714	false
recall	oneLayer	oneLayer - rat 1	0	0.2721772	-0.17993572	false
recall	oneLayer	oneLayer - rat 1	0	0.2796196	-0.17249332	false
recall	oneLayer	oneLayer - rat 1	0	0.28725797	-0.16485494	false
recall	oneLayer	oneLayer - rat 1	0	0.29680628	-0.1608999	false
recall	oneLayer	oneLayer - rat 1	0	0.30389515	-0.15381105	false
recall	oneLayer	oneLayer - rat 1	0	0.31143644	-0.14626975	false
recall	oneLayer	oneLayer - rat 1	0	0.31904918	-0.13865702	false
recall	oneLayer	oneLayer - rat 1	0	0.32324854	-0.12851883	false
recall	oneLayer	oneLayer - rat 1	0	0.32714224	-0.11911862	false
recall	oneLayer	oneLayer - rat 1	0	0.33131763	-0.109038346	false
recall	oneLayer	oneLayer - rat 1	0	0.3385487	-0.10180729	false
recall	oneLayer	oneLayer - rat 1	0	0.3480649	-0.097865544	false
recall	oneLayer	oneLayer - rat 1	0	0.35742742	-0.093987465	false
recall	oneLayer	oneLayer - rat 1	0	0.36838314	-0.093987465	false
recall	oneLayer	oneLayer - rat 1	0	0.37789717	-0.09792831	false
recall	oneLayer	oneLayer - rat 1	0	0.3880409	-0.10212998	false
recall	oneLayer	oneLayer - rat 1	0	0.39841902	-0.10212998	false
recall	oneLayer	oneLayer - rat 1	0	0.4083911	-0.0979994	false
recall	oneLayer	oneLayer - rat 1	0	0.41573822	-0.09065229	false
recall	oneLayer	oneLayer - rat 1	0	0.42348793	-0.08290257	false
recall	oneLayer	oneLayer - rat 1	0	0.4308658	-0.0755247	false
recall	oneLayer	oneLayer - rat 1	0	0.4349953	-0.065555245	false
recall	oneLayer	oneLayer - rat 1	0	0.4389123	-0.056098733	false
recall	oneLayer	oneLayer - rat 1	0	0.44289753	-0.046477567	false
recall	oneLayer	oneLayer - rat 1	0	0.44690102	-0.036812205	false
recall	oneLayer	oneLayer - rat 1	0	0.44690102	-0.026589667	false
recall	oneLayer	oneLayer - rat 1	0	0.44690102	-0.016220752	false
recall	oneLayer	oneLayer - rat 1	0	0.44272992	-0.006150769	false
recall	oneLayer	oneLayer - rat 1	0	0.43874007	0.0034815434	false
recall	oneLayer	oneLayer - rat 1	0	0.43146744	0.010754175	false
recall	oneLayer	oneLayer - rat 1	0	0.4237321	0.018489515	false
recall	oneLayer	oneLayer - rat 1	0	0.41632658	0.025895035	false
recall	oneLayer	oneLayer - rat 1	0	0.40886542	0.0333562	false
recall	oneLayer	oneLayer - rat 1	0	0.39891565	0.037477523	false
recall	oneLayer	oneLayer - rat 1	0	0.38953963	0.04136121	false
recall	oneLayer	oneLayer - rat 1	0	0.38005918	0.04528813	false
recall	oneLayer	oneLayer - rat 1	0	0.37076238	0.04913899	false
recall	oneLayer	oneLayer - rat 1	0	0.36110863	0.05313771	false
recall	oneLayer	oneLayer - rat 1	0	0.35166535	0.057049245	false
recall	oneLayer	oneLayer - rat 1	0	0.34177956	0.06114407	false
recall	oneLayer	oneLayer - rat 1	0	0.33194444	0.06521791	false
recall	oneLayer	oneLayer - rat 1	0	0.3211512	0.06521791	false
recall	oneLayer	oneLayer - rat 1	0	0.31143203	0.061192095	false
recall	oneLayer	oneLayer - rat 1	0	0.30130845	0.056998774	false
recall	oneLayer	oneLayer - rat 1	0	0.29204455	0.053161547	false
recall	oneLayer	oneLayer - rat 1	0	0.28233472	0.049139597	false
recall	oneLayer	oneLayer - rat 1	0	0.27464834	0.0414532	false
recall	oneLayer	oneLayer - rat 1	0	0.26724687	0.034051757	false
recall	oneLayer	oneLayer - rat 1	0	0.26011536	0.026920235	false
recall	oneLayer	oneLayer - rat 1	0	0.25294074	0.019745614	false
recall	oneLayer	oneLayer - rat 1	0	0.24543342	0.012238288	false
recall	oneLayer	oneLayer - rat 1	0	0.24141607	0.0025395423	false
recall	oneLayer	oneLayer - rat 1	0	0.2373875	-0.0071863197	false
recall	oneLayer	oneLayer - rat 1	0	0.23322646	-0.017231915	false
recall	oneLayer	oneLayer - rat 1	0	0.22924852	-0.026835537	false
recall	oneLayer	oneLayer - rat 1	0	0.22510216	-0.036845747	false
recall	oneLayer	oneLayer - rat 1	0	0.22089644	-0.046999253	false
recall	oneLayer	oneLayer - rat 1	0	0.21700776	-0.05638738	false
recall	oneLayer	oneLayer - rat 1	0	0.20923671	-0.064158425	false
recall	oneLayer	oneLayer - rat 1	0	0.19922943	-0.06830357	false
recall	oneLayer	oneLayer - rat 1	0	0.18974952	-0.07223028	false
recall	oneLayer	oneLayer - rat 1	0	0.18028289	-0.07615149	false
recall	oneLayer	oneLayer - rat 1	0	0.17067349	-0.080131836	false
recall	oneLayer	oneLayer - rat 1	0	0.1613851	-0.08397921	false
recall	oneLayer	oneLayer - rat 1	0	0.15131338	-0.08815106	false
recall	oneLayer	oneLayer - rat 1	0	0.14171308	-0.09212763	false
recall	oneLayer	oneLayer - rat 1	0	0.13224171	-0.09605081	false
recall	oneLayer	oneLayer - rat 1	0	0.12475543	-0.10353709	false
recall	oneLayer	oneLayer - rat 1	0	0.12088822	-0.11287336	false
recall	oneLayer	oneLayer - rat 1	0	0.11678972	-0.122768015	false
recall	oneLayer	oneLayer - rat 1	0	0.1126252	-0.13282208	false
recall	oneLayer	oneLayer - rat 1	0	0.10854159	-0.14268076	false
recall	oneLayer	oneLayer - rat 1	0	0.10445313	-0.15255119	false
recall	oneLayer	oneLayer - rat 1	0	0.10040187	-0.1623318	false
recall	oneLayer	oneLayer - rat 1	0	0.096404016	-0.17198347	false
recall	oneLayer	oneLayer - rat 1	0	0.09640402	-0.18238746	false
recall	oneLayer	oneLayer - rat 1	0	0.09231044	-0.19227022	false
recall	oneLayer	oneLayer - rat 1	0	0.08811331	-0.20240302	false
recall	oneLayer	oneLayer - rat 1	0	0.08415052	-0.21197002	false
recall	oneLayer	oneLayer - rat 1	0	0.07654732	-0.21957323	false
recall	oneLayer	oneLayer - rat 1	0	0.07235248	-0.22970046	false
recall	oneLayer	oneLayer - rat 1	0	0.068177804	-0.23977903	false
recall	oneLayer	oneLayer - rat 1	0	0.06421741	-0.24934027	false
recall	oneLayer	oneLayer - rat 1	0	0.06421741	-0.2598761	false
recall	oneLayer	oneLayer - rat 1	0	0.06421741	-0.26993895	false
recall	oneLayer	oneLayer - rat 1	0	0.060102385	-0.2798735	false
recall	oneLayer	oneLayer - rat 1	0	0.056054886	-0.28964502	false
recall	oneLayer	oneLayer - rat 1	0	0.048545558	-0.29715434	false
recall	oneLayer	oneLayer - rat 1	0	0.040856294	-0.3048436	false
recall	oneLayer	oneLayer - rat 1	0	0.03087329	-0.3089787	false
recall	oneLayer	oneLayer - rat 1	0	0.020738749	-0.31317657	false
recall	oneLayer	oneLayer - rat 1	0	0.010247186	-0.31317657	false
recall	oneLayer	oneLayer - rat 1	0	9.249469E-4	-0.31703797	false
recall	oneLayer	oneLayer - rat 1	0	-0.008817609	-0.32107347	false
recall	oneLayer	oneLayer - rat 1	0	-0.01630931	-0.32856518	false
recall	oneLayer	oneLayer - rat 1	0	-0.023469778	-0.33572564	false
recall	oneLayer	oneLayer - rat 1	0	-0.027568325	-0.34562042	false
recall	oneLayer	oneLayer - rat 1	0	-0.03153087	-0.35518685	false
recall	oneLayer	oneLayer - rat 1	0	-0.035510045	-0.36479345	false
recall	oneLayer	oneLayer - rat 1	0	-0.03941912	-0.37423077	false
recall	oneLayer	oneLayer - rat 1	0	-0.03941912	-0.38481575	false
recall	oneLayer	oneLayer - rat 1	0	-0.039419115	-0.39483216	false
recall	oneLayer	oneLayer - rat 1	0	-0.043300048	-0.40420157	false
recall	oneLayer	oneLayer - rat 1	0	-0.05092531	-0.41182685	false
recall	oneLayer	oneLayer - rat 1	0	-0.058108266	-0.4190098	false
recall	oneLayer	oneLayer - rat 1	0	-0.06751859	-0.42290768	false
recall	oneLayer	oneLayer - rat 1	0	-0.076798104	-0.42675138	false
recall	oneLayer	oneLayer - rat 1	0	-0.08648326	-0.43076313	false
recall	oneLayer	oneLayer - rat 1	0	-0.096536554	-0.43076313	false
recall	oneLayer	oneLayer - rat 1	0	-0.106654495	-0.4265721	false
recall	oneLayer	oneLayer - rat 1	0	-0.11632335	-0.42256716	false
recall	oneLayer	oneLayer - rat 1	0	-0.12640661	-0.41839054	false
recall	oneLayer	oneLayer - rat 1	0	-0.1359878	-0.4144219	false
recall	oneLayer	oneLayer - rat 1	0	-0.14593461	-0.41030177	false
recall	oneLayer	oneLayer - rat 1	0	-0.15587035	-0.40618625	false
recall	oneLayer	oneLayer - rat 1	0	-0.16558596	-0.40216193	false
recall	oneLayer	oneLayer - rat 1	0	-0.17537874	-0.39810562	false
recall	oneLayer	oneLayer - rat 1	0	-0.18621248	-0.39810562	false
recall	oneLayer	oneLayer - rat 1	0	-0.19634649	-0.39390796	false
recall	oneLayer	oneLayer - rat 1	0	-0.20587854	-0.38995966	false
recall	oneLayer	oneLayer - rat 1	0	-0.21513268	-0.3861265	false
recall	oneLayer	oneLayer - rat 1	0	-0.22513185	-0.38198468	false
recall	oneLayer	oneLayer - rat 1	0	-0.23510706	-0.37785283	false
recall	oneLayer	oneLayer - rat 1	0	-0.24275191	-0.37020797	false
recall	oneLayer	oneLayer - rat 1	0	-0.25015956	-0.36280033	false
recall	oneLayer	oneLayer - rat 1	0	-0.25778016	-0.35517973	false
recall	oneLayer	oneLayer - rat 1	0	-0.2653869	-0.34757298	false
recall	oneLayer	oneLayer - rat 1	0	-0.2747783	-0.34368294	false
recall	oneLayer	oneLayer - rat 1	0	-0.28410232	-0.3398208	false
recall	oneLayer	oneLayer - rat 1	0	-0.29136616	-0.33255696	false
recall	oneLayer	oneLayer - rat 1	0	-0.29850766	-0.32541546	false
recall	oneLayer	oneLayer - rat 1	0	-0.30576566	-0.31815746	false
recall	oneLayer	oneLayer - rat 1	0	-0.31336063	-0.3105625	false
recall	oneLayer	oneLayer - rat 1	0	-0.3232914	-0.30644903	false
recall	oneLayer	oneLayer - rat 1	0	-0.33060598	-0.29913446	false
recall	oneLayer	oneLayer - rat 1	0	-0.3379514	-0.29178903	false
recall	oneLayer	oneLayer - rat 1	0	-0.3453959	-0.28434452	false
recall	oneLayer	oneLayer - rat 1	0	-0.35260087	-0.27713957	false
recall	oneLayer	oneLayer - rat 1	0	-0.3600248	-0.26971564	false
recall	oneLayer	oneLayer - rat 1	0	-0.36776102	-0.2619794	false
recall	oneLayer	oneLayer - rat 1	0	-0.37487552	-0.2548649	false
recall	oneLayer	oneLayer - rat 1	0	-0.38198805	-0.2477524	false
recall	oneLayer	oneLayer - rat 1	0	-0.3891233	-0.24061714	false
recall	oneLayer	oneLayer - rat 1	0	-0.39644775	-0.23329268	false
recall	oneLayer	oneLayer - rat 1	0	-0.40354156	-0.22619887	false
recall	oneLayer	oneLayer - rat 1	0	-0.4112378	-0.21850263	false
recall	oneLayer	oneLayer - rat 1	0	-0.41521168	-0.20890887	false
recall	oneLayer	oneLayer - rat 1	0	-0.41521168	-0.19890548	false
recall	oneLayer	oneLayer - rat 1	0	-0.41923463	-0.18919319	false
recall	oneLayer	oneLayer - rat 1	0	-0.41923463	-0.17829794	false
recall	oneLayer	oneLayer - rat 1	0	-0.42344195	-0.16814059	false
recall	oneLayer	oneLayer - rat 1	0	-0.42344195	-0.15738568	false
recall	oneLayer	oneLayer - rat 1	0	-0.42731673	-0.14803116	false
recall	oneLayer	oneLayer - rat 1	0	-0.43135497	-0.13828199	false
recall	oneLayer	oneLayer - rat 1	0	-0.43135497	-0.12775522	false
recall	oneLayer	oneLayer - rat 1	0	-0.43520334	-0.11846443	false
recall	oneLayer	oneLayer - rat 1	0	-0.43924284	-0.108712174	false
recall	oneLayer	oneLayer - rat 1	0	-0.44325754	-0.09901986	false
recall	oneLayer	oneLayer - rat 1	0	-0.44717333	-0.08956634	false
recall	oneLayer	oneLayer - rat 1	0	-0.44717333	-0.07946573	false
recall	oneLayer	oneLayer - rat 1	0	-0.45113558	-0.0699	false
recall	oneLayer	oneLayer - rat 1	0	-0.45519522	-0.060099162	false
recall	oneLayer	oneLayer - rat 1	0	-0.45938516	-0.049983755	false
recall	oneLayer	oneLayer - rat 1	0	-0.4634187	-0.040245913	false
recall	oneLayer	oneLayer - rat 1	0	-0.4634187	-0.0301262	false
recall	oneLayer	oneLayer - rat 1	0	-0.4634187	-0.019338343	false
recall	oneLayer	oneLayer - rat 1	0	-0.4634187	-0.009101312	false
recall	oneLayer	oneLayer - rat 1	0	-0.4634187	0.0012732102	false
recall	oneLayer	oneLayer - rat 1	0	-0.4634187	0.011712138	false
recall	oneLayer	oneLayer - rat 1	0	-0.4634187	0.022694949	false
recall	oneLayer	oneLayer - rat 1	0	-0.4634187	0.03314679	false
recall	oneLayer	oneLayer - rat 1	0	-0.4634187	0.044083007	false
recall	oneLayer	oneLayer - rat 1	0	-0.4634187	0.05484684	false
recall	oneLayer	oneLayer - rat 1	0	-0.4634187	0.06570004	false
recall	oneLayer	oneLayer - rat 1	0	-0.4634187	0.07663166	false
recall	oneLayer	oneLayer - rat 1	0	-0.46341872	0.08721275	false
recall	oneLayer	oneLayer - rat 1	0	-0.46341872	0.09753445	false
recall	oneLayer	oneLayer - rat 1	0	-0.45957744	0.10680812	false
recall	oneLayer	oneLayer - rat 1	0	-0.45541802	0.11684982	false
recall	oneLayer	oneLayer - rat 1	0	-0.4512303	0.1269599	false
recall	oneLayer	oneLayer - rat 1	0	-0.44712025	0.13688238	false
recall	oneLayer	oneLayer - rat 1	0	-0.44305268	0.14670241	false
recall	oneLayer	oneLayer - rat 1	0	-0.4389149	0.15669186	false
recall	oneLayer	oneLayer - rat 1	0	-0.43127048	0.16433628	false
recall	oneLayer	oneLayer - rat 1	0	-0.4238617	0.17174505	false
recall	oneLayer	oneLayer - rat 1	0	-0.41616678	0.17943998	false
recall	oneLayer	oneLayer - rat 1	0	-0.4062464	0.18354914	false
recall	oneLayer	oneLayer - rat 1	0	-0.39639604	0.1876293	false
recall	oneLayer	oneLayer - rat 1	0	-0.3892745	0.19475083	false
recall	oneLayer	oneLayer - rat 1	0	-0.38216767	0.20185764	false
recall	oneLayer	oneLayer - rat 1	0	-0.3746011	0.20942423	false
recall	oneLayer	oneLayer - rat 1	0	-0.36446172	0.21362409	false
recall	oneLayer	oneLayer - rat 1	0	-0.35454008	0.21773377	false
recall	oneLayer	oneLayer - rat 1	0	-0.34690267	0.22537117	false
recall	oneLayer	oneLayer - rat 1	0	-0.3391317	0.23314214	false
recall	oneLayer	oneLayer - rat 1	0	-0.33202827	0.24024558	false
recall	oneLayer	oneLayer - rat 1	0	-0.32489124	0.24738261	false
recall	oneLayer	oneLayer - rat 1	0	-0.31476328	0.25157776	false
recall	oneLayer	oneLayer - rat 1	0	-0.30726662	0.25907442	false
recall	oneLayer	oneLayer - rat 1	0	-0.30343303	0.26832953	false
recall	oneLayer	oneLayer - rat 1	0	-0.29940012	0.27806577	false
recall	oneLayer	oneLayer - rat 1	0	-0.29523683	0.28811693	false
recall	oneLayer	oneLayer - rat 1	0	-0.29118136	0.29790768	false
recall	oneLayer	oneLayer - rat 1	0	-0.28718382	0.30755857	false
recall	oneLayer	oneLayer - rat 1	0	-0.28314155	0.3173175	false
recall	oneLayer	oneLayer - rat 1	0	-0.2791858	0.3268675	false
recall	oneLayer	oneLayer - rat 1	0	-0.2750235	0.33691624	false
recall	oneLayer	oneLayer - rat 1	0	-0.27104858	0.3465125	false
recall	oneLayer	oneLayer - rat 1	0	-0.26691988	0.35648003	false
recall	oneLayer	oneLayer - rat 1	0	-0.259232	0.3641679	false
recall	oneLayer	oneLayer - rat 1	0	-0.24928574	0.3682878	false
recall	oneLayer	oneLayer - rat 1	0	-0.23918606	0.3682878	false
recall	oneLayer	oneLayer - rat 1	0	-0.22897781	0.3682878	false
recall	oneLayer	oneLayer - rat 1	0	-0.21914141	0.37236217	false
recall	oneLayer	oneLayer - rat 1	0	-0.20964257	0.3762967	false
recall	oneLayer	oneLayer - rat 1	0	-0.20221575	0.38372353	false
recall	oneLayer	oneLayer - rat 1	0	-0.19485775	0.39108154	false
recall	oneLayer	oneLayer - rat 1	0	-0.1877365	0.3982028	false
recall	oneLayer	oneLayer - rat 1	0	-0.17845413	0.40204766	false
recall	oneLayer	oneLayer - rat 1	0	-0.1685102	0.40616658	false
recall	oneLayer	oneLayer - rat 1	0	-0.15802643	0.40616658	false
recall	oneLayer	oneLayer - rat 1	0	-0.1478739	0.40196127	false
recall	oneLayer	oneLayer - rat 1	0	-0.13692579	0.40196127	false
recall	oneLayer	oneLayer - rat 1	0	-0.12641187	0.40196127	false
recall	oneLayer	oneLayer - rat 1	0	-0.11689825	0.40590194	false
recall	oneLayer	oneLayer - rat 1	0	-0.10749481	0.40979698	false
recall	oneLayer	oneLayer - rat 1	0	-0.09776967	0.41382527	false
recall	oneLayer	oneLayer - rat 1	0	-0.08765065	0.4180167	false
recall	oneLayer	oneLayer - rat 1	0	-0.0775742	0.4221905	false
recall	oneLayer	oneLayer - rat 1	0	-0.067512065	0.4221905	false
recall	oneLayer	oneLayer - rat 1	0	-0.057970934	0.41823843	false
recall	oneLayer	oneLayer - rat 1	0	-0.048051912	0.41412982	false
recall	oneLayer	oneLayer - rat 1	0	-0.037451293	0.41412982	false
recall	oneLayer	oneLayer - rat 1	0	-0.027577594	0.41004002	false
recall	oneLayer	oneLayer - rat 1	0	-0.017926779	0.40604252	false
recall	oneLayer	oneLayer - rat 1	0	-0.010297859	0.3984136	false
recall	oneLayer	oneLayer - rat 1	0	-5.487905E-4	0.3943754	false
recall	oneLayer	oneLayer - rat 1	0	0.009566236	0.39018562	false
recall	oneLayer	oneLayer - rat 1	0	0.016783949	0.38296792	false
recall	oneLayer	oneLayer - rat 1	0	0.024036283	0.37571558	false
recall	oneLayer	oneLayer - rat 1	0	0.031813454	0.3679384	false
recall	oneLayer	oneLayer - rat 1	0	0.041407824	0.3639643	false
recall	oneLayer	oneLayer - rat 1	0	0.052338827	0.3639643	false
recall	oneLayer	oneLayer - rat 1	0	0.062166214	0.35989365	false
recall	oneLayer	oneLayer - rat 1	0	0.07161831	0.35597846	false
recall	oneLayer	oneLayer - rat 1	0	0.07917405	0.34842274	false
recall	oneLayer	oneLayer - rat 1	0	0.08632947	0.3412673	false
recall	oneLayer	oneLayer - rat 1	0	0.09379904	0.33379772	false
recall	oneLayer	oneLayer - rat 1	0	0.10152586	0.3260709	false
recall	oneLayer	oneLayer - rat 1	0	0.11153499	0.32192498	false
recall	oneLayer	oneLayer - rat 1	0	0.11899782	0.31446216	false
recall	oneLayer	oneLayer - rat 1	0	0.12676395	0.30669603	false
recall	oneLayer	oneLayer - rat 1	0	0.13421278	0.2992472	false
recall	oneLayer	oneLayer - rat 1	0	0.14195026	0.29150972	false
recall	oneLayer	oneLayer - rat 1	0	0.14595608	0.28183883	false
recall	oneLayer	oneLayer - rat 1	0	0.15350892	0.274286	false
recall	oneLayer	oneLayer - rat 1	0	0.16298544	0.27036068	false
recall	oneLayer	oneLayer - rat 1	0	0.17061861	0.26272753	false
recall	oneLayer	oneLayer - rat 1	0	0.17797878	0.25536734	false
recall	oneLayer	oneLayer - rat 1	0	0.18544538	0.24790075	false
recall	oneLayer	oneLayer - rat 1	0	0.19520335	0.24385887	false
recall	oneLayer	oneLayer - rat 1	0	0.20244092	0.2366213	false
recall	oneLayer	oneLayer - rat 1	0	0.210091	0.22897123	false
recall	oneLayer	oneLayer - rat 1	0	0.21951984	0.22506566	false
recall	oneLayer	oneLayer - rat 1	0	0.2295521	0.22506566	false
recall	oneLayer	oneLayer - rat 1	0	0.24004617	0.22506566	false
recall	oneLayer	oneLayer - rat 1	0	0.24943863	0.22117518	false
recall	oneLayer	oneLayer - rat 1	0	0.25652012	0.21409369	false
recall	oneLayer	oneLayer - rat 1	0	0.26372194	0.20689186	false
recall	oneLayer	oneLayer - rat 1	0	0.27372444	0.20274869	false
recall	oneLayer	oneLayer - rat 1	0	0.28378475	0.19858158	false
recall	oneLayer	oneLayer - rat 1	0	0.29409802	0.19858158	false
recall	oneLayer	oneLayer - rat 1	0	0.30391115	0.20264632	false
recall	oneLayer	oneLayer - rat 1	0	0.31324825	0.20651385	false
recall	oneLayer	oneLayer - rat 1	0	0.32389447	0.20651385	false
recall	oneLayer	oneLayer - rat 1	0	0.3334134	0.20257099	false
recall	oneLayer	oneLayer - rat 1	0	0.34074527	0.19523913	false
recall	oneLayer	oneLayer - rat 1	0	0.34796983	0.18801457	false
recall	oneLayer	oneLayer - rat 1	0	0.35531932	0.18066508	false
recall	oneLayer	oneLayer - rat 1	0	0.36506894	0.17662665	false
recall	oneLayer	oneLayer - rat 1	0	0.37483895	0.17257978	false
recall	oneLayer	oneLayer - rat 1	0	0.38413262	0.16873021	false
recall	oneLayer	oneLayer - rat 1	0	0.39120933	0.16165349	false
recall	oneLayer	oneLayer - rat 1	0	0.39883336	0.15402947	false
recall	oneLayer	oneLayer - rat 1	0	0.40612972	0.1467331	false
recall	oneLayer	oneLayer - rat 1	0	0.4103037	0.13665618	false
recall	oneLayer	oneLayer - rat 1	0	0.4180707	0.12888919	false
recall	oneLayer	oneLayer - rat 1	0	0.4220271	0.11933761	false
recall	oneLayer	oneLayer - rat 1	0	0.42614076	0.10940636	false
recall	oneLayer	oneLayer - rat 1	0	0.43010873	0.09982688	false
recall	oneLayer	oneLayer - rat 1	0	0.43010873	0.08973115	false
recall	oneLayer	oneLayer - rat 1	0	0.43398404	0.08037527	false
recall	oneLayer	oneLayer - rat 1	0	0.43398404	0.069812216	false
recall	oneLayer	oneLayer - rat 1	0	0.438183	0.05967499	false
recall	oneLayer	oneLayer - rat 1	0	0.438183	0.049304213	false
recall	oneLayer	oneLayer - rat 1	0	0.438183	0.0386674	false
recall	oneLayer	oneLayer - rat 1	0	0.43409142	0.028789373	false
recall	oneLayer	oneLayer - rat 1	0	0.43409142	0.018283067	false
recall	oneLayer	oneLayer - rat 1	0	0.43409142	0.008134204	false
recall	oneLayer	oneLayer - rat 1	0	0.42999956	-0.001744398	false
recall	oneLayer	oneLayer - rat 1	0	0.42254043	-0.009203523	false
recall	oneLayer	oneLayer - rat 1	0	0.4185895	-0.018741878	false
recall	oneLayer	oneLayer - rat 1	0	0.4185895	-0.029103538	false
recall	oneLayer	oneLayer - rat 1	0	0.4144496	-0.03909818	false
recall	oneLayer	oneLayer - rat 1	0	0.40689144	-0.04665634	false
recall	oneLayer	oneLayer - rat 1	0	0.3971666	-0.050684493	false
recall	oneLayer	oneLayer - rat 1	0	0.38653123	-0.050684493	false
recall	oneLayer	oneLayer - rat 1	0	0.37709653	-0.054592464	false
recall	oneLayer	oneLayer - rat 1	0	0.36638886	-0.054592464	false
recall	oneLayer	oneLayer - rat 1	0	0.3564225	-0.05046426	false
recall	oneLayer	oneLayer - rat 1	0	0.34631565	-0.04627786	false
recall	oneLayer	oneLayer - rat 1	0	0.33679807	-0.042335548	false
recall	oneLayer	oneLayer - rat 1	0	0.32669812	-0.038152013	false
recall	oneLayer	oneLayer - rat 1	0	0.31739077	-0.034296773	false
recall	oneLayer	oneLayer - rat 1	0	0.30813357	-0.030462317	false
recall	oneLayer	oneLayer - rat 1	0	0.2986464	-0.026532605	false
recall	oneLayer	oneLayer - rat 1	0	0.28923497	-0.02263426	false
recall	oneLayer	oneLayer - rat 1	0	0.27961844	-0.018650962	false
recall	oneLayer	oneLayer - rat 1	0	0.27025816	-0.014773812	false
recall	oneLayer	oneLayer - rat 1	0	0.2601972	-0.010606419	false
recall	oneLayer	oneLayer - rat 1	0	0.2503898	-0.0065440675	false
recall	oneLayer	oneLayer - rat 1	0	0.24039768	-0.002405188	false
recall	oneLayer	oneLayer - rat 1	0	0.23062134	0.001644304	false
recall	oneLayer	oneLayer - rat 1	0	0.2202184	0.001644305	false
recall	oneLayer	oneLayer - rat 1	0	0.21022166	0.005785095	false
recall	oneLayer	oneLayer - rat 1	0	0.20075232	0.009707424	false
recall	oneLayer	oneLayer - rat 1	0	0.19062266	0.013903273	false
recall	oneLayer	oneLayer - rat 1	0	0.18129367	0.017767467	false
recall	oneLayer	oneLayer - rat 1	0	0.17179453	0.021702135	false
recall	oneLayer	oneLayer - rat 1	0	0.16248482	0.025558343	false
recall	oneLayer	oneLayer - rat 1	0	0.15259045	0.02965673	false
recall	oneLayer	oneLayer - rat 1	0	0.1429725	0.03364062	false
recall	oneLayer	oneLayer - rat 1	0	0.13525766	0.041355457	false
recall	oneLayer	oneLayer - rat 1	0	0.12782867	0.048784446	false
recall	oneLayer	oneLayer - rat 1	0	0.12051503	0.05609808	false
recall	oneLayer	oneLayer - rat 1	0	0.11323345	0.063379675	false
recall	oneLayer	oneLayer - rat 1	0	0.10548017	0.07113295	false
recall	oneLayer	oneLayer - rat 1	0	0.09806664	0.07854648	false
recall	oneLayer	oneLayer - rat 1	0	0.08857905	0.08247637	false
recall	oneLayer	oneLayer - rat 1	0	0.08125972	0.0897957	false
recall	oneLayer	oneLayer - rat 1	0	0.07364964	0.097405784	false
recall	oneLayer	oneLayer - rat 1	0	0.06588379	0.105171636	false
recall	oneLayer	oneLayer - rat 1	0	0.05843099	0.11262444	false
recall	oneLayer	oneLayer - rat 1	0	0.0506867	0.120368734	false
recall	oneLayer	oneLayer - rat 1	0	0.042923693	0.12813173	false
recall	oneLayer	oneLayer - rat 1	0	0.035478063	0.13557737	false
recall	oneLayer	oneLayer - rat 1	0	0.02832188	0.14273356	false
recall	oneLayer	oneLayer - rat 1	0	0.020860257	0.15019518	false
recall	oneLayer	oneLayer - rat 1	0	0.013182949	0.15787248	false
recall	oneLayer	oneLayer - rat 1	0	0.009019624	0.16792364	false
recall	oneLayer	oneLayer - rat 1	0	0.0051619816	0.17723683	false
recall	oneLayer	oneLayer - rat 1	0	0.001044957	0.1871762	false
recall	oneLayer	oneLayer - rat 1	0	-0.0030813804	0.19713807	false
recall	oneLayer	oneLayer - rat 1	0	-0.00725088	0.20720413	false
recall	oneLayer	oneLayer - rat 1	0	-0.01132225	0.2170333	false
recall	oneLayer	oneLayer - rat 1	0	-0.015348289	0.22675301	false
recall	oneLayer	oneLayer - rat 1	0	-0.019508226	0.23679599	false
recall	oneLayer	oneLayer - rat 1	0	-0.023600819	0.24667639	false
recall	oneLayer	oneLayer - rat 1	0	-0.02765175	0.2564562	false
recall	oneLayer	oneLayer - rat 1	0	-0.03150458	0.26575777	false
recall	oneLayer	oneLayer - rat 1	0	-0.035454683	0.27529415	false
recall	oneLayer	oneLayer - rat 1	0	-0.0393962	0.28480983	false
recall	oneLayer	oneLayer - rat 1	0	-0.04336802	0.29439867	false
recall	oneLayer	oneLayer - rat 1	0	-0.04336802	0.30539113	false
recall	oneLayer	oneLayer - rat 1	0	-0.04336802	0.3159773	false
recall	oneLayer	oneLayer - rat 1	0	-0.043368015	0.32643676	false
recall	oneLayer	oneLayer - rat 1	0	-0.043368015	0.33738273	false
recall	oneLayer	oneLayer - rat 1	0	-0.04723829	0.34672642	false
recall	oneLayer	oneLayer - rat 1	0	-0.054989133	0.35447726	false
recall	oneLayer	oneLayer - rat 1	0	-0.06457641	0.35844845	false
recall	oneLayer	oneLayer - rat 1	0	-0.07527348	0.35844845	false
recall	oneLayer	oneLayer - rat 1	0	-0.08471161	0.35453904	false
recall	oneLayer	oneLayer - rat 1	0	-0.09211734	0.3471333	false
recall	oneLayer	oneLayer - rat 1	0	-0.096021	0.33770904	false
recall	oneLayer	oneLayer - rat 1	0	-0.09991361	0.32831144	false
recall	oneLayer	oneLayer - rat 1	0	-0.10768722	0.32053784	false
recall	oneLayer	oneLayer - rat 1	0	-0.111596756	0.31109938	false
recall	oneLayer	oneLayer - rat 1	0	-0.11553589	0.30158946	false
recall	oneLayer	oneLayer - rat 1	0	-0.1194111	0.29223385	false
recall	oneLayer	oneLayer - rat 1	0	-0.1194111	0.28196806	false
recall	oneLayer	oneLayer - rat 1	0	-0.123464495	0.27218232	false
recall	oneLayer	oneLayer - rat 1	0	-0.12743537	0.26259577	false
recall	oneLayer	oneLayer - rat 1	0	-0.13462497	0.25540617	false
recall	oneLayer	oneLayer - rat 1	0	-0.14204387	0.24798727	false
recall	oneLayer	oneLayer - rat 1	0	-0.14617005	0.23802583	false
recall	oneLayer	oneLayer - rat 1	0	-0.15028463	0.22809231	false
recall	oneLayer	oneLayer - rat 1	0	-0.154134	0.21879911	false
recall	oneLayer	oneLayer - rat 1	0	-0.154134	0.20830894	false
recall	oneLayer	oneLayer - rat 1	0	-0.154134	0.19760656	false
recall	oneLayer	oneLayer - rat 1	0	-0.15824717	0.1876765	false
recall	oneLayer	oneLayer - rat 1	0	-0.1624356	0.17756473	false
recall	oneLayer	oneLayer - rat 1	0	-0.16644387	0.16788793	false
recall	oneLayer	oneLayer - rat 1	0	-0.17403305	0.16029875	false
recall	oneLayer	oneLayer - rat 1	0	-0.1841872	0.15609276	false
recall	oneLayer	oneLayer - rat 1	0	-0.19369133	0.15215603	false
recall	oneLayer	oneLayer - rat 1	0	-0.20324719	0.14819786	false
recall	oneLayer	oneLayer - rat 1	0	-0.2129934	0.14416085	false
recall	oneLayer	oneLayer - rat 1	0	-0.22048558	0.13666867	false
recall	oneLayer	oneLayer - rat 1	0	-0.22765471	0.12949954	false
recall	oneLayer	oneLayer - rat 1	0	-0.2317325	0.11965487	false
recall	oneLayer	oneLayer - rat 1	0	-0.2358623	0.10968466	false
recall	oneLayer	oneLayer - rat 1	0	-0.2398094	0.10015555	false
recall	oneLayer	oneLayer - rat 1	0	-0.24704412	0.09292082	false
recall	oneLayer	oneLayer - rat 1	0	-0.25643742	0.08902998	false
recall	oneLayer	oneLayer - rat 1	0	-0.26638827	0.0849082	false
recall	oneLayer	oneLayer - rat 1	0	-0.27584502	0.0809911	false
recall	oneLayer	oneLayer - rat 1	0	-0.28357273	0.07326338	false
recall	oneLayer	oneLayer - rat 1	0	-0.29133904	0.06549707	false
recall	oneLayer	oneLayer - rat 1	0	-0.29905418	0.057781953	false
recall	oneLayer	oneLayer - rat 1	0	-0.30289397	0.04851186	false
recall	oneLayer	oneLayer - rat 1	0	-0.30679366	0.039097186	false
recall	oneLayer	oneLayer - rat 1	0	-0.31391984	0.031970993	false
recall	oneLayer	oneLayer - rat 1	0	-0.3213286	0.02456224	false
recall	oneLayer	oneLayer - rat 1	0	-0.3313075	0.02042885	false
recall	oneLayer	oneLayer - rat 1	0	-0.34190208	0.02042885	false
recall	oneLayer	oneLayer - rat 1	0	-0.35128573	0.024315685	false
recall	oneLayer	oneLayer - rat 1	0	-0.3618819	0.024315685	false
recall	oneLayer	oneLayer - rat 1	0	-0.37170297	0.020247662	false
recall	oneLayer	oneLayer - rat 1	0	-0.38133067	0.01625974	false
recall	oneLayer	oneLayer - rat 1	0	-0.3914062	0.012086314	false
recall	oneLayer	oneLayer - rat 1	0	-0.39897287	0.0045196656	false
recall	oneLayer	oneLayer - rat 1	0	-0.40647423	-0.0029817005	false
recall	oneLayer	oneLayer - rat 1	0	-0.41361454	-0.010121999	false
recall	oneLayer	oneLayer - rat 1	0	-0.41746023	-0.019406347	false
recall	oneLayer	oneLayer - rat 1	0	-0.42460766	-0.026553767	false
recall	oneLayer	oneLayer - rat 1	0	-0.42857784	-0.036138628	false
recall	oneLayer	oneLayer - rat 1	0	-0.43268532	-0.04605494	false
recall	oneLayer	oneLayer - rat 1	0	-0.43669832	-0.055743158	false
recall	oneLayer	oneLayer - rat 1	0	-0.4405879	-0.065133505	false
recall	oneLayer	oneLayer - rat 1	0	-0.4405879	-0.07517974	false
recall	oneLayer	oneLayer - rat 1	0	-0.4405879	-0.08521471	false
recall	oneLayer	oneLayer - rat 1	0	-0.4405879	-0.095863484	false
recall	oneLayer	oneLayer - rat 1	0	-0.4405879	-0.10660416	false
recall	oneLayer	oneLayer - rat 1	0	-0.4405879	-0.11702727	false
recall	oneLayer	oneLayer - rat 1	0	-0.4405879	-0.12790309	false
recall	oneLayer	oneLayer - rat 1	0	-0.4405879	-0.13822031	false
recall	oneLayer	oneLayer - rat 1	0	-0.43660146	-0.1478445	false
recall	oneLayer	oneLayer - rat 1	0	-0.43268615	-0.15729687	false
recall	oneLayer	oneLayer - rat 1	0	-0.4285001	-0.16740292	false
recall	oneLayer	oneLayer - rat 1	0	-0.4245552	-0.17692666	false
recall	oneLayer	oneLayer - rat 1	0	-0.42068875	-0.18626118	false
recall	oneLayer	oneLayer - rat 1	0	-0.416695	-0.1959029	false
recall	oneLayer	oneLayer - rat 1	0	-0.41269413	-0.20556189	false
recall	oneLayer	oneLayer - rat 1	0	-0.40874448	-0.21509713	false
recall	oneLayer	oneLayer - rat 1	0	-0.40478513	-0.22465591	false
recall	oneLayer	oneLayer - rat 1	0	-0.40070838	-0.23449801	false
recall	oneLayer	oneLayer - rat 1	0	-0.39686576	-0.24377494	false
recall	oneLayer	oneLayer - rat 1	0	-0.39275882	-0.25368997	false
recall	oneLayer	oneLayer - rat 1	0	-0.38872638	-0.2634251	false
recall	oneLayer	oneLayer - rat 1	0	-0.38471958	-0.27309844	false
recall	oneLayer	oneLayer - rat 1	0	-0.37744415	-0.28037387	false
recall	oneLayer	oneLayer - rat 1	0	-0.3697279	-0.2880901	false
recall	oneLayer	oneLayer - rat 1	0	-0.3625307	-0.2952873	false
recall	oneLayer	oneLayer - rat 1	0	-0.3548269	-0.30299112	false
recall	oneLayer	oneLayer - rat 1	0	-0.34765023	-0.31016776	false
recall	oneLayer	oneLayer - rat 1	0	-0.34009212	-0.3177259	false
recall	oneLayer	oneLayer - rat 1	0	-0.33266258	-0.3251554	false
recall	oneLayer	oneLayer - rat 1	0	-0.3251416	-0.3326764	false
recall	oneLayer	oneLayer - rat 1	0	-0.31747892	-0.34033906	false
recall	oneLayer	oneLayer - rat 1	0	-0.31009385	-0.34772417	false
recall	oneLayer	oneLayer - rat 1	0	-0.30253172	-0.3552863	false
recall	oneLayer	oneLayer - rat 1	0	-0.2951402	-0.3626778	false
recall	oneLayer	oneLayer - rat 1	0	-0.28797185	-0.36984617	false
recall	oneLayer	oneLayer - rat 1	0	-0.2807595	-0.37705848	false
recall	oneLayer	oneLayer - rat 1	0	-0.27320284	-0.38461518	false
recall	oneLayer	oneLayer - rat 1	0	-0.26589853	-0.3919195	false
recall	oneLayer	oneLayer - rat 1	0	-0.25582656	-0.39609143	false
recall	oneLayer	oneLayer - rat 1	0	-0.24591607	-0.4001965	false
recall	oneLayer	oneLayer - rat 1	0	-0.23609538	-0.40426436	false
recall	oneLayer	oneLayer - rat 1	0	-0.22661522	-0.40819117	false
recall	oneLayer	oneLayer - rat 1	0	-0.21719404	-0.41209355	false
recall	oneLayer	oneLayer - rat 1	0	-0.2077281	-0.41601446	false
recall	oneLayer	oneLayer - rat 1	0	-0.19806457	-0.42001724	false
recall	oneLayer	oneLayer - rat 1	0	-0.1887131	-0.42389074	false
recall	oneLayer	oneLayer - rat 1	0	-0.17897312	-0.42792517	false
recall	oneLayer	oneLayer - rat 1	0	-0.16972865	-0.43175435	false
recall	oneLayer	oneLayer - rat 1	0	-0.16014904	-0.43572235	false
recall	oneLayer	oneLayer - rat 1	0	-0.15085497	-0.4395721	false
recall	oneLayer	oneLayer - rat 1	0	-0.14073384	-0.4437644	false
recall	oneLayer	oneLayer - rat 1	0	-0.13114986	-0.4477342	false
recall	oneLayer	oneLayer - rat 1	0	-0.12127513	-0.45182446	false
recall	oneLayer	oneLayer - rat 1	0	-0.11128591	-0.45596212	false
recall	oneLayer	oneLayer - rat 1	0	-0.10151865	-0.46000788	false
recall	oneLayer	oneLayer - rat 1	0	-0.09167287	-0.46408612	false
recall	oneLayer	oneLayer - rat 1	0	-0.08139375	-0.46408612	false
recall	oneLayer	oneLayer - rat 1	0	-0.07117389	-0.46408612	false
recall	oneLayer	oneLayer - rat 1	0	-0.060696088	-0.46408612	false
recall	oneLayer	oneLayer - rat 1	0	-0.050508633	-0.46408612	false
recall	oneLayer	oneLayer - rat 1	0	-0.039890483	-0.46408612	false
recall	oneLayer	oneLayer - rat 1	0	-0.029194389	-0.46408612	false
recall	oneLayer	oneLayer - rat 1	0	-0.018350428	-0.46408612	false
recall	oneLayer	oneLayer - rat 1	0	-0.008287376	-0.46408612	false
recall	oneLayer	oneLayer - rat 1	0	0.002446883	-0.46408612	false
recall	oneLayer	oneLayer - rat 1	0	0.01315304	-0.46408612	false
recall	oneLayer	oneLayer - rat 1	0	0.023651058	-0.46408612	false
recall	oneLayer	oneLayer - rat 1	0	0.034248617	-0.46408612	false
recall	oneLayer	oneLayer - rat 1	0	0.044089783	-0.46000978	false
recall	oneLayer	oneLayer - rat 1	0	0.054175787	-0.455832	false
recall	oneLayer	oneLayer - rat 1	0	0.0635442	-0.4519515	false
recall	oneLayer	oneLayer - rat 1	0	0.07329593	-0.4479122	false
recall	oneLayer	oneLayer - rat 1	0	0.082602315	-0.44405735	false
recall	oneLayer	oneLayer - rat 1	0	0.09269435	-0.4398771	false
recall	oneLayer	oneLayer - rat 1	0	0.10218722	-0.43594503	false
recall	oneLayer	oneLayer - rat 1	0	0.11230818	-0.4317528	false
recall	oneLayer	oneLayer - rat 1	0	0.12231621	-0.42760733	false
recall	oneLayer	oneLayer - rat 1	0	0.13221984	-0.4235051	false
recall	oneLayer	oneLayer - rat 1	0	0.14229047	-0.41933373	false
recall	oneLayer	oneLayer - rat 1	0	0.15168688	-0.4154416	false
recall	oneLayer	oneLayer - rat 1	0	0.1609694	-0.41159666	false
recall	oneLayer	oneLayer - rat 1	0	0.17112306	-0.40739086	false
recall	oneLayer	oneLayer - rat 1	0	0.17882657	-0.39968735	false
recall	oneLayer	oneLayer - rat 1	0	0.18601716	-0.39249676	false
recall	oneLayer	oneLayer - rat 1	0	0.19379486	-0.38471907	false
recall	oneLayer	oneLayer - rat 1	0	0.20092341	-0.3775905	false
recall	oneLayer	oneLayer - rat 1	0	0.20810977	-0.37040415	false
recall	oneLayer	oneLayer - rat 1	0	0.21548569	-0.36302823	false
recall	oneLayer	oneLayer - rat 1	0	0.22325106	-0.35526288	false
recall	oneLayer	oneLayer - rat 1	0	0.23098965	-0.34752426	false
recall	oneLayer	oneLayer - rat 1	0	0.2349365	-0.33799574	false
recall	oneLayer	oneLayer - rat 1	0	0.23895776	-0.32828757	false
recall	oneLayer	oneLayer - rat 1	0	0.24311845	-0.31824276	false
recall	oneLayer	oneLayer - rat 1	0	0.24699731	-0.30887836	false
recall	oneLayer	oneLayer - rat 1	0	0.25115317	-0.29884526	false
recall	oneLayer	oneLayer - rat 1	0	0.25509405	-0.28933114	false
recall	oneLayer	oneLayer - rat 1	0	0.25925943	-0.27927497	false
recall	oneLayer	oneLayer - rat 1	0	0.26311472	-0.26996753	false
recall	oneLayer	oneLayer - rat 1	0	0.26311472	-0.25929642	false
recall	oneLayer	oneLayer - rat 1	0	0.25903696	-0.24945183	false
recall	oneLayer	oneLayer - rat 1	0	0.25150895	-0.24192382	false
recall	oneLayer	oneLayer - rat 1	0	0.24183486	-0.2379167	false
recall	oneLayer	oneLayer - rat 1	0	0.23194638	-0.23382075	false
recall	oneLayer	oneLayer - rat 1	0	0.22173674	-0.23382075	false
recall	oneLayer	oneLayer - rat 1	0	0.21200983	-0.22979173	false
recall	oneLayer	oneLayer - rat 1	0	0.20127894	-0.22979173	false
recall	oneLayer	oneLayer - rat 1	0	0.19075574	-0.22979173	false
recall	oneLayer	oneLayer - rat 1	0	0.18107085	-0.22578011	false
recall	oneLayer	oneLayer - rat 1	0	0.17057584	-0.22578011	false
recall	oneLayer	oneLayer - rat 1	0	0.16050774	-0.22995046	false
recall	oneLayer	oneLayer - rat 1	0	0.15037361	-0.22995046	false
recall	oneLayer	oneLayer - rat 1	0	0.14101878	-0.23382536	false
recall	oneLayer	oneLayer - rat 1	0	0.13149923	-0.23776847	false
recall	oneLayer	oneLayer - rat 1	0	0.121569775	-0.2418814	false
recall	oneLayer	oneLayer - rat 1	0	0.11058809	-0.2418814	false
recall	oneLayer	oneLayer - rat 1	0	0.09990583	-0.2418814	false
recall	oneLayer	oneLayer - rat 1	0	0.090459734	-0.2457941	false
recall	oneLayer	oneLayer - rat 1	0	0.080649845	-0.2498575	false
recall	oneLayer	oneLayer - rat 1	0	0.07304698	-0.25746036	false
recall	oneLayer	oneLayer - rat 1	0	0.06555283	-0.2649545	false
recall	oneLayer	oneLayer - rat 1	0	0.05832464	-0.2721827	false
recall	oneLayer	oneLayer - rat 1	0	0.048245106	-0.2763578	false
recall	oneLayer	oneLayer - rat 1	0	0.038875826	-0.28023866	false
recall	oneLayer	oneLayer - rat 1	0	0.031278256	-0.28783625	false
recall	oneLayer	oneLayer - rat 1	0	0.02145994	-0.29190314	false
recall	oneLayer	oneLayer - rat 1	0	0.013961246	-0.29940182	false
recall	oneLayer	oneLayer - rat 1	0	0.004474469	-0.30333138	false
recall	oneLayer	oneLayer - rat 1	0	-0.0028725225	-0.31067836	false
recall	oneLayer	oneLayer - rat 1	0	-0.010293383	-0.31809923	false
recall	oneLayer	oneLayer - rat 1	0	-0.01955775	-0.32193667	false
recall	oneLayer	oneLayer - rat 1	0	-0.027119277	-0.32949817	false
recall	oneLayer	oneLayer - rat 1	0	-0.036578577	-0.33341634	false
recall	oneLayer	oneLayer - rat 1	0	-0.04418511	-0.34102288	false
recall	oneLayer	oneLayer - rat 1	0	-0.053769816	-0.344993	false
recall	oneLayer	oneLayer - rat 1	0	-0.063856415	-0.349171	false
recall	oneLayer	oneLayer - rat 1	0	-0.07132653	-0.35664114	false
recall	oneLayer	oneLayer - rat 1	0	-0.08066557	-0.36050949	false
recall	oneLayer	oneLayer - rat 1	0	-0.08798266	-0.36782658	false
recall	oneLayer	oneLayer - rat 1	0	-0.09799195	-0.37197256	false
recall	oneLayer	oneLayer - rat 1	0	-0.10567378	-0.3796544	false
recall	oneLayer	oneLayer - rat 1	0	-0.115078434	-0.38354993	false
recall	oneLayer	oneLayer - rat 1	0	-0.12251308	-0.39098457	false
recall	oneLayer	oneLayer - rat 1	0	-0.13262045	-0.3951712	false
recall	oneLayer	oneLayer - rat 1	0	-0.14261012	-0.39930904	false
recall	oneLayer	oneLayer - rat 1	0	-0.15194455	-0.4031755	false
recall	oneLayer	oneLayer - rat 1	0	-0.16252385	-0.4031755	false
recall	oneLayer	oneLayer - rat 1	0	-0.17237379	-0.3990955	false
recall	oneLayer	oneLayer - rat 1	0	-0.18258283	-0.3990955	false
recall	oneLayer	oneLayer - rat 1	0	-0.19332537	-0.39909554	false
recall	oneLayer	oneLayer - rat 1	0	-0.203377	-0.39909554	false
recall	oneLayer	oneLayer - rat 1	0	-0.21306266	-0.39508358	false
recall	oneLayer	oneLayer - rat 1	0	-0.2232176	-0.39087728	false
recall	oneLayer	oneLayer - rat 1	0	-0.23253222	-0.38701904	false
recall	oneLayer	oneLayer - rat 1	0	-0.24230756	-0.38296995	false
recall	oneLayer	oneLayer - rat 1	0	-0.25216445	-0.3788871	false
recall	oneLayer	oneLayer - rat 1	0	-0.26190403	-0.37485284	false
recall	oneLayer	oneLayer - rat 1	0	-0.27202177	-0.3706619	false
recall	oneLayer	oneLayer - rat 1	0	-0.27963513	-0.36304858	false
recall	oneLayer	oneLayer - rat 1	0	-0.28942707	-0.35899264	false
recall	oneLayer	oneLayer - rat 1	0	-0.29880163	-0.35510954	false
recall	oneLayer	oneLayer - rat 1	0	-0.30638754	-0.34752366	false
recall	oneLayer	oneLayer - rat 1	0	-0.31022543	-0.33825815	false
recall	oneLayer	oneLayer - rat 1	0	-0.3173329	-0.33115068	false
recall	oneLayer	oneLayer - rat 1	0	-0.32148913	-0.3211167	false
recall	oneLayer	oneLayer - rat 1	0	-0.32148913	-0.3105889	false
recall	oneLayer	oneLayer - rat 1	0	-0.32559896	-0.3006669	false
recall	oneLayer	oneLayer - rat 1	0	-0.32559896	-0.29037142	false
recall	oneLayer	oneLayer - rat 1	0	-0.32559896	-0.28021097	false
recall	oneLayer	oneLayer - rat 1	0	-0.32974607	-0.2701989	false
recall	oneLayer	oneLayer - rat 1	0	-0.3337394	-0.26055816	false
recall	oneLayer	oneLayer - rat 1	0	-0.34138772	-0.25290987	false
recall	oneLayer	oneLayer - rat 1	0	-0.34873188	-0.2455657	false
recall	oneLayer	oneLayer - rat 1	0	-0.35848197	-0.24152707	false
recall	oneLayer	oneLayer - rat 1	0	-0.368326	-0.23744954	false
recall	oneLayer	oneLayer - rat 1	0	-0.37580973	-0.22996584	false
recall	oneLayer	oneLayer - rat 1	0	-0.38348058	-0.22229499	false
recall	oneLayer	oneLayer - rat 1	0	-0.38757655	-0.21240641	false
recall	oneLayer	oneLayer - rat 1	0	-0.38757655	-0.20227681	false
recall	oneLayer	oneLayer - rat 1	0	-0.38757655	-0.1920453	false
recall	oneLayer	oneLayer - rat 1	0	-0.3837424	-0.18278883	false
recall	oneLayer	oneLayer - rat 1	0	-0.3798226	-0.1733256	false
recall	oneLayer	oneLayer - rat 1	0	-0.37575865	-0.16351436	false
recall	oneLayer	oneLayer - rat 1	0	-0.37160304	-0.15348186	false
recall	oneLayer	oneLayer - rat 1	0	-0.36760762	-0.143836	false
recall	oneLayer	oneLayer - rat 1	0	-0.36340073	-0.1336797	false
recall	oneLayer	oneLayer - rat 1	0	-0.3592216	-0.123590425	false
recall	oneLayer	oneLayer - rat 1	0	-0.3550702	-0.11356801	false
recall	oneLayer	oneLayer - rat 1	0	-0.35114628	-0.10409481	false
recall	oneLayer	oneLayer - rat 1	0	-0.3470795	-0.09427672	false
recall	oneLayer	oneLayer - rat 1	0	-0.3432463	-0.08502264	false
recall	oneLayer	oneLayer - rat 1	0	-0.33910748	-0.07503063	false
recall	oneLayer	oneLayer - rat 1	0	-0.33516556	-0.06551393	false
recall	oneLayer	oneLayer - rat 1	0	-0.33102843	-0.055526033	false
recall	oneLayer	oneLayer - rat 1	0	-0.3269127	-0.045589764	false
recall	oneLayer	oneLayer - rat 1	0	-0.31945696	-0.03813403	false
recall	oneLayer	oneLayer - rat 1	0	-0.31527713	-0.02804303	false
recall	oneLayer	oneLayer - rat 1	0	-0.31527713	-0.017692473	false
recall	oneLayer	oneLayer - rat 1	0	-0.31127644	-0.008033915	false
recall	oneLayer	oneLayer - rat 1	0	-0.3072188	0.0017621049	false
recall	oneLayer	oneLayer - rat 1	0	-0.3030984	0.01170954	false
recall	oneLayer	oneLayer - rat 1	0	-0.29890049	0.02184425	false
recall	oneLayer	oneLayer - rat 1	0	-0.29890049	0.0327148	false
recall	oneLayer	oneLayer - rat 1	0	-0.30287233	0.04230371	false
recall	oneLayer	oneLayer - rat 1	0	-0.3100404	0.049471784	false
recall	oneLayer	oneLayer - rat 1	0	-0.31732854	0.056759913	false
recall	oneLayer	oneLayer - rat 1	0	-0.3249497	0.06438106	false
recall	oneLayer	oneLayer - rat 1	0	-0.33494952	0.06852313	false
recall	oneLayer	oneLayer - rat 1	0	-0.34594628	0.068523124	false
recall	oneLayer	oneLayer - rat 1	0	-0.3561144	0.068523124	false
recall	oneLayer	oneLayer - rat 1	0	-0.36643925	0.068523124	false
recall	oneLayer	oneLayer - rat 1	0	-0.37597767	0.06457218	false
recall	oneLayer	oneLayer - rat 1	0	-0.3856176	0.060579184	false
recall	oneLayer	oneLayer - rat 1	0	-0.3954225	0.056517873	false
recall	oneLayer	oneLayer - rat 1	0	-0.40280938	0.049130984	false
recall	oneLayer	oneLayer - rat 1	0	-0.41002426	0.041916095	false
recall	oneLayer	oneLayer - rat 1	0	-0.41409084	0.032098506	false
recall	oneLayer	oneLayer - rat 1	0	-0.421252	0.02493734	false
recall	oneLayer	oneLayer - rat 1	0	-0.42516127	0.015499496	false
recall	oneLayer	oneLayer - rat 1	0	-0.4326428	0.008018005	false
recall	oneLayer	oneLayer - rat 1	0	-0.43682215	-0.0020718991	false
recall	oneLayer	oneLayer - rat 1	0	-0.44076306	-0.011586128	false
recall	oneLayer	oneLayer - rat 1	0	-0.44076306	-0.022065602	false
recall	oneLayer	oneLayer - rat 1	0	-0.43685654	-0.0314968	false
recall	oneLayer	oneLayer - rat 1	0	-0.42908537	-0.039267953	false
recall	oneLayer	oneLayer - rat 1	0	-0.41933742	-0.043305688	false
recall	oneLayer	oneLayer - rat 1	0	-0.40895498	-0.043305684	false
recall	oneLayer	oneLayer - rat 1	0	-0.3989065	-0.039143473	false
recall	oneLayer	oneLayer - rat 1	0	-0.38802433	-0.03914347	false
recall	oneLayer	oneLayer - rat 1	0	-0.3783075	-0.03511863	false
recall	oneLayer	oneLayer - rat 1	0	-0.37110788	-0.027918998	false
recall	oneLayer	oneLayer - rat 1	0	-0.36720684	-0.018501088	false
recall	oneLayer	oneLayer - rat 1	0	-0.36322966	-0.008899319	false
recall	oneLayer	oneLayer - rat 1	0	-0.35911268	0.0010399694	false
recall	oneLayer	oneLayer - rat 1	0	-0.3549235	0.011153593	false
recall	oneLayer	oneLayer - rat 1	0	-0.3549235	0.021739854	false
recall	oneLayer	oneLayer - rat 1	0	-0.35082376	0.031637434	false
recall	oneLayer	oneLayer - rat 1	0	-0.34690842	0.04108991	false
recall	oneLayer	oneLayer - rat 1	0	-0.34304488	0.050417352	false
recall	oneLayer	oneLayer - rat 1	0	-0.34304488	0.06058344	false
recall	oneLayer	oneLayer - rat 1	0	-0.34694034	0.06998787	false
recall	oneLayer	oneLayer - rat 1	0	-0.3508841	0.079508975	false
recall	oneLayer	oneLayer - rat 1	0	-0.3508841	0.09037417	false
recall	oneLayer	oneLayer - rat 1	0	-0.3549496	0.10018915	false
recall	oneLayer	oneLayer - rat 1	0	-0.35885105	0.10960806	false
recall	oneLayer	oneLayer - rat 1	0	-0.3630301	0.119697176	false
recall	oneLayer	oneLayer - rat 1	0	-0.37063956	0.12730666	false
recall	oneLayer	oneLayer - rat 1	0	-0.37830248	0.13496955	false
recall	oneLayer	oneLayer - rat 1	0	-0.38564983	0.14231691	false
recall	oneLayer	oneLayer - rat 1	0	-0.38955542	0.15174583	false
recall	oneLayer	oneLayer - rat 1	0	-0.39353532	0.1613541	false
recall	oneLayer	oneLayer - rat 1	0	-0.39353532	0.1715223	false
recall	oneLayer	oneLayer - rat 1	0	-0.39353532	0.18218124	false
recall	oneLayer	oneLayer - rat 1	0	-0.389626	0.19161916	false
recall	oneLayer	oneLayer - rat 1	0	-0.3854255	0.20176004	false
recall	oneLayer	oneLayer - rat 1	0	-0.38125703	0.21182366	false
recall	oneLayer	oneLayer - rat 1	0	-0.37708175	0.22190368	false
recall	oneLayer	oneLayer - rat 1	0	-0.37708175	0.23218289	false
recall	oneLayer	oneLayer - rat 1	0	-0.37309548	0.24180661	false
recall	oneLayer	oneLayer - rat 1	0	-0.3691674	0.25128987	false
recall	oneLayer	oneLayer - rat 1	0	-0.36508378	0.26114854	false
recall	oneLayer	oneLayer - rat 1	0	-0.36122426	0.2704663	false
recall	oneLayer	oneLayer - rat 1	0	-0.35705674	0.28052756	false
recall	oneLayer	oneLayer - rat 1	0	-0.35304648	0.2902092	false
recall	oneLayer	oneLayer - rat 1	0	-0.3491782	0.29954803	false
recall	oneLayer	oneLayer - rat 1	0	-0.34163046	0.3070958	false
recall	oneLayer	oneLayer - rat 1	0	-0.332215	0.3109958	false
recall	oneLayer	oneLayer - rat 1	0	-0.3248643	0.3183465	false
recall	oneLayer	oneLayer - rat 1	0	-0.31716624	0.32604456	false
recall	oneLayer	oneLayer - rat 1	0	-0.30792093	0.3298741	false
recall	oneLayer	oneLayer - rat 1	0	-0.29703563	0.3298741	false
recall	oneLayer	oneLayer - rat 1	0	-0.28701153	0.3298741	false
recall	oneLayer	oneLayer - rat 1	0	-0.2769311	0.3298741	false
recall	oneLayer	oneLayer - rat 1	0	-0.26603067	0.3298741	false
recall	oneLayer	oneLayer - rat 1	0	-0.25516084	0.3298741	false
recall	oneLayer	oneLayer - rat 1	0	-0.24444132	0.32987413	false
recall	oneLayer	oneLayer - rat 1	0	-0.23347698	0.32987413	false
recall	oneLayer	oneLayer - rat 1	0	-0.22284645	0.32987413	false
recall	oneLayer	oneLayer - rat 1	0	-0.21188541	0.32987413	false
recall	oneLayer	oneLayer - rat 1	0	-0.20144257	0.32987413	false
recall	oneLayer	oneLayer - rat 1	0	-0.19124699	0.32987413	false
recall	oneLayer	oneLayer - rat 1	0	-0.1802938	0.32987413	false
recall	oneLayer	oneLayer - rat 1	0	-0.16945726	0.32987413	false
recall	oneLayer	oneLayer - rat 1	0	-0.15897548	0.32987413	false
recall	oneLayer	oneLayer - rat 1	0	-0.14863361	0.32987413	false
recall	oneLayer	oneLayer - rat 1	0	-0.13808893	0.32987413	false
recall	oneLayer	oneLayer - rat 1	0	-0.12747382	0.32987413	false
recall	oneLayer	oneLayer - rat 1	0	-0.117256425	0.32987413	false
recall	oneLayer	oneLayer - rat 1	0	-0.10677466	0.32987413	false
recall	oneLayer	oneLayer - rat 1	0	-0.096137874	0.32987413	false
recall	oneLayer	oneLayer - rat 1	0	-0.08586521	0.32987413	false
recall	oneLayer	oneLayer - rat 1	0	-0.07586104	0.32987413	false
recall	oneLayer	oneLayer - rat 1	0	-0.065395035	0.32987416	false
recall	oneLayer	oneLayer - rat 1	0	-0.054842737	0.32987416	false
recall	oneLayer	oneLayer - rat 1	0	-0.044196386	0.32987416	false
recall	oneLayer	oneLayer - rat 1	0	-0.033360824	0.32987416	false
recall	oneLayer	oneLayer - rat 1	0	-0.022568325	0.32987416	false
recall	oneLayer	oneLayer - rat 1	0	-0.011864545	0.32987416	false
recall	oneLayer	oneLayer - rat 1	0	-0.0016023321	0.32987416	false
recall	oneLayer	oneLayer - rat 1	0	0.009341821	0.32987416	false
recall	oneLayer	oneLayer - rat 1	0	0.019321963	0.33400807	false
recall	oneLayer	oneLayer - rat 1	0	0.028663872	0.33787763	false
recall	oneLayer	oneLayer - rat 1	0	0.03835166	0.34189042	false
recall	oneLayer	oneLayer - rat 1	0	0.048162278	0.34595412	false
recall	oneLayer	oneLayer - rat 1	0	0.057841036	0.3499632	false
recall	oneLayer	oneLayer - rat 1	0	0.067888856	0.3499632	false
recall	oneLayer	oneLayer - rat 1	0	0.077957906	0.34996322	false
recall	oneLayer	oneLayer - rat 1	0	0.0878275	0.34587508	false
recall	oneLayer	oneLayer - rat 1	0	0.097280286	0.34195963	false
recall	oneLayer	oneLayer - rat 1	0	0.10675472	0.33803517	false
recall	oneLayer	oneLayer - rat 1	0	0.11621873	0.33411506	false
recall	oneLayer	oneLayer - rat 1	0	0.12557371	0.3302401	false
recall	oneLayer	oneLayer - rat 1	0	0.13560592	0.3260846	false
recall	oneLayer	oneLayer - rat 1	0	0.14524005	0.32209405	false
recall	oneLayer	oneLayer - rat 1	0	0.15520732	0.31796545	false
recall	oneLayer	oneLayer - rat 1	0	0.16519336	0.31382912	false
recall	oneLayer	oneLayer - rat 1	0	0.17517182	0.3096959	false
recall	oneLayer	oneLayer - rat 1	0	0.1847027	0.30574808	false
recall	oneLayer	oneLayer - rat 1	0	0.19456615	0.3016625	false
recall	oneLayer	oneLayer - rat 1	0	0.20430975	0.29762658	false
recall	oneLayer	oneLayer - rat 1	0	0.21431862	0.29348078	false
recall	oneLayer	oneLayer - rat 1	0	0.2243505	0.28932545	false
recall	oneLayer	oneLayer - rat 1	0	0.23433068	0.2851915	false
recall	oneLayer	oneLayer - rat 1	0	0.24425061	0.28108254	false
recall	oneLayer	oneLayer - rat 1	0	0.25419724	0.27696252	false
recall	oneLayer	oneLayer - rat 1	0	0.26354018	0.27309254	false
recall	oneLayer	oneLayer - rat 1	0	0.27354753	0.26894736	false
recall	oneLayer	oneLayer - rat 1	0	0.2835452	0.2648062	false
recall	oneLayer	oneLayer - rat 1	0	0.2929906	0.2608938	false
recall	oneLayer	oneLayer - rat 1	0	0.30238405	0.2570029	false
recall	oneLayer	oneLayer - rat 1	0	0.31186834	0.25307438	false
recall	oneLayer	oneLayer - rat 1	0	0.3215913	0.249047	false
recall	oneLayer	oneLayer - rat 1	0	0.33170208	0.24485898	false
recall	oneLayer	oneLayer - rat 1	0	0.3412185	0.24091715	false
recall	oneLayer	oneLayer - rat 1	0	0.35064968	0.23701063	false
recall	oneLayer	oneLayer - rat 1	0	0.3598915	0.23318253	false
recall	oneLayer	oneLayer - rat 1	0	0.36993343	0.22902304	false
recall	oneLayer	oneLayer - rat 1	0	0.37712675	0.22182974	false
recall	oneLayer	oneLayer - rat 1	0	0.38451368	0.2144428	false
recall	oneLayer	oneLayer - rat 1	0	0.3916831	0.20727338	false
recall	oneLayer	oneLayer - rat 1	0	0.3988423	0.20011418	false
recall	oneLayer	oneLayer - rat 1	0	0.40641627	0.19254021	false
recall	oneLayer	oneLayer - rat 1	0	0.41403133	0.18492517	false
recall	oneLayer	oneLayer - rat 1	0	0.42135465	0.17760183	false
recall	oneLayer	oneLayer - rat 1	0	0.42530486	0.16806519	false
recall	oneLayer	oneLayer - rat 1	0	0.42936715	0.15825798	false
recall	oneLayer	oneLayer - rat 1	0	0.4334403	0.14842455	false
recall	oneLayer	oneLayer - rat 1	0	0.43749633	0.13863242	false
recall	oneLayer	oneLayer - rat 1	0	0.441425	0.12914774	false
recall	oneLayer	oneLayer - rat 1	0	0.4454981	0.11931442	false
recall	oneLayer	oneLayer - rat 1	0	0.4495369	0.1095639	false
recall	oneLayer	oneLayer - rat 1	0	0.45337868	0.10028905	false
recall	oneLayer	oneLayer - rat 1	0	0.45728743	0.09085249	false
recall	oneLayer	oneLayer - rat 1	0	0.4611729	0.08147212	false
recall	oneLayer	oneLayer - rat 1	0	0.4650452	0.07212355	false
recall	oneLayer	oneLayer - rat 1	0	0.4650452	0.06205969	false
recall	oneLayer	oneLayer - rat 1	0	0.4650452	0.051579177	false
recall	oneLayer	oneLayer - rat 1	0	0.4650452	0.04099317	false
recall	oneLayer	oneLayer - rat 1	0	0.4650452	0.030639794	false
recall	oneLayer	oneLayer - rat 1	0	0.4650452	0.02009199	false
recall	oneLayer	oneLayer - rat 1	0	0.4650452	0.010016908	false
recall	oneLayer	oneLayer - rat 1	0	0.4650452	-6.4766614E-6	false
recall	oneLayer	oneLayer - rat 1	0	0.4650452	-0.010186342	false
recall	oneLayer	oneLayer - rat 1	0	0.4650452	-0.021046132	false
recall	oneLayer	oneLayer - rat 1	0	0.4650452	-0.0311789	false
recall	oneLayer	oneLayer - rat 1	0	0.4650452	-0.04138003	false
recall	oneLayer	oneLayer - rat 1	0	0.46504524	-0.052295994	false
recall	oneLayer	oneLayer - rat 1	0	0.46504524	-0.06322938	false
recall	oneLayer	oneLayer - rat 1	0	0.46504524	-0.07340137	false
recall	oneLayer	oneLayer - rat 1	0	0.46504524	-0.08436683	false
recall	oneLayer	oneLayer - rat 1	0	0.4611367	-0.09380287	false
recall	oneLayer	oneLayer - rat 1	0	0.4572749	-0.103126034	false
recall	oneLayer	oneLayer - rat 1	0	0.4531568	-0.11306809	false
recall	oneLayer	oneLayer - rat 1	0	0.44913563	-0.12277602	false
recall	oneLayer	oneLayer - rat 1	0	0.44497952	-0.13280976	false
recall	oneLayer	oneLayer - rat 1	0	0.44078922	-0.14292604	false
recall	oneLayer	oneLayer - rat 1	0	0.43680498	-0.15254489	false
recall	oneLayer	oneLayer - rat 1	0	0.43289438	-0.16198586	false
recall	oneLayer	oneLayer - rat 1	0	0.42898694	-0.1714193	false
recall	oneLayer	oneLayer - rat 1	0	0.4251376	-0.18071239	false
recall	oneLayer	oneLayer - rat 1	0	0.42113495	-0.19037566	false
recall	oneLayer	oneLayer - rat 1	0	0.41723636	-0.19978769	false
recall	oneLayer	oneLayer - rat 1	0	0.41326308	-0.20938005	false
recall	oneLayer	oneLayer - rat 1	0	0.40913013	-0.21935792	false
recall	oneLayer	oneLayer - rat 1	0	0.4051528	-0.22896004	false
recall	oneLayer	oneLayer - rat 1	0	0.40101007	-0.23896141	false
recall	oneLayer	oneLayer - rat 1	0	0.39689508	-0.24889593	false
recall	oneLayer	oneLayer - rat 1	0	0.39274186	-0.25892267	false
recall	oneLayer	oneLayer - rat 1	0	0.38874835	-0.26856387	false
recall	oneLayer	oneLayer - rat 1	0	0.3816444	-0.27566782	false
recall	oneLayer	oneLayer - rat 1	0	0.37430143	-0.28301078	false
recall	oneLayer	oneLayer - rat 1	0	0.3666221	-0.29069012	false
recall	oneLayer	oneLayer - rat 1	0	0.35912612	-0.29818612	false
recall	oneLayer	oneLayer - rat 1	0	0.35189754	-0.3054147	false
recall	oneLayer	oneLayer - rat 1	0	0.3447481	-0.3125641	false
recall	oneLayer	oneLayer - rat 1	0	0.3372827	-0.32002953	false
recall	oneLayer	oneLayer - rat 1	0	0.32983777	-0.32747447	false
recall	oneLayer	oneLayer - rat 1	0	0.3221162	-0.33519605	false
recall	oneLayer	oneLayer - rat 1	0	0.31447846	-0.3428338	false
recall	oneLayer	oneLayer - rat 1	0	0.3067156	-0.35059664	false
recall	oneLayer	oneLayer - rat 1	0	0.29918188	-0.35813037	false
recall	oneLayer	oneLayer - rat 1	0	0.29141724	-0.365895	false
recall	oneLayer	oneLayer - rat 1	0	0.28411034	-0.3732019	false
recall	oneLayer	oneLayer - rat 1	0	0.276883	-0.38042924	false
recall	oneLayer	oneLayer - rat 1	0	0.26927513	-0.38803712	false
recall	oneLayer	oneLayer - rat 1	0	0.26201472	-0.39529753	false
recall	oneLayer	oneLayer - rat 1	0	0.25255543	-0.3992157	false
recall	oneLayer	oneLayer - rat 1	0	0.24330328	-0.40304807	false
recall	oneLayer	oneLayer - rat 1	0	0.23340419	-0.4071484	false
recall	oneLayer	oneLayer - rat 1	0	0.22408697	-0.4110077	false
recall	oneLayer	oneLayer - rat 1	0	0.21402851	-0.41517407	false
recall	oneLayer	oneLayer - rat 1	0	0.2043601	-0.41917884	false
recall	oneLayer	oneLayer - rat 1	0	0.1942319	-0.4233741	false
recall	oneLayer	oneLayer - rat 1	0	0.18426272	-0.42750347	false
recall	oneLayer	oneLayer - rat 1	0	0.17379773	-0.42750347	false
recall	oneLayer	oneLayer - rat 1	0	0.16448274	-0.43136185	false
recall	oneLayer	oneLayer - rat 1	0	0.15444215	-0.4355208	false
recall	oneLayer	oneLayer - rat 1	0	0.14498553	-0.43943787	false
recall	oneLayer	oneLayer - rat 1	0	0.135044	-0.4435558	false
recall	oneLayer	oneLayer - rat 1	0	0.1251155	-0.4476683	false
recall	oneLayer	oneLayer - rat 1	0	0.1157636	-0.451542	false
recall	oneLayer	oneLayer - rat 1	0	0.10573415	-0.4556963	false
recall	oneLayer	oneLayer - rat 1	0	0.096029565	-0.4597161	false
recall	oneLayer	oneLayer - rat 1	0	0.0866847	-0.46358687	false
recall	oneLayer	oneLayer - rat 1	0	0.07582186	-0.46358687	false
recall	oneLayer	oneLayer - rat 1	0	0.06606479	-0.45954537	false
recall	oneLayer	oneLayer - rat 1	0	0.055193964	-0.45954537	false
recall	oneLayer	oneLayer - rat 1	0	0.044741325	-0.45954537	false
recall	oneLayer	oneLayer - rat 1	0	0.03471188	-0.45539105	false
recall	oneLayer	oneLayer - rat 1	0	0.02497449	-0.4513577	false
recall	oneLayer	oneLayer - rat 1	0	0.014032513	-0.4513577	false
recall	oneLayer	oneLayer - rat 1	0	0.0042276084	-0.455419	false
recall	oneLayer	oneLayer - rat 1	0	-0.005863143	-0.455419	false
recall	oneLayer	oneLayer - rat 1	0	-0.015223436	-0.45154184	false
recall	oneLayer	oneLayer - rat 1	0	-0.025309501	-0.44736406	false
recall	oneLayer	oneLayer - rat 1	0	-0.035428517	-0.44317263	false
recall	oneLayer	oneLayer - rat 1	0	-0.045442384	-0.43902475	false
recall	oneLayer	oneLayer - rat 1	0	-0.055935908	-0.43902475	false
recall	oneLayer	oneLayer - rat 1	0	-0.06599305	-0.44319054	false
recall	oneLayer	oneLayer - rat 1	0	-0.07607387	-0.44319054	false
recall	oneLayer	oneLayer - rat 1	0	-0.0861211	-0.44319054	false
recall	oneLayer	oneLayer - rat 1	0	-0.095854476	-0.43915886	false
recall	oneLayer	oneLayer - rat 1	0	-0.1058592	-0.43501478	false
recall	oneLayer	oneLayer - rat 1	0	-0.116447605	-0.43501478	false
recall	oneLayer	oneLayer - rat 1	0	-0.12720849	-0.43501478	false
recall	oneLayer	oneLayer - rat 1	0	-0.13726799	-0.430848	false
recall	oneLayer	oneLayer - rat 1	0	-0.14742811	-0.430848	false
recall	oneLayer	oneLayer - rat 1	0	-0.15796377	-0.430848	false
recall	oneLayer	oneLayer - rat 1	0	-0.16801074	-0.4266864	false
recall	oneLayer	oneLayer - rat 1	0	-0.17746322	-0.42277107	false
recall	oneLayer	oneLayer - rat 1	0	-0.18484654	-0.41538775	false
recall	oneLayer	oneLayer - rat 1	0	-0.194607	-0.41134483	false
recall	oneLayer	oneLayer - rat 1	0	-0.20194708	-0.40400475	false
recall	oneLayer	oneLayer - rat 1	0	-0.2093063	-0.39664555	false
recall	oneLayer	oneLayer - rat 1	0	-0.21313332	-0.3874063	false
recall	oneLayer	oneLayer - rat 1	0	-0.21702878	-0.3780018	false
recall	oneLayer	oneLayer - rat 1	0	-0.22096176	-0.36850676	false
recall	oneLayer	oneLayer - rat 1	0	-0.22500157	-0.3587538	false
recall	oneLayer	oneLayer - rat 1	0	-0.22886479	-0.34942716	false
recall	oneLayer	oneLayer - rat 1	0	-0.23278634	-0.3399597	false
recall	oneLayer	oneLayer - rat 1	0	-0.24002716	-0.33271888	false
recall	oneLayer	oneLayer - rat 1	0	-0.24988298	-0.32863647	false
recall	oneLayer	oneLayer - rat 1	0	-0.25913706	-0.3248033	false
recall	oneLayer	oneLayer - rat 1	0	-0.26939934	-0.3248033	false
recall	oneLayer	oneLayer - rat 1	0	-0.2802184	-0.3248033	false
recall	oneLayer	oneLayer - rat 1	0	-0.2894583	-0.32097602	false
recall	oneLayer	oneLayer - rat 1	0	-0.29950815	-0.3168132	false
recall	oneLayer	oneLayer - rat 1	0	-0.30942637	-0.31270498	false
recall	oneLayer	oneLayer - rat 1	0	-0.3168778	-0.3052535	false
recall	oneLayer	oneLayer - rat 1	0	-0.32104003	-0.29520503	false
recall	oneLayer	oneLayer - rat 1	0	-0.32490018	-0.28588584	false
recall	oneLayer	oneLayer - rat 1	0	-0.3287639	-0.27655792	false
recall	oneLayer	oneLayer - rat 1	0	-0.3328886	-0.26660007	false
recall	oneLayer	oneLayer - rat 1	0	-0.33697656	-0.25673088	false
recall	oneLayer	oneLayer - rat 1	0	-0.3411589	-0.24663383	false
recall	oneLayer	oneLayer - rat 1	0	-0.34827912	-0.23951359	false
recall	oneLayer	oneLayer - rat 1	0	-0.35783255	-0.23555644	false
recall	oneLayer	oneLayer - rat 1	0	-0.36544153	-0.22794746	false
recall	oneLayer	oneLayer - rat 1	0	-0.36950824	-0.21812956	false
recall	oneLayer	oneLayer - rat 1	0	-0.3734769	-0.2085484	false
recall	oneLayer	oneLayer - rat 1	0	-0.3776395	-0.19849896	false
recall	oneLayer	oneLayer - rat 1	0	-0.38178632	-0.18848768	false
recall	oneLayer	oneLayer - rat 1	0	-0.38894385	-0.18133014	false
recall	oneLayer	oneLayer - rat 1	0	-0.39301345	-0.17150524	false
recall	oneLayer	oneLayer - rat 1	0	-0.3968542	-0.1622329	false
recall	oneLayer	oneLayer - rat 1	0	-0.40086618	-0.15254708	false
recall	oneLayer	oneLayer - rat 1	0	-0.40825558	-0.1451577	false
recall	oneLayer	oneLayer - rat 1	0	-0.41575995	-0.1376533	false
recall	oneLayer	oneLayer - rat 1	0	-0.4195963	-0.12839152	false
recall	oneLayer	oneLayer - rat 1	0	-0.42356706	-0.11880529	false
recall	oneLayer	oneLayer - rat 1	0	-0.42750368	-0.10930149	false
recall	oneLayer	oneLayer - rat 1	0	-0.4349103	-0.10189488	false
recall	oneLayer	oneLayer - rat 1	0	-0.43894628	-0.092151135	false
recall	oneLayer	oneLayer - rat 1	0	-0.44286224	-0.08269715	false
recall	oneLayer	oneLayer - rat 1	0	-0.44698995	-0.07273195	false
recall	oneLayer	oneLayer - rat 1	0	-0.44698995	-0.062173463	false
recall	oneLayer	oneLayer - rat 1	0	-0.44698995	-0.05126883	false
recall	oneLayer	oneLayer - rat 1	0	-0.44698998	-0.04037041	false
recall	oneLayer	oneLayer - rat 1	0	-0.44698998	-0.029639719	false
recall	oneLayer	oneLayer - rat 1	0	-0.44698998	-0.018878588	false
recall	oneLayer	oneLayer - rat 1	0	-0.44698998	-0.008415322	false
recall	oneLayer	oneLayer - rat 1	0	-0.44698998	0.0021773365	false
recall	oneLayer	oneLayer - rat 1	0	-0.44698998	0.013017979	false
recall	oneLayer	oneLayer - rat 1	0	-0.44698998	0.023175763	false
recall	oneLayer	oneLayer - rat 1	0	-0.44698998	0.033303678	false
recall	oneLayer	oneLayer - rat 1	0	-0.44698998	0.044200268	false
recall	oneLayer	oneLayer - rat 1	0	-0.44698998	0.054421216	false
recall	oneLayer	oneLayer - rat 1	0	-0.44698998	0.06528486	false
recall	oneLayer	oneLayer - rat 1	0	-0.44698998	0.076148435	false
recall	oneLayer	oneLayer - rat 1	0	-0.44698998	0.08628056	false
recall	oneLayer	oneLayer - rat 1	0	-0.44698998	0.09707198	false
recall	oneLayer	oneLayer - rat 1	0	-0.44698998	0.10720077	false
recall	oneLayer	oneLayer - rat 1	0	-0.44698998	0.11761105	false
recall	oneLayer	oneLayer - rat 1	0	-0.44698998	0.12857728	false
recall	oneLayer	oneLayer - rat 1	0	-0.44292992	0.13837913	false
recall	oneLayer	oneLayer - rat 1	0	-0.4389344	0.14802518	false
recall	oneLayer	oneLayer - rat 1	0	-0.43500826	0.1575037	false
recall	oneLayer	oneLayer - rat 1	0	-0.43110234	0.16693345	false
recall	oneLayer	oneLayer - rat 1	0	-0.42721432	0.17631991	false
recall	oneLayer	oneLayer - rat 1	0	-0.423023	0.18643872	false
recall	oneLayer	oneLayer - rat 1	0	-0.41906	0.1960062	false
recall	oneLayer	oneLayer - rat 1	0	-0.4114094	0.2036568	false
recall	oneLayer	oneLayer - rat 1	0	-0.40387392	0.21119228	false
recall	oneLayer	oneLayer - rat 1	0	-0.39631122	0.21875498	false
recall	oneLayer	oneLayer - rat 1	0	-0.38891333	0.22615287	false
recall	oneLayer	oneLayer - rat 1	0	-0.37908292	0.23022476	false
recall	oneLayer	oneLayer - rat 1	0	-0.36946887	0.23420703	false
recall	oneLayer	oneLayer - rat 1	0	-0.35958084	0.23830278	false
recall	oneLayer	oneLayer - rat 1	0	-0.34952402	0.24246846	false
recall	oneLayer	oneLayer - rat 1	0	-0.33865502	0.24246846	false
recall	oneLayer	oneLayer - rat 1	0	-0.327874	0.24246846	false
recall	oneLayer	oneLayer - rat 1	0	-0.31808504	0.24652319	false
recall	oneLayer	oneLayer - rat 1	0	-0.30730918	0.24652319	false
recall	oneLayer	oneLayer - rat 1	0	-0.29674098	0.24652319	false
recall	oneLayer	oneLayer - rat 1	0	-0.28654796	0.24652319	false
recall	oneLayer	oneLayer - rat 1	0	-0.2767889	0.25056553	false
recall	oneLayer	oneLayer - rat 1	0	-0.26750413	0.2544114	false
recall	oneLayer	oneLayer - rat 1	0	-0.25683382	0.2544114	false
recall	oneLayer	oneLayer - rat 1	0	-0.24711594	0.25038612	false
recall	oneLayer	oneLayer - rat 1	0	-0.23637678	0.25038612	false
recall	oneLayer	oneLayer - rat 1	0	-0.22570008	0.25038612	false
recall	oneLayer	oneLayer - rat 1	0	-0.21567337	0.25038612	false
recall	oneLayer	oneLayer - rat 1	0	-0.20519038	0.25038612	false
recall	oneLayer	oneLayer - rat 1	0	-0.19462082	0.25038612	false
recall	oneLayer	oneLayer - rat 1	0	-0.18471025	0.2544912	false
recall	oneLayer	oneLayer - rat 1	0	-0.17746994	0.2617315	false
recall	oneLayer	oneLayer - rat 1	0	-0.17001466	0.2691868	false
recall	oneLayer	oneLayer - rat 1	0	-0.1628043	0.27639717	false
recall	oneLayer	oneLayer - rat 1	0	-0.15518762	0.28401384	false
recall	oneLayer	oneLayer - rat 1	0	-0.14804722	0.29115424	false
recall	oneLayer	oneLayer - rat 1	0	-0.14089818	0.29830328	false
recall	oneLayer	oneLayer - rat 1	0	-0.13684706	0.30808353	false
recall	oneLayer	oneLayer - rat 1	0	-0.13267629	0.3181527	false
recall	oneLayer	oneLayer - rat 1	0	-0.12868367	0.32779172	false
recall	oneLayer	oneLayer - rat 1	0	-0.12450085	0.33788994	false
recall	oneLayer	oneLayer - rat 1	0	-0.12049939	0.34755033	false
recall	oneLayer	oneLayer - rat 1	0	-0.11634387	0.35758263	false
recall	oneLayer	oneLayer - rat 1	0	-0.112290524	0.36736828	false
recall	oneLayer	oneLayer - rat 1	0	-0.112290524	0.37809533	false
recall	oneLayer	oneLayer - rat 1	0	-0.11641231	0.3880462	false
recall	oneLayer	oneLayer - rat 1	0	-0.12383019	0.3954641	false
recall	oneLayer	oneLayer - rat 1	0	-0.13386199	0.3996194	false
recall	oneLayer	oneLayer - rat 1	0	-0.14411427	0.3996194	false
recall	oneLayer	oneLayer - rat 1	0	-0.15505022	0.3996194	false
recall	oneLayer	oneLayer - rat 1	0	-0.16482256	0.39557156	false
recall	oneLayer	oneLayer - rat 1	0	-0.1749509	0.39137626	false
recall	oneLayer	oneLayer - rat 1	0	-0.18471056	0.38733366	false
recall	oneLayer	oneLayer - rat 1	0	-0.1953235	0.38733366	false
recall	oneLayer	oneLayer - rat 1	0	-0.20622489	0.38733366	false
recall	oneLayer	oneLayer - rat 1	0	-0.21622401	0.38319188	false
recall	oneLayer	oneLayer - rat 1	0	-0.2260244	0.37913242	false
recall	oneLayer	oneLayer - rat 1	0	-0.23535635	0.37526703	false
recall	oneLayer	oneLayer - rat 1	0	-0.2428447	0.36777866	false
recall	oneLayer	oneLayer - rat 1	0	-0.25286886	0.3636265	false
recall	oneLayer	oneLayer - rat 1	0	-0.26038745	0.3561079	false
recall	oneLayer	oneLayer - rat 1	0	-0.27052015	0.3519108	false
recall	oneLayer	oneLayer - rat 1	0	-0.280019	0.34797627	false
recall	oneLayer	oneLayer - rat 1	0	-0.28965068	0.3439867	false
recall	oneLayer	oneLayer - rat 1	0	-0.29946458	0.33992162	false
recall	oneLayer	oneLayer - rat 1	0	-0.30960253	0.33572236	false
recall	oneLayer	oneLayer - rat 1	0	-0.3171438	0.32818106	false
recall	oneLayer	oneLayer - rat 1	0	-0.32434806	0.32097682	false
recall	oneLayer	oneLayer - rat 1	0	-0.3320003	0.3133246	false
recall	oneLayer	oneLayer - rat 1	0	-0.33966082	0.30566406	false
recall	oneLayer	oneLayer - rat 1	0	-0.34714615	0.2981787	false
recall	oneLayer	oneLayer - rat 1	0	-0.35457483	0.29075006	false
recall	oneLayer	oneLayer - rat 1	0	-0.3619333	0.2833916	false
recall	oneLayer	oneLayer - rat 1	0	-0.36967713	0.27564773	false
recall	oneLayer	oneLayer - rat 1	0	-0.37735674	0.26796815	false
recall	oneLayer	oneLayer - rat 1	0	-0.38477457	0.2605503	false
recall	oneLayer	oneLayer - rat 1	0	-0.39238593	0.25293896	false
recall	oneLayer	oneLayer - rat 1	0	-0.39972126	0.2456036	false
recall	oneLayer	oneLayer - rat 1	0	-0.4036605	0.23609342	false
recall	oneLayer	oneLayer - rat 1	0	-0.40774447	0.22623388	false
recall	oneLayer	oneLayer - rat 1	0	-0.41166288	0.21677399	false
recall	oneLayer	oneLayer - rat 1	0	-0.41569573	0.20703779	false
recall	oneLayer	oneLayer - rat 1	0	-0.4195609	0.19770642	false
recall	oneLayer	oneLayer - rat 1	0	-0.42345876	0.18829623	false
recall	oneLayer	oneLayer - rat 1	0	-0.4273936	0.17879668	false
recall	oneLayer	oneLayer - rat 1	0	-0.43145877	0.16898246	false
recall	oneLayer	oneLayer - rat 1	0	-0.43531087	0.15968265	false
recall	oneLayer	oneLayer - rat 1	0	-0.4394455	0.1497008	false
recall	oneLayer	oneLayer - rat 1	0	-0.44351903	0.13986643	false
recall	oneLayer	oneLayer - rat 1	0	-0.44738263	0.13053885	false
recall	oneLayer	oneLayer - rat 1	0	-0.45140663	0.12082406	false
recall	oneLayer	oneLayer - rat 1	0	-0.45542678	0.111118525	false
recall	oneLayer	oneLayer - rat 1	0	-0.4592664	0.10184886	false
recall	oneLayer	oneLayer - rat 1	0	-0.46336848	0.091945566	false
recall	oneLayer	oneLayer - rat 1	0	-0.46336848	0.08177516	false
recall	oneLayer	oneLayer - rat 1	0	-0.46336848	0.0707893	false
recall	oneLayer	oneLayer - rat 1	0	-0.46336848	0.0598614	false
recall	oneLayer	oneLayer - rat 1	0	-0.46336848	0.049728878	false
recall	oneLayer	oneLayer - rat 1	0	-0.46336848	0.039540347	false
recall	oneLayer	oneLayer - rat 1	0	-0.46336848	0.029347869	false
recall	oneLayer	oneLayer - rat 1	0	-0.46336848	0.018939396	false
recall	oneLayer	oneLayer - rat 1	0	-0.46336848	0.008047481	false
recall	oneLayer	oneLayer - rat 1	0	-0.46336848	-0.0028815505	false
recall	oneLayer	oneLayer - rat 1	0	-0.46336848	-0.013698748	false
recall	oneLayer	oneLayer - rat 1	0	-0.46336848	-0.0239385	false
recall	oneLayer	oneLayer - rat 1	0	-0.46336848	-0.034570888	false
recall	oneLayer	oneLayer - rat 1	0	-0.46336848	-0.045518573	false
recall	oneLayer	oneLayer - rat 1	0	-0.46336845	-0.055770237	false
recall	oneLayer	oneLayer - rat 1	0	-0.46336845	-0.06658987	false
recall	oneLayer	oneLayer - rat 1	0	-0.46336845	-0.07743524	false
recall	oneLayer	oneLayer - rat 1	0	-0.46336845	-0.08788446	false
recall	oneLayer	oneLayer - rat 1	0	-0.45930544	-0.09769349	false
recall	oneLayer	oneLayer - rat 1	0	-0.45546928	-0.106954746	false
recall	oneLayer	oneLayer - rat 1	0	-0.45126623	-0.117101826	false
recall	oneLayer	oneLayer - rat 1	0	-0.44718897	-0.12694517	false
recall	oneLayer	oneLayer - rat 1	0	-0.44299343	-0.13707414	false
recall	oneLayer	oneLayer - rat 1	0	-0.43911192	-0.1464449	false
recall	oneLayer	oneLayer - rat 1	0	-0.43510234	-0.15612489	false
recall	oneLayer	oneLayer - rat 1	0	-0.42741528	-0.16381194	false
recall	oneLayer	oneLayer - rat 1	0	-0.4199047	-0.17132251	false
recall	oneLayer	oneLayer - rat 1	0	-0.4103166	-0.17529404	false
recall	oneLayer	oneLayer - rat 1	0	-0.3994832	-0.17529404	false
recall	oneLayer	oneLayer - rat 1	0	-0.38999897	-0.17136553	false
recall	oneLayer	oneLayer - rat 1	0	-0.38015613	-0.1672885	false
recall	oneLayer	oneLayer - rat 1	0	-0.36988184	-0.1672885	false
recall	oneLayer	oneLayer - rat 1	0	-0.36054197	-0.17115718	false
recall	oneLayer	oneLayer - rat 1	0	-0.3499722	-0.17115718	false
recall	oneLayer	oneLayer - rat 1	0	-0.33984706	-0.17535114	false
recall	oneLayer	oneLayer - rat 1	0	-0.32970038	-0.17955405	false
recall	oneLayer	oneLayer - rat 1	0	-0.31919006	-0.17955405	false
recall	oneLayer	oneLayer - rat 1	0	-0.3091755	-0.17540586	false
recall	oneLayer	oneLayer - rat 1	0	-0.2993577	-0.17133921	false
recall	oneLayer	oneLayer - rat 1	0	-0.28912905	-0.1713392	false
recall	oneLayer	oneLayer - rat 1	0	-0.27910155	-0.1713392	false
recall	oneLayer	oneLayer - rat 1	0	-0.26913318	-0.17546824	false
recall	oneLayer	oneLayer - rat 1	0	-0.2591297	-0.17961182	false
recall	oneLayer	oneLayer - rat 1	0	-0.24920754	-0.1837217	false
recall	oneLayer	oneLayer - rat 1	0	-0.23971456	-0.18765382	false
recall	oneLayer	oneLayer - rat 1	0	-0.22961645	-0.18765382	false
recall	oneLayer	oneLayer - rat 1	0	-0.21950445	-0.1834653	false
recall	oneLayer	oneLayer - rat 1	0	-0.20950907	-0.17932507	false
recall	oneLayer	oneLayer - rat 1	0	-0.20226586	-0.17208186	false
recall	oneLayer	oneLayer - rat 1	0	-0.19255503	-0.1680595	false
recall	oneLayer	oneLayer - rat 1	0	-0.18330516	-0.16422807	false
recall	oneLayer	oneLayer - rat 1	0	-0.17315744	-0.16002475	false
recall	oneLayer	oneLayer - rat 1	0	-0.1639071	-0.15619312	false
recall	oneLayer	oneLayer - rat 1	0	-0.15387489	-0.15619312	false
recall	oneLayer	oneLayer - rat 1	0	-0.14396542	-0.16029775	false
recall	oneLayer	oneLayer - rat 1	0	-0.13672161	-0.16754156	false
recall	oneLayer	oneLayer - rat 1	0	-0.12955092	-0.17471226	false
recall	oneLayer	oneLayer - rat 1	0	-0.122440755	-0.18182242	false
recall	oneLayer	oneLayer - rat 1	0	-0.11833034	-0.19174585	false
recall	oneLayer	oneLayer - rat 1	0	-0.11446468	-0.20107837	false
recall	oneLayer	oneLayer - rat 1	0	-0.11446468	-0.21163526	false
recall	oneLayer	oneLayer - rat 1	0	-0.11446467	-0.22232206	false
recall	oneLayer	oneLayer - rat 1	0	-0.11446467	-0.23261485	false
recall	oneLayer	oneLayer - rat 1	0	-0.11446467	-0.24286954	false
recall	oneLayer	oneLayer - rat 1	0	-0.11446467	-0.25343624	false
recall	oneLayer	oneLayer - rat 1	0	-0.11446467	-0.26414186	false
recall	oneLayer	oneLayer - rat 1	0	-0.11446466	-0.27450797	false
recall	oneLayer	oneLayer - rat 1	0	-0.11446466	-0.2852385	false
recall	oneLayer	oneLayer - rat 1	0	-0.11446466	-0.29582983	false
recall	oneLayer	oneLayer - rat 1	0	-0.11446466	-0.30612075	false
recall	oneLayer	oneLayer - rat 1	0	-0.11446466	-0.3167429	false
recall	oneLayer	oneLayer - rat 1	0	-0.11446466	-0.32729015	false
recall	oneLayer	oneLayer - rat 1	0	-0.114464656	-0.33790073	false
recall	oneLayer	oneLayer - rat 1	0	-0.114464656	-0.34809595	false
recall	oneLayer	oneLayer - rat 1	0	-0.114464656	-0.35883072	false
recall	oneLayer	oneLayer - rat 1	0	-0.110520385	-0.368353	false
recall	oneLayer	oneLayer - rat 1	0	-0.110520385	-0.3784663	false
recall	oneLayer	oneLayer - rat 1	0	-0.110520385	-0.38862357	false
recall	oneLayer	oneLayer - rat 1	0	-0.106464654	-0.39841497	false
recall	oneLayer	oneLayer - rat 1	0	-0.10243944	-0.4081327	false
recall	oneLayer	oneLayer - rat 1	0	-0.09502306	-0.41554907	false
recall	oneLayer	oneLayer - rat 1	0	-0.08545547	-0.4195121	false
recall	oneLayer	oneLayer - rat 1	0	-0.075195484	-0.4195121	false
recall	oneLayer	oneLayer - rat 1	0	-0.06560016	-0.42348662	false
recall	oneLayer	oneLayer - rat 1	0	-0.058004066	-0.4310827	false
recall	oneLayer	oneLayer - rat 1	0	-0.048530582	-0.43500674	false
recall	oneLayer	oneLayer - rat 1	0	-0.038435817	-0.43500674	false
recall	oneLayer	oneLayer - rat 1	0	-0.028301544	-0.43920448	false
recall	oneLayer	oneLayer - rat 1	0	-0.017646657	-0.43920448	false
recall	oneLayer	oneLayer - rat 1	0	-0.008374831	-0.443045	false
recall	oneLayer	oneLayer - rat 1	0	0.0020198082	-0.443045	false
recall	oneLayer	oneLayer - rat 1	0	0.012121171	-0.44722912	false
recall	oneLayer	oneLayer - rat 1	0	0.02235453	-0.44722912	false
recall	oneLayer	oneLayer - rat 1	0	0.032095034	-0.44319448	false
recall	oneLayer	oneLayer - rat 1	0	0.04165398	-0.43923503	false
recall	oneLayer	oneLayer - rat 1	0	0.051565602	-0.4351295	false
recall	oneLayer	oneLayer - rat 1	0	0.061344296	-0.43107903	false
recall	oneLayer	oneLayer - rat 1	0	0.07089576	-0.42712268	false
recall	oneLayer	oneLayer - rat 1	0	0.08063341	-0.4230892	false
recall	oneLayer	oneLayer - rat 1	0	0.09056765	-0.4189743	false
recall	oneLayer	oneLayer - rat 1	0	0.10104778	-0.4189743	false
recall	oneLayer	oneLayer - rat 1	0	0.11032701	-0.4228179	false
recall	oneLayer	oneLayer - rat 1	0	0.12078683	-0.4228179	false
recall	oneLayer	oneLayer - rat 1	0	0.13055313	-0.41877255	false
recall	oneLayer	oneLayer - rat 1	0	0.14045319	-0.4146718	false
recall	oneLayer	oneLayer - rat 1	0	0.1501436	-0.4106579	false
recall	oneLayer	oneLayer - rat 1	0	0.16028708	-0.40645635	false
recall	oneLayer	oneLayer - rat 1	0	0.16749868	-0.39924473	false
recall	oneLayer	oneLayer - rat 1	0	0.17511065	-0.39163277	false
recall	oneLayer	oneLayer - rat 1	0	0.18236312	-0.38438028	false
recall	oneLayer	oneLayer - rat 1	0	0.19000088	-0.37674254	false
recall	oneLayer	oneLayer - rat 1	0	0.19767118	-0.36907223	false
recall	oneLayer	oneLayer - rat 1	0	0.20522267	-0.36152074	false
recall	oneLayer	oneLayer - rat 1	0	0.2125441	-0.3541993	false
recall	oneLayer	oneLayer - rat 1	0	0.22012503	-0.34661835	false
recall	oneLayer	oneLayer - rat 1	0	0.22775254	-0.33899087	false
recall	oneLayer	oneLayer - rat 1	0	0.23522897	-0.33151442	false
recall	oneLayer	oneLayer - rat 1	0	0.24517305	-0.32739544	false
recall	oneLayer	oneLayer - rat 1	0	0.2552364	-0.32739544	false
recall	oneLayer	oneLayer - rat 1	0	0.2644877	-0.3235634	false
recall	oneLayer	oneLayer - rat 1	0	0.27487352	-0.3235634	false
recall	oneLayer	oneLayer - rat 1	0	0.28501865	-0.31936115	false
recall	oneLayer	oneLayer - rat 1	0	0.29242492	-0.3119549	false
recall	oneLayer	oneLayer - rat 1	0	0.29962796	-0.3047518	false
recall	oneLayer	oneLayer - rat 1	0	0.30676064	-0.29761916	false
recall	oneLayer	oneLayer - rat 1	0	0.31424403	-0.29013577	false
recall	oneLayer	oneLayer - rat 1	0	0.32140398	-0.28297582	false
recall	oneLayer	oneLayer - rat 1	0	0.3289544	-0.27542537	false
recall	oneLayer	oneLayer - rat 1	0	0.33656895	-0.26781085	false
recall	oneLayer	oneLayer - rat 1	0	0.3438012	-0.26057857	false
recall	oneLayer	oneLayer - rat 1	0	0.35131866	-0.25306112	false
recall	oneLayer	oneLayer - rat 1	0	0.3587989	-0.24558087	false
recall	oneLayer	oneLayer - rat 1	0	0.36811468	-0.24172215	false
recall	oneLayer	oneLayer - rat 1	0	0.37549368	-0.23434316	false
recall	oneLayer	oneLayer - rat 1	0	0.38277623	-0.22706059	false
recall	oneLayer	oneLayer - rat 1	0	0.39008877	-0.21974806	false
recall	oneLayer	oneLayer - rat 1	0	0.39771575	-0.21212108	false
recall	oneLayer	oneLayer - rat 1	0	0.40489173	-0.20494509	false
recall	oneLayer	oneLayer - rat 1	0	0.40879002	-0.19553377	false
recall	oneLayer	oneLayer - rat 1	0	0.41283062	-0.18577886	false
recall	oneLayer	oneLayer - rat 1	0	0.41694927	-0.17583558	false
recall	oneLayer	oneLayer - rat 1	0	0.420802	-0.16653425	false
recall	oneLayer	oneLayer - rat 1	0	0.42464948	-0.15724562	false
recall	oneLayer	oneLayer - rat 1	0	0.4284831	-0.14799042	false
recall	oneLayer	oneLayer - rat 1	0	0.43263835	-0.13795877	false
recall	oneLayer	oneLayer - rat 1	0	0.43263835	-0.12723862	false
recall	oneLayer	oneLayer - rat 1	0	0.43263835	-0.11672785	false
recall	oneLayer	oneLayer - rat 1	0	0.4367437	-0.10681666	false
recall	oneLayer	oneLayer - rat 1	0	0.4367437	-0.096154734	false
recall	oneLayer	oneLayer - rat 1	0	0.4367437	-0.08613281	false
recall	oneLayer	oneLayer - rat 1	0	0.44083214	-0.07626244	false
recall	oneLayer	oneLayer - rat 1	0	0.44497618	-0.06625785	false
recall	oneLayer	oneLayer - rat 1	0	0.44913802	-0.056210246	false
recall	oneLayer	oneLayer - rat 1	0	0.45318636	-0.046436667	false
recall	oneLayer	oneLayer - rat 1	0	0.45716226	-0.036838003	false
recall	oneLayer	oneLayer - rat 1	0	0.46128428	-0.026886528	false
recall	oneLayer	oneLayer - rat 1	0	0.46128428	-0.016253775	false
recall	oneLayer	oneLayer - rat 1	0	0.45714912	-0.006270571	false
recall	oneLayer	oneLayer - rat 1	0	0.45323133	0.003187742	false
recall	oneLayer	oneLayer - rat 1	0	0.45323133	0.013278249	false
recall	oneLayer	oneLayer - rat 1	0	0.44929004	0.02279339	false
recall	oneLayer	oneLayer - rat 1	0	0.44532067	0.032376297	false
recall	oneLayer	oneLayer - rat 1	0	0.4380216	0.039675366	false
recall	oneLayer	oneLayer - rat 1	0	0.42840213	0.043659877	false
recall	oneLayer	oneLayer - rat 1	0	0.418556	0.047738273	false
recall	oneLayer	oneLayer - rat 1	0	0.40891796	0.051730476	false
recall	oneLayer	oneLayer - rat 1	0	0.39856562	0.051730473	false
recall	oneLayer	oneLayer - rat 1	0	0.3883959	0.05173047	false
recall	oneLayer	oneLayer - rat 1	0	0.37780675	0.051730465	false
recall	oneLayer	oneLayer - rat 1	0	0.36712414	0.051730465	false
recall	oneLayer	oneLayer - rat 1	0	0.35700536	0.05173046	false
recall	oneLayer	oneLayer - rat 1	0	0.34616733	0.051730458	false
recall	oneLayer	oneLayer - rat 1	0	0.33539686	0.051730454	false
recall	oneLayer	oneLayer - rat 1	0	0.32529625	0.051730454	false
recall	oneLayer	oneLayer - rat 1	0	0.31528762	0.05173045	false
recall	oneLayer	oneLayer - rat 1	0	0.3044544	0.051730447	false
recall	oneLayer	oneLayer - rat 1	0	0.29430506	0.051730447	false
recall	oneLayer	oneLayer - rat 1	0	0.2844161	0.055826582	false
recall	oneLayer	oneLayer - rat 1	0	0.27688542	0.063357264	false
recall	oneLayer	oneLayer - rat 1	0	0.269514	0.07072868	false
recall	oneLayer	oneLayer - rat 1	0	0.2655756	0.080236845	false
recall	oneLayer	oneLayer - rat 1	0	0.26154515	0.0899672	false
recall	oneLayer	oneLayer - rat 1	0	0.25436953	0.09714279	false
recall	oneLayer	oneLayer - rat 1	0	0.24719158	0.10432076	false
recall	oneLayer	oneLayer - rat 1	0	0.24320236	0.11395157	false
recall	oneLayer	oneLayer - rat 1	0	0.23933303	0.123292945	false
recall	oneLayer	oneLayer - rat 1	0	0.23933303	0.13416466	false
recall	oneLayer	oneLayer - rat 1	0	0.24334158	0.14384218	false
recall	oneLayer	oneLayer - rat 1	0	0.24334158	0.15440445	false
recall	oneLayer	oneLayer - rat 1	0	0.23943461	0.16383669	false
recall	oneLayer	oneLayer - rat 1	0	0.23526733	0.17389742	false
recall	oneLayer	oneLayer - rat 1	0	0.2311465	0.18384598	false
recall	oneLayer	oneLayer - rat 1	0	0.22703071	0.19378236	false
recall	oneLayer	oneLayer - rat 1	0	0.21948148	0.20133157	false
recall	oneLayer	oneLayer - rat 1	0	0.21228772	0.20852533	false
recall	oneLayer	oneLayer - rat 1	0	0.20302221	0.21236323	false
recall	oneLayer	oneLayer - rat 1	0	0.19293873	0.21653995	false
recall	oneLayer	oneLayer - rat 1	0	0.18198483	0.21653995	false
recall	oneLayer	oneLayer - rat 1	0	0.17137793	0.21653993	false
recall	oneLayer	oneLayer - rat 1	0	0.16102529	0.21653993	false
recall	oneLayer	oneLayer - rat 1	0	0.15049176	0.21653993	false
recall	oneLayer	oneLayer - rat 1	0	0.13981922	0.21653993	false
recall	oneLayer	oneLayer - rat 1	0	0.12926045	0.21653993	false
recall	oneLayer	oneLayer - rat 1	0	0.11899069	0.21653993	false
recall	oneLayer	oneLayer - rat 1	0	0.108151786	0.21653992	false
recall	oneLayer	oneLayer - rat 1	0	0.09717647	0.21653992	false
recall	oneLayer	oneLayer - rat 1	0	0.086916156	0.21653992	false
recall	oneLayer	oneLayer - rat 1	0	0.07614399	0.21653992	false
recall	oneLayer	oneLayer - rat 1	0	0.065588936	0.21653992	false
recall	oneLayer	oneLayer - rat 1	0	0.05537785	0.2165399	false
recall	oneLayer	oneLayer - rat 1	0	0.04492411	0.2165399	false
recall	oneLayer	oneLayer - rat 1	0	0.03443982	0.2165399	false
recall	oneLayer	oneLayer - rat 1	0	0.024173217	0.2165399	false
recall	oneLayer	oneLayer - rat 1	0	0.014246573	0.22065166	false
recall	oneLayer	oneLayer - rat 1	0	0.004245292	0.22479431	false
recall	oneLayer	oneLayer - rat 1	0	-0.0054233763	0.22879921	false
recall	oneLayer	oneLayer - rat 1	0	-0.0154890595	0.23296854	false
recall	oneLayer	oneLayer - rat 1	0	-0.025031919	0.23692133	false
recall	oneLayer	oneLayer - rat 1	0	-0.035052028	0.24107179	false
recall	oneLayer	oneLayer - rat 1	0	-0.045206703	0.24527799	false
recall	oneLayer	oneLayer - rat 1	0	-0.05547747	0.24527799	false
recall	oneLayer	oneLayer - rat 1	0	-0.06555863	0.24527799	false
recall	oneLayer	oneLayer - rat 1	0	-0.076027095	0.24527797	false
recall	oneLayer	oneLayer - rat 1	0	-0.086151645	0.24527797	false
recall	oneLayer	oneLayer - rat 1	0	-0.096724756	0.24527797	false
recall	oneLayer	oneLayer - rat 1	0	-0.10747291	0.24527797	false
recall	oneLayer	oneLayer - rat 1	0	-0.117214814	0.24124274	false
recall	oneLayer	oneLayer - rat 1	0	-0.12694971	0.23721041	false
recall	oneLayer	oneLayer - rat 1	0	-0.13623916	0.23336259	false
recall	oneLayer	oneLayer - rat 1	0	-0.14629135	0.22919883	false
recall	oneLayer	oneLayer - rat 1	0	-0.15559496	0.22534515	false
recall	oneLayer	oneLayer - rat 1	0	-0.16566338	0.22117467	false
recall	oneLayer	oneLayer - rat 1	0	-0.17552292	0.21709071	false
recall	oneLayer	oneLayer - rat 1	0	-0.1856435	0.21289863	false
recall	oneLayer	oneLayer - rat 1	0	-0.19506648	0.20899549	false
recall	oneLayer	oneLayer - rat 1	0	-0.2047269	0.20499401	false
recall	oneLayer	oneLayer - rat 1	0	-0.21195525	0.19776566	false
recall	oneLayer	oneLayer - rat 1	0	-0.21917602	0.19054489	false
recall	oneLayer	oneLayer - rat 1	0	-0.22667207	0.18304883	false
recall	oneLayer	oneLayer - rat 1	0	-0.23391935	0.17580155	false
recall	oneLayer	oneLayer - rat 1	0	-0.24133587	0.16838503	false
recall	oneLayer	oneLayer - rat 1	0	-0.24890818	0.16081272	false
recall	oneLayer	oneLayer - rat 1	0	-0.25606957	0.15365133	false
recall	oneLayer	oneLayer - rat 1	0	-0.26006302	0.14401022	false
recall	oneLayer	oneLayer - rat 1	0	-0.26408747	0.13429435	false
recall	oneLayer	oneLayer - rat 1	0	-0.2680851	0.124643244	false
recall	oneLayer	oneLayer - rat 1	0	-0.27215236	0.11482398	false
recall	oneLayer	oneLayer - rat 1	0	-0.27215236	0.104145505	false
recall	oneLayer	oneLayer - rat 1	0	-0.27215236	0.093520336	false
recall	oneLayer	oneLayer - rat 1	0	-0.27215236	0.08340329	false
recall	oneLayer	oneLayer - rat 1	0	-0.27215233	0.072966315	false
recall	oneLayer	oneLayer - rat 1	0	-0.27215233	0.062754475	false
recall	oneLayer	oneLayer - rat 1	0	-0.27628186	0.052784912	false
recall	oneLayer	oneLayer - rat 1	0	-0.27628186	0.04255276	false
recall	oneLayer	oneLayer - rat 1	0	-0.27628186	0.032056246	false
recall	oneLayer	oneLayer - rat 1	0	-0.2721381	0.022052323	false
recall	oneLayer	oneLayer - rat 1	0	-0.26826552	0.012703075	false
recall	oneLayer	oneLayer - rat 1	0	-0.26414198	0.0027480319	false
recall	oneLayer	oneLayer - rat 1	0	-0.26001245	-0.0072215847	false
recall	oneLayer	oneLayer - rat 1	0	-0.25260544	-0.014628565	false
recall	oneLayer	oneLayer - rat 1	0	-0.24493334	-0.02230067	false
recall	oneLayer	oneLayer - rat 1	0	-0.24083	-0.03220701	false
recall	oneLayer	oneLayer - rat 1	0	-0.2334419	-0.0395951	false
recall	oneLayer	oneLayer - rat 1	0	-0.22955275	-0.048984334	false
recall	oneLayer	oneLayer - rat 1	0	-0.22225417	-0.056282904	false
recall	oneLayer	oneLayer - rat 1	0	-0.21811767	-0.066269286	false
recall	oneLayer	oneLayer - rat 1	0	-0.21056668	-0.07382027	false
recall	oneLayer	oneLayer - rat 1	0	-0.20669982	-0.08315569	false
recall	oneLayer	oneLayer - rat 1	0	-0.19927329	-0.09058223	false
recall	oneLayer	oneLayer - rat 1	0	-0.19528106	-0.10022031	false
recall	oneLayer	oneLayer - rat 1	0	-0.18761906	-0.1078823	false
recall	oneLayer	oneLayer - rat 1	0	-0.18349941	-0.11782801	false
recall	oneLayer	oneLayer - rat 1	0	-0.17572944	-0.12559798	false
recall	oneLayer	oneLayer - rat 1	0	-0.171725	-0.13526553	false
recall	oneLayer	oneLayer - rat 1	0	-0.16419509	-0.14279543	false
recall	oneLayer	oneLayer - rat 1	0	-0.16023056	-0.15236667	false
recall	oneLayer	oneLayer - rat 1	0	-0.15290192	-0.1596953	false
recall	oneLayer	oneLayer - rat 1	0	-0.14894111	-0.16925749	false
recall	oneLayer	oneLayer - rat 1	0	-0.14129105	-0.17690755	false
recall	oneLayer	oneLayer - rat 1	0	-0.13726233	-0.18663374	false
recall	oneLayer	oneLayer - rat 1	0	-0.13016658	-0.1937295	false
recall	oneLayer	oneLayer - rat 1	0	-0.12616788	-0.20338319	false
recall	oneLayer	oneLayer - rat 1	0	-0.11849435	-0.21105671	false
recall	oneLayer	oneLayer - rat 1	0	-0.114444174	-0.22083469	false
recall	oneLayer	oneLayer - rat 1	0	-0.10702171	-0.22825715	false
recall	oneLayer	oneLayer - rat 1	0	-0.10281984	-0.23840135	false
recall	oneLayer	oneLayer - rat 1	0	-0.09523614	-0.24598505	false
recall	oneLayer	oneLayer - rat 1	0	-0.09122782	-0.25566196	false
recall	oneLayer	oneLayer - rat 1	0	-0.083967164	-0.2629226	false
recall	oneLayer	oneLayer - rat 1	0	-0.073879726	-0.26710096	false
recall	oneLayer	oneLayer - rat 1	0	-0.0632407	-0.26710096	false
recall	oneLayer	oneLayer - rat 1	0	-0.053778384	-0.26318154	false
recall	oneLayer	oneLayer - rat 1	0	-0.046090387	-0.25549355	false
recall	oneLayer	oneLayer - rat 1	0	-0.042103823	-0.24586911	false
recall	oneLayer	oneLayer - rat 1	0	-0.0380109	-0.2359879	false
recall	oneLayer	oneLayer - rat 1	0	-0.034072064	-0.22647871	false
recall	oneLayer	oneLayer - rat 1	0	-0.02677303	-0.21917967	false
recall	oneLayer	oneLayer - rat 1	0	-0.022852253	-0.20971407	false
recall	oneLayer	oneLayer - rat 1	0	-0.019009953	-0.20043792	false
recall	oneLayer	oneLayer - rat 1	0	-0.019009957	-0.19028826	false
recall	oneLayer	oneLayer - rat 1	0	-0.01498238	-0.18056482	false
recall	oneLayer	oneLayer - rat 1	0	-0.011125978	-0.17125463	false
recall	oneLayer	oneLayer - rat 1	0	-0.011125982	-0.16079532	false
recall	oneLayer	oneLayer - rat 1	0	-0.006975025	-0.150774	false
recall	oneLayer	oneLayer - rat 1	0	-0.003085075	-0.14138283	false
recall	oneLayer	oneLayer - rat 1	0	-0.0030850791	-0.13122371	false
recall	oneLayer	oneLayer - rat 1	0	7.932007E-4	-0.1218607	false
recall	oneLayer	oneLayer - rat 1	0	0.0049225315	-0.1118916	false
recall	oneLayer	oneLayer - rat 1	0	0.0049225274	-0.10175347	false
recall	oneLayer	oneLayer - rat 1	0	0.009123289	-0.09161192	false
recall	oneLayer	oneLayer - rat 1	0	0.013319146	-0.08148222	false
recall	oneLayer	oneLayer - rat 1	0	0.01737436	-0.07169206	false
recall	oneLayer	oneLayer - rat 1	0	0.021550607	-0.06160969	false
recall	oneLayer	oneLayer - rat 1	0	0.021550603	-0.05146814	false
recall	oneLayer	oneLayer - rat 1	0	0.017684007	-0.04213336	false
recall	oneLayer	oneLayer - rat 1	0	0.017684001	-0.031174753	false
recall	oneLayer	oneLayer - rat 1	0	0.021698749	-0.021482289	false
recall	oneLayer	oneLayer - rat 1	0	0.021698743	-0.010593584	false
recall	oneLayer	oneLayer - rat 1	0	0.01779965	-0.0011803489	false
recall	oneLayer	oneLayer - rat 1	0	0.013773909	0.008538638	false
recall	oneLayer	oneLayer - rat 1	0	0.006535041	0.0157775	false
recall	oneLayer	oneLayer - rat 1	0	-0.0029166199	0.019692501	false
recall	oneLayer	oneLayer - rat 1	0	-0.013106394	0.019692497	false
recall	oneLayer	oneLayer - rat 1	0	-0.022864575	0.015650522	false
recall	oneLayer	oneLayer - rat 1	0	-0.032772366	0.0115465745	false
recall	oneLayer	oneLayer - rat 1	0	-0.04257008	0.0074882233	false
recall	oneLayer	oneLayer - rat 1	0	-0.052426256	0.0034056555	false
recall	oneLayer	oneLayer - rat 1	0	-0.061796367	-4.755751E-4	false
recall	oneLayer	oneLayer - rat 1	0	-0.071133286	-0.0043430584	false
recall	oneLayer	oneLayer - rat 1	0	-0.08065231	-0.008285974	false
recall	oneLayer	oneLayer - rat 1	0	-0.08993918	-0.012132723	false
recall	oneLayer	oneLayer - rat 1	0	-0.099684946	-0.01616956	false
recall	oneLayer	oneLayer - rat 1	0	-0.109432556	-0.020207155	false
recall	oneLayer	oneLayer - rat 1	0	-0.12006481	-0.020207161	false
recall	oneLayer	oneLayer - rat 1	0	-0.12954521	-0.016280256	false
recall	oneLayer	oneLayer - rat 1	0	-0.13970639	-0.01628026	false
recall	oneLayer	oneLayer - rat 1	0	-0.14951539	-0.012217243	false
recall	oneLayer	oneLayer - rat 1	0	-0.16005339	-0.012217248	false
recall	oneLayer	oneLayer - rat 1	0	-0.17016312	-0.008029664	false
recall	oneLayer	oneLayer - rat 1	0	-0.18074605	-0.008029669	false
recall	oneLayer	oneLayer - rat 1	0	-0.19056475	-0.0039626355	false
recall	oneLayer	oneLayer - rat 1	0	-0.19822954	0.003702147	false
recall	oneLayer	oneLayer - rat 1	0	-0.20788862	0.0077030673	false
recall	oneLayer	oneLayer - rat 1	0	-0.21802294	0.0077030626	false
recall	oneLayer	oneLayer - rat 1	0	-0.22739945	0.0038191786	false
recall	oneLayer	oneLayer - rat 1	0	-0.23698407	-1.5090524E-4	false
recall	oneLayer	oneLayer - rat 1	0	-0.24625729	-0.0039920015	false
recall	oneLayer	oneLayer - rat 1	0	-0.25623006	-0.008122862	false
recall	oneLayer	oneLayer - rat 1	0	-0.26559952	-0.0120038325	false
recall	oneLayer	oneLayer - rat 1	0	-0.27556825	-0.016133018	false
recall	oneLayer	oneLayer - rat 1	0	-0.2857092	-0.020333538	false
recall	oneLayer	oneLayer - rat 1	0	-0.29572937	-0.024484038	false
recall	oneLayer	oneLayer - rat 1	0	-0.30540535	-0.028491963	false
recall	oneLayer	oneLayer - rat 1	0	-0.31538472	-0.03262556	false
recall	oneLayer	oneLayer - rat 1	0	-0.32531935	-0.03674062	false
recall	oneLayer	oneLayer - rat 1	0	-0.3354208	-0.036740623	false
recall	oneLayer	oneLayer - rat 1	0	-0.34557268	-0.04094568	false
recall	oneLayer	oneLayer - rat 1	0	-0.35511363	-0.044897668	false
recall	oneLayer	oneLayer - rat 1	0	-0.3647063	-0.04887109	false
recall	oneLayer	oneLayer - rat 1	0	-0.3743847	-0.052880015	false
recall	oneLayer	oneLayer - rat 1	0	-0.384234	-0.05695974	false
recall	oneLayer	oneLayer - rat 1	0	-0.39434183	-0.056959745	false
recall	oneLayer	oneLayer - rat 1	0	-0.40394184	-0.060936198	false
recall	oneLayer	oneLayer - rat 1	0	-0.4115598	-0.06855418	false
recall	oneLayer	oneLayer - rat 1	0	-0.4155706	-0.07823709	false
recall	oneLayer	oneLayer - rat 1	0	-0.41958582	-0.08793075	false
recall	oneLayer	oneLayer - rat 1	0	-0.42379	-0.09808058	false
recall	oneLayer	oneLayer - rat 1	0	-0.42764947	-0.10739816	false
recall	oneLayer	oneLayer - rat 1	0	-0.42764947	-0.11797967	false
recall	oneLayer	oneLayer - rat 1	0	-0.42344463	-0.12813108	false
recall	oneLayer	oneLayer - rat 1	0	-0.41585997	-0.13571572	false
recall	oneLayer	oneLayer - rat 1	0	-0.4060612	-0.13977449	false
recall	oneLayer	oneLayer - rat 1	0	-0.3955866	-0.13977449	false
recall	oneLayer	oneLayer - rat 1	0	-0.3854727	-0.13558517	false
recall	oneLayer	oneLayer - rat 1	0	-0.37833682	-0.12844926	false
recall	oneLayer	oneLayer - rat 1	0	-0.3742291	-0.11853236	false
recall	oneLayer	oneLayer - rat 1	0	-0.36679244	-0.11109568	false
recall	oneLayer	oneLayer - rat 1	0	-0.36295897	-0.101840794	false
recall	oneLayer	oneLayer - rat 1	0	-0.36295897	-0.09165434	false
recall	oneLayer	oneLayer - rat 1	0	-0.35900417	-0.0821066	false
recall	oneLayer	oneLayer - rat 1	0	-0.35493276	-0.07227731	false
recall	oneLayer	oneLayer - rat 1	0	-0.35493276	-0.061762165	false
recall	oneLayer	oneLayer - rat 1	0	-0.35896105	-0.05203703	false
recall	oneLayer	oneLayer - rat 1	0	-0.3630585	-0.042144895	false
recall	oneLayer	oneLayer - rat 1	0	-0.36690867	-0.032849815	false
recall	oneLayer	oneLayer - rat 1	0	-0.3740839	-0.025674572	false
recall	oneLayer	oneLayer - rat 1	0	-0.384081	-0.021533642	false
recall	oneLayer	oneLayer - rat 1	0	-0.39495057	-0.02153365	false
recall	oneLayer	oneLayer - rat 1	0	-0.40445492	-0.017596837	false
recall	oneLayer	oneLayer - rat 1	0	-0.41170576	-0.010345987	false
recall	oneLayer	oneLayer - rat 1	0	-0.4157315	-6.270202E-4	false
recall	oneLayer	oneLayer - rat 1	0	-0.4157315	0.010090272	false
recall	oneLayer	oneLayer - rat 1	0	-0.4115884	0.020092608	false
recall	oneLayer	oneLayer - rat 1	0	-0.40415955	0.027521465	false
recall	oneLayer	oneLayer - rat 1	0	-0.39473477	0.031425346	false
recall	oneLayer	oneLayer - rat 1	0	-0.38421834	0.03142535	false
recall	oneLayer	oneLayer - rat 1	0	-0.37464494	0.027459921	false
recall	oneLayer	oneLayer - rat 1	0	-0.36691874	0.019733762	false
recall	oneLayer	oneLayer - rat 1	0	-0.362929	0.010101632	false
recall	oneLayer	oneLayer - rat 1	0	-0.362929	3.3148986E-5	false
recall	oneLayer	oneLayer - rat 1	0	-0.36711383	-0.010069936	false
recall	oneLayer	oneLayer - rat 1	0	-0.37418777	-0.017143885	false
recall	oneLayer	oneLayer - rat 1	0	-0.38393956	-0.02118322	false
recall	oneLayer	oneLayer - rat 1	0	-0.394651	-0.021183226	false
recall	oneLayer	oneLayer - rat 1	0	-0.4042253	-0.017217433	false
recall	oneLayer	oneLayer - rat 1	0	-0.4115268	-0.009915913	false
recall	oneLayer	oneLayer - rat 1	0	-0.41556683	-1.6242854E-4	false
recall	oneLayer	oneLayer - rat 1	0	-0.41556683	0.010297865	false
recall	oneLayer	oneLayer - rat 1	0	-0.41973847	0.020369045	false
recall	oneLayer	oneLayer - rat 1	0	-0.41973847	0.030713642	false
recall	oneLayer	oneLayer - rat 1	0	-0.42371434	0.0403122	false
recall	oneLayer	oneLayer - rat 1	0	-0.42371434	0.0510122	false
recall	oneLayer	oneLayer - rat 1	0	-0.4277021	0.060639504	false
recall	oneLayer	oneLayer - rat 1	0	-0.43173498	0.07037572	false
recall	oneLayer	oneLayer - rat 1	0	-0.4356771	0.07989287	false
recall	oneLayer	oneLayer - rat 1	0	-0.4356771	0.09023657	false
recall	oneLayer	oneLayer - rat 1	0	-0.4316983	0.09984228	false
recall	oneLayer	oneLayer - rat 1	0	-0.42759815	0.10974092	false
recall	oneLayer	oneLayer - rat 1	0	-0.4235615	0.11948621	false
recall	oneLayer	oneLayer - rat 1	0	-0.41970488	0.12879695	false
recall	oneLayer	oneLayer - rat 1	0	-0.4157978	0.13822952	false
recall	oneLayer	oneLayer - rat 1	0	-0.40830112	0.14572622	false
recall	oneLayer	oneLayer - rat 1	0	-0.40440404	0.15513456	false
recall	oneLayer	oneLayer - rat 1	0	-0.40054366	0.16445436	false
recall	oneLayer	oneLayer - rat 1	0	-0.39324138	0.17175664	false
recall	oneLayer	oneLayer - rat 1	0	-0.38612166	0.17887639	false
recall	oneLayer	oneLayer - rat 1	0	-0.38210082	0.18858351	false
recall	oneLayer	oneLayer - rat 1	0	-0.37467483	0.19600952	false
recall	oneLayer	oneLayer - rat 1	0	-0.3672106	0.20347376	false
recall	oneLayer	oneLayer - rat 1	0	-0.35997996	0.2107044	false
recall	oneLayer	oneLayer - rat 1	0	-0.35609812	0.220076	false
recall	oneLayer	oneLayer - rat 1	0	-0.3488461	0.22732802	false
recall	oneLayer	oneLayer - rat 1	0	-0.34147388	0.23470023	false
recall	oneLayer	oneLayer - rat 1	0	-0.33428466	0.24188946	false
recall	oneLayer	oneLayer - rat 1	0	-0.33020434	0.25174025	false
recall	oneLayer	oneLayer - rat 1	0	-0.32294244	0.25900215	false
recall	oneLayer	oneLayer - rat 1	0	-0.31328452	0.2630026	false
recall	oneLayer	oneLayer - rat 1	0	-0.3061141	0.27017298	false
recall	oneLayer	oneLayer - rat 1	0	-0.29596627	0.27437636	false
recall	oneLayer	oneLayer - rat 1	0	-0.28503507	0.27437636	false
recall	oneLayer	oneLayer - rat 1	0	-0.2755103	0.2704311	false
recall	oneLayer	oneLayer - rat 1	0	-0.2682288	0.2631496	false
recall	oneLayer	oneLayer - rat 1	0	-0.26423645	0.25351122	false
recall	oneLayer	oneLayer - rat 1	0	-0.26423645	0.24279206	false
recall	oneLayer	oneLayer - rat 1	0	-0.2682406	0.23312521	false
recall	oneLayer	oneLayer - rat 1	0	-0.27554366	0.22582214	false
recall	oneLayer	oneLayer - rat 1	0	-0.28486365	0.22196166	false
recall	oneLayer	oneLayer - rat 1	0	-0.2954981	0.22196166	false
recall	oneLayer	oneLayer - rat 1	0	-0.3053967	0.22606179	false
recall	oneLayer	oneLayer - rat 1	0	-0.31269917	0.23336425	false
recall	oneLayer	oneLayer - rat 1	0	-0.320153	0.2408181	false
recall	oneLayer	oneLayer - rat 1	0	-0.3278847	0.24854979	false
recall	oneLayer	oneLayer - rat 1	0	-0.33723485	0.25242275	false
recall	oneLayer	oneLayer - rat 1	0	-0.34804988	0.25242275	false
recall	oneLayer	oneLayer - rat 1	0	-0.3577745	0.24839468	false
recall	oneLayer	oneLayer - rat 1	0	-0.36491898	0.24125017	false
recall	oneLayer	oneLayer - rat 1	0	-0.36909765	0.23116195	false
recall	oneLayer	oneLayer - rat 1	0	-0.37639347	0.22386615	false
recall	oneLayer	oneLayer - rat 1	0	-0.38022044	0.21462698	false
recall	oneLayer	oneLayer - rat 1	0	-0.38761437	0.20723306	false
recall	oneLayer	oneLayer - rat 1	0	-0.3915209	0.19780189	false
recall	oneLayer	oneLayer - rat 1	0	-0.39902255	0.19030023	false
recall	oneLayer	oneLayer - rat 1	0	-0.40301564	0.18066004	false
recall	oneLayer	oneLayer - rat 1	0	-0.41035038	0.1733253	false
recall	oneLayer	oneLayer - rat 1	0	-0.41420966	0.16400819	false
recall	oneLayer	oneLayer - rat 1	0	-0.4219321	0.15628572	false
recall	oneLayer	oneLayer - rat 1	0	-0.42593083	0.14663194	false
recall	oneLayer	oneLayer - rat 1	0	-0.42593083	0.13657516	false
recall	oneLayer	oneLayer - rat 1	0	-0.43011838	0.12646547	false
recall	oneLayer	oneLayer - rat 1	0	-0.43011838	0.115865655	false
recall	oneLayer	oneLayer - rat 1	0	-0.4342291	0.10594149	false
recall	oneLayer	oneLayer - rat 1	0	-0.4342291	0.095603205	false
recall	oneLayer	oneLayer - rat 1	0	-0.43821836	0.08597233	false
recall	oneLayer	oneLayer - rat 1	0	-0.43821836	0.07544114	false
recall	oneLayer	oneLayer - rat 1	0	-0.44211215	0.06604065	false
recall	oneLayer	oneLayer - rat 1	0	-0.44211215	0.056008782	false
recall	oneLayer	oneLayer - rat 1	0	-0.4463039	0.045888945	false
recall	oneLayer	oneLayer - rat 1	0	-0.4463039	0.03563376	false
recall	oneLayer	oneLayer - rat 1	0	-0.45027742	0.026040846	false
recall	oneLayer	oneLayer - rat 1	0	-0.45027742	0.015227295	false
recall	oneLayer	oneLayer - rat 1	0	-0.45421818	0.005713477	false
recall	oneLayer	oneLayer - rat 1	0	-0.45421818	-0.0045694616	false
recall	oneLayer	oneLayer - rat 1	0	-0.45022833	-0.014201754	false
recall	oneLayer	oneLayer - rat 1	0	-0.45022833	-0.024910325	false
recall	oneLayer	oneLayer - rat 1	0	-0.4463778	-0.034206323	false
recall	oneLayer	oneLayer - rat 1	0	-0.4463778	-0.044711005	false
recall	oneLayer	oneLayer - rat 1	0	-0.44227782	-0.05460921	false
recall	oneLayer	oneLayer - rat 1	0	-0.44227782	-0.065088585	false
recall	oneLayer	oneLayer - rat 1	0	-0.43809098	-0.07519652	false
recall	oneLayer	oneLayer - rat 1	0	-0.43809098	-0.08556953	false
recall	oneLayer	oneLayer - rat 1	0	-0.43422914	-0.094892815	false
recall	oneLayer	oneLayer - rat 1	0	-0.43422914	-0.10589236	false
recall	oneLayer	oneLayer - rat 1	0	-0.43026403	-0.11546495	false
recall	oneLayer	oneLayer - rat 1	0	-0.43026403	-0.1261768	false
recall	oneLayer	oneLayer - rat 1	0	-0.42628422	-0.13578486	false
recall	oneLayer	oneLayer - rat 1	0	-0.42628422	-0.14619274	false
recall	oneLayer	oneLayer - rat 1	0	-0.42237195	-0.15563782	false
recall	oneLayer	oneLayer - rat 1	0	-0.42237195	-0.16607031	false
recall	oneLayer	oneLayer - rat 1	0	-0.4185171	-0.1753767	false
recall	oneLayer	oneLayer - rat 1	0	-0.41074914	-0.18314469	false
recall	oneLayer	oneLayer - rat 1	0	-0.4065783	-0.19321397	false
recall	oneLayer	oneLayer - rat 1	0	-0.3989076	-0.20088466	false
recall	oneLayer	oneLayer - rat 1	0	-0.39496425	-0.21040471	false
recall	oneLayer	oneLayer - rat 1	0	-0.38722244	-0.21814652	false
recall	oneLayer	oneLayer - rat 1	0	-0.3833755	-0.22743388	false
recall	oneLayer	oneLayer - rat 1	0	-0.37590495	-0.23490441	false
recall	oneLayer	oneLayer - rat 1	0	-0.37191185	-0.24454458	false
recall	oneLayer	oneLayer - rat 1	0	-0.36450174	-0.25195467	false
recall	oneLayer	oneLayer - rat 1	0	-0.36052617	-0.26155257	false
recall	oneLayer	oneLayer - rat 1	0	-0.3533941	-0.26868466	false
recall	oneLayer	oneLayer - rat 1	0	-0.34949666	-0.27809384	false
recall	oneLayer	oneLayer - rat 1	0	-0.34209794	-0.28549257	false
recall	oneLayer	oneLayer - rat 1	0	-0.33808517	-0.2951802	false
recall	oneLayer	oneLayer - rat 1	0	-0.3306572	-0.30260816	false
recall	oneLayer	oneLayer - rat 1	0	-0.32656708	-0.31248263	false
recall	oneLayer	oneLayer - rat 1	0	-0.31885746	-0.32019222	false
recall	oneLayer	oneLayer - rat 1	0	-0.3147609	-0.33008224	false
recall	oneLayer	oneLayer - rat 1	0	-0.30767202	-0.3371711	false
recall	oneLayer	oneLayer - rat 1	0	-0.29794073	-0.34120193	false
recall	oneLayer	oneLayer - rat 1	0	-0.2873757	-0.34120193	false
recall	oneLayer	oneLayer - rat 1	0	-0.27807027	-0.3373475	false
recall	oneLayer	oneLayer - rat 1	0	-0.27068955	-0.32996678	false
recall	oneLayer	oneLayer - rat 1	0	-0.26658693	-0.3200622	false
recall	oneLayer	oneLayer - rat 1	0	-0.26658693	-0.30933586	false
recall	oneLayer	oneLayer - rat 1	0	-0.2707258	-0.29934376	false
recall	oneLayer	oneLayer - rat 1	0	-0.27072582	-0.2885001	false
recall	oneLayer	oneLayer - rat 1	0	-0.2746256	-0.27908516	false
recall	oneLayer	oneLayer - rat 1	0	-0.2746256	-0.26894763	false
recall	oneLayer	oneLayer - rat 1	0	-0.27863285	-0.2592733	false
recall	oneLayer	oneLayer - rat 1	0	-0.27863285	-0.249223	false
recall	oneLayer	oneLayer - rat 1	0	-0.2828252	-0.23910178	false
recall	oneLayer	oneLayer - rat 1	0	-0.2828252	-0.22825634	false
recall	oneLayer	oneLayer - rat 1	0	-0.2828252	-0.2175952	false
recall	oneLayer	oneLayer - rat 1	0	-0.2867888	-0.20802626	false
recall	oneLayer	oneLayer - rat 1	0	-0.2867888	-0.19779083	false
recall	oneLayer	oneLayer - rat 1	0	-0.2867888	-0.18700917	false
recall	oneLayer	oneLayer - rat 1	0	-0.28678882	-0.17661603	false
recall	oneLayer	oneLayer - rat 1	0	-0.2909557	-0.16655627	false
recall	oneLayer	oneLayer - rat 1	0	-0.29483834	-0.15718278	false
recall	oneLayer	oneLayer - rat 1	0	-0.29888737	-0.14740756	false
recall	oneLayer	oneLayer - rat 1	0	-0.3030856	-0.13727212	false
recall	oneLayer	oneLayer - rat 1	0	-0.3072441	-0.12723269	false
recall	oneLayer	oneLayer - rat 1	0	-0.3072441	-0.11652202	false
recall	oneLayer	oneLayer - rat 1	0	-0.3072441	-0.10632844	false
recall	oneLayer	oneLayer - rat 1	0	-0.31120086	-0.09677599	false
recall	oneLayer	oneLayer - rat 1	0	-0.31512186	-0.08730982	false
recall	oneLayer	oneLayer - rat 1	0	-0.319214	-0.07743059	false
recall	oneLayer	oneLayer - rat 1	0	-0.32314315	-0.06794471	false
recall	oneLayer	oneLayer - rat 1	0	-0.32698712	-0.058664616	false
recall	oneLayer	oneLayer - rat 1	0	-0.33104298	-0.048872914	false
recall	oneLayer	oneLayer - rat 1	0	-0.3351495	-0.03895889	false
recall	oneLayer	oneLayer - rat 1	0	-0.3393138	-0.028905405	false
recall	oneLayer	oneLayer - rat 1	0	-0.34318665	-0.019555504	false
recall	oneLayer	oneLayer - rat 1	0	-0.34710795	-0.010088695	false
recall	oneLayer	oneLayer - rat 1	0	-0.35107636	-5.0807913E-4	false
recall	oneLayer	oneLayer - rat 1	0	-0.35835066	0.0067662145	false
recall	oneLayer	oneLayer - rat 1	0	-0.36578697	0.014202519	false
recall	oneLayer	oneLayer - rat 1	0	-0.37341845	0.021833975	false
recall	oneLayer	oneLayer - rat 1	0	-0.38334414	0.025945332	false
recall	oneLayer	oneLayer - rat 1	0	-0.39051238	0.033113558	false
recall	oneLayer	oneLayer - rat 1	0	-0.39827216	0.040873323	false
recall	oneLayer	oneLayer - rat 1	0	-0.40774167	0.04479572	false
recall	oneLayer	oneLayer - rat 1	0	-0.41492477	0.051978827	false
recall	oneLayer	oneLayer - rat 1	0	-0.41884506	0.061443165	false
recall	oneLayer	oneLayer - rat 1	0	-0.4229108	0.07125879	false
recall	oneLayer	oneLayer - rat 1	0	-0.42675	0.08052742	false
recall	oneLayer	oneLayer - rat 1	0	-0.43079782	0.090299696	false
recall	oneLayer	oneLayer - rat 1	0	-0.43079782	0.10095145	false
recall	oneLayer	oneLayer - rat 1	0	-0.42664793	0.11097016	false
recall	oneLayer	oneLayer - rat 1	0	-0.4224968	0.12099192	false
recall	oneLayer	oneLayer - rat 1	0	-0.4184995	0.13064228	false
recall	oneLayer	oneLayer - rat 1	0	-0.4184995	0.14123401	false
recall	oneLayer	oneLayer - rat 1	0	-0.41441166	0.15110289	false
recall	oneLayer	oneLayer - rat 1	0	-0.41044238	0.1606856	false
recall	oneLayer	oneLayer - rat 1	0	-0.41044238	0.17167492	false
recall	oneLayer	oneLayer - rat 1	0	-0.40644458	0.18132652	false
recall	oneLayer	oneLayer - rat 1	0	-0.4026131	0.19057657	false
recall	oneLayer	oneLayer - rat 1	0	-0.4026131	0.20060748	false
recall	oneLayer	oneLayer - rat 1	0	-0.3985163	0.21049805	false
recall	oneLayer	oneLayer - rat 1	0	-0.39435464	0.22054519	false
recall	oneLayer	oneLayer - rat 1	0	-0.39044937	0.2299733	false
recall	oneLayer	oneLayer - rat 1	0	-0.38627824	0.24004333	false
recall	oneLayer	oneLayer - rat 1	0	-0.38209507	0.25014243	false
recall	oneLayer	oneLayer - rat 1	0	-0.37804624	0.2599172	false
recall	oneLayer	oneLayer - rat 1	0	-0.37406132	0.26953766	false
recall	oneLayer	oneLayer - rat 1	0	-0.37019297	0.27887663	false
recall	oneLayer	oneLayer - rat 1	0	-0.36625814	0.28837618	false
recall	oneLayer	oneLayer - rat 1	0	-0.35863537	0.29599896	false
