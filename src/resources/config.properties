Rat.PIXELES_RUIDO=100
# Cantidad de pixeles que puede medir una marca en el laberinto 3400
Rat.MIN_PIXEL_MARCA=200
Rat.MAX_PIXEL_MARCA=1500

# Angulo de giro de la cabeza de la rata para armar la panoramica en las ratas la panorámica es de 320.
Robot.ANGLE_HEAD_TURN=45
# Conteo de pixeles para determinar los affordances 510 y 965 para MazeWallSinAff.xml
# Conteo de pixeles para determinar los affordances 1200 y 2000 para 2008-01
# si conteoRojo < MAX_PIXEL agrego affordance
RobotVirtual.MAX_PIXEL_LATERAL=4000
RobotVirtual.MAX_PIXEL_DIAGONAL=2000
# Este debe ser alto para asegurar que no avanzo fuera de las paredes
RobotVirtual.MAX_PIXEL_FRENTE=1500
RobotVirtual.Step = 0.01

VirtualUniverse.closeToFood = 0.05

UniverseFrame.display=true

Simulation.DIRECTORY=simulaciones
Log.DIRECTORY=logs/

Experiment.MAZE_FILE=/edu/usf/ratsim/experiment/mazes/morrisCircular.xml

#Reflexion.Robot=robot.GlobalPositionActionRobot
Reflexion.Robot=edu.usf.ratsim.robot.virtual.VirtualRobot
#Reflexion.Robot=robot.SpatialCognitionInterfaceOpenCV
#Reflexion.Robot=robot.RobotKhepera

# Universe where the experiments take place (Virtual, USFLab, UdelaRLab...)
Reflexion.Universe=edu.usf.ratsim.robot.virtual.VirtualExpUniverse

# Parameters controlling the artificial place cell layer
ArtificialPlaceCells.numLayers = 1
ArtificialPlaceCells.minRadius = .01
ArtificialPlaceCells.maxRadius = .01
ArtificialPlaceCells.minX = -.5
ArtificialPlaceCells.maxX = .5
ArtificialPlaceCells.minY = -.5
ArtificialPlaceCells.maxY =.5
ArtificialPlaceCells.dumpPointsStep = .04

# Q learning constants
QLearning.foodReward = 100
# Penalize non food reward
QLearning.nonFoodReward = -.001
# Deterministic configurations
QLearning.discountFactor = .95
QLearning.learningRate = .6